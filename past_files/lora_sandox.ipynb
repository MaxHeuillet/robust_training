{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import torch.nn.utils.parametrize as parametrize\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "import lora\n",
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return sample, label\n",
    "\n",
    "def add_lora(model):\n",
    "\n",
    "    # the list layers contains all the elements of the neural architecture on which you want to add lora matrices\n",
    "    layers = [ model.conv1, model.layer1[0].conv1, model.layer1[0].conv2, model.layer1[0].conv3,\n",
    "                model.layer2[0].conv1, model.layer2[0].conv2, model.layer2[0].conv3,\n",
    "                model.layer3[0].conv1, model.layer3[0].conv2, model.layer3[0].conv3,\n",
    "                model.layer4[0].conv1, model.layer4[0].conv2, model.layer4[0].conv3, model.fc ]\n",
    "\n",
    "    for conv_layer in layers:\n",
    "        lora_param = lora.layer_parametrization(conv_layer, device=\"cuda\", rank=10, lora_alpha=1)\n",
    "        parametrize.register_parametrization(conv_layer, 'weight', lora_param)\n",
    "\n",
    "    lora.set_lora_gradients(model, layers)\n",
    "\n",
    "model = resnet50().to('cuda')\n",
    "add_lora(model)\n",
    "\n",
    "size = 32\n",
    "data = [torch.rand(3, size, size) for _ in range(100)]\n",
    "labels = torch.randint(0, 10, (100,))\n",
    "dataset = CustomDataset(data, labels)\n",
    "loader = DataLoader(dataset, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9553,  0.1934, -0.4419,  0.6612,  1.2280, -0.7828,  0.0132, -0.4347,\n",
      "        -2.3182,  1.0015,  0.9982, -1.7255, -1.5165, -0.9702, -1.0734, -0.5069,\n",
      "         0.0177, -0.5905,  0.4840,  0.1061, -0.6364,  0.0383, -0.3670, -0.9739,\n",
      "         1.0738, -0.9023,  1.0535,  0.7725, -0.9731, -2.2512, -0.0550, -2.2016,\n",
      "        -0.1342,  0.7784, -0.1760, -0.0151,  0.4480, -1.7760,  1.8451,  1.7483,\n",
      "         0.6928,  1.0304, -0.8913,  1.0149, -1.5610, -1.0897, -1.3492,  0.4384,\n",
      "         0.1059, -0.2361,  1.3165,  0.2678,  1.6965,  1.3362, -0.3240, -1.3411,\n",
      "        -0.4276, -0.5909, -0.0803, -0.4822, -2.9535,  0.2598, -0.8454, -1.0809],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.parametrizations.weight[0].mat_A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.parametrizations.weight[0].mat_B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0002,  0.0204,  0.0120, -0.0117,  0.0048,  0.0408,  0.0248],\n",
      "        [-0.0418, -0.0147, -0.0225,  0.0543, -0.0298,  0.0335,  0.0003],\n",
      "        [-0.0220, -0.0219,  0.0298, -0.0174,  0.0036,  0.0399, -0.0435],\n",
      "        [-0.0197, -0.0251,  0.0499, -0.0140, -0.0510, -0.0500,  0.0119],\n",
      "        [-0.0058, -0.0120,  0.0267,  0.0366, -0.0328,  0.0133, -0.0200],\n",
      "        [ 0.0522,  0.0435, -0.0193,  0.0181,  0.0252,  0.0232,  0.0311],\n",
      "        [ 0.0139,  0.0073, -0.0141, -0.0039,  0.0301, -0.0426,  0.0161]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.parametrizations.weight.original[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss tensor(7.4598, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "loss tensor(6.9148, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "loss tensor(6.9586, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
      "loss tensor(7.0233, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "for data, target in loader:\n",
    "\n",
    "    data, target = data.to('cuda'), target.to('cuda')\n",
    "    optimizer.zero_grad()\n",
    "    logits = model(data)\n",
    "    loss = criterion(logits,target)\n",
    "    print('loss', loss)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1.9575,  0.1928, -0.4407,  0.6611,  1.2258, -0.7848,  0.0152, -0.4324,\n",
      "        -2.3184,  1.0024,  0.9970, -1.7276, -1.5179, -0.9680, -1.0733, -0.5053,\n",
      "         0.0181, -0.5896,  0.4828,  0.1066, -0.6343,  0.0386, -0.3664, -0.9748,\n",
      "         1.0746, -0.9033,  1.0556,  0.7733, -0.9709, -2.2500, -0.0554, -2.2023,\n",
      "        -0.1340,  0.7774, -0.1766, -0.0161,  0.4462, -1.7782,  1.8442,  1.7463,\n",
      "         0.6906,  1.0282, -0.8912,  1.0148, -1.5610, -1.0916, -1.3502,  0.4384,\n",
      "         0.1075, -0.2373,  1.3168,  0.2664,  1.6963,  1.3352, -0.3247, -1.3422,\n",
      "        -0.4286, -0.5899, -0.0792, -0.4842, -2.9525,  0.2606, -0.8432, -1.0796],\n",
      "       device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.parametrizations.weight[0].mat_A[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0030,  0.0023,  0.0011,  0.0021, -0.0024,  0.0011,  0.0032,  0.0028,\n",
      "        -0.0031,  0.0034], device='cuda:0', grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.parametrizations.weight[0].mat_B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0002,  0.0204,  0.0120, -0.0117,  0.0048,  0.0408,  0.0248],\n",
      "        [-0.0418, -0.0147, -0.0225,  0.0543, -0.0298,  0.0335,  0.0003],\n",
      "        [-0.0220, -0.0219,  0.0298, -0.0174,  0.0036,  0.0399, -0.0435],\n",
      "        [-0.0197, -0.0251,  0.0499, -0.0140, -0.0510, -0.0500,  0.0119],\n",
      "        [-0.0058, -0.0120,  0.0267,  0.0366, -0.0328,  0.0133, -0.0200],\n",
      "        [ 0.0522,  0.0435, -0.0193,  0.0181,  0.0252,  0.0232,  0.0311],\n",
      "        [ 0.0139,  0.0073, -0.0141, -0.0039,  0.0301, -0.0426,  0.0161]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(model.conv1.parametrizations.weight.original[0][0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
