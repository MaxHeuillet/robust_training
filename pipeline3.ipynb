{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoImageProcessor, ResNetModel\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"frgfm/imagenette\", 'full_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x281 at 0x7F07BA15E2B0>\n"
     ]
    }
   ],
   "source": [
    "print(dataset['train'][0]['image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initialize image processor\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "\n",
    "print('initialize image processor')\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"./resnet-50\", local_files_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 224, 224)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor( dataset['train'][0]['image'] )['pixel_values'][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataset\n",
      "initialize image processor\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.distributed as dist\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "from torchvision.models import resnet50\n",
    "from torchvision.datasets import ImageNet\n",
    "from torchvision import transforms\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from transformers import AutoImageProcessor, ResNetModel\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "\n",
    "import os\n",
    "import io\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoImageProcessor\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, hf_dataset, transform=None):\n",
    "        self.hf_dataset = hf_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.hf_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the image and label from the Hugging Face dataset\n",
    "        item = self.hf_dataset[idx]\n",
    "        image = item['image']\n",
    "        # print(image.shape)\n",
    "        # Check if the image needs to be opened from a bytes-like object\n",
    "        # if not isinstance(image, Image.Image):\n",
    "        #     image = Image.open(io.BytesIO(image)).convert(\"RGB\")\n",
    "\n",
    "        # print(image.shape)\n",
    "        # Apply the transformation\n",
    "        # if self.transform:\n",
    "        image = self.transform(images=image)['pixel_values'][0]\n",
    "\n",
    "        # Labels can be handled here if needed\n",
    "        label = item.get('label', torch.tensor(-1))  # Dummy label handling\n",
    "\n",
    "        return image, label\n",
    "\n",
    "print('load dataset')\n",
    "# dataset = load_dataset(\"imagenet-1k\", cache_dir='/home/mheuill/scratch')\n",
    "test_dataset = dataset['train']  # Select the test split\n",
    "\n",
    "print('initialize image processor')\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"./resnet-50\", local_files_only=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "create custom dataset\n"
     ]
    }
   ],
   "source": [
    "print('create custom dataset')\n",
    "custom_dataset = CustomImageDataset(test_dataset, transform=image_processor)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load dataloader\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print('load dataloader')\n",
    "dataloader = DataLoader(custom_dataset, batch_size=1024,  num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./resnet-50/preprocessor_config.json']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dataset = load_dataset(\"imagenet-1k\")\n",
    "# image = dataset[\"test\"][\"image\"][0]\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "image_processor.save_pretrained(\"./resnet-50\")\n",
    "# inputs = image_processor(image, return_tensors=\"pt\")\n",
    "\n",
    "# model = ResNetModel.from_pretrained(\"microsoft/resnet-50\")\n",
    "\n",
    "\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     outputs = model(**inputs)\n",
    "\n",
    "# last_hidden_states = outputs.last_hidden_state\n",
    "# list(last_hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNextImageProcessor {\n",
       "  \"_valid_processor_keys\": [\n",
       "    \"images\",\n",
       "    \"do_resize\",\n",
       "    \"size\",\n",
       "    \"crop_pct\",\n",
       "    \"resample\",\n",
       "    \"do_rescale\",\n",
       "    \"rescale_factor\",\n",
       "    \"do_normalize\",\n",
       "    \"image_mean\",\n",
       "    \"image_std\",\n",
       "    \"return_tensors\",\n",
       "    \"data_format\",\n",
       "    \"input_data_format\"\n",
       "  ],\n",
       "  \"crop_pct\": 0.875,\n",
       "  \"do_normalize\": true,\n",
       "  \"do_rescale\": true,\n",
       "  \"do_resize\": true,\n",
       "  \"image_mean\": [\n",
       "    0.485,\n",
       "    0.456,\n",
       "    0.406\n",
       "  ],\n",
       "  \"image_processor_type\": \"ConvNextImageProcessor\",\n",
       "  \"image_std\": [\n",
       "    0.229,\n",
       "    0.224,\n",
       "    0.225\n",
       "  ],\n",
       "  \"resample\": 3,\n",
       "  \"rescale_factor\": 0.00392156862745098,\n",
       "  \"size\": {\n",
       "    \"shortest_edge\": 224\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs['pixel_values'].shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
