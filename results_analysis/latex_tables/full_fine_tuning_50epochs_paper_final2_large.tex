\begin{table}[ht]
\centering
\caption{Tier 1 fine-tuning configurations among large architectures}
\label{tab:full_fine_tuning_50epochs_paper_final2_large}
\resizebox{\textwidth}{!}{%
\begin{tabular}{|c|c|c|c|c|c|c|c|c|c|}
\hline
                                          backbone &        loss &      pre\_training\_strategy &         model\_type &  total\ Borda\ rank &  total\ geom\ rank &  total\ cumulative\ rank &  total\ Borda\ value &  total\ geom\ value &  total\ cumulative\ value \\
\hline
\hline
   vit\_base\_patch16\_clip\_224.laion2b\_ft\_in1k &  TRADES\_v2 & self-supervised (multimodal) &     fully attention &                 9.0 &                1.0 &                      1.0 &               0.6422 &             15.2407 &                     516.0 \\
\hline
 CLIP-convnext\_base\_w-laion\_aesthetic-s13B-b82K &  TRADES\_v2 & self-supervised (multimodal) & fully convolutional &                 1.0 &               25.0 &                      2.0 &               0.2062 &             13.9746 &                     644.0 \\
\hline
swin\_base\_patch4\_window7\_224.ms\_in22k\_ft\... &  TRADES\_v2 &                   supervised &     fully attention &                 3.0 &                2.0 &                      3.0 &               0.5768 &             13.7652 &                     615.0 \\
\hline
              eva02\_base\_patch14\_224.mim\_in22k &  TRADES\_v2 &              self-supervised &     fully attention &                 2.0 &               27.0 &                      4.0 &               0.1485 &             13.2365 &                     619.0 \\
\hline
             vit\_base\_patch16\_clip\_224.laion2b &  TRADES\_v2 & self-supervised (multimodal) &     fully attention &                14.0 &               14.0 &                      5.0 &               0.4280 &             12.8314 &                     473.0 \\
\hline
swin\_base\_patch4\_window7\_224.ms\_in22k\_ft\... & CLASSIC\_AT &                   supervised &     fully attention &                 8.0 &                4.0 &                      6.0 &               0.5339 &             12.5444 &                     533.0 \\
\hline
              vit\_base\_patch16\_224.augreg\_in1k &  TRADES\_v2 &                   supervised &     fully attention &                18.0 &                6.0 &                      7.0 &               0.5264 &             12.4978 &                     392.0 \\
\hline
                            robust\_convnext\_base &  TRADES\_v2 &          supervised (robust) & fully convolutional &                 5.0 &               11.0 &                      8.0 &               0.4413 &             12.2393 &                     612.0 \\
\hline
          CLIP-convnext\_base\_w-laion2B-s13B-b82K &  TRADES\_v2 & self-supervised (multimodal) & fully convolutional &                 6.0 &               10.0 &                      9.0 &               0.4689 &             11.9503 &                     576.0 \\
\hline
                          convnext\_base.fb\_in22k &  TRADES\_v2 &                   supervised & fully convolutional &                 4.0 &                3.0 &                     10.0 &               0.5469 &             11.5743 &                     614.0 \\
\hline
              vit\_base\_patch16\_224.augreg\_in1k & CLASSIC\_AT &                   supervised &     fully attention &                23.0 &                5.0 &                     11.0 &               0.5309 &             11.3069 &                     320.0 \\
\hline
          CLIP-convnext\_base\_w-laion2B-s13B-b82K & CLASSIC\_AT & self-supervised (multimodal) & fully convolutional &                11.0 &               17.0 &                     12.0 &               0.3960 &             11.3032 &                     494.0 \\
\hline
\hline
\hline
\end{tabular}
}
\end{table}