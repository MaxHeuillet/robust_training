{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_stanford_cars_TRADES_v2.pkl\n",
      "HEY\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_caltech101_TRADES_v2.pkl\n",
      "HEY\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "HEY\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_flowers-102_TRADES_v2.pkl\n",
      "HEY\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "HEY\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_caltech101_CLASSIC_AT.pkl\n",
      "HEY\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n"
     ]
    }
   ],
   "source": [
    "from load_results import load_result_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pn1 = 'full_fine_tuning_50epochs_edge_paper_final2'\n",
    "pn2 = 'full_fine_tuning_50epochs_paper_final2'\n",
    "\n",
    "final_data = load_result_dataset(pn1, pn2)\n",
    "final_data = [{**d, 'ft_strategy': 'FFT (50 epochs)'} for d in final_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values, for small architecture: 1.1904761904761905\n",
      "Percentage of NaN values, for medium architecture: 0.0\n",
      "Percentage of NaN values, for large architecture: 0.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values, for small architecture: 1.1904761904761905\n",
      "Percentage of NaN values, for medium architecture: 0.0\n",
      "Percentage of NaN values, for large architecture: 0.0\n",
      "{'clean_acc': nan, 'Linf_acc': nan, 'L1_acc': 0.34, 'L2_acc': 0.454, 'common_acc': 0.48} dict_values([nan, nan, 0.34, 0.454, 0.48]) True\n",
      "{'clean_acc': 0.912, 'Linf_acc': 0.763, 'L1_acc': nan, 'L2_acc': nan, 'common_acc': nan} dict_values([0.912, 0.763, nan, nan, nan]) True\n",
      "{'clean_acc': nan, 'Linf_acc': nan, 'L1_acc': 0.038, 'L2_acc': 0.08, 'common_acc': 0.159} dict_values([nan, nan, 0.038, 0.08, 0.159]) True\n",
      "{'clean_acc': nan, 'Linf_acc': nan, 'L1_acc': 0.764, 'L2_acc': 0.811, 'common_acc': 0.801} dict_values([nan, nan, 0.764, 0.811, 0.801]) True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "df = pd.DataFrame(final_data)\n",
    "for arch_size in ('small', 'medium', 'large'):\n",
    "    df_curr = df[ df.model_size == arch_size ]\n",
    "    nan_percentage = (df_curr.isna().sum().sum() / df_curr.size) * 100\n",
    "    print(\"Percentage of NaN values, for {} architecture: {}\".format(arch_size, nan_percentage) )\n",
    "\n",
    "df = pd.DataFrame(final_data)\n",
    "\n",
    "def get_restart_job(row):\n",
    "\n",
    "    if row.isna().any():\n",
    "\n",
    "        missing = {col: row[col] for col in ['clean_acc', 'Linf_acc', 'L1_acc', 'L2_acc', 'common_acc']}\n",
    "        print(missing, missing.values(), all( list(missing.values()) ))\n",
    "\n",
    "        if all(missing.values()):\n",
    "            return \"job1_hpo.sh\"\n",
    "        elif not missing['clean_acc'] and not missing['Linf_acc'] and missing['L1_acc']:\n",
    "            return \"job4_test_l1.sh\"\n",
    "        elif not missing['clean_acc'] and not missing['Linf_acc'] and not missing['L1_acc'] and missing['L2_acc']:\n",
    "            return \"job5_test_l2.sh\"\n",
    "        elif not missing['clean_acc'] and not missing['Linf_acc'] and not missing['L1_acc'] and not missing['L2_acc'] and missing['common_acc']:\n",
    "            return \"job6_test_common.sh\"\n",
    "    else:\n",
    "        return None  # means no job needs to be restarted\n",
    "\n",
    "df['restart_from'] = df.apply(get_restart_job, axis=1)\n",
    "to_restart = df[df['restart_from'].notna()][['backbone', 'dataset', 'loss_function', 'restart_from', 'model_size']]\n",
    "to_restart\n",
    "to_restart.to_csv(\"./restart_max.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values: 0.21%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"8\" halign=\"left\">TOTAL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">caltech101</th>\n",
       "      <th>...</th>\n",
       "      <th>stanford_cars</th>\n",
       "      <th colspan=\"9\" halign=\"left\">uc-merced-land-use-dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>borda</th>\n",
       "      <th>nan_geom_cnt</th>\n",
       "      <th>nan_sum_cnt</th>\n",
       "      <th>rank_borda</th>\n",
       "      <th>rank_geom</th>\n",
       "      <th>rank_sum</th>\n",
       "      <th>score_geom</th>\n",
       "      <th>score_sum</th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_pre_training_data</th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>Linf_acc</th>\n",
       "      <th>borda</th>\n",
       "      <th>clean_acc</th>\n",
       "      <th>common_acc</th>\n",
       "      <th>geom</th>\n",
       "      <th>sum</th>\n",
       "      <th>volume_pre_training_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <th>backbone_name</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>pre_training_strategy</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size</th>\n",
       "      <th>ft_strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k</th>\n",
       "      <th>convnext_b,sup,in22k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>983.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.320645</td>\n",
       "      <td>19.789302</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>4.951017e-01</td>\n",
       "      <td>4.353968</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion2B-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laion2b</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>840.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.001878</td>\n",
       "      <td>19.396968</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.854667</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.749206</td>\n",
       "      <td>0.888095</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>4.296971e-01</td>\n",
       "      <td>4.237302</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k</th>\n",
       "      <th>coatnet_2,sup,in12k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>859.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.085487</td>\n",
       "      <td>18.874429</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>...</td>\n",
       "      <td>9000000</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.959524</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>4.207975e-01</td>\n",
       "      <td>4.221429</td>\n",
       "      <td>9000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k_ft_in1k</th>\n",
       "      <th>coatnet_2,sup,in12k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>866.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.147118</td>\n",
       "      <td>18.743905</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>...</td>\n",
       "      <td>10281167</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>4.898830e-01</td>\n",
       "      <td>4.345238</td>\n",
       "      <td>10281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion_aesthetic-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laiona</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>808.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.651343</td>\n",
       "      <td>18.235889</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>...</td>\n",
       "      <td>900000000</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.520635</td>\n",
       "      <td>0.193651</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>3.917079e-02</td>\n",
       "      <td>2.972222</td>\n",
       "      <td>900000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_base_patch4_window7_224.ms_in22k_ft_in1k</th>\n",
       "      <th>swin_b,sup,ink22k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>769.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.037708</td>\n",
       "      <td>18.053905</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.854762</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>4.323401e-01</td>\n",
       "      <td>4.245238</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eva02_base_patch14_224.mim_in22k</th>\n",
       "      <th>eva02_b,mim,ink22k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>802.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.651285</td>\n",
       "      <td>17.599524</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>3.576140e-02</td>\n",
       "      <td>3.426190</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k_ft_in1k</th>\n",
       "      <th>convnext_b,sup,in22k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>849.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>17.016397</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.758730</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_base_patch4_window7_224.ms_in22k_ft_in1k</th>\n",
       "      <th>swin_b,sup,ink22k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>658.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.962976</td>\n",
       "      <td>16.772365</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.879365</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>4.091918e-01</td>\n",
       "      <td>4.196032</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_convnext_base</th>\n",
       "      <th>convnext_b,rob-sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>794.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.955159</td>\n",
       "      <td>16.631302</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>4.044271e-01</td>\n",
       "      <td>4.203968</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in1k</th>\n",
       "      <th>convnext_b,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>785.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.623310</td>\n",
       "      <td>16.420429</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.921429</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k</th>\n",
       "      <th>convnext_b,sup,in22k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>812.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.799936</td>\n",
       "      <td>15.992889</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.159524</td>\n",
       "      <td>0.136508</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>7.690471e-05</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion2B-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laion2b</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>583.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.770802</td>\n",
       "      <td>15.419238</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>3.368357e-01</td>\n",
       "      <td>4.045238</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b_ft_in1k</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>546.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.642220</td>\n",
       "      <td>15.240730</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>2321281167</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.575628e-01</td>\n",
       "      <td>3.858730</td>\n",
       "      <td>2321281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k_ft_in1k</th>\n",
       "      <th>convnext_b,sup,in22k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>703.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.005809</td>\n",
       "      <td>15.127683</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.892063</td>\n",
       "      <td>0.788095</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>4.758292e-01</td>\n",
       "      <td>4.323016</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.clip_laion2b_augreg_ft_in12k_in1k</th>\n",
       "      <th>convnext_b,hybrid,laion2b-in12k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>634.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>14.625873</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>...</td>\n",
       "      <td>2330281167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.569048</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>1.147706e-02</td>\n",
       "      <td>2.099206</td>\n",
       "      <td>2330281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion_aesthetic-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laiona</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>497.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.716907</td>\n",
       "      <td>14.510619</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>...</td>\n",
       "      <td>900000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.622695e-01</td>\n",
       "      <td>4.097619</td>\n",
       "      <td>900000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k_ft_in1k</th>\n",
       "      <th>coatnet_2,sup,in12k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>531.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.730333</td>\n",
       "      <td>14.404333</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>...</td>\n",
       "      <td>10281167</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.722446e-01</td>\n",
       "      <td>3.883333</td>\n",
       "      <td>10281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in1k</th>\n",
       "      <th>convnext_b,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>629.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.563928</td>\n",
       "      <td>14.390857</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.378571</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.859524</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_convnext_base</th>\n",
       "      <th>convnext_b,rob-sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>639.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.562490</td>\n",
       "      <td>13.771698</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>4.296681e-05</td>\n",
       "      <td>0.679365</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k</th>\n",
       "      <th>coatnet_2,sup,in12k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.663465</td>\n",
       "      <td>13.656476</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>...</td>\n",
       "      <td>9000000</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>1.513687e-01</td>\n",
       "      <td>3.457143</td>\n",
       "      <td>9000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eva02_base_patch14_224.mim_in22k</th>\n",
       "      <th>eva02_b,mim,ink22k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>483.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.832322</td>\n",
       "      <td>13.163381</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>3.715125e-01</td>\n",
       "      <td>4.119048</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.428039</td>\n",
       "      <td>12.831397</td>\n",
       "      <td>0.757333</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>0.082540</td>\n",
       "      <td>2.679353e-07</td>\n",
       "      <td>0.275397</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_base_patch16_224.augreg_in1k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_b,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>397.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.526426</td>\n",
       "      <td>12.497778</td>\n",
       "      <td>0.717333</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>2.562525e-01</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>325.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.530873</td>\n",
       "      <td>11.306857</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>2.827642e-01</td>\n",
       "      <td>3.909524</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_base_patch16_224.mae</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_b,mae,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>366.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.053784</td>\n",
       "      <td>10.922762</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.788095</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>306.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.325365</td>\n",
       "      <td>10.652857</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>1.127445e-01</td>\n",
       "      <td>3.376190</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.clip_laion2b_augreg_ft_in12k_in1k</th>\n",
       "      <th>convnext_b,hybrid,laion2b-in12k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>344.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.406625</td>\n",
       "      <td>9.757952</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>...</td>\n",
       "      <td>2330281167</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>3.092505e-02</td>\n",
       "      <td>2.530952</td>\n",
       "      <td>2330281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_vit_base_patch16_224</th>\n",
       "      <th>vit_b,rob-sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>367.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.438403</td>\n",
       "      <td>9.284619</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_base_patch16_224.augreg_in21k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_b,sup,in22k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>267.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.314362</td>\n",
       "      <td>9.204524</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>4.640042e-04</td>\n",
       "      <td>1.609524</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.268741</td>\n",
       "      <td>8.744079</td>\n",
       "      <td>0.658667</td>\n",
       "      <td>0.709333</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.669841</td>\n",
       "      <td>0.530952</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>7.852726e-02</td>\n",
       "      <td>3.115079</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.289556</td>\n",
       "      <td>8.554016</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>1.647349e-01</td>\n",
       "      <td>3.539683</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224.augreg_in21k_ft_in1k</th>\n",
       "      <th>vit_b,sup,ink22k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>232.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.304043</td>\n",
       "      <td>7.766048</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_vit_base_patch16_224</th>\n",
       "      <th>vit_b,rob-sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>7.738222</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>1.236257e-07</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224.augreg_in21k_ft_in1k</th>\n",
       "      <th>vit_b,sup,ink22k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.282617</td>\n",
       "      <td>7.513095</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.097619</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>2.879747e-05</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b_ft_in1k</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.053082</td>\n",
       "      <td>5.820127</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>...</td>\n",
       "      <td>2321281167</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.098413</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.482540</td>\n",
       "      <td>0.403175</td>\n",
       "      <td>6.737992e-04</td>\n",
       "      <td>1.367460</td>\n",
       "      <td>2321281167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                                                                                                                                                         TOTAL  \\\n",
       "metric                                                                                                                                                                          borda   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy              \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  983.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  840.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  859.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  866.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  808.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  769.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  802.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  849.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  658.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  794.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  785.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  812.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  583.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  546.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  703.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  634.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  497.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  531.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  629.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  639.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  512.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  483.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  512.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  397.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  325.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  366.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  306.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  344.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  367.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  267.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  230.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  216.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  232.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  347.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  236.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  158.0   \n",
       "\n",
       "dataset                                                                                                                                                                                      \\\n",
       "metric                                                                                                                                                                         nan_geom_cnt   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                    \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)            0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)            0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)            0   \n",
       "\n",
       "dataset                                                                                                                                                                                     \\\n",
       "metric                                                                                                                                                                         nan_sum_cnt   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)           0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)           0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)           0   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                         rank_borda   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)        1.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)        5.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)        3.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)        2.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)        7.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       11.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)        8.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)        4.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       13.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)        9.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)       10.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)        6.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)       17.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)       18.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)       12.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)       15.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)       22.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)       19.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)       16.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)       14.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)       20.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)       23.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)       20.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       24.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       29.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)       26.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)       30.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)       28.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)       25.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       31.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       34.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)       35.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       33.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)       27.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       32.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)       36.0   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                         rank_geom   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)       1.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)       6.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)       3.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)       2.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      16.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       4.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)      17.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      10.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       7.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)       8.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      19.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)      11.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      12.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)      18.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)       5.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)      20.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      14.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)      13.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)      21.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)      22.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)      15.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)       9.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)      27.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      24.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      23.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)      35.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)      29.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)      28.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)      26.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      30.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      34.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)      32.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      31.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)      25.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      33.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)      36.0   \n",
       "\n",
       "dataset                                                                                                                                                                                  \\\n",
       "metric                                                                                                                                                                         rank_sum   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      1.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      2.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)      3.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)      4.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      5.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      6.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)      7.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      8.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      9.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)     10.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)     11.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)     12.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)     13.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)     14.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)     15.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)     16.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)     17.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)     18.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)     19.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)     20.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)     21.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)     22.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)     23.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)     24.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)     25.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)     26.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)     27.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)     28.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)     29.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)     30.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)     31.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)     32.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)     33.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)     34.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)     35.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)     36.0   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                         score_geom   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   1.320645   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   1.001878   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   1.085487   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   1.147118   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.651343   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   1.037708   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.651285   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.815672   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.962976   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)   0.955159   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.623310   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.799936   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.770802   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)   0.642220   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   1.005809   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   0.564483   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.716907   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.730333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.563928   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   0.562490   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.663465   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.832322   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.428039   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.526426   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.530873   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.053784   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.325365   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   0.406625   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   0.438403   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.314362   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.268741   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.289556   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.304043   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   0.475919   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.282617   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   0.053082   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                          score_sum   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  19.789302   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  19.396968   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  18.874429   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  18.743905   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  18.235889   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  18.053905   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  17.599524   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  17.016397   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  16.772365   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  16.631302   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  16.420429   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  15.992889   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  15.419238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  15.240730   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  15.127683   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  14.625873   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  14.510619   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  14.404333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  14.390857   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  13.771698   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  13.656476   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  13.163381   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  12.831397   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  12.497778   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  11.306857   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  10.922762   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  10.652857   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   9.757952   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   9.284619   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   9.204524   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   8.744079   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   8.554016   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   7.766048   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   7.738222   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   7.513095   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   5.820127   \n",
       "\n",
       "dataset                                                                                                                                                                        caltech101  \\\n",
       "metric                                                                                                                                                                             L1_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.860000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.803000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.816000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.800000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.794000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.836000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.844000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.857000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.816000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)   0.748000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.838000   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.844000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.784000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)   0.776000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.842000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   0.812000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.770000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.782000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.825000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   0.736000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.832000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.810000   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.757333   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.717333   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.681000   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.155000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.587000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   0.794000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   0.755000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.733000   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.658667   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.609000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.666000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   0.760000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.730000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   0.460000   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                            L2_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.888000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.854667   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.864000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.881333   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.856000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.866667   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.890000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.898000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.840000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.892000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.871000   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.887000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.828000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.820000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.888000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.843000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.792000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.852000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.860000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.872000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.865000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.843000   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.829000   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.748000   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.756000   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.600000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.767000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.816000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.855000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.802000   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.709333   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.652000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.811000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.872000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.783000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.558000   \n",
       "\n",
       "dataset                                                                                                                                                                         ...  \\\n",
       "metric                                                                                                                                                                          ...   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy      ...   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  ...   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  ...   \n",
       "\n",
       "dataset                                                                                                                                                                                   stanford_cars  \\\n",
       "metric                                                                                                                                                                         volume_pre_training_data   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                                \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 14197122   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                  9000000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                 10281167   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                 14197122   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 15478289   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 14197122   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)               2321281167   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 15478289   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)               2330281167   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                 10281167   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                  9000000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                 14197122   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                  1281167   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                  1281167   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                  1281167   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                  1281167   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)               2330281167   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 14197122   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 14197122   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)               2321281167   \n",
       "\n",
       "dataset                                                                                                                                                                        uc-merced-land-use-dataset  \\\n",
       "metric                                                                                                                                                                                             L1_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                   0.823810   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.749206   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                   0.792857   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                   0.819048   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.519048   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.854762   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                   0.073810   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                   0.000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.833333   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)                   0.664286   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                   0.102381   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                   0.159524   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.690476   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)                   0.585714   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                   0.800000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)                   0.416667   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.733333   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                   0.650000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                   0.000000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)                   0.104762   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                   0.609524   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                   0.742857   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)                   0.023810   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.680952   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.685714   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                   0.000000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                   0.366667   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)                   0.419048   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)                   0.000000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.028571   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.380952   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)                   0.652381   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.000000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)                   0.009524   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.061905   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)                   0.230952   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                            L2_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.900000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.888095   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.866667   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.895238   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.520635   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.876190   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.800000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.879365   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.880952   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.009524   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.136508   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.857143   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.809524   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.892063   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.415873   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.866667   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.814286   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.161905   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.676190   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.869841   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.030952   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.795238   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.809524   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.000000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.704762   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.495238   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.000000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.238095   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.669841   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.680952   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.000000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.021429   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.097619   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.152381   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                          Linf_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.800000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.800000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.740476   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.802381   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.193651   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.721429   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.761905   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.738095   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.825397   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.085714   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.757143   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.733333   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.788095   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.276190   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.759524   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.707143   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.121429   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.609524   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.759524   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.050000   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.634921   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.692857   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.269841   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.633333   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.414286   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.000000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.228571   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.530952   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.555556   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.000000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.028571   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.140476   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.098413   \n",
       "\n",
       "dataset                                                                                                                                                                                \\\n",
       "metric                                                                                                                                                                          borda   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy              \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  170.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  151.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  149.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  167.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   96.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  148.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  126.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   55.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  138.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  158.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   74.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   45.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  127.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  111.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  169.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   66.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  128.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  105.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   19.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   43.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   87.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  135.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   26.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  109.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  110.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   44.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   89.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   72.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)    7.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   57.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   77.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   96.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)    7.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   28.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   41.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   52.0   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                         clean_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.966667   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.952381   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.959524   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.971429   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.955556   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.954762   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.976190   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.952381   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.942857   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.971429   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.952381   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.219048   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.945238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.952381   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.976190   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.569048   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.938095   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.928571   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.480952   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.164286   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.866667   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.950000   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.088095   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.942857   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.935714   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.873016   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.933333   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.642857   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.107143   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.666667   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.857143   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.942857   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.042857   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.174603   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.209524   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.482540   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                         common_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.863492   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.847619   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.861905   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.857143   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.783333   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.838095   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.814286   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.806349   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.802381   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)   0.861905   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.857143   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.188095   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.795238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)   0.777778   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.866667   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   0.421429   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.800000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.783333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.378571   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   0.126984   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.695238   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.796825   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.082540   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.790476   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.785714   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.645238   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.738095   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   0.559524   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   0.073810   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.447619   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.676190   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.707937   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.092857   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   0.121429   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.161905   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   0.403175   \n",
       "\n",
       "dataset                                                                                                                                                                                       \\\n",
       "metric                                                                                                                                                                                  geom   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                     \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  4.951017e-01   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.296971e-01   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.207975e-01   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.898830e-01   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  3.917079e-02   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  4.323401e-01   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  3.576140e-02   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000e+00   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  4.091918e-01   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  4.044271e-01   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000e+00   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  7.690471e-05   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  3.368357e-01   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  2.575628e-01   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  4.758292e-01   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  1.147706e-02   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  3.622695e-01   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  2.722446e-01   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.000000e+00   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  4.296681e-05   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  1.513687e-01   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  3.715125e-01   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  2.679353e-07   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  2.562525e-01   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  2.827642e-01   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.000000e+00   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  1.127445e-01   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  3.092505e-02   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.000000e+00   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  4.640042e-04   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  7.852726e-02   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  1.647349e-01   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.000000e+00   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  1.236257e-07   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  2.879747e-05   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  6.737992e-04   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                               sum   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  4.353968   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.237302   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.221429   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.345238   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  2.972222   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  4.245238   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  3.426190   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  1.758730   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  4.196032   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  4.203968   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  1.921429   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.788889   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.045238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  3.858730   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  4.323016   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  2.099206   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.097619   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  3.883333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.859524   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.679365   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  3.457143   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  4.119048   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.275397   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  3.844444   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  3.909524   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  1.788095   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  3.376190   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  2.530952   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.180952   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  1.609524   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  3.115079   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  3.539683   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.135714   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.355556   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.671429   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  1.367460   \n",
       "\n",
       "dataset                                                                                                                                                                                                  \n",
       "metric                                                                                                                                                                         volume_pre_training_data  \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                               \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 14197122  \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000  \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                  9000000  \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                 10281167  \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000  \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                 14197122  \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 15478289  \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 14197122  \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000  \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)               2321281167  \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 15478289  \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)               2330281167  \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000  \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                 10281167  \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                  9000000  \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                 14197122  \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000  \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                  1281167  \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                  1281167  \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                  1281167  \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                  1281167  \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)               2330281167  \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167  \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 14197122  \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 14197122  \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000  \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167  \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)               2321281167  \n",
       "\n",
       "[36 rows x 62 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_database import process_grouped_df, process_rankings, compute_odds_ratio_by_group\n",
    "\n",
    "size = \"large\" #\"small\"\n",
    "grouped_df = process_grouped_df(final_data, size)\n",
    "grouped_df = process_rankings(grouped_df)\n",
    "grouped_df\n",
    "# grouped_df.sort_values(by=\"sum\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'L1_acc': 0.096,\n",
       " 'L2_acc': 0.567,\n",
       " 'Linf_acc': 0.687,\n",
       " 'clean_acc': 0.889,\n",
       " 'common_acc': 0.772,\n",
       " 'backbone_name': 'convnext_b,clip,laion2b',\n",
       " 'loss_function': 'TRADES_v2'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "metric_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "fill": "toself",
         "fillcolor": "rgba(102,194,165, 0.3)",
         "line": {
          "color": "rgb(102,194,165)",
          "width": 4.5
         },
         "name": "caltech101<br>convnext_b,sup,in22k-in1k<br>TRADES_v2",
         "r": [
          0.857,
          0.898,
          0.842,
          0.86,
          0.958,
          0.857
         ],
         "theta": [
          "T(1)",
          "T(2)",
          "T(∞)",
          "T(common)",
          "T(∅)",
          "T(1)"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(252,141,98, 0.3)",
         "line": {
          "color": "rgb(252,141,98)",
          "width": 4.5
         },
         "name": "uc-merced-land-use-dataset<br>convnext_b,sup,in22k<br>TRADES_v2",
         "r": [
          0.8238095238095238,
          0.9,
          0.8,
          0.8634920634920635,
          0.9666666666666667,
          0.8238095238095238
         ],
         "theta": [
          "T(1)",
          "T(2)",
          "T(∞)",
          "T(common)",
          "T(∅)",
          "T(1)"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(141,160,203, 0.3)",
         "line": {
          "color": "rgb(141,160,203)",
          "width": 4.5
         },
         "name": "flowers-102<br>convnext_b,sup,in22k<br>TRADES_v2",
         "r": [
          0.639,
          0.769,
          0.677,
          0.821,
          0.907,
          0.639
         ],
         "theta": [
          "T(1)",
          "T(2)",
          "T(∞)",
          "T(common)",
          "T(∅)",
          "T(1)"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(231,138,195, 0.3)",
         "line": {
          "color": "rgb(231,138,195)",
          "width": 4.5
         },
         "name": "stanford_cars<br>convnext_b,clip,laion2b<br>TRADES_v2",
         "r": [
          0.096,
          0.567,
          0.687,
          0.772,
          0.889,
          0.096
         ],
         "theta": [
          "T(1)",
          "T(2)",
          "T(∞)",
          "T(common)",
          "T(∅)",
          "T(1)"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(166,216,84, 0.3)",
         "line": {
          "color": "rgb(166,216,84)",
          "width": 4.5
         },
         "name": "oxford-iiit-pet<br>convnext_b,rob-sup,in1k<br>CLASSIC_AT",
         "r": [
          0.162,
          0.529,
          0.618,
          0.747,
          0.856,
          0.162
         ],
         "theta": [
          "T(1)",
          "T(2)",
          "T(∞)",
          "T(common)",
          "T(∅)",
          "T(1)"
         ],
         "type": "scatterpolar"
        },
        {
         "fill": "toself",
         "fillcolor": "rgba(255,217,47, 0.3)",
         "line": {
          "color": "rgb(255,217,47)",
          "width": 4.5
         },
         "name": "fgvc-aircraft-2013b<br>convnext_b,clip,laion2b<br>TRADES_v2",
         "r": [
          0.04,
          0.33066666666666666,
          0.46,
          0.66,
          0.739,
          0.04
         ],
         "theta": [
          "T(1)",
          "T(2)",
          "T(∞)",
          "T(common)",
          "T(∅)",
          "T(1)"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "height": 500,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.5)",
         "font": {
          "size": 9
         },
         "x": 0,
         "xanchor": "right",
         "y": 0.85,
         "yanchor": "top"
        },
        "margin": {
         "b": 20,
         "l": 50,
         "r": 30,
         "t": 60
        },
        "paper_bgcolor": "white",
        "polar": {
         "angularaxis": {
          "direction": "clockwise",
          "gridcolor": "lightgray",
          "linecolor": "lightgray",
          "rotation": 90,
          "tickfont": {
           "size": 15
          }
         },
         "bgcolor": "white",
         "radialaxis": {
          "gridcolor": "lightgray",
          "linecolor": "lightgray",
          "showticklabels": true,
          "ticks": "",
          "visible": true
         }
        },
        "showlegend": true,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 500
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Rebuild radar data with config names included for each dataset's rank-1 configuration\n",
    "radar_data_with_names = []\n",
    "\n",
    "datas= [ 'stanford_cars',\n",
    "        'oxford-iiit-pet',\n",
    "        'caltech101' ,\n",
    "        'flowers-102' ,\n",
    "        'fgvc-aircraft-2013b',\n",
    "        'uc-merced-land-use-dataset' ]\n",
    "\n",
    "\n",
    "results = []\n",
    "for dataset in sorted(datas):\n",
    "\n",
    "        grouped_df[ (dataset, \"sum_rank\") ] =  grouped_df[(dataset, 'sum')].rank(ascending=False, method='min')\n",
    "        extraction = grouped_df[ grouped_df[ (dataset, \"sum_rank\") ] == 1 ]\n",
    "        idx = pd.IndexSlice\n",
    "        extr = extraction.loc[:, idx[dataset, ['L1_acc', 'L2_acc', 'Linf_acc', 'clean_acc', 'common_acc']]]\n",
    "        metric_dict = {metric: float(extr[(dataset, metric)]) for metric in ['L1_acc', 'L2_acc', 'Linf_acc', 'clean_acc', 'common_acc']}\n",
    "        metric_dict['backbone_name'] = extraction.index.get_level_values('backbone_name')[0]\n",
    "        metric_dict['loss_function'] = extraction.index.get_level_values('loss_function')[0]\n",
    "        metric_dict['dataset'] = dataset\n",
    "        results.append( metric_dict )\n",
    "\n",
    "results = pd.DataFrame(results)\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.colors as pc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Define axis labels\n",
    "categories = ['L1_acc', 'L2_acc', 'Linf_acc', 'common_acc', 'clean_acc']\n",
    "symbol_labels = [r'T(1)', r'T(2)', r'T(∞)', r'T(common)', r'T(∅)']\n",
    "\n",
    "# Compute area as sum of metrics (proxy for polygon area)\n",
    "results['area'] = results[categories].sum(axis=1)\n",
    "\n",
    "# Sort results from highest to lowest area\n",
    "results_sorted = results.sort_values(by='area', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Use Plotly's qualitative color set\n",
    "colors = pc.qualitative.Set2\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for i, (_, row) in enumerate(results_sorted.iterrows()):\n",
    "    lbl = f\"{row['dataset']}<br>{row['backbone_name']}<br>{row['loss_function']}\"\n",
    "    values = [row[metric] for metric in categories]\n",
    "    values += [values[0]]  # Close shape\n",
    "\n",
    "    color = colors[i % len(colors)]\n",
    "\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=values,\n",
    "        theta=symbol_labels + [symbol_labels[0]],\n",
    "        fill='toself',\n",
    "        name=lbl,\n",
    "        fillcolor=color.replace('rgb', 'rgba').replace(')', ', 0.3)'),  # 30% fill opacity\n",
    "        line=dict(color=color, width=4.5)  # Increased line thickness and full opacity\n",
    "    ))\n",
    "\n",
    "# Layout\n",
    "fig.update_layout(\n",
    "    polar=dict(\n",
    "        bgcolor='white',\n",
    "\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            showticklabels=True,\n",
    "            ticks='',\n",
    "            gridcolor='lightgray',\n",
    "            linecolor='lightgray'\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            rotation=90,  # Move 0° to the top (default is 0 at the right)\n",
    "            direction='clockwise',\n",
    "            tickfont=dict(size=15),\n",
    "            gridcolor='lightgray',\n",
    "            linecolor='lightgray'\n",
    "        ),\n",
    "    ),\n",
    "    legend=dict(\n",
    "        font=dict(size=9),\n",
    "        bgcolor='rgba(255,255,255,0.5)',\n",
    "        x=-0.0,\n",
    "        y=0.85,\n",
    "        xanchor='right',\n",
    "        yanchor='top'\n",
    "    ),\n",
    "    paper_bgcolor='white',\n",
    "    showlegend=True,\n",
    "    margin=dict(l=50, r=30, t=60, b=20),\n",
    "    width=500,\n",
    "    height=500\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(\"paper_figures/best_performing_per_dataset.pdf\", format='pdf', width=450, height=400, scale=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>Linf_acc</th>\n",
       "      <th>clean_acc</th>\n",
       "      <th>common_acc</th>\n",
       "      <th>backbone_name</th>\n",
       "      <th>loss_function</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.85700</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>0.842</td>\n",
       "      <td>0.958000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>convnext_b,sup,in22k-in1k</td>\n",
       "      <td>TRADES_v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.04000</td>\n",
       "      <td>0.330667</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.739000</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>convnext_b,clip,laion2b</td>\n",
       "      <td>TRADES_v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.63900</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>0.677</td>\n",
       "      <td>0.907000</td>\n",
       "      <td>0.821000</td>\n",
       "      <td>convnext_b,sup,in22k</td>\n",
       "      <td>TRADES_v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.529000</td>\n",
       "      <td>0.618</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>0.747000</td>\n",
       "      <td>convnext_b,rob-sup,in1k</td>\n",
       "      <td>CLASSIC_AT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.09600</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>0.687</td>\n",
       "      <td>0.889000</td>\n",
       "      <td>0.772000</td>\n",
       "      <td>convnext_b,clip,laion2b</td>\n",
       "      <td>TRADES_v2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.82381</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>convnext_b,sup,in22k</td>\n",
       "      <td>TRADES_v2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    L1_acc    L2_acc  Linf_acc  clean_acc  common_acc  \\\n",
       "0  0.85700  0.898000     0.842   0.958000    0.860000   \n",
       "1  0.04000  0.330667     0.460   0.739000    0.660000   \n",
       "2  0.63900  0.769000     0.677   0.907000    0.821000   \n",
       "3  0.16200  0.529000     0.618   0.856000    0.747000   \n",
       "4  0.09600  0.567000     0.687   0.889000    0.772000   \n",
       "5  0.82381  0.900000     0.800   0.966667    0.863492   \n",
       "\n",
       "               backbone_name loss_function  \n",
       "0  convnext_b,sup,in22k-in1k     TRADES_v2  \n",
       "1    convnext_b,clip,laion2b     TRADES_v2  \n",
       "2       convnext_b,sup,in22k     TRADES_v2  \n",
       "3    convnext_b,rob-sup,in1k    CLASSIC_AT  \n",
       "4    convnext_b,clip,laion2b     TRADES_v2  \n",
       "5       convnext_b,sup,in22k     TRADES_v2  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values: 0.21%\n"
     ]
    }
   ],
   "source": [
    "from process_database import process_grouped_df, process_rankings, compute_odds_ratio_by_group\n",
    "\n",
    "grouped_df = process_grouped_df(final_data, size=\"small\")\n",
    "grouped_df = process_rankings(grouped_df)\n",
    "grouped_df.to_csv(\"./perdataset_perf.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values: 3.75%\n",
      "Percentage of NaN values: 3.75%\n",
      "Percentage of NaN values: 3.75%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from process_database import process_grouped_df, process_rankings, compute_odds_ratio_by_group\n",
    "import pandas as pd\n",
    "\n",
    "odds_loss_list = []\n",
    "odds_architecture_list = []\n",
    "odds_pretraining_list = []\n",
    "\n",
    "for size_id,size in [ (0,'small'),(1,'medium'),(2,'large')]:\n",
    "    grouped_df = process_grouped_df(final_data, size)\n",
    "    grouped_df = process_rankings(grouped_df)\n",
    "\n",
    "    odds_df = grouped_df['TOTAL']\n",
    "    odds_df = odds_df.reset_index()\n",
    "    odds_df.to_csv(\"./odds_ratio.csv\")\n",
    "\n",
    "    # Define tier1 threshold based on the number of rows\n",
    "    n_rows = odds_df.shape[0]\n",
    "    top_k = int(np.ceil(0.33 * n_rows))  # top 10% as tier1\n",
    "\n",
    "    # Apply tier1 flag\n",
    "    odds_df[\"in_tier1\"] = 0\n",
    "    odds_df.loc[odds_df.sort_values(by=\"score_sum\", ascending=False).head(top_k).index, \"in_tier1\"] = 1\n",
    "\n",
    "    # Compute odds ratios for model_type and loss_function\n",
    "    odds_model_type = compute_odds_ratio_by_group(odds_df, \"model_type\")\n",
    "    odds_pretrain_type = compute_odds_ratio_by_group(odds_df, \"pre_training_strategy\")\n",
    "    odds_loss_function = compute_odds_ratio_by_group(odds_df, \"loss_function\")\n",
    "    odds_loss_function['size'] = size\n",
    "    odds_pretrain_type['size'] = size\n",
    "    odds_model_type['size'] = size\n",
    "\n",
    "    odds_loss_list.append(odds_loss_function)\n",
    "    odds_architecture_list.append(odds_model_type)\n",
    "    odds_pretraining_list.append(odds_pretrain_type)\n",
    "\n",
    "combined_odds_loss = pd.concat(odds_loss_list, axis=0)\n",
    "combined_odds_architecture = pd.concat(odds_architecture_list, axis=0)\n",
    "combined_odds_pretraining = pd.concat(odds_pretraining_list, axis=0)\n",
    "\n",
    "combined_odds_pretraining = combined_odds_pretraining.fillna(0)\n",
    "combined_odds_pretraining = combined_odds_pretraining[combined_odds_pretraining[\"size\"].isin([\"medium\", \"large\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "loss_function=TRADES_v2<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "TRADES_v2",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "TRADES_v2",
         "offsetgroup": "TRADES_v2",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "8<br>(p=0.116)",
          "1.83<br>(p=0.441)",
          "5<br>(p=0.041)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          8,
          1.8333333333333333,
          5
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "loss_function=CLASSIC_AT<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "CLASSIC_AT",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "CLASSIC_AT",
         "offsetgroup": "CLASSIC_AT",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.12<br>(p=0.116)",
          "0.55<br>(p=0.441)",
          "0.20<br>(p=0.041)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.125,
          0.5454545454545454,
          0.2
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255,255,255,1)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 12
         },
         "title": {
          "text": "loss_function"
         },
         "tracegroupgap": 0,
         "xanchor": "right",
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "uniformtext": {
         "minsize": 11,
         "mode": "show"
        },
        "width": 450,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": false,
         "title": {
          "text": "Model Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "range": [
          0,
          25
         ],
         "showgrid": true,
         "title": {
          "text": "Odds Ratio"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "model_type=hybrid<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "hybrid",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "hybrid",
         "offsetgroup": "hybrid",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.20<br>(p=0.217)",
          "2.11<br>(p=0.611)",
          "0.21<br>(p=0.310)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.2,
          2.111111111111111,
          0.20833333333333334
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "model_type=fully attention<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "fully attention",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "fully attention",
         "offsetgroup": "fully attention",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "2<br>(p=0.653)",
          "0.11<br>(p=0.016)",
          "1.65<br>(p=0.481)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          2,
          0.10714285714285714,
          1.6545454545454545
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "model_type=fully convolutional<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "fully convolutional",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "fully convolutional",
         "offsetgroup": "fully convolutional",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "3<br>(p=0.341)",
          "7<br>(p=0.024)",
          "1.19<br>(p=0.809)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          3,
          7,
          1.1904761904761905
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255,255,255,1)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 12
         },
         "title": {
          "text": "model_type"
         },
         "tracegroupgap": 0,
         "xanchor": "right",
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "uniformtext": {
         "minsize": 7,
         "mode": "show"
        },
        "width": 450,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": false,
         "title": {
          "text": "Model Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "range": [
          0,
          25
         ],
         "showgrid": true,
         "title": {
          "text": "Odds Ratio"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=supervised<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "supervised",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "supervised",
         "offsetgroup": "supervised",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.64<br>(p=0.585)",
          "0.60<br>(p=0.481)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.6428571428571429,
          0.6043956043956044
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=supervised (robust)<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "supervised (robust)",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "supervised (robust)",
         "offsetgroup": "supervised (robust)",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "6<br>(p=0.069)",
          "0.64<br>(p=0.709)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          6,
          0.6363636363636364
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=self-supervised<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "self-supervised",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "self-supervised",
         "offsetgroup": "self-supervised",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.20<br>(p=0.300)",
          "0.64<br>(p=0.709)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.2,
          0.6363636363636364
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=self-supervised (multimodal)<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "self-supervised (multimodal)",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "self-supervised (multimodal)",
         "offsetgroup": "self-supervised (multimodal)",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "5<br>(p=0.059)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "large"
         ],
         "xaxis": "x",
         "y": [
          5
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=hybrid (multimodal)<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "hybrid (multimodal)",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "hybrid (multimodal)",
         "offsetgroup": "hybrid (multimodal)",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.46<br>(p=0.630)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.4583333333333333
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255,255,255,1)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 12
         },
         "title": {
          "text": "pre_training_strategy"
         },
         "tracegroupgap": 0,
         "xanchor": "right",
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "uniformtext": {
         "minsize": 7,
         "mode": "show"
        },
        "width": 450,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": false,
         "title": {
          "text": "Model Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "range": [
          0,
          25
         ],
         "showgrid": true,
         "title": {
          "text": "Odds Ratio"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create mapping from numeric size to categorical label\n",
    "size_map = {\"small\":0, \"medium\":1, \"large\":2}\n",
    "\n",
    "# Convert numeric size columns to categorical labels\n",
    "combined_odds_loss[\"size_label\"] = combined_odds_loss[\"size\"].map(size_map)\n",
    "combined_odds_architecture[\"size_label\"] = combined_odds_architecture[\"size\"].map(size_map)\n",
    "combined_odds_pretraining[\"size_label\"] = combined_odds_pretraining[\"size\"].map(size_map)\n",
    "\n",
    "plots = [\n",
    "    (\"loss_function\", combined_odds_loss),\n",
    "    (\"model_type\", combined_odds_architecture),\n",
    "    (\"pre_training_strategy\", combined_odds_pretraining)\n",
    "]\n",
    "\n",
    "\n",
    "figs = []\n",
    "\n",
    "for var, plot_df in plots:\n",
    "\n",
    "    plot_df = plot_df.copy()\n",
    "    plot_df[\"odds_ratio\"] = plot_df[\"odds_ratio\"].replace(0, 0)\n",
    "\n",
    "    # plot_df[\"text_label\"] = plot_df.apply(\n",
    "    #     lambda row: (\n",
    "    #         f'{int(row[\"odds_ratio\"])}' if row[\"odds_ratio\"] == int(row[\"odds_ratio\"])\n",
    "    #         else f'{row[\"odds_ratio\"]:.2f}'\n",
    "    #     ) + f'  (p:{row[\"p_value\"]:.3f})',\n",
    "    #     axis=1\n",
    "    # )\n",
    "    plot_df[\"text_label\"] = plot_df.apply(\n",
    "        lambda row: f'{int(row[\"odds_ratio\"])}' if row[\"odds_ratio\"] == int(row[\"odds_ratio\"])\n",
    "        else f'{row[\"odds_ratio\"]:.2f}', axis=1 )\n",
    "    plot_df[\"text_label\"] = plot_df.apply(\n",
    "        lambda row: f'{row[\"text_label\"]}<br>(p={row[\"p_value\"]:.3f})', axis=1)\n",
    "            \n",
    "    fig = px.bar(\n",
    "        plot_df,\n",
    "        x=\"size\",\n",
    "        y=\"odds_ratio\",\n",
    "        color=var,\n",
    "        barmode=\"group\",\n",
    "        text=\"text_label\",\n",
    "        labels={\"size_label\": \"Model Size\", \"odds_ratio\": \"Odds Ratio\"},\n",
    "    )\n",
    "\n",
    "    fig.update_layout(yaxis=dict(range=[0, 25]),)\n",
    "\n",
    "    fig.update_traces(\n",
    "        textposition=\"outside\",\n",
    "        textangle=-90,  # Rotate text vertically\n",
    "        textfont=dict(\n",
    "            color=\"black\",\n",
    "            family=\"Arial\"\n",
    "        ),\n",
    "        cliponaxis=False\n",
    "    )\n",
    "\n",
    "    if var == 'loss_function':\n",
    "        fig.update_layout(\n",
    "        uniformtext_minsize=11,  # or your desired minimum font size\n",
    "        uniformtext_mode='show',  # force showing all text\n",
    "        )\n",
    "    else:\n",
    "        fig.update_layout(\n",
    "        uniformtext_minsize=7,  # or your desired minimum font size\n",
    "        uniformtext_mode='show',  # force showing all text\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "            margin=dict(l=0, r=0, t=0, b=0),  # remove all outer margins\n",
    "            width=450,    # in pixels (~2.5 inches at 96 DPI)\n",
    "            height=400,    # in pixels (~1.875 inches)\n",
    "            yaxis_title=\"Odds Ratio\",\n",
    "            xaxis_title=\"Model Size\",\n",
    "            legend_title_text=var,\n",
    "            \n",
    "            # White background\n",
    "            plot_bgcolor=\"white\",\n",
    "            paper_bgcolor=\"white\",\n",
    "            \n",
    "            # Light grey grid\n",
    "            xaxis=dict(showgrid=False, gridcolor=\"lightgrey\"),\n",
    "            yaxis=dict(showgrid=True, gridcolor=\"lightgrey\"),\n",
    "            \n",
    "            # Legend inside figure\n",
    "            legend=dict(    \n",
    "                font=dict(size=12),  # Adjust font size here \n",
    "                yanchor=\"top\",\n",
    "                xanchor=\"right\",\n",
    "                bgcolor=\"rgba(255,255,255,1)\",  # semi-transparent white box\n",
    "                bordercolor=\"lightgrey\",\n",
    "                borderwidth=1\n",
    "            )\n",
    "        )\n",
    "    fig.show()\n",
    "    fig.write_image(\"./paper_figures/oddsratio_{}_{}.png\".format(pn2,var), scale=3  )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#9e3303",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b_ft_in1k (TRADES_v2)",
         "r": [
          1.641714285714286,
          2.575857142857143,
          2.4633333333333334,
          4.657380952380953,
          3.902444444444444,
          1.641714285714286
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#8e8ac0",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K (TRADES_v2)",
         "r": [
          2.0030476190476194,
          2.5049682539682543,
          3.185984126984127,
          5.188555555555555,
          3.647333333333333,
          2.0030476190476194
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f3701b",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "swin_base_patch4_window7_224.ms_in22k_ft_in1k (TRADES_v2)",
         "r": [
          2.6397619047619045,
          2.566190476190476,
          2.9914285714285715,
          4.830761904761904,
          3.308095238095238,
          2.6397619047619045
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#fd8c3b",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "eva02_base_patch14_224.mim_in22k (TRADES_v2)",
         "r": [
          1.7624761904761905,
          2.627,
          3.2612380952380953,
          4.864857142857143,
          3.3379523809523812,
          1.7624761904761905
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#b03903",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b (TRADES_v2)",
         "r": [
          1.281142857142857,
          2.2386190476190477,
          2.226,
          3.8190952380952385,
          3.266539682539683,
          1.281142857142857
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f3701b",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "swin_base_patch4_window7_224.ms_in22k_ft_in1k (CLASSIC_AT)",
         "r": [
          1.743666666666667,
          2.366365079365079,
          2.7670952380952385,
          4.457857142857143,
          2.943380952380952,
          1.743666666666667
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#ec620f",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in1k (TRADES_v2)",
         "r": [
          1.5542857142857145,
          2.141238095238095,
          1.8439206349206347,
          3.7818571428571435,
          3.1764761904761905,
          1.5542857142857145
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#4f1f8b",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_convnext_base (TRADES_v2)",
         "r": [
          1.7849523809523808,
          2.1596190476190475,
          3.2573968253968255,
          4.541428571428572,
          3.0859047619047617,
          1.7849523809523808
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#9e9ac8",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion2B-s13B-b82K (TRADES_v2)",
         "r": [
          2.3152063492063495,
          2.1927619047619045,
          3.66,
          5.1943809523809525,
          2.9729523809523815,
          2.3152063492063495
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#674ba0",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k (TRADES_v2)",
         "r": [
          2.2261428571428574,
          2.18,
          3.5759999999999996,
          5.057666666666666,
          2.778492063492063,
          2.2261428571428574
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#ec620f",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in1k (CLASSIC_AT)",
         "r": [
          1.6133809523809526,
          2.0508571428571427,
          1.874190476190476,
          3.127714285714286,
          2.640714285714286,
          1.6133809523809526
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#9e9ac8",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion2B-s13B-b82K (CLASSIC_AT)",
         "r": [
          1.5124761904761905,
          2.137142857142857,
          2.767142857142857,
          4.016238095238095,
          2.5502380952380954,
          1.5124761904761905
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#c54102",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.mae (TRADES_v2)",
         "r": [
          0.244,
          1.3846666666666667,
          1.9228412698412698,
          4.0620158730158735,
          3.3092380952380953,
          0.244
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#5b3495",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k_ft_in1k (CLASSIC_AT)",
         "r": [
          1.3576666666666668,
          1.9860634920634923,
          2.681095238095238,
          3.9505238095238098,
          2.5333333333333337,
          1.3576666666666668
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#c54102",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.mae (CLASSIC_AT)",
         "r": [
          1.0303333333333333,
          1.8767619047619046,
          1.9003333333333332,
          3.168333333333333,
          2.677095238095238,
          1.0303333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#8e8ac0",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K (CLASSIC_AT)",
         "r": [
          1.4209999999999998,
          1.994,
          2.5188571428571427,
          3.7970952380952383,
          2.4206666666666665,
          1.4209999999999998
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7e79b8",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.clip_laion2b_augreg_ft_in12k_in1k (TRADES_v2)",
         "r": [
          1.9113333333333333,
          1.891873015873016,
          2.6211904761904763,
          3.952047619047619,
          2.5784285714285713,
          1.9113333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#4f1f8b",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_convnext_base (CLASSIC_AT)",
         "r": [
          0.7857619047619047,
          1.665904761904762,
          2.6744285714285714,
          3.771952380952381,
          2.3656507936507936,
          0.7857619047619047
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f87f2c",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_vit_base_patch16_224 (TRADES_v2)",
         "r": [
          0.8570000000000001,
          1.4140000000000001,
          1.282,
          3.0621428571428573,
          2.669476190476191,
          0.8570000000000001
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#e25508",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k (TRADES_v2)",
         "r": [
          0.7805714285714286,
          1.406095238095238,
          1.2805714285714287,
          3.1346666666666665,
          2.602619047619048,
          0.7805714285714286
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#fd8c3b",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "eva02_base_patch14_224.mim_in22k (CLASSIC_AT)",
         "r": [
          1.3278571428571428,
          1.7268412698412698,
          2.2768571428571427,
          3.319,
          2.0548253968253967,
          1.3278571428571428
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7262ac",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in1k (TRADES_v2)",
         "r": [
          1.9413809523809524,
          1.2045238095238093,
          2.473,
          4.971380952380952,
          2.775142857142857,
          1.9413809523809524
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#5b3495",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k_ft_in1k (TRADES_v2)",
         "r": [
          1.3893333333333333,
          1.2389999999999999,
          2.707,
          5.011380952380952,
          2.7066825396825394,
          1.3893333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#e25508",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k (CLASSIC_AT)",
         "r": [
          1.1779523809523809,
          1.6521746031746032,
          1.4322857142857144,
          2.4564761904761903,
          2.0251904761904767,
          1.1779523809523809
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#b03903",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b (CLASSIC_AT)",
         "r": [
          1.3503809523809525,
          1.5679523809523812,
          1.4128888888888889,
          2.333190476190476,
          1.8896031746031747,
          1.3503809523809525
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#674ba0",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k (CLASSIC_AT)",
         "r": [
          0.7791904761904761,
          1.3965079365079365,
          2.7663809523809526,
          4.2587142857142855,
          1.979095238095238,
          0.7791904761904761
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#d84801",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k_ft_in1k (TRADES_v2)",
         "r": [
          0.7693333333333334,
          1.237,
          1.115,
          2.495857142857143,
          2.148857142857143,
          0.7693333333333334
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f87f2c",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_vit_base_patch16_224 (CLASSIC_AT)",
         "r": [
          0.9258571428571428,
          1.4007619047619049,
          1.3442380952380952,
          2.1749365079365077,
          1.8924285714285716,
          0.9258571428571428
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#d84801",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k_ft_in1k (CLASSIC_AT)",
         "r": [
          0.8602380952380952,
          1.065952380952381,
          0.9944761904761905,
          2.4435238095238097,
          2.148904761904762,
          0.8602380952380952
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7262ac",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in1k (CLASSIC_AT)",
         "r": [
          0.5393333333333333,
          1.069,
          2.259666666666667,
          4.200619047619048,
          2.0175714285714283,
          0.5393333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#73c476",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k (CLASSIC_AT)",
         "r": [
          0.7731904761904762,
          1.002857142857143,
          2.4248571428571424,
          3.758,
          1.3952380952380952,
          0.7731904761904762
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#006428",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k_ft_in1k (TRADES_v2)",
         "r": [
          0.8670476190476191,
          1.1492380952380952,
          2.978714285714285,
          4.252428571428571,
          1.4051428571428572,
          0.8670476190476191
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#9e3303",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b_ft_in1k (CLASSIC_AT)",
         "r": [
          0.7599523809523809,
          0.9180476190476191,
          0.8100793650793651,
          1.8392063492063493,
          1.4928412698412696,
          0.7599523809523809
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#006428",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k_ft_in1k (CLASSIC_AT)",
         "r": [
          0.8240000000000001,
          1.0012857142857143,
          2.575142857142857,
          4.0525714285714285,
          1.3133333333333335,
          0.8240000000000001
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7e79b8",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.clip_laion2b_augreg_ft_in12k_in1k (CLASSIC_AT)",
         "r": [
          0.726047619047619,
          1.0182380952380954,
          1.6612857142857145,
          2.5708571428571427,
          1.3645238095238095,
          0.726047619047619
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#73c476",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k (TRADES_v2)",
         "r": [
          0.7928571428571428,
          0.8666666666666667,
          2.91747619047619,
          4.25052380952381,
          0.861904761904762,
          0.7928571428571428
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "font": {
         "color": "black"
        },
        "height": 500,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.9)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 11
         },
         "x": 0,
         "xanchor": "left",
         "y": 1,
         "yanchor": "top"
        },
        "margin": {
         "b": 25,
         "l": 25,
         "r": 25,
         "t": 25
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "polar": {
         "angularaxis": {
          "direction": "clockwise",
          "gridcolor": "lightgrey",
          "gridwidth": 0.5,
          "linecolor": "lightgrey",
          "linewidth": 1,
          "showline": true
         },
         "bgcolor": "white",
         "radialaxis": {
          "gridcolor": "lightgrey",
          "gridwidth": 0.5,
          "linecolor": "lightgrey",
          "linewidth": 1,
          "range": [
           0,
           6
          ],
          "showline": true,
          "visible": true
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 500
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_hex\n",
    "import re\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = grouped_df.copy()\n",
    "\n",
    "metrics_to_sum = [\"L1_acc\", \"L2_acc\", \"Linf_acc\", \"clean_acc\", \"common_acc\"]\n",
    "\n",
    "for metric in metrics_to_sum:\n",
    "    metric_cols = [col for col in df1.columns if col[1] == metric]\n",
    "    df1[f'sum_{metric}'] = df1[metric_cols].sum(axis=1)\n",
    "\n",
    "df_per_row_sums = df1[[f'sum_{m}' for m in metrics_to_sum]]\n",
    "\n",
    "df_per_row_sums.columns = df_per_row_sums.columns.get_level_values(0)\n",
    "\n",
    "df_per_row_sums.columns.name = 'metric'\n",
    "\n",
    "df_per_row_sums\n",
    "\n",
    "\n",
    "# Your model type mapping\n",
    "model_type_map = {\n",
    "    'convnext_base': \"fully convolutional\",\n",
    "    'convnext_tiny': \"fully convolutional\",\n",
    "    'deit_small': \"fully attention\",\n",
    "    'vit_base': \"fully attention\",\n",
    "    'vit_small': \"fully attention\",\n",
    "    'resnet50': \"fully convolutional\",\n",
    "    'eva02_base': \"fully attention\",\n",
    "    'eva02_tiny': \"fully attention\",\n",
    "    'swin_base': \"fully attention\",\n",
    "    'swin_tiny': \"fully attention\",\n",
    "    'coatnet_0': \"hybrid\",\n",
    "    'coatnet_2': \"hybrid\",\n",
    "    'regnetx_004': \"fully convolutional\",\n",
    "    'efficientnet-b0': \"fully convolutional\", \n",
    "    'deit_tiny': \"fully attention\",\n",
    "    'mobilevit-small': \"hybrid\",\n",
    "    'mobilenetv3': \"fully convolutional\",\n",
    "    'edgenext_small': \"fully convolutional\",\n",
    "    'coat_tiny': \"hybrid\",\n",
    "}\n",
    "\n",
    "# Colormap for each model type\n",
    "type_to_cmap = {\n",
    "    'fully convolutional': cm.Purples,     # deep violet → lavender\n",
    "    'fully attention': cm.Oranges,         # strong orange → light peach\n",
    "    'hybrid': cm.Greens                    # forest → mint\n",
    "}\n",
    "\n",
    "# Extract base backbone name from full backbone string\n",
    "def extract_base_name(backbone_name):\n",
    "    for base in model_type_map:\n",
    "        if base in backbone_name:\n",
    "            return base\n",
    "    return 'unknown'\n",
    "\n",
    "# Get all unique backbones\n",
    "backbones = sorted(set(backbone for backbone, _, _, _ in df_per_row_sums.index))\n",
    "\n",
    "# Map backbones to model type\n",
    "backbone_model_type = {b: model_type_map.get(extract_base_name(b), 'unknown') for b in backbones}\n",
    "\n",
    "# Assign gradient color per backbone based on model type\n",
    "color_map = {}\n",
    "for model_type in ['fully convolutional', 'fully attention', 'hybrid']:\n",
    "    bks = [bk for bk in backbones if backbone_model_type[bk] == model_type]\n",
    "    n = len(bks)\n",
    "    for i, bk in enumerate(bks):\n",
    "        start, end = 0.5, 0.9  # avoid very light or very dark edges\n",
    "        position = start + (end - start) * (i / max(n - 1, 1))\n",
    "        color = to_hex(type_to_cmap[model_type](position))\n",
    "        color_map[bk] = color\n",
    "\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['sum_L1_acc', 'sum_L2_acc', 'sum_Linf_acc', 'sum_clean_acc', 'sum_common_acc']\n",
    "\n",
    "# Create a list of unique backbones (regardless of loss)\n",
    "unique_backbones = sorted(set(backbone for backbone, _, _, _ in df_per_row_sums.index))\n",
    "\n",
    "# # Assign a unique color to each backbone\n",
    "# color_palette = px.colors.qualitative.Plotly\n",
    "# color_map = dict(zip(unique_backbones, color_palette * (len(unique_backbones) // len(color_palette) + 1)))\n",
    "\n",
    "# Define line styles per loss function\n",
    "line_styles = {\n",
    "    'CLASSIC_AT': 'solid',\n",
    "    'TRADES_v2': 'dot'\n",
    "}\n",
    "\n",
    "# Create the radar plot\n",
    "\n",
    "from plotly.colors import qualitative\n",
    "color_palette = qualitative.Bold\n",
    "\n",
    "# Get unique backbones\n",
    "unique_backbones = sorted(set(backbone for backbone, _, _, _ in df_per_row_sums.index))\n",
    "\n",
    "# Assign colors per backbone\n",
    "# color_map = dict(zip(unique_backbones, color_palette * (len(unique_backbones) // len(color_palette) + 1)))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for (backbone, loss, _, _), row in df_per_row_sums.iterrows():\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=row.tolist() + [row.tolist()[0]],  # Close the loop\n",
    "        theta=metrics + [metrics[0]],\n",
    "        mode='lines',\n",
    "        name=f\"{backbone} ({loss})\",\n",
    "        line=dict(\n",
    "            width=2,\n",
    "            color=color_map[backbone],\n",
    "            dash=line_styles.get(loss, 'solid')\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=500, \n",
    "    height=500,\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 6],\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor=\"lightgrey\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "            gridwidth=0.5,\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            direction=\"clockwise\",\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor=\"lightgrey\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "            gridwidth=0.5,\n",
    "        ),\n",
    "        bgcolor='white'\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        xanchor='left',\n",
    "        yanchor='top',\n",
    "        bgcolor='rgba(255,255,255,0.9)',\n",
    "        bordercolor='lightgrey',\n",
    "        borderwidth=1,\n",
    "        font=dict(size=11),\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    font=dict(color='black'),\n",
    "    margin=dict(l=25, r=25, t=25, b=25)  # <<< reduced margins\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"./radar_plot_{}_{}.png\".format(size, pn2), scale=3  )                # upscale for higher DPI (1 = default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
