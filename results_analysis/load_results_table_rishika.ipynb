{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_uc-merced-land-use-dataset_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_stanford_cars_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_caltech101_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_fgvc-aircraft-2013b_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_flowers-102_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_oxford-iiit-pet_TRADES_v2.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_uc-merced-land-use-dataset_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_stanford_cars_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coat_tiny.in1k_caltech101_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_fgvc-aircraft-2013b_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_flowers-102_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion_aesthetic-s13B-b82K_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/CLIP-convnext_base_w-laion2B-s13B-b82K_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/deit_small_patch16_224.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_resnet50_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/resnet50.a1_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_vit_base_patch16_224_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.mae_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.dino_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_base_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_convnext_tiny_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/robust_deit_small_patch16_224_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_clip_224.laion2b_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_base_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/vit_small_patch16_224.augreg_in21k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_base_patch14_224.mim_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/eva02_tiny_patch14_224.mim_in22k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_base_patch4_window7_224.ms_in22k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/swin_tiny_patch4_window7_224.ms_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.clip_laion2b_augreg_ft_in12k_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_base.fb_in22k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/convnext_tiny.fb_in22k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_0_rw_224.sw_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_ft_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_paper_final2/coatnet_2_rw_224.sw_in12k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/regnetx_004.pycls_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/efficientnet-b0_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/deit_tiny_patch16_224.fb_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilevit-small_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/mobilenetv3_large_100.ra_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/edgenext_small.usi_in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n",
      "../results/full_fine_tuning_50epochs_edge_paper_final2/coat_tiny.in1k_oxford-iiit-pet_CLASSIC_AT.pkl\n"
     ]
    }
   ],
   "source": [
    "from load_results import load_result_dataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pn1 = 'full_fine_tuning_50epochs_edge_paper_final2'\n",
    "pn2 = 'full_fine_tuning_50epochs_paper_final2'\n",
    "\n",
    "final_data = load_result_dataset(pn1, pn2)\n",
    "final_data = [{**d, 'ft_strategy': 'FFT (50 epochs)'} for d in final_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values, for small architecture: 1.4705882352941175\n",
      "Percentage of NaN values, for medium architecture: 0.0\n",
      "Percentage of NaN values, for large architecture: 0.10893246187363835\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(final_data)\n",
    "for arch_size in ('small', 'medium', 'large'):\n",
    "    df_curr = df[ df.model_size == arch_size ]\n",
    "    nan_percentage = (df_curr.isna().sum().sum() / df_curr.size) * 100\n",
    "    print(\"Percentage of NaN values, for {} architecture: {}\".format(arch_size, nan_percentage) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backbone</th>\n",
       "      <th>dataset</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>restart_from</th>\n",
       "      <th>model_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>coatnet_2_rw_224.sw_in12k</td>\n",
       "      <td>stanford_cars</td>\n",
       "      <td>TRADES_v2</td>\n",
       "      <td>job5_test_l2.sh</td>\n",
       "      <td>large</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>coat_tiny.in1k</td>\n",
       "      <td>stanford_cars</td>\n",
       "      <td>TRADES_v2</td>\n",
       "      <td>job5_test_l2.sh</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>coat_tiny.in1k</td>\n",
       "      <td>caltech101</td>\n",
       "      <td>TRADES_v2</td>\n",
       "      <td>job4_test_l1.sh</td>\n",
       "      <td>small</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      backbone        dataset loss_function     restart_from  \\\n",
       "72   coatnet_2_rw_224.sw_in12k  stanford_cars     TRADES_v2  job5_test_l2.sh   \n",
       "79              coat_tiny.in1k  stanford_cars     TRADES_v2  job5_test_l2.sh   \n",
       "119             coat_tiny.in1k     caltech101     TRADES_v2  job4_test_l1.sh   \n",
       "\n",
       "    model_size  \n",
       "72       large  \n",
       "79       small  \n",
       "119      small  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "\n",
    "df = pd.DataFrame(final_data)\n",
    "# df = df[df[\"model_size\"].isin([  ])] # 'medium', 'large'\n",
    "# df.to_csv(\"./{}.csv\".format(\"result_with_missing_values_max\"))\n",
    "\n",
    "def get_restart_job(row):\n",
    "    is_missing = lambda col: pd.isna(row[col])\n",
    "\n",
    "    missing = {col: is_missing(col) for col in ['clean_acc', 'Linf_acc', 'L1_acc', 'L2_acc', 'common_acc']}\n",
    "\n",
    "    if all(missing.values()):\n",
    "        return \"job1_hpo.sh\"\n",
    "    elif not missing['clean_acc'] and not missing['Linf_acc'] and missing['L1_acc']:\n",
    "        return \"job4_test_l1.sh\"\n",
    "    elif not missing['clean_acc'] and not missing['Linf_acc'] and not missing['L1_acc'] and missing['L2_acc']:\n",
    "        return \"job5_test_l2.sh\"\n",
    "    elif not missing['clean_acc'] and not missing['Linf_acc'] and not missing['L1_acc'] and not missing['L2_acc'] and missing['common_acc']:\n",
    "        return \"job6_test_common.sh\"\n",
    "    else:\n",
    "        return None  # means no job needs to be restarted\n",
    "\n",
    "df['restart_from'] = df.apply(get_restart_job, axis=1)\n",
    "\n",
    "to_restart = df[df['restart_from'].notna()][['backbone', 'dataset', 'loss_function', 'restart_from', 'model_size']]\n",
    "# to_restart = to_restart[ to_restart.restart_from == \"job1_hpo.sh\" ]\n",
    "to_restart.to_csv(\"./to_relaunch_rishika.csv\")\n",
    "to_restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values: 0.39%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"8\" halign=\"left\">TOTAL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">caltech101</th>\n",
       "      <th>...</th>\n",
       "      <th>stanford_cars</th>\n",
       "      <th colspan=\"9\" halign=\"left\">uc-merced-land-use-dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>borda</th>\n",
       "      <th>nan_geom_cnt</th>\n",
       "      <th>nan_sum_cnt</th>\n",
       "      <th>rank_borda</th>\n",
       "      <th>rank_geom</th>\n",
       "      <th>rank_sum</th>\n",
       "      <th>score_geom</th>\n",
       "      <th>score_sum</th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_pre_training_data</th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>Linf_acc</th>\n",
       "      <th>borda</th>\n",
       "      <th>clean_acc</th>\n",
       "      <th>common_acc</th>\n",
       "      <th>geom</th>\n",
       "      <th>sum</th>\n",
       "      <th>volume_pre_training_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <th>backbone_name</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>pre_training_strategy</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size</th>\n",
       "      <th>ft_strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k</th>\n",
       "      <th>convnext_b,sup,in22k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>978.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.320645</td>\n",
       "      <td>19.789302</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.823810</td>\n",
       "      <td>0.900000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.863492</td>\n",
       "      <td>4.951017e-01</td>\n",
       "      <td>4.353968</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion2B-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laion2b</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>835.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.001878</td>\n",
       "      <td>19.396968</td>\n",
       "      <td>0.803000</td>\n",
       "      <td>0.854667</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.749206</td>\n",
       "      <td>0.888095</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>151.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.847619</td>\n",
       "      <td>4.296971e-01</td>\n",
       "      <td>4.237302</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion_aesthetic-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laiona</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>803.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.651343</td>\n",
       "      <td>18.235889</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.856000</td>\n",
       "      <td>...</td>\n",
       "      <td>900000000</td>\n",
       "      <td>0.519048</td>\n",
       "      <td>0.520635</td>\n",
       "      <td>0.193651</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.955556</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>3.917079e-02</td>\n",
       "      <td>2.972222</td>\n",
       "      <td>900000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_base_patch4_window7_224.ms_in22k_ft_in1k</th>\n",
       "      <th>swin_b,sup,ink22k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>767.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.037708</td>\n",
       "      <td>18.053905</td>\n",
       "      <td>0.836000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.854762</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.721429</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.954762</td>\n",
       "      <td>0.838095</td>\n",
       "      <td>4.323401e-01</td>\n",
       "      <td>4.245238</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eva02_base_patch14_224.mim_in22k</th>\n",
       "      <th>eva02_b,mim,ink22k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>798.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.651285</td>\n",
       "      <td>17.599524</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.761905</td>\n",
       "      <td>126.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>3.576140e-02</td>\n",
       "      <td>3.426190</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k_ft_in1k</th>\n",
       "      <th>convnext_b,sup,in22k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>846.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.815672</td>\n",
       "      <td>17.016397</td>\n",
       "      <td>0.857000</td>\n",
       "      <td>0.898000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.806349</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.758730</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>swin_base_patch4_window7_224.ms_in22k_ft_in1k</th>\n",
       "      <th>swin_b,sup,ink22k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>657.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.962976</td>\n",
       "      <td>16.772365</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.879365</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>4.091918e-01</td>\n",
       "      <td>4.196032</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_convnext_base</th>\n",
       "      <th>convnext_b,rob-sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>792.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.955159</td>\n",
       "      <td>16.631302</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>0.892000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.664286</td>\n",
       "      <td>0.880952</td>\n",
       "      <td>0.825397</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>4.044271e-01</td>\n",
       "      <td>4.203968</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k_ft_in1k</th>\n",
       "      <th>coatnet_2,sup,in12k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>735.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.139192</td>\n",
       "      <td>16.434905</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.881333</td>\n",
       "      <td>...</td>\n",
       "      <td>10281167</td>\n",
       "      <td>0.819048</td>\n",
       "      <td>0.895238</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>167.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>4.898830e-01</td>\n",
       "      <td>4.345238</td>\n",
       "      <td>10281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in1k</th>\n",
       "      <th>convnext_b,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>782.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.623310</td>\n",
       "      <td>16.420429</td>\n",
       "      <td>0.838000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.102381</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.921429</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k</th>\n",
       "      <th>coatnet_2,sup,in12k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>707.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.073895</td>\n",
       "      <td>16.405762</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.864000</td>\n",
       "      <td>...</td>\n",
       "      <td>9000000</td>\n",
       "      <td>0.792857</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.959524</td>\n",
       "      <td>0.861905</td>\n",
       "      <td>4.207975e-01</td>\n",
       "      <td>4.221429</td>\n",
       "      <td>9000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k</th>\n",
       "      <th>convnext_b,sup,in22k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>809.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.799936</td>\n",
       "      <td>15.992889</td>\n",
       "      <td>0.844000</td>\n",
       "      <td>0.887000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.159524</td>\n",
       "      <td>0.136508</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.188095</td>\n",
       "      <td>7.690471e-05</td>\n",
       "      <td>0.788889</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion2B-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laion2b</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>581.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.770802</td>\n",
       "      <td>15.419238</td>\n",
       "      <td>0.784000</td>\n",
       "      <td>0.828000</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.690476</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.757143</td>\n",
       "      <td>127.0</td>\n",
       "      <td>0.945238</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>3.368357e-01</td>\n",
       "      <td>4.045238</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b_ft_in1k</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>545.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.642220</td>\n",
       "      <td>15.240730</td>\n",
       "      <td>0.776000</td>\n",
       "      <td>0.820000</td>\n",
       "      <td>...</td>\n",
       "      <td>2321281167</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>2.575628e-01</td>\n",
       "      <td>3.858730</td>\n",
       "      <td>2321281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k_ft_in1k</th>\n",
       "      <th>convnext_b,sup,in22k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>701.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.005809</td>\n",
       "      <td>15.127683</td>\n",
       "      <td>0.842000</td>\n",
       "      <td>0.888000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.892063</td>\n",
       "      <td>0.788095</td>\n",
       "      <td>169.0</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>4.758292e-01</td>\n",
       "      <td>4.323016</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.clip_laion2b_augreg_ft_in12k_in1k</th>\n",
       "      <th>convnext_b,hybrid,laion2b-in12k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>628.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.564483</td>\n",
       "      <td>14.625873</td>\n",
       "      <td>0.812000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>...</td>\n",
       "      <td>2330281167</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.415873</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0.569048</td>\n",
       "      <td>0.421429</td>\n",
       "      <td>1.147706e-02</td>\n",
       "      <td>2.099206</td>\n",
       "      <td>2330281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLIP-convnext_base_w-laion_aesthetic-s13B-b82K</th>\n",
       "      <th>convnext_b,clip,laiona</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>497.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.716907</td>\n",
       "      <td>14.510619</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.792000</td>\n",
       "      <td>...</td>\n",
       "      <td>900000000</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>3.622695e-01</td>\n",
       "      <td>4.097619</td>\n",
       "      <td>900000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k_ft_in1k</th>\n",
       "      <th>coatnet_2,sup,in12k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>531.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.730333</td>\n",
       "      <td>14.404333</td>\n",
       "      <td>0.782000</td>\n",
       "      <td>0.852000</td>\n",
       "      <td>...</td>\n",
       "      <td>10281167</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.707143</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.783333</td>\n",
       "      <td>2.722446e-01</td>\n",
       "      <td>3.883333</td>\n",
       "      <td>10281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in1k</th>\n",
       "      <th>convnext_b,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>627.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.563928</td>\n",
       "      <td>14.390857</td>\n",
       "      <td>0.825000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.480952</td>\n",
       "      <td>0.378571</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.859524</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_convnext_base</th>\n",
       "      <th>convnext_b,rob-sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>638.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.562490</td>\n",
       "      <td>13.771698</td>\n",
       "      <td>0.736000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.104762</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.164286</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>4.296681e-05</td>\n",
       "      <td>0.679365</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coatnet_2_rw_224.sw_in12k</th>\n",
       "      <th>coatnet_2,sup,in12k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>512.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.663465</td>\n",
       "      <td>13.656476</td>\n",
       "      <td>0.832000</td>\n",
       "      <td>0.865000</td>\n",
       "      <td>...</td>\n",
       "      <td>9000000</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.695238</td>\n",
       "      <td>1.513687e-01</td>\n",
       "      <td>3.457143</td>\n",
       "      <td>9000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eva02_base_patch14_224.mim_in22k</th>\n",
       "      <th>eva02_b,mim,ink22k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>483.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.832322</td>\n",
       "      <td>13.163381</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.843000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.869841</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>135.0</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.796825</td>\n",
       "      <td>3.715125e-01</td>\n",
       "      <td>4.119048</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>509.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.428039</td>\n",
       "      <td>12.831397</td>\n",
       "      <td>0.757333</td>\n",
       "      <td>0.829000</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.088095</td>\n",
       "      <td>0.082540</td>\n",
       "      <td>2.679353e-07</td>\n",
       "      <td>0.275397</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_base_patch16_224.augreg_in1k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_b,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>397.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.526426</td>\n",
       "      <td>12.497778</td>\n",
       "      <td>0.717333</td>\n",
       "      <td>0.748000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.795238</td>\n",
       "      <td>0.634921</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.790476</td>\n",
       "      <td>2.562525e-01</td>\n",
       "      <td>3.844444</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>325.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.530873</td>\n",
       "      <td>11.306857</td>\n",
       "      <td>0.681000</td>\n",
       "      <td>0.756000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>2.827642e-01</td>\n",
       "      <td>3.909524</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_base_patch16_224.mae</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_b,mae,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>366.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.053784</td>\n",
       "      <td>10.922762</td>\n",
       "      <td>0.155000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.269841</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.788095</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>306.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.325365</td>\n",
       "      <td>10.652857</td>\n",
       "      <td>0.587000</td>\n",
       "      <td>0.767000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.633333</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>0.738095</td>\n",
       "      <td>1.127445e-01</td>\n",
       "      <td>3.376190</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.clip_laion2b_augreg_ft_in12k_in1k</th>\n",
       "      <th>convnext_b,hybrid,laion2b-in12k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>344.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.406625</td>\n",
       "      <td>9.757952</td>\n",
       "      <td>0.794000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>...</td>\n",
       "      <td>2330281167</td>\n",
       "      <td>0.419048</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.414286</td>\n",
       "      <td>72.0</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.559524</td>\n",
       "      <td>3.092505e-02</td>\n",
       "      <td>2.530952</td>\n",
       "      <td>2330281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_vit_base_patch16_224</th>\n",
       "      <th>vit_b,rob-sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>367.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.438403</td>\n",
       "      <td>9.284619</td>\n",
       "      <td>0.755000</td>\n",
       "      <td>0.855000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.107143</td>\n",
       "      <td>0.073810</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.180952</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_base_patch16_224.augreg_in21k</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">vit_b,sup,in22k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>267.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.314362</td>\n",
       "      <td>9.204524</td>\n",
       "      <td>0.733000</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.447619</td>\n",
       "      <td>4.640042e-04</td>\n",
       "      <td>1.609524</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>230.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.268741</td>\n",
       "      <td>8.744079</td>\n",
       "      <td>0.658667</td>\n",
       "      <td>0.709333</td>\n",
       "      <td>...</td>\n",
       "      <td>14197122</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.669841</td>\n",
       "      <td>0.530952</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.676190</td>\n",
       "      <td>7.852726e-02</td>\n",
       "      <td>3.115079</td>\n",
       "      <td>14197122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>self-supervised (multimodal)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.289556</td>\n",
       "      <td>8.554016</td>\n",
       "      <td>0.609000</td>\n",
       "      <td>0.652000</td>\n",
       "      <td>...</td>\n",
       "      <td>2320000000</td>\n",
       "      <td>0.652381</td>\n",
       "      <td>0.680952</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.942857</td>\n",
       "      <td>0.707937</td>\n",
       "      <td>1.647349e-01</td>\n",
       "      <td>3.539683</td>\n",
       "      <td>2320000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224.augreg_in21k_ft_in1k</th>\n",
       "      <th>vit_b,sup,ink22k-in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>232.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.304043</td>\n",
       "      <td>7.766048</td>\n",
       "      <td>0.666000</td>\n",
       "      <td>0.811000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.042857</td>\n",
       "      <td>0.092857</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.135714</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_vit_base_patch16_224</th>\n",
       "      <th>vit_b,rob-sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised (robust)</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>347.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.475919</td>\n",
       "      <td>7.738222</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.872000</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.009524</td>\n",
       "      <td>0.021429</td>\n",
       "      <td>0.028571</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.174603</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>1.236257e-07</td>\n",
       "      <td>0.355556</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224.augreg_in21k_ft_in1k</th>\n",
       "      <th>vit_b,sup,ink22k-in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>236.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.282617</td>\n",
       "      <td>7.513095</td>\n",
       "      <td>0.730000</td>\n",
       "      <td>0.783000</td>\n",
       "      <td>...</td>\n",
       "      <td>15478289</td>\n",
       "      <td>0.061905</td>\n",
       "      <td>0.097619</td>\n",
       "      <td>0.140476</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.209524</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>2.879747e-05</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>15478289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_clip_224.laion2b_ft_in1k</th>\n",
       "      <th>vit_b,clip,laion2b</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>large</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.053082</td>\n",
       "      <td>5.820127</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.558000</td>\n",
       "      <td>...</td>\n",
       "      <td>2321281167</td>\n",
       "      <td>0.230952</td>\n",
       "      <td>0.152381</td>\n",
       "      <td>0.098413</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.482540</td>\n",
       "      <td>0.403175</td>\n",
       "      <td>6.737992e-04</td>\n",
       "      <td>1.367460</td>\n",
       "      <td>2321281167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>36 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                                                                                                                                                         TOTAL  \\\n",
       "metric                                                                                                                                                                          borda   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy              \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  978.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  835.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  803.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  767.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  798.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  846.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  657.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  792.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  735.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  782.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  707.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  809.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  581.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  545.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  701.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  628.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  497.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  531.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  627.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  638.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  512.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  483.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  509.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  397.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  325.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  366.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  306.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  344.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  367.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  267.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  230.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  216.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  232.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  347.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  236.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  158.0   \n",
       "\n",
       "dataset                                                                                                                                                                                      \\\n",
       "metric                                                                                                                                                                         nan_geom_cnt   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                    \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)            1   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)            1   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)            0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)            0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)            0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)            0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)            0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)            0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)            0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)            0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)            0   \n",
       "\n",
       "dataset                                                                                                                                                                                     \\\n",
       "metric                                                                                                                                                                         nan_sum_cnt   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)           1   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)           1   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)           0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)           0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)           0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)           0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)           0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)           0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)           0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)           0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)           0   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                         rank_borda   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)        1.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)        3.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)        5.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)        9.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)        6.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)        2.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       13.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)        7.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)       10.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)        8.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)       11.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)        4.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)       17.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)       18.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)       12.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)       15.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)       22.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)       19.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)       16.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)       14.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)       20.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)       23.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)       21.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       24.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       29.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)       26.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)       30.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)       28.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)       25.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       31.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       34.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)       35.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       33.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)       27.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       32.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)       36.0   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                         rank_geom   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)       1.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)       6.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      16.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)       4.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)      17.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      10.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)       7.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)       8.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)       2.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      19.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)       3.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)      11.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      12.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)      18.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)       5.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)      20.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      14.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)      13.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)      21.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)      22.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)      15.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)       9.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)      27.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      24.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      23.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)      35.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)      29.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)      28.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)      26.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      30.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      34.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)      32.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      31.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)      25.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      33.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)      36.0   \n",
       "\n",
       "dataset                                                                                                                                                                                  \\\n",
       "metric                                                                                                                                                                         rank_sum   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      1.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      2.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)      3.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)      4.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)      5.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)      6.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)      7.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)      8.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)      9.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)     10.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)     11.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)     12.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)     13.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)     14.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)     15.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)     16.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)     17.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)     18.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)     19.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)     20.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)     21.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)     22.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)     23.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)     24.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)     25.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)     26.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)     27.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)     28.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)     29.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)     30.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)     31.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)     32.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)     33.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)     34.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)     35.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)     36.0   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                         score_geom   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   1.320645   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   1.001878   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.651343   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   1.037708   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.651285   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.815672   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.962976   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)   0.955159   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   1.139192   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.623310   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   1.073895   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.799936   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.770802   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)   0.642220   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   1.005809   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   0.564483   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.716907   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.730333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.563928   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   0.562490   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.663465   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.832322   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.428039   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.526426   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.530873   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.053784   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.325365   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   0.406625   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   0.438403   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.314362   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.268741   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.289556   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.304043   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   0.475919   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.282617   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   0.053082   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                          score_sum   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  19.789302   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  19.396968   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  18.235889   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  18.053905   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  17.599524   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  17.016397   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  16.772365   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  16.631302   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  16.434905   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  16.420429   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  16.405762   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  15.992889   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  15.419238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  15.240730   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  15.127683   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  14.625873   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  14.510619   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  14.404333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  14.390857   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  13.771698   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  13.656476   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  13.163381   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  12.831397   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  12.497778   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  11.306857   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  10.922762   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  10.652857   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   9.757952   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   9.284619   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   9.204524   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   8.744079   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   8.554016   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   7.766048   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   7.738222   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   7.513095   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   5.820127   \n",
       "\n",
       "dataset                                                                                                                                                                        caltech101  \\\n",
       "metric                                                                                                                                                                             L1_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.860000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.803000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.794000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.836000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.844000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.857000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.816000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)   0.748000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.800000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.838000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.816000   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.844000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.784000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)   0.776000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.842000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   0.812000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.770000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.782000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.825000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   0.736000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.832000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.810000   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.757333   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.717333   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.681000   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.155000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.587000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   0.794000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   0.755000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.733000   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.658667   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.609000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.666000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   0.760000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.730000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   0.460000   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                            L2_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.888000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.854667   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.856000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.866667   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.890000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.898000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.840000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.892000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.881333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.871000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.864000   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.887000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.828000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.820000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.888000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.843000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.792000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.852000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.860000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.872000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.865000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.843000   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.829000   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.748000   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.756000   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.600000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.767000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.816000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.855000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.802000   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.709333   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.652000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.811000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.872000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.783000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.558000   \n",
       "\n",
       "dataset                                                                                                                                                                         ...  \\\n",
       "metric                                                                                                                                                                          ...   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy      ...   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  ...   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  ...   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  ...   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  ...   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  ...   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  ...   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  ...   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  ...   \n",
       "\n",
       "dataset                                                                                                                                                                                   stanford_cars  \\\n",
       "metric                                                                                                                                                                         volume_pre_training_data   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                                \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 14197122   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                 14197122   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 15478289   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                 10281167   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                  9000000   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 14197122   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)               2321281167   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 15478289   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)               2330281167   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                 10281167   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                  9000000   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                 14197122   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                  1281167   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                  1281167   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                  1281167   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                  1281167   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)               2330281167   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 14197122   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 14197122   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)               2321281167   \n",
       "\n",
       "dataset                                                                                                                                                                        uc-merced-land-use-dataset  \\\n",
       "metric                                                                                                                                                                                             L1_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                   0.823810   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.749206   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.519048   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.854762   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                   0.073810   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                   0.000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.833333   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)                   0.664286   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                   0.819048   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                   0.102381   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                   0.792857   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                   0.159524   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.690476   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)                   0.585714   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                   0.800000   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)                   0.416667   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                   0.733333   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                   0.650000   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                   0.000000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)                   0.104762   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                   0.609524   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                   0.742857   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)                   0.023810   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.680952   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.685714   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                   0.000000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                   0.366667   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)                   0.419048   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)                   0.000000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.028571   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.380952   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)                   0.652381   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                   0.000000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)                   0.009524   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                   0.061905   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)                   0.230952   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                            L2_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.900000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.888095   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.520635   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.876190   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.800000   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.879365   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.880952   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.895238   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.009524   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.866667   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.136508   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.857143   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.809524   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.892063   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.415873   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.866667   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.814286   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.161905   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.676190   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.869841   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.030952   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.795238   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.809524   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.000000   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.704762   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.495238   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.000000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.238095   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.669841   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.680952   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.000000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.021429   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.097619   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.152381   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                          Linf_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.800000   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.800000   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.193651   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.721429   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.761905   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.738095   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.825397   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.802381   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.740476   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.085714   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.757143   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.733333   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.788095   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.276190   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.759524   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.707143   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.000000   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.121429   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.609524   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.759524   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.050000   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.634921   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.692857   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.269841   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.633333   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.414286   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.000000   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.228571   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.530952   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.555556   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.000000   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.028571   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.140476   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.098413   \n",
       "\n",
       "dataset                                                                                                                                                                                \\\n",
       "metric                                                                                                                                                                          borda   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy              \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  170.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  151.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   96.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  148.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  126.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   55.0   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  138.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  158.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  167.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   74.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  149.0   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   45.0   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  127.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  111.0   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  169.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   66.0   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  128.0   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  105.0   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   19.0   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   43.0   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   87.0   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  135.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   26.0   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  109.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  110.0   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   44.0   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   89.0   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   72.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)    7.0   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   57.0   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   77.0   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   96.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)    7.0   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   28.0   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   41.0   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   52.0   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                         clean_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.966667   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.952381   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.955556   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.954762   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.976190   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.952381   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.942857   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  0.971429   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.971429   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.952381   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  0.959524   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.219048   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.945238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  0.952381   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.976190   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  0.569048   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  0.938095   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.928571   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.480952   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.164286   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  0.866667   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.950000   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.088095   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.942857   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.935714   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.873016   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  0.933333   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  0.642857   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.107143   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.666667   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.857143   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.942857   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.042857   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.174603   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.209524   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  0.482540   \n",
       "\n",
       "dataset                                                                                                                                                                                    \\\n",
       "metric                                                                                                                                                                         common_acc   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.863492   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.847619   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.783333   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.838095   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.814286   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.806349   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.802381   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)   0.861905   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.857143   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)   0.857143   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)   0.861905   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.188095   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.795238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)   0.777778   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.866667   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)   0.421429   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)   0.800000   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.783333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)   0.378571   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)   0.126984   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)   0.695238   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.796825   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.082540   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.790476   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.785714   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)   0.645238   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)   0.738095   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)   0.559524   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)   0.073810   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.447619   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.676190   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)   0.707937   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)   0.092857   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)   0.121429   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)   0.161905   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)   0.403175   \n",
       "\n",
       "dataset                                                                                                                                                                                       \\\n",
       "metric                                                                                                                                                                                  geom   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                     \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  4.951017e-01   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.296971e-01   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  3.917079e-02   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  4.323401e-01   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  3.576140e-02   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000e+00   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  4.091918e-01   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  4.044271e-01   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.898830e-01   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  0.000000e+00   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.207975e-01   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  7.690471e-05   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  3.368357e-01   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  2.575628e-01   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  4.758292e-01   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  1.147706e-02   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  3.622695e-01   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  2.722446e-01   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.000000e+00   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  4.296681e-05   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  1.513687e-01   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  3.715125e-01   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  2.679353e-07   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  2.562525e-01   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  2.827642e-01   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  0.000000e+00   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  1.127445e-01   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  3.092505e-02   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.000000e+00   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  4.640042e-04   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  7.852726e-02   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  1.647349e-01   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.000000e+00   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  1.236257e-07   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  2.879747e-05   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  6.737992e-04   \n",
       "\n",
       "dataset                                                                                                                                                                                   \\\n",
       "metric                                                                                                                                                                               sum   \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                 \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  4.353968   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.237302   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  2.972222   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  4.245238   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  3.426190   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  1.758730   \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  4.196032   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)  4.203968   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.345238   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)  1.921429   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)  4.221429   \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.788889   \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.045238   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)  3.858730   \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  4.323016   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)  2.099206   \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)  4.097619   \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  3.883333   \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)  0.859524   \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)  0.679365   \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)  3.457143   \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  4.119048   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)  0.275397   \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  3.844444   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  3.909524   \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)  1.788095   \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)  3.376190   \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)  2.530952   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)  0.180952   \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  1.609524   \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  3.115079   \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)  3.539683   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)  0.135714   \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)  0.355556   \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)  0.671429   \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)  1.367460   \n",
       "\n",
       "dataset                                                                                                                                                                                                  \n",
       "metric                                                                                                                                                                         volume_pre_training_data  \n",
       "backbone                                        backbone_name                        loss_function pre_training_strategy        model_type          model_size ft_strategy                               \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 14197122  \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000  \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               TRADES_v2     self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000  \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                 14197122  \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                 15478289  \n",
       "swin_base_patch4_window7_224.ms_in22k_ft_in1k   swin_b,sup,ink22k-in1k               CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              TRADES_v2     supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                 10281167  \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  TRADES_v2     supervised                   fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  TRADES_v2     supervised                   hybrid              large      FFT (50 epochs)                  9000000  \n",
       "convnext_base.fb_in22k                          convnext_b,sup,in22k                 CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 14197122  \n",
       "CLIP-convnext_base_w-laion2B-s13B-b82K          convnext_b,clip,laion2b              CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)               2320000000  \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   TRADES_v2     hybrid                       fully attention     large      FFT (50 epochs)               2321281167  \n",
       "convnext_base.fb_in22k_ft_in1k                  convnext_b,sup,in22k-in1k            CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                 15478289  \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k TRADES_v2     hybrid                       fully convolutional large      FFT (50 epochs)               2330281167  \n",
       "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K  convnext_b,clip,laiona               CLASSIC_AT    self-supervised (multimodal) fully convolutional large      FFT (50 epochs)                900000000  \n",
       "coatnet_2_rw_224.sw_in12k_ft_in1k               coatnet_2,sup,in12k-in1k             CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                 10281167  \n",
       "convnext_base.fb_in1k                           convnext_b,sup,in1k                  CLASSIC_AT    supervised                   fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "robust_convnext_base                            convnext_b,rob-sup,in1k              CLASSIC_AT    supervised (robust)          fully convolutional large      FFT (50 epochs)                  1281167  \n",
       "coatnet_2_rw_224.sw_in12k                       coatnet_2,sup,in12k                  CLASSIC_AT    supervised                   hybrid              large      FFT (50 epochs)                  9000000  \n",
       "eva02_base_patch14_224.mim_in22k                eva02_b,mim,ink22k                   CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                 14197122  \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   TRADES_v2     self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000  \n",
       "vit_base_patch16_224.augreg_in1k                vit_b,sup,in1k                       TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                  1281167  \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                  1281167  \n",
       "vit_base_patch16_224.mae                        vit_b,mae,in1k                       TRADES_v2     self-supervised              fully attention     large      FFT (50 epochs)                  1281167  \n",
       "                                                                                     CLASSIC_AT    self-supervised              fully attention     large      FFT (50 epochs)                  1281167  \n",
       "convnext_base.clip_laion2b_augreg_ft_in12k_in1k convnext_b,hybrid,laion2b-in12k-in1k CLASSIC_AT    hybrid                       fully convolutional large      FFT (50 epochs)               2330281167  \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   TRADES_v2     supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167  \n",
       "vit_base_patch16_224.augreg_in21k               vit_b,sup,in22k                      TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 14197122  \n",
       "                                                                                     CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 14197122  \n",
       "vit_base_patch16_clip_224.laion2b               vit_b,clip,laion2b                   CLASSIC_AT    self-supervised (multimodal) fully attention     large      FFT (50 epochs)               2320000000  \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                TRADES_v2     supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "robust_vit_base_patch16_224                     vit_b,rob-sup,in1k                   CLASSIC_AT    supervised (robust)          fully attention     large      FFT (50 epochs)                  1281167  \n",
       "vit_base_patch16_224.augreg_in21k_ft_in1k       vit_b,sup,ink22k-in1k                CLASSIC_AT    supervised                   fully attention     large      FFT (50 epochs)                 15478289  \n",
       "vit_base_patch16_clip_224.laion2b_ft_in1k       vit_b,clip,laion2b                   CLASSIC_AT    hybrid                       fully attention     large      FFT (50 epochs)               2321281167  \n",
       "\n",
       "[36 rows x 62 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_database import process_grouped_df, process_rankings, compute_odds_ratio_by_group\n",
    "\n",
    "size = \"large\"\n",
    "grouped_df = process_grouped_df(final_data, size)\n",
    "grouped_df = process_rankings(grouped_df)\n",
    "grouped_df\n",
    "# grouped_df.sort_values(by=\"sum\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values: 0.49%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th colspan=\"8\" halign=\"left\">TOTAL</th>\n",
       "      <th colspan=\"2\" halign=\"left\">caltech101</th>\n",
       "      <th>...</th>\n",
       "      <th>stanford_cars</th>\n",
       "      <th colspan=\"9\" halign=\"left\">uc-merced-land-use-dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>borda</th>\n",
       "      <th>nan_geom_cnt</th>\n",
       "      <th>nan_sum_cnt</th>\n",
       "      <th>rank_borda</th>\n",
       "      <th>rank_geom</th>\n",
       "      <th>rank_sum</th>\n",
       "      <th>score_geom</th>\n",
       "      <th>score_sum</th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>...</th>\n",
       "      <th>volume_pre_training_data</th>\n",
       "      <th>L1_acc</th>\n",
       "      <th>L2_acc</th>\n",
       "      <th>Linf_acc</th>\n",
       "      <th>borda</th>\n",
       "      <th>clean_acc</th>\n",
       "      <th>common_acc</th>\n",
       "      <th>geom</th>\n",
       "      <th>sum</th>\n",
       "      <th>volume_pre_training_data</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>backbone</th>\n",
       "      <th>backbone_name</th>\n",
       "      <th>loss_function</th>\n",
       "      <th>pre_training_strategy</th>\n",
       "      <th>model_type</th>\n",
       "      <th>model_size</th>\n",
       "      <th>ft_strategy</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>edgenext_small.usi_in1k</th>\n",
       "      <th>edgenetx_s,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>370.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495538</td>\n",
       "      <td>14.662857</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.811</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.702381</td>\n",
       "      <td>0.361905</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.938095</td>\n",
       "      <td>0.740476</td>\n",
       "      <td>0.129487</td>\n",
       "      <td>3.476190</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deit_tiny_patch16_224.fb_in1k</th>\n",
       "      <th>deit_t,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325177</td>\n",
       "      <td>11.266238</td>\n",
       "      <td>0.656</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.478571</td>\n",
       "      <td>0.709524</td>\n",
       "      <td>0.561905</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.919048</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.121495</td>\n",
       "      <td>3.361905</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regnetx_004.pycls_in1k</th>\n",
       "      <th>regnetx_004,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>252.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.437787</td>\n",
       "      <td>10.845762</td>\n",
       "      <td>0.568</td>\n",
       "      <td>0.660</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.692857</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.736508</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0.949206</td>\n",
       "      <td>0.759524</td>\n",
       "      <td>0.294316</td>\n",
       "      <td>3.938095</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coat_tiny.in1k</th>\n",
       "      <th>coat_t,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>261.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.201988</td>\n",
       "      <td>9.891683</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.625397</td>\n",
       "      <td>0.704762</td>\n",
       "      <td>0.523810</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.747619</td>\n",
       "      <td>0.167673</td>\n",
       "      <td>3.573016</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regnetx_004.pycls_in1k</th>\n",
       "      <th>regnetx_004,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>158.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.057308</td>\n",
       "      <td>9.000444</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.468</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.011905</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.923810</td>\n",
       "      <td>0.663492</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.761111</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenetv3_large_100.ra_in1k</th>\n",
       "      <th>mobilenet_v3,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.038294</td>\n",
       "      <td>8.869429</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.481</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.219048</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.516667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.721429</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edgenext_small.usi_in1k</th>\n",
       "      <th>edgenetx_s,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>276.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.291578</td>\n",
       "      <td>8.825714</td>\n",
       "      <td>0.764</td>\n",
       "      <td>0.811</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.797619</td>\n",
       "      <td>0.802381</td>\n",
       "      <td>0.630952</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.935714</td>\n",
       "      <td>0.752381</td>\n",
       "      <td>0.284285</td>\n",
       "      <td>3.919048</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilenetv3_large_100.ra_in1k</th>\n",
       "      <th>mobilenet_v3,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>208.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.141107</td>\n",
       "      <td>8.747540</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.646</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.433333</td>\n",
       "      <td>0.178571</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.859524</td>\n",
       "      <td>0.463492</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>1.965873</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deit_tiny_patch16_224.fb_in1k</th>\n",
       "      <th>deit_t,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully attention</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>167.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.280623</td>\n",
       "      <td>7.611524</td>\n",
       "      <td>0.646</td>\n",
       "      <td>0.721</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.659524</td>\n",
       "      <td>0.547619</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.878571</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.098777</td>\n",
       "      <td>3.209524</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>coat_tiny.in1k</th>\n",
       "      <th>coat_t,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>158.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.304666</td>\n",
       "      <td>5.544095</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.789</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.171429</td>\n",
       "      <td>0.154762</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.359524</td>\n",
       "      <td>0.276190</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>1.104762</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilevit-small</th>\n",
       "      <th>mobilevit_s,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>177.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.035784</td>\n",
       "      <td>4.924286</td>\n",
       "      <td>0.427</td>\n",
       "      <td>0.515</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.192857</td>\n",
       "      <td>0.280952</td>\n",
       "      <td>0.261905</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.380952</td>\n",
       "      <td>0.297619</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>1.414286</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">efficientnet-b0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">efficientnet_b0,sup,in1k</th>\n",
       "      <th>CLASSIC_AT</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>124.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.012939</td>\n",
       "      <td>3.946429</td>\n",
       "      <td>0.343</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.078571</td>\n",
       "      <td>0.161905</td>\n",
       "      <td>0.185714</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.402381</td>\n",
       "      <td>0.292857</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>1.121429</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>fully convolutional</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>3.465190</td>\n",
       "      <td>0.246</td>\n",
       "      <td>0.297</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.030952</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.080952</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.319048</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.992857</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobilevit-small</th>\n",
       "      <th>mobilevit_s,sup,in1k</th>\n",
       "      <th>TRADES_v2</th>\n",
       "      <th>supervised</th>\n",
       "      <th>hybrid</th>\n",
       "      <th>small</th>\n",
       "      <th>FFT (50 epochs)</th>\n",
       "      <td>139.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>3.295667</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.454</td>\n",
       "      <td>...</td>\n",
       "      <td>1281167</td>\n",
       "      <td>0.121429</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.245238</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.645238</td>\n",
       "      <td>0.388095</td>\n",
       "      <td>0.001989</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>1281167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14 rows  62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "dataset                                                                                                                                    TOTAL  \\\n",
       "metric                                                                                                                                     borda   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy              \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  370.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  256.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  252.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  261.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  158.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  177.0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  276.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  208.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  167.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  158.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  177.0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  124.0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   91.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  139.0   \n",
       "\n",
       "dataset                                                                                                                                                 \\\n",
       "metric                                                                                                                                    nan_geom_cnt   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                    \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)            0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)            0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)            0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)            2   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)            0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)            0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)            1   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)            0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)            0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)            1   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)            0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)            0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)            0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)            1   \n",
       "\n",
       "dataset                                                                                                                                                \\\n",
       "metric                                                                                                                                    nan_sum_cnt   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)           0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)           0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)           0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)           2   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)           0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)           0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)           1   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)           0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)           0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)           1   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)           0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)           0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)           0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)           1   \n",
       "\n",
       "dataset                                                                                                                                               \\\n",
       "metric                                                                                                                                    rank_borda   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)        1.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)        4.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)        5.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)        3.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)       10.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)        7.0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)        2.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)        6.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)        9.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)       10.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)        7.0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)       13.0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)       14.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)       12.0   \n",
       "\n",
       "dataset                                                                                                                                              \\\n",
       "metric                                                                                                                                    rank_geom   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                 \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)       1.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)       3.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)       2.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)       7.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)       9.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      10.0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)       5.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)       8.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)       6.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)       4.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)      11.0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)      12.0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      13.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)      14.0   \n",
       "\n",
       "dataset                                                                                                                                             \\\n",
       "metric                                                                                                                                    rank_sum   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)      1.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)      2.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)      3.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)      4.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      5.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      6.0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)      7.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)      8.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)      9.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)     10.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)     11.0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)     12.0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)     13.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)     14.0   \n",
       "\n",
       "dataset                                                                                                                                               \\\n",
       "metric                                                                                                                                    score_geom   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   0.495538   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)   0.325177   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   0.437787   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   0.201988   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   0.057308   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   0.038294   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   0.291578   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   0.141107   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)   0.280623   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   0.304666   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   0.035784   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   0.012939   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   0.002835   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   0.002004   \n",
       "\n",
       "dataset                                                                                                                                               \\\n",
       "metric                                                                                                                                     score_sum   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  14.662857   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  11.266238   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  10.845762   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   9.891683   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   9.000444   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   8.869429   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   8.825714   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   8.747540   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)   7.611524   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   5.544095   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   4.924286   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   3.946429   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   3.465190   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   3.295667   \n",
       "\n",
       "dataset                                                                                                                                   caltech101  \\\n",
       "metric                                                                                                                                        L1_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)      0.794   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)      0.656   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)      0.568   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)        NaN   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      0.536   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      0.652   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)      0.764   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)      0.724   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)      0.646   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)      0.749   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)      0.427   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)      0.343   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)      0.246   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)      0.340   \n",
       "\n",
       "dataset                                                                                                                                           \\\n",
       "metric                                                                                                                                    L2_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy              \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.811   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  0.731   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.660   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)    NaN   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.468   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.481   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.811   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.646   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  0.721   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.789   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.515   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.414   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.297   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.454   \n",
       "\n",
       "dataset                                                                                                                                    ...  \\\n",
       "metric                                                                                                                                     ...   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy      ...   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  ...   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  ...   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  ...   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  ...   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  ...   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  ...   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  ...   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  ...   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  ...   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  ...   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  ...   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  ...   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  ...   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  ...   \n",
       "\n",
       "dataset                                                                                                                                              stanford_cars  \\\n",
       "metric                                                                                                                                    volume_pre_training_data   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                                \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                  1281167   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)                  1281167   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                  1281167   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                  1281167   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                  1281167   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                  1281167   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                  1281167   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                  1281167   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)                  1281167   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                  1281167   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                  1281167   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                  1281167   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                  1281167   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                  1281167   \n",
       "\n",
       "dataset                                                                                                                                   uc-merced-land-use-dataset  \\\n",
       "metric                                                                                                                                                        L1_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                                  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                   0.733333   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)                   0.478571   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                   0.692857   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                   0.625397   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                   0.161905   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                   0.219048   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                   0.797619   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                   0.433333   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)                   0.495238   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                   0.142857   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                   0.192857   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                   0.078571   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                   0.030952   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                   0.121429   \n",
       "\n",
       "dataset                                                                                                                                              \\\n",
       "metric                                                                                                                                       L2_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                 \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.702381   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  0.709524   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.800000   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.704762   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.011905   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.023810   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.802381   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.178571   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  0.659524   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.171429   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.280952   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.161905   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.095238   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.266667   \n",
       "\n",
       "dataset                                                                                                                                              \\\n",
       "metric                                                                                                                                     Linf_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                 \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.361905   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  0.561905   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.736508   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.523810   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.000000   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.000000   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.630952   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.030952   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  0.547619   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.154762   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.261905   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.185714   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.080952   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.245238   \n",
       "\n",
       "dataset                                                                                                                                          \\\n",
       "metric                                                                                                                                    borda   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy             \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  54.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  51.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  65.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  58.0   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  25.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  30.0   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  64.0   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  29.0   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  45.0   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  16.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  27.0   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  17.0   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  16.0   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  27.0   \n",
       "\n",
       "dataset                                                                                                                                              \\\n",
       "metric                                                                                                                                    clean_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                 \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.938095   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  0.919048   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.949206   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.971429   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.923810   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.961905   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.935714   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.859524   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  0.878571   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.359524   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.380952   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.402381   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.466667   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.645238   \n",
       "\n",
       "dataset                                                                                                                                               \\\n",
       "metric                                                                                                                                    common_acc   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   0.740476   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)   0.692857   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   0.759524   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   0.747619   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   0.663492   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   0.516667   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   0.752381   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   0.463492   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)   0.628571   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   0.276190   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)   0.297619   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)   0.292857   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)   0.319048   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)   0.388095   \n",
       "\n",
       "dataset                                                                                                                                              \\\n",
       "metric                                                                                                                                         geom   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                 \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.129487   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  0.121495   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.294316   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.167673   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.000000   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.000000   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.284285   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.000954   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  0.098777   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.000376   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  0.001609   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  0.000278   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.000036   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  0.001989   \n",
       "\n",
       "dataset                                                                                                                                              \\\n",
       "metric                                                                                                                                          sum   \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                 \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  3.476190   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)  3.361905   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  3.938095   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  3.573016   \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  1.761111   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  1.721429   \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  3.919048   \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  1.965873   \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)  3.209524   \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  1.104762   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)  1.414286   \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)  1.121429   \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)  0.992857   \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)  1.666667   \n",
       "\n",
       "dataset                                                                                                                                                             \n",
       "metric                                                                                                                                    volume_pre_training_data  \n",
       "backbone                      backbone_name            loss_function pre_training_strategy model_type          model_size ft_strategy                               \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                  1281167  \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          TRADES_v2     supervised            fully attention     small      FFT (50 epochs)                  1281167  \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                  1281167  \n",
       "coat_tiny.in1k                coat_t,sup,in1k          TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                  1281167  \n",
       "regnetx_004.pycls_in1k        regnetx_004,sup,in1k     TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                  1281167  \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                  1281167  \n",
       "edgenext_small.usi_in1k       edgenetx_s,sup,in1k      CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                  1281167  \n",
       "mobilenetv3_large_100.ra_in1k mobilenet_v3,sup,in1k    CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                  1281167  \n",
       "deit_tiny_patch16_224.fb_in1k deit_t,sup,in1k          CLASSIC_AT    supervised            fully attention     small      FFT (50 epochs)                  1281167  \n",
       "coat_tiny.in1k                coat_t,sup,in1k          CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                  1281167  \n",
       "mobilevit-small               mobilevit_s,sup,in1k     CLASSIC_AT    supervised            hybrid              small      FFT (50 epochs)                  1281167  \n",
       "efficientnet-b0               efficientnet_b0,sup,in1k CLASSIC_AT    supervised            fully convolutional small      FFT (50 epochs)                  1281167  \n",
       "                                                       TRADES_v2     supervised            fully convolutional small      FFT (50 epochs)                  1281167  \n",
       "mobilevit-small               mobilevit_s,sup,in1k     TRADES_v2     supervised            hybrid              small      FFT (50 epochs)                  1281167  \n",
       "\n",
       "[14 rows x 62 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from process_database import process_grouped_df, process_rankings, compute_odds_ratio_by_group\n",
    "\n",
    "grouped_df = process_grouped_df(final_data, size=\"small\")\n",
    "grouped_df = process_rankings(grouped_df)\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of NaN values: 3.75%\n",
      "Percentage of NaN values: 3.75%\n",
      "Percentage of NaN values: 3.75%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from process_database import process_grouped_df, process_rankings, compute_odds_ratio_by_group\n",
    "import pandas as pd\n",
    "\n",
    "odds_loss_list = []\n",
    "odds_architecture_list = []\n",
    "odds_pretraining_list = []\n",
    "\n",
    "for size_id,size in [ (0,'small'),(1,'medium'),(2,'large')]:\n",
    "    grouped_df = process_grouped_df(final_data, size)\n",
    "    grouped_df = process_rankings(grouped_df)\n",
    "\n",
    "    odds_df = grouped_df['TOTAL']\n",
    "    odds_df = odds_df.reset_index()\n",
    "    odds_df.to_csv(\"./odds_ratio.csv\")\n",
    "\n",
    "    # Define tier1 threshold based on the number of rows\n",
    "    n_rows = odds_df.shape[0]\n",
    "    top_k = int(np.ceil(0.33 * n_rows))  # top 10% as tier1\n",
    "\n",
    "    # Apply tier1 flag\n",
    "    odds_df[\"in_tier1\"] = 0\n",
    "    odds_df.loc[odds_df.sort_values(by=\"score_sum\", ascending=False).head(top_k).index, \"in_tier1\"] = 1\n",
    "\n",
    "    # Compute odds ratios for model_type and loss_function\n",
    "    odds_model_type = compute_odds_ratio_by_group(odds_df, \"model_type\")\n",
    "    odds_pretrain_type = compute_odds_ratio_by_group(odds_df, \"pre_training_strategy\")\n",
    "    odds_loss_function = compute_odds_ratio_by_group(odds_df, \"loss_function\")\n",
    "    odds_loss_function['size'] = size\n",
    "    odds_pretrain_type['size'] = size\n",
    "    odds_model_type['size'] = size\n",
    "\n",
    "    odds_loss_list.append(odds_loss_function)\n",
    "    odds_architecture_list.append(odds_model_type)\n",
    "    odds_pretraining_list.append(odds_pretrain_type)\n",
    "\n",
    "combined_odds_loss = pd.concat(odds_loss_list, axis=0)\n",
    "combined_odds_architecture = pd.concat(odds_architecture_list, axis=0)\n",
    "combined_odds_pretraining = pd.concat(odds_pretraining_list, axis=0)\n",
    "\n",
    "combined_odds_pretraining = combined_odds_pretraining.fillna(0)\n",
    "combined_odds_pretraining = combined_odds_pretraining[combined_odds_pretraining[\"size\"].isin([\"medium\", \"large\"])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "loss_function=TRADES_v2<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "TRADES_v2",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "TRADES_v2",
         "offsetgroup": "TRADES_v2",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "8<br>(p=0.116)",
          "1.83<br>(p=0.441)",
          "5<br>(p=0.041)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          8,
          1.8333333333333333,
          5
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "loss_function=CLASSIC_AT<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "CLASSIC_AT",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "CLASSIC_AT",
         "offsetgroup": "CLASSIC_AT",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.12<br>(p=0.116)",
          "0.55<br>(p=0.441)",
          "0.20<br>(p=0.041)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.125,
          0.5454545454545454,
          0.2
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255,255,255,1)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 12
         },
         "title": {
          "text": "loss_function"
         },
         "tracegroupgap": 0,
         "xanchor": "right",
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "uniformtext": {
         "minsize": 11,
         "mode": "show"
        },
        "width": 450,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": false,
         "title": {
          "text": "Model Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "range": [
          0,
          25
         ],
         "showgrid": true,
         "title": {
          "text": "Odds Ratio"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "model_type=hybrid<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "hybrid",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "hybrid",
         "offsetgroup": "hybrid",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.20<br>(p=0.217)",
          "2.11<br>(p=0.611)",
          "0.21<br>(p=0.310)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.2,
          2.111111111111111,
          0.20833333333333334
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "model_type=fully attention<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "fully attention",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "fully attention",
         "offsetgroup": "fully attention",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "2<br>(p=0.653)",
          "0.11<br>(p=0.016)",
          "1.65<br>(p=0.481)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          2,
          0.10714285714285714,
          1.6545454545454545
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "model_type=fully convolutional<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "fully convolutional",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "fully convolutional",
         "offsetgroup": "fully convolutional",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "3<br>(p=0.341)",
          "7<br>(p=0.024)",
          "1.19<br>(p=0.809)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "small",
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          3,
          7,
          1.1904761904761905
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255,255,255,1)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 12
         },
         "title": {
          "text": "model_type"
         },
         "tracegroupgap": 0,
         "xanchor": "right",
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "uniformtext": {
         "minsize": 7,
         "mode": "show"
        },
        "width": 450,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": false,
         "title": {
          "text": "Model Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "range": [
          0,
          25
         ],
         "showgrid": true,
         "title": {
          "text": "Odds Ratio"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=supervised<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "supervised",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "supervised",
         "offsetgroup": "supervised",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.64<br>(p=0.585)",
          "0.60<br>(p=0.481)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.6428571428571429,
          0.6043956043956044
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=supervised (robust)<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "supervised (robust)",
         "marker": {
          "color": "#EF553B",
          "pattern": {
           "shape": ""
          }
         },
         "name": "supervised (robust)",
         "offsetgroup": "supervised (robust)",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "6<br>(p=0.069)",
          "0.64<br>(p=0.709)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          6,
          0.6363636363636364
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=self-supervised<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "self-supervised",
         "marker": {
          "color": "#00cc96",
          "pattern": {
           "shape": ""
          }
         },
         "name": "self-supervised",
         "offsetgroup": "self-supervised",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.20<br>(p=0.300)",
          "0.64<br>(p=0.709)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "medium",
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.2,
          0.6363636363636364
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=self-supervised (multimodal)<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "self-supervised (multimodal)",
         "marker": {
          "color": "#ab63fa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "self-supervised (multimodal)",
         "offsetgroup": "self-supervised (multimodal)",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "5<br>(p=0.059)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "large"
         ],
         "xaxis": "x",
         "y": [
          5
         ],
         "yaxis": "y"
        },
        {
         "alignmentgroup": "True",
         "cliponaxis": false,
         "hovertemplate": "pre_training_strategy=hybrid (multimodal)<br>size=%{x}<br>Odds Ratio=%{y}<br>text_label=%{text}<extra></extra>",
         "legendgroup": "hybrid (multimodal)",
         "marker": {
          "color": "#FFA15A",
          "pattern": {
           "shape": ""
          }
         },
         "name": "hybrid (multimodal)",
         "offsetgroup": "hybrid (multimodal)",
         "orientation": "v",
         "showlegend": true,
         "text": [
          "0.46<br>(p=0.630)"
         ],
         "textangle": -90,
         "textfont": {
          "color": "black",
          "family": "Arial"
         },
         "textposition": "outside",
         "type": "bar",
         "x": [
          "large"
         ],
         "xaxis": "x",
         "y": [
          0.4583333333333333
         ],
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "group",
        "height": 400,
        "legend": {
         "bgcolor": "rgba(255,255,255,1)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 12
         },
         "title": {
          "text": "pre_training_strategy"
         },
         "tracegroupgap": 0,
         "xanchor": "right",
         "yanchor": "top"
        },
        "margin": {
         "b": 0,
         "l": 0,
         "r": 0,
         "t": 0
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "uniformtext": {
         "minsize": 7,
         "mode": "show"
        },
        "width": 450,
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "showgrid": false,
         "title": {
          "text": "Model Size"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "gridcolor": "lightgrey",
         "range": [
          0,
          25
         ],
         "showgrid": true,
         "title": {
          "text": "Odds Ratio"
         }
        }
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "# Create mapping from numeric size to categorical label\n",
    "size_map = {\"small\":0, \"medium\":1, \"large\":2}\n",
    "\n",
    "# Convert numeric size columns to categorical labels\n",
    "combined_odds_loss[\"size_label\"] = combined_odds_loss[\"size\"].map(size_map)\n",
    "combined_odds_architecture[\"size_label\"] = combined_odds_architecture[\"size\"].map(size_map)\n",
    "combined_odds_pretraining[\"size_label\"] = combined_odds_pretraining[\"size\"].map(size_map)\n",
    "\n",
    "plots = [\n",
    "    (\"loss_function\", combined_odds_loss),\n",
    "    (\"model_type\", combined_odds_architecture),\n",
    "    (\"pre_training_strategy\", combined_odds_pretraining)\n",
    "]\n",
    "\n",
    "\n",
    "figs = []\n",
    "\n",
    "for var, plot_df in plots:\n",
    "\n",
    "    plot_df = plot_df.copy()\n",
    "    plot_df[\"odds_ratio\"] = plot_df[\"odds_ratio\"].replace(0, 0)\n",
    "\n",
    "    # plot_df[\"text_label\"] = plot_df.apply(\n",
    "    #     lambda row: (\n",
    "    #         f'{int(row[\"odds_ratio\"])}' if row[\"odds_ratio\"] == int(row[\"odds_ratio\"])\n",
    "    #         else f'{row[\"odds_ratio\"]:.2f}'\n",
    "    #     ) + f'  (p:{row[\"p_value\"]:.3f})',\n",
    "    #     axis=1\n",
    "    # )\n",
    "    plot_df[\"text_label\"] = plot_df.apply(\n",
    "        lambda row: f'{int(row[\"odds_ratio\"])}' if row[\"odds_ratio\"] == int(row[\"odds_ratio\"])\n",
    "        else f'{row[\"odds_ratio\"]:.2f}', axis=1 )\n",
    "    plot_df[\"text_label\"] = plot_df.apply(\n",
    "        lambda row: f'{row[\"text_label\"]}<br>(p={row[\"p_value\"]:.3f})', axis=1)\n",
    "            \n",
    "    fig = px.bar(\n",
    "        plot_df,\n",
    "        x=\"size\",\n",
    "        y=\"odds_ratio\",\n",
    "        color=var,\n",
    "        barmode=\"group\",\n",
    "        text=\"text_label\",\n",
    "        labels={\"size_label\": \"Model Size\", \"odds_ratio\": \"Odds Ratio\"},\n",
    "    )\n",
    "\n",
    "    fig.update_layout(yaxis=dict(range=[0, 25]),)\n",
    "\n",
    "    fig.update_traces(\n",
    "        textposition=\"outside\",\n",
    "        textangle=-90,  # Rotate text vertically\n",
    "        textfont=dict(\n",
    "            color=\"black\",\n",
    "            family=\"Arial\"\n",
    "        ),\n",
    "        cliponaxis=False\n",
    "    )\n",
    "\n",
    "    if var == 'loss_function':\n",
    "        fig.update_layout(\n",
    "        uniformtext_minsize=11,  # or your desired minimum font size\n",
    "        uniformtext_mode='show',  # force showing all text\n",
    "        )\n",
    "    else:\n",
    "        fig.update_layout(\n",
    "        uniformtext_minsize=7,  # or your desired minimum font size\n",
    "        uniformtext_mode='show',  # force showing all text\n",
    "        )\n",
    "\n",
    "\n",
    "\n",
    "    fig.update_layout(\n",
    "            margin=dict(l=0, r=0, t=0, b=0),  # remove all outer margins\n",
    "            width=450,    # in pixels (~2.5 inches at 96 DPI)\n",
    "            height=400,    # in pixels (~1.875 inches)\n",
    "            yaxis_title=\"Odds Ratio\",\n",
    "            xaxis_title=\"Model Size\",\n",
    "            legend_title_text=var,\n",
    "            \n",
    "            # White background\n",
    "            plot_bgcolor=\"white\",\n",
    "            paper_bgcolor=\"white\",\n",
    "            \n",
    "            # Light grey grid\n",
    "            xaxis=dict(showgrid=False, gridcolor=\"lightgrey\"),\n",
    "            yaxis=dict(showgrid=True, gridcolor=\"lightgrey\"),\n",
    "            \n",
    "            # Legend inside figure\n",
    "            legend=dict(    \n",
    "                font=dict(size=12),  # Adjust font size here \n",
    "                yanchor=\"top\",\n",
    "                xanchor=\"right\",\n",
    "                bgcolor=\"rgba(255,255,255,1)\",  # semi-transparent white box\n",
    "                bordercolor=\"lightgrey\",\n",
    "                borderwidth=1\n",
    "            )\n",
    "        )\n",
    "    fig.show()\n",
    "    fig.write_image(\"./paper_figures/oddsratio_{}_{}.png\".format(pn2,var), scale=3  )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "line": {
          "color": "#9e3303",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b_ft_in1k (TRADES_v2)",
         "r": [
          1.641714285714286,
          2.575857142857143,
          2.4633333333333334,
          4.657380952380953,
          3.902444444444444,
          1.641714285714286
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#8e8ac0",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K (TRADES_v2)",
         "r": [
          2.0030476190476194,
          2.5049682539682543,
          3.185984126984127,
          5.188555555555555,
          3.647333333333333,
          2.0030476190476194
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f3701b",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "swin_base_patch4_window7_224.ms_in22k_ft_in1k (TRADES_v2)",
         "r": [
          2.6397619047619045,
          2.566190476190476,
          2.9914285714285715,
          4.830761904761904,
          3.308095238095238,
          2.6397619047619045
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#fd8c3b",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "eva02_base_patch14_224.mim_in22k (TRADES_v2)",
         "r": [
          1.7624761904761905,
          2.627,
          3.2612380952380953,
          4.864857142857143,
          3.3379523809523812,
          1.7624761904761905
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#b03903",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b (TRADES_v2)",
         "r": [
          1.281142857142857,
          2.2386190476190477,
          2.226,
          3.8190952380952385,
          3.266539682539683,
          1.281142857142857
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f3701b",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "swin_base_patch4_window7_224.ms_in22k_ft_in1k (CLASSIC_AT)",
         "r": [
          1.743666666666667,
          2.366365079365079,
          2.7670952380952385,
          4.457857142857143,
          2.943380952380952,
          1.743666666666667
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#ec620f",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in1k (TRADES_v2)",
         "r": [
          1.5542857142857145,
          2.141238095238095,
          1.8439206349206347,
          3.7818571428571435,
          3.1764761904761905,
          1.5542857142857145
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#4f1f8b",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_convnext_base (TRADES_v2)",
         "r": [
          1.7849523809523808,
          2.1596190476190475,
          3.2573968253968255,
          4.541428571428572,
          3.0859047619047617,
          1.7849523809523808
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#9e9ac8",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion2B-s13B-b82K (TRADES_v2)",
         "r": [
          2.3152063492063495,
          2.1927619047619045,
          3.66,
          5.1943809523809525,
          2.9729523809523815,
          2.3152063492063495
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#674ba0",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k (TRADES_v2)",
         "r": [
          2.2261428571428574,
          2.18,
          3.5759999999999996,
          5.057666666666666,
          2.778492063492063,
          2.2261428571428574
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#ec620f",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in1k (CLASSIC_AT)",
         "r": [
          1.6133809523809526,
          2.0508571428571427,
          1.874190476190476,
          3.127714285714286,
          2.640714285714286,
          1.6133809523809526
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#9e9ac8",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion2B-s13B-b82K (CLASSIC_AT)",
         "r": [
          1.5124761904761905,
          2.137142857142857,
          2.767142857142857,
          4.016238095238095,
          2.5502380952380954,
          1.5124761904761905
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#c54102",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.mae (TRADES_v2)",
         "r": [
          0.244,
          1.3846666666666667,
          1.9228412698412698,
          4.0620158730158735,
          3.3092380952380953,
          0.244
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#5b3495",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k_ft_in1k (CLASSIC_AT)",
         "r": [
          1.3576666666666668,
          1.9860634920634923,
          2.681095238095238,
          3.9505238095238098,
          2.5333333333333337,
          1.3576666666666668
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#c54102",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.mae (CLASSIC_AT)",
         "r": [
          1.0303333333333333,
          1.8767619047619046,
          1.9003333333333332,
          3.168333333333333,
          2.677095238095238,
          1.0303333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#8e8ac0",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "CLIP-convnext_base_w-laion_aesthetic-s13B-b82K (CLASSIC_AT)",
         "r": [
          1.4209999999999998,
          1.994,
          2.5188571428571427,
          3.7970952380952383,
          2.4206666666666665,
          1.4209999999999998
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7e79b8",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.clip_laion2b_augreg_ft_in12k_in1k (TRADES_v2)",
         "r": [
          1.9113333333333333,
          1.891873015873016,
          2.6211904761904763,
          3.952047619047619,
          2.5784285714285713,
          1.9113333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#4f1f8b",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_convnext_base (CLASSIC_AT)",
         "r": [
          0.7857619047619047,
          1.665904761904762,
          2.6744285714285714,
          3.771952380952381,
          2.3656507936507936,
          0.7857619047619047
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f87f2c",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_vit_base_patch16_224 (TRADES_v2)",
         "r": [
          0.8570000000000001,
          1.4140000000000001,
          1.282,
          3.0621428571428573,
          2.669476190476191,
          0.8570000000000001
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#e25508",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k (TRADES_v2)",
         "r": [
          0.7805714285714286,
          1.406095238095238,
          1.2805714285714287,
          3.1346666666666665,
          2.602619047619048,
          0.7805714285714286
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#fd8c3b",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "eva02_base_patch14_224.mim_in22k (CLASSIC_AT)",
         "r": [
          1.3278571428571428,
          1.7268412698412698,
          2.2768571428571427,
          3.319,
          2.0548253968253967,
          1.3278571428571428
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7262ac",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in1k (TRADES_v2)",
         "r": [
          1.9413809523809524,
          1.2045238095238093,
          2.473,
          4.971380952380952,
          2.775142857142857,
          1.9413809523809524
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#5b3495",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k_ft_in1k (TRADES_v2)",
         "r": [
          1.3893333333333333,
          1.2389999999999999,
          2.707,
          5.011380952380952,
          2.7066825396825394,
          1.3893333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#e25508",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k (CLASSIC_AT)",
         "r": [
          1.1779523809523809,
          1.6521746031746032,
          1.4322857142857144,
          2.4564761904761903,
          2.0251904761904767,
          1.1779523809523809
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#b03903",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b (CLASSIC_AT)",
         "r": [
          1.3503809523809525,
          1.5679523809523812,
          1.4128888888888889,
          2.333190476190476,
          1.8896031746031747,
          1.3503809523809525
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#674ba0",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in22k (CLASSIC_AT)",
         "r": [
          0.7791904761904761,
          1.3965079365079365,
          2.7663809523809526,
          4.2587142857142855,
          1.979095238095238,
          0.7791904761904761
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#d84801",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k_ft_in1k (TRADES_v2)",
         "r": [
          0.7693333333333334,
          1.237,
          1.115,
          2.495857142857143,
          2.148857142857143,
          0.7693333333333334
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#f87f2c",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "robust_vit_base_patch16_224 (CLASSIC_AT)",
         "r": [
          0.9258571428571428,
          1.4007619047619049,
          1.3442380952380952,
          2.1749365079365077,
          1.8924285714285716,
          0.9258571428571428
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#d84801",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_224.augreg_in21k_ft_in1k (CLASSIC_AT)",
         "r": [
          0.8602380952380952,
          1.065952380952381,
          0.9944761904761905,
          2.4435238095238097,
          2.148904761904762,
          0.8602380952380952
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7262ac",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.fb_in1k (CLASSIC_AT)",
         "r": [
          0.5393333333333333,
          1.069,
          2.259666666666667,
          4.200619047619048,
          2.0175714285714283,
          0.5393333333333333
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#73c476",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k (CLASSIC_AT)",
         "r": [
          0.7731904761904762,
          1.002857142857143,
          2.4248571428571424,
          3.758,
          1.3952380952380952,
          0.7731904761904762
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#006428",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k_ft_in1k (TRADES_v2)",
         "r": [
          0.8670476190476191,
          1.1492380952380952,
          2.978714285714285,
          4.252428571428571,
          1.4051428571428572,
          0.8670476190476191
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#9e3303",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "vit_base_patch16_clip_224.laion2b_ft_in1k (CLASSIC_AT)",
         "r": [
          0.7599523809523809,
          0.9180476190476191,
          0.8100793650793651,
          1.8392063492063493,
          1.4928412698412696,
          0.7599523809523809
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#006428",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k_ft_in1k (CLASSIC_AT)",
         "r": [
          0.8240000000000001,
          1.0012857142857143,
          2.575142857142857,
          4.0525714285714285,
          1.3133333333333335,
          0.8240000000000001
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#7e79b8",
          "dash": "solid",
          "width": 2
         },
         "mode": "lines",
         "name": "convnext_base.clip_laion2b_augreg_ft_in12k_in1k (CLASSIC_AT)",
         "r": [
          0.726047619047619,
          1.0182380952380954,
          1.6612857142857145,
          2.5708571428571427,
          1.3645238095238095,
          0.726047619047619
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        },
        {
         "line": {
          "color": "#73c476",
          "dash": "dot",
          "width": 2
         },
         "mode": "lines",
         "name": "coatnet_2_rw_224.sw_in12k (TRADES_v2)",
         "r": [
          0.7928571428571428,
          0.8666666666666667,
          2.91747619047619,
          4.25052380952381,
          0.861904761904762,
          0.7928571428571428
         ],
         "theta": [
          "sum_L1_acc",
          "sum_L2_acc",
          "sum_Linf_acc",
          "sum_clean_acc",
          "sum_common_acc",
          "sum_L1_acc"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "font": {
         "color": "black"
        },
        "height": 500,
        "legend": {
         "bgcolor": "rgba(255,255,255,0.9)",
         "bordercolor": "lightgrey",
         "borderwidth": 1,
         "font": {
          "size": 11
         },
         "x": 0,
         "xanchor": "left",
         "y": 1,
         "yanchor": "top"
        },
        "margin": {
         "b": 25,
         "l": 25,
         "r": 25,
         "t": 25
        },
        "paper_bgcolor": "white",
        "plot_bgcolor": "white",
        "polar": {
         "angularaxis": {
          "direction": "clockwise",
          "gridcolor": "lightgrey",
          "gridwidth": 0.5,
          "linecolor": "lightgrey",
          "linewidth": 1,
          "showline": true
         },
         "bgcolor": "white",
         "radialaxis": {
          "gridcolor": "lightgrey",
          "gridwidth": 0.5,
          "linecolor": "lightgrey",
          "linewidth": 1,
          "range": [
           0,
           6
          ],
          "showline": true,
          "visible": true
         }
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "width": 500
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import to_hex\n",
    "import re\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df1 = grouped_df.copy()\n",
    "\n",
    "metrics_to_sum = [\"L1_acc\", \"L2_acc\", \"Linf_acc\", \"clean_acc\", \"common_acc\"]\n",
    "\n",
    "for metric in metrics_to_sum:\n",
    "    metric_cols = [col for col in df1.columns if col[1] == metric]\n",
    "    df1[f'sum_{metric}'] = df1[metric_cols].sum(axis=1)\n",
    "\n",
    "df_per_row_sums = df1[[f'sum_{m}' for m in metrics_to_sum]]\n",
    "\n",
    "df_per_row_sums.columns = df_per_row_sums.columns.get_level_values(0)\n",
    "\n",
    "df_per_row_sums.columns.name = 'metric'\n",
    "\n",
    "df_per_row_sums\n",
    "\n",
    "\n",
    "# Your model type mapping\n",
    "model_type_map = {\n",
    "    'convnext_base': \"fully convolutional\",\n",
    "    'convnext_tiny': \"fully convolutional\",\n",
    "    'deit_small': \"fully attention\",\n",
    "    'vit_base': \"fully attention\",\n",
    "    'vit_small': \"fully attention\",\n",
    "    'resnet50': \"fully convolutional\",\n",
    "    'eva02_base': \"fully attention\",\n",
    "    'eva02_tiny': \"fully attention\",\n",
    "    'swin_base': \"fully attention\",\n",
    "    'swin_tiny': \"fully attention\",\n",
    "    'coatnet_0': \"hybrid\",\n",
    "    'coatnet_2': \"hybrid\",\n",
    "    'regnetx_004': \"fully convolutional\",\n",
    "    'efficientnet-b0': \"fully convolutional\", \n",
    "    'deit_tiny': \"fully attention\",\n",
    "    'mobilevit-small': \"hybrid\",\n",
    "    'mobilenetv3': \"fully convolutional\",\n",
    "    'edgenext_small': \"fully convolutional\",\n",
    "    'coat_tiny': \"hybrid\",\n",
    "}\n",
    "\n",
    "# Colormap for each model type\n",
    "type_to_cmap = {\n",
    "    'fully convolutional': cm.Purples,     # deep violet  lavender\n",
    "    'fully attention': cm.Oranges,         # strong orange  light peach\n",
    "    'hybrid': cm.Greens                    # forest  mint\n",
    "}\n",
    "\n",
    "# Extract base backbone name from full backbone string\n",
    "def extract_base_name(backbone_name):\n",
    "    for base in model_type_map:\n",
    "        if base in backbone_name:\n",
    "            return base\n",
    "    return 'unknown'\n",
    "\n",
    "# Get all unique backbones\n",
    "backbones = sorted(set(backbone for backbone, _, _, _ in df_per_row_sums.index))\n",
    "\n",
    "# Map backbones to model type\n",
    "backbone_model_type = {b: model_type_map.get(extract_base_name(b), 'unknown') for b in backbones}\n",
    "\n",
    "# Assign gradient color per backbone based on model type\n",
    "color_map = {}\n",
    "for model_type in ['fully convolutional', 'fully attention', 'hybrid']:\n",
    "    bks = [bk for bk in backbones if backbone_model_type[bk] == model_type]\n",
    "    n = len(bks)\n",
    "    for i, bk in enumerate(bks):\n",
    "        start, end = 0.5, 0.9  # avoid very light or very dark edges\n",
    "        position = start + (end - start) * (i / max(n - 1, 1))\n",
    "        color = to_hex(type_to_cmap[model_type](position))\n",
    "        color_map[bk] = color\n",
    "\n",
    "\n",
    "# Define metrics\n",
    "metrics = ['sum_L1_acc', 'sum_L2_acc', 'sum_Linf_acc', 'sum_clean_acc', 'sum_common_acc']\n",
    "\n",
    "# Create a list of unique backbones (regardless of loss)\n",
    "unique_backbones = sorted(set(backbone for backbone, _, _, _ in df_per_row_sums.index))\n",
    "\n",
    "# # Assign a unique color to each backbone\n",
    "# color_palette = px.colors.qualitative.Plotly\n",
    "# color_map = dict(zip(unique_backbones, color_palette * (len(unique_backbones) // len(color_palette) + 1)))\n",
    "\n",
    "# Define line styles per loss function\n",
    "line_styles = {\n",
    "    'CLASSIC_AT': 'solid',\n",
    "    'TRADES_v2': 'dot'\n",
    "}\n",
    "\n",
    "# Create the radar plot\n",
    "\n",
    "from plotly.colors import qualitative\n",
    "color_palette = qualitative.Bold\n",
    "\n",
    "# Get unique backbones\n",
    "unique_backbones = sorted(set(backbone for backbone, _, _, _ in df_per_row_sums.index))\n",
    "\n",
    "# Assign colors per backbone\n",
    "# color_map = dict(zip(unique_backbones, color_palette * (len(unique_backbones) // len(color_palette) + 1)))\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "for (backbone, loss, _, _), row in df_per_row_sums.iterrows():\n",
    "    fig.add_trace(go.Scatterpolar(\n",
    "        r=row.tolist() + [row.tolist()[0]],  # Close the loop\n",
    "        theta=metrics + [metrics[0]],\n",
    "        mode='lines',\n",
    "        name=f\"{backbone} ({loss})\",\n",
    "        line=dict(\n",
    "            width=2,\n",
    "            color=color_map[backbone],\n",
    "            dash=line_styles.get(loss, 'solid')\n",
    "        )\n",
    "    ))\n",
    "\n",
    "fig.update_layout(\n",
    "    width=500, \n",
    "    height=500,\n",
    "    paper_bgcolor='white',\n",
    "    plot_bgcolor='white',\n",
    "    polar=dict(\n",
    "        radialaxis=dict(\n",
    "            visible=True,\n",
    "            range=[0, 6],\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor=\"lightgrey\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "            gridwidth=0.5,\n",
    "        ),\n",
    "        angularaxis=dict(\n",
    "            direction=\"clockwise\",\n",
    "            showline=True,\n",
    "            linewidth=1,\n",
    "            linecolor=\"lightgrey\",\n",
    "            gridcolor=\"lightgrey\",\n",
    "            gridwidth=0.5,\n",
    "        ),\n",
    "        bgcolor='white'\n",
    "    ),\n",
    "    legend=dict(\n",
    "        x=0,\n",
    "        y=1.0,\n",
    "        xanchor='left',\n",
    "        yanchor='top',\n",
    "        bgcolor='rgba(255,255,255,0.9)',\n",
    "        bordercolor='lightgrey',\n",
    "        borderwidth=1,\n",
    "        font=dict(size=11),\n",
    "    ),\n",
    "    showlegend=False,\n",
    "    font=dict(color='black'),\n",
    "    margin=dict(l=25, r=25, t=25, b=25)  # <<< reduced margins\n",
    ")\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig.write_image(\"./radar_plot_{}_{}.png\".format(size, pn2), scale=3  )                # upscale for higher DPI (1 = default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
