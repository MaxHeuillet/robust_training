{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class ThompsonSamplingLinear:\n",
    "    \n",
    "    def __init__(self, n_actions, n_features, alpha=1.0):\n",
    "        self.n_actions = n_actions\n",
    "        self.n_features = n_features\n",
    "        self.alpha = alpha\n",
    "        \n",
    "        # Prior mean (initially zero)\n",
    "        self.mu = np.zeros(n_features)\n",
    "        \n",
    "        # Prior covariance (identity matrix scaled by alpha)\n",
    "        self.Sigma = np.eye(n_features) * alpha\n",
    "    \n",
    "    def select_action(self, action_features):\n",
    "        # Sample from the posterior distribution\n",
    "        theta_sampled = np.random.multivariate_normal(self.mu, self.Sigma)\n",
    "        \n",
    "        # Compute expected reward for each action based on the sampled theta\n",
    "        expected_rewards = np.maximum(0, action_features.dot(theta_sampled))\n",
    "        \n",
    "        # Select the action with the highest expected reward\n",
    "        return np.argmax(expected_rewards)\n",
    "    \n",
    "    def update(self, chosen_action_features, reward):\n",
    "        # Update posterior distribution using Bayesian linear regression\n",
    "        x = chosen_action_features.reshape(-1, 1)\n",
    "        \n",
    "        # Update the covariance matrix\n",
    "        self.Sigma = np.linalg.inv(np.linalg.inv(self.Sigma) + x.dot(x.T))\n",
    "        \n",
    "        # Update the mean vector\n",
    "        self.mu = self.Sigma.dot(np.linalg.inv(self.Sigma).dot(self.mu) + reward * x.flatten())\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "\n",
    "    n_actions = 10\n",
    "    n_features = 2048\n",
    "    ts_linear = ThompsonSamplingLinear(n_actions, n_features)\n",
    "    \n",
    "    # Assume we have some action features and true rewards\n",
    "    action_features = np.random.randn(n_actions, n_features)  # Random features for each action\n",
    "    true_theta = np.random.randn(n_features)  # True underlying linear relationship\n",
    "    rewards = action_features.dot(true_theta) + np.random.randn(n_actions) * 0.1  # Rewards with noise\n",
    "\n",
    "    for _ in range(100):  # Simulate 100 iterations\n",
    "        chosen_action = ts_linear.select_action(action_features)\n",
    "        ts_linear.update(action_features[chosen_action], rewards[chosen_action])\n",
    "        print(f\"Selected action {chosen_action}, Reward: {rewards[chosen_action]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225 ms ± 9.47 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "1.22 s ± 18.8 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.linalg import cholesky, solve_triangular\n",
    "\n",
    "n = 3048  # Dimension of the matrix\n",
    "\n",
    "# Generate a random positive-definite matrix\n",
    "A = np.random.randn(n, n)\n",
    "A = A.T @ A + np.eye(n)  # Ensure positive-definiteness\n",
    "\n",
    "# Cholesky decomposition\n",
    "%timeit L = cholesky(A, lower=True)\n",
    "\n",
    "# Matrix inversion\n",
    "%timeit A_inv = np.linalg.inv(A)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
