{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import IndexedDataset, WeightedDataset\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "from utils import get_args\n",
    "from architectures import load_architecture\n",
    "\n",
    "from samplers import DistributedCustomSampler\n",
    "from losses import trades_loss\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "args = get_args()\n",
    "args.arch = 'resnet50'\n",
    "args.dataset = 'CIFAR10'\n",
    "args.selection_method = 'none'\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "model, target_layers = load_architecture(args)\n",
    "\n",
    "args.epochs = 2\n",
    "args.pruning_ratio = 0\n",
    "args.delta = 1\n",
    "args.batch_size = 2\n",
    "args.pruning_strategy = 'score_v1'\n",
    "args.batch_strategy = 'random'\n",
    "args.sample_size= 5\n",
    "\n",
    "# train_dataset = IndexedDataset()\n",
    "print('init weighted dataset')\n",
    "train_dataset = WeightedDataset(args, train=True, prune_ratio = args.pruning_ratio,  )\n",
    "\n",
    "# for i in range(len(train_dataset)):\n",
    "#     print(train_dataset[i])\n",
    "\n",
    "dist_sampler = DistributedCustomSampler(args, train_dataset, num_replicas=2, rank=1, drop_last=True)\n",
    "\n",
    "print('init dataloder')\n",
    "trainloader = DataLoader(train_dataset, batch_size=None, sampler = dist_sampler,)  \n",
    "\n",
    "keep_track = []\n",
    "\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "class VarTS:\n",
    "  \n",
    "  def __init__(self, args, dataset, n, params):\n",
    "\n",
    "\n",
    "    self.args = args\n",
    "    self.dataset = dataset\n",
    "    self.K = self.dataset.K\n",
    "\n",
    "    \n",
    "    for attr, val in params.items():\n",
    "      if isinstance(val, np.ndarray):\n",
    "        setattr(self, attr, np.copy(val))\n",
    "      else:\n",
    "        setattr(self, attr, val)\n",
    "\n",
    "    # self.mu0 = np.zeros(self.K)\n",
    "    # self.kappa0 = np.ones(self.K)\n",
    "    # self.alpha0 = np.ones(self.K)\n",
    "    # self.beta0 = np.ones(self.K)\n",
    "\n",
    "    # self.pulls = np.zeros(self.K)  # number of pulls\n",
    "    # self.reward = np.zeros(self.K)  # cumulative reward\n",
    "    # self.reward2 = np.zeros(self.K)  # cumulative squared reward\n",
    "\n",
    "  # def update(self, t, arm, r):\n",
    "  #   self.pulls[arm] += 1\n",
    "  #   self.reward[arm] += r\n",
    "  #   self.reward2[arm] += r * r\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "for iteration in range(100):\n",
    "    \n",
    "    print()\n",
    "    print('Start of iteration', iteration)\n",
    "    print()\n",
    "    \n",
    "    dist_sampler.set_epoch(iteration)\n",
    "    \n",
    "    for batch_id, batch in enumerate( trainloader ):\n",
    "        print('batch no.', batch_id,batch)\n",
    "        data, label, idx = batch\n",
    "        keep_track.append( data[0].tolist()[0] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.28404528, -1.4729944 ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.randn(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
