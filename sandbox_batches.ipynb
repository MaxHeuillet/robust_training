{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n",
      "init weighted dataset\n",
      "60000 60000\n",
      "init dataloder\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import IndexedDataset, WeightedDataset\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "from utils import get_args\n",
    "from architectures import load_architecture\n",
    "\n",
    "from samplers import DistributedCustomSampler\n",
    "from losses import trades_loss\n",
    "from tqdm.notebook import tqdm\n",
    "from architectures import load_architecture, load_statedict, add_lora\n",
    "\n",
    "args = get_args()\n",
    "args.arch = 'LeNet5'\n",
    "args.dataset = 'MNIST'\n",
    "args.selection_method = 'uncertainty'\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "model, target_layers = load_architecture(args)\n",
    "model.to('cuda')\n",
    "\n",
    "# statedict = load_statedict(args)\n",
    "# model.load_state_dict(statedict)\n",
    "# add_lora(target_layers, model)\n",
    "\n",
    "args.pruning_ratio = 0\n",
    "args.delta = 1\n",
    "args.batch_size = 128\n",
    "args.pruning_strategy = 'random'\n",
    "args.batch_strategy = 'random'\n",
    "args.sample_size= 128\n",
    "\n",
    "# train_dataset = IndexedDataset()\n",
    "print('init weighted dataset')\n",
    "train_dataset = WeightedDataset(args, train=True, prune_ratio = args.pruning_ratio,  )\n",
    "\n",
    "train_sampler = DistributedCustomSampler(args, train_dataset, num_replicas=2, rank=0, drop_last=True)\n",
    "\n",
    "print('init dataloder')\n",
    "trainloader = DataLoader(train_dataset, batch_size=None, sampler = train_sampler,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pruning\n",
      "remove tail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e1c951a8d347508b0efbd32434cfe0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  0,   2,   4,   6,   8,  10,  12,  14,  16,  18,  20,  22,  24,  26,\n",
      "         28,  30,  32,  34,  36,  38,  40,  42,  44,  46,  48,  50,  52,  54,\n",
      "         56,  58,  60,  62,  64,  66,  68,  70,  72,  74,  76,  78,  80,  82,\n",
      "         84,  86,  88,  90,  92,  94,  96,  98, 100, 102, 104, 106, 108, 110,\n",
      "        112, 114, 116, 118, 120, 122, 124, 126, 128, 130, 132, 134, 136, 138,\n",
      "        140, 142, 144, 146, 148, 150, 152, 154, 156, 158, 160, 162, 164, 166,\n",
      "        168, 170, 172, 174, 176, 178, 180, 182, 184, 186, 188, 190, 192, 194,\n",
      "        196, 198, 200, 202, 204, 206, 208, 210, 212, 214, 216, 218, 220, 222,\n",
      "        224, 226, 228, 230, 232, 234, 236, 238, 240, 242, 244, 246, 248, 250,\n",
      "        252, 254])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape mismatch: value tensor of shape [128, 10] cannot be broadcast to indexing result of shape [128, 1, 10]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m\n\u001b[1;32m     23\u001b[0m loss_values, clean_values, robust_values, logits_nat, logits_adv \u001b[38;5;241m=\u001b[39m get_loss(args, model, data, target, optimizer)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# assert torch.isfinite(loss_values).all(), \"Loss contains NaNs!\"\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# assert torch.isfinite(logits_nat).all(), \"Logits_nat contains NaNs!\"\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# assert torch.isfinite(logits_adv).all(), \"Logits_adv contains NaNs!\"\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# train_dataset.update_scores(iteration, idxs,loss_values)\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m \u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrank\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midxs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclean_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrobust_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_values\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_nat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogits_adv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# loss = train_dataset.compute_loss(idxs, loss_values)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/robust_training/datasets/weighted_dataset.py:135\u001b[0m, in \u001b[0;36mWeightedDataset.update_scores\u001b[0;34m(self, rank, indices, clean_values, robust_values, global_values, clean_pred, robust_pred)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobust_scores[indices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mlong()] \u001b[38;5;241m=\u001b[39m robust_loss_val\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mglobal_scores[indices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mlong()] \u001b[38;5;241m=\u001b[39m global_loss_val\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[0;32m--> 135\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclean_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m clean_pred\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrobust_pred[indices\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mlong()] \u001b[38;5;241m=\u001b[39m robust_pred\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape mismatch: value tensor of shape [128, 10] cannot be broadcast to indexing result of shape [128, 1, 10]"
     ]
    }
   ],
   "source": [
    "from losses import get_loss, get_eval_loss\n",
    "\n",
    "iterations = 1\n",
    "rank = 'cuda'\n",
    "\n",
    "optimizer = torch.optim.SGD( model.parameters(),lr=args.init_lr, weight_decay=args.weight_decay, momentum=args.momentum, nesterov=True, )\n",
    "\n",
    "for iteration in range(iterations):\n",
    "\n",
    "    model.train()\n",
    "    train_sampler.set_epoch(iteration)\n",
    "\n",
    "    for batch_id, batch in tqdm(enumerate( trainloader ) ):\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        data, target, idxs = batch\n",
    "\n",
    "        print(idxs)\n",
    "\n",
    "        data, target = data.to(rank), target.to(rank) \n",
    "         \n",
    "        loss_values, clean_values, robust_values, logits_nat, logits_adv = get_loss(args, model, data, target, optimizer)\n",
    "\n",
    "        # assert torch.isfinite(loss_values).all(), \"Loss contains NaNs!\"\n",
    "        # assert torch.isfinite(logits_nat).all(), \"Logits_nat contains NaNs!\"\n",
    "        # assert torch.isfinite(logits_adv).all(), \"Logits_adv contains NaNs!\"\n",
    "\n",
    "        # train_dataset.update_scores(iteration, idxs,loss_values)\n",
    "        train_dataset.update_scores(rank, idxs, clean_values, robust_values, loss_values, logits_nat, logits_adv)\n",
    "        # loss = train_dataset.compute_loss(idxs, loss_values)\n",
    "\n",
    "        # loss.backward()\n",
    "        # optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),   ])\n",
    "                # transforms.Normalize( mean=(0.4914, 0.4822, 0.4465), std=(0.2471, 0.2435, 0.2616) \n",
    "                                    #  )  ])\n",
    "\n",
    "\n",
    "dataset = datasets.CIFAR10(root=args.data_dir, train=True, download=True, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_transform = transforms.Compose([transforms.RandomCrop(32, padding=4), \n",
    "                                      transforms.RandomHorizontalFlip(0.5), \n",
    "                                      transforms.ToTensor()])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available arrays in the .npz file: ['image', 'label']\n",
      "torch.Size([1000000, 32, 32, 3])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Load the .npz file using NumPy\n",
    "npz_file = np.load('/home/mheuillet/Downloads/1m.npz')\n",
    "\n",
    "# Print keys to see what arrays are available in the .npz file\n",
    "print(\"Available arrays in the .npz file:\", npz_file.files)\n",
    "\n",
    "# Example: Load a specific array by its key\n",
    "# Replace 'array_key' with the actual key in your .npz file\n",
    "array_key = 'image'  # Change to your actual key\n",
    "numpy_array = npz_file[array_key]\n",
    "\n",
    "\n",
    "numpy\n",
    "# Convert the NumPy array to a PyTorch tensor\n",
    "# torch_tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "# Print the tensor to verify\n",
    "print(torch_tensor.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[144, 141, 129],\n",
       "         [142, 139, 126],\n",
       "         [141, 139, 126],\n",
       "         ...,\n",
       "         [144, 143, 134],\n",
       "         [143, 142, 134],\n",
       "         [143, 143, 135]],\n",
       "\n",
       "        [[147, 144, 131],\n",
       "         [145, 142, 129],\n",
       "         [144, 141, 128],\n",
       "         ...,\n",
       "         [145, 145, 136],\n",
       "         [144, 144, 136],\n",
       "         [144, 144, 136]],\n",
       "\n",
       "        [[146, 143, 130],\n",
       "         [144, 141, 129],\n",
       "         [143, 141, 128],\n",
       "         ...,\n",
       "         [144, 144, 134],\n",
       "         [143, 143, 135],\n",
       "         [143, 144, 136]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 35,  34,  21],\n",
       "         [ 42,  40,  25],\n",
       "         [ 45,  45,  26],\n",
       "         ...,\n",
       "         [ 89,  86,  63],\n",
       "         [110, 109,  79],\n",
       "         [114, 113,  84]],\n",
       "\n",
       "        [[ 69,  67,  48],\n",
       "         [ 71,  70,  47],\n",
       "         [ 78,  76,  51],\n",
       "         ...,\n",
       "         [ 82,  79,  56],\n",
       "         [ 93,  92,  62],\n",
       "         [ 96,  94,  65]],\n",
       "\n",
       "        [[ 99,  94,  69],\n",
       "         [104,  99,  71],\n",
       "         [106, 102,  72],\n",
       "         ...,\n",
       "         [107, 105,  77],\n",
       "         [107, 106,  74],\n",
       "         [105, 103,  74]]],\n",
       "\n",
       "\n",
       "       [[[151, 140, 165],\n",
       "         [155, 146, 170],\n",
       "         [154, 149, 172],\n",
       "         ...,\n",
       "         [164, 175, 204],\n",
       "         [163, 174, 202],\n",
       "         [160, 170, 196]],\n",
       "\n",
       "        [[154, 142, 164],\n",
       "         [157, 147, 168],\n",
       "         [156, 150, 171],\n",
       "         ...,\n",
       "         [165, 176, 201],\n",
       "         [165, 175, 201],\n",
       "         [161, 172, 197]],\n",
       "\n",
       "        [[157, 146, 163],\n",
       "         [160, 150, 167],\n",
       "         [160, 154, 170],\n",
       "         ...,\n",
       "         [166, 178, 200],\n",
       "         [166, 177, 200],\n",
       "         [163, 174, 197]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 28,  19,  17],\n",
       "         [ 17,  10,   6],\n",
       "         [ 16,  10,   6],\n",
       "         ...,\n",
       "         [109, 102,  36],\n",
       "         [102,  93,  39],\n",
       "         [ 97,  87,  36]],\n",
       "\n",
       "        [[ 49,  40,  36],\n",
       "         [ 28,  21,  18],\n",
       "         [ 12,   7,   4],\n",
       "         ...,\n",
       "         [ 99,  90,  32],\n",
       "         [ 97,  85,  34],\n",
       "         [ 96,  82,  32]],\n",
       "\n",
       "        [[ 85,  75,  70],\n",
       "         [ 44,  38,  34],\n",
       "         [  9,   5,   3],\n",
       "         ...,\n",
       "         [ 93,  81,  29],\n",
       "         [ 95,  82,  30],\n",
       "         [ 96,  83,  32]]],\n",
       "\n",
       "\n",
       "       [[[ 95, 102, 106],\n",
       "         [110, 117, 120],\n",
       "         [120, 128, 129],\n",
       "         ...,\n",
       "         [ 67,  88,  58],\n",
       "         [ 61,  83,  48],\n",
       "         [ 76,  99,  63]],\n",
       "\n",
       "        [[107, 116, 120],\n",
       "         [110, 120, 123],\n",
       "         [ 98, 107, 110],\n",
       "         ...,\n",
       "         [ 73,  96,  56],\n",
       "         [ 70,  93,  56],\n",
       "         [ 72,  93,  56]],\n",
       "\n",
       "        [[ 60,  73,  77],\n",
       "         [ 10,  21,  24],\n",
       "         [ 54,  64,  69],\n",
       "         ...,\n",
       "         [ 76, 102,  51],\n",
       "         [ 75,  99,  57],\n",
       "         [ 60,  81,  43]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 97, 121,  97],\n",
       "         [ 91, 118,  91],\n",
       "         [ 83, 112,  83],\n",
       "         ...,\n",
       "         [115, 133, 109],\n",
       "         [113, 131, 107],\n",
       "         [111, 128, 105]],\n",
       "\n",
       "        [[110, 133, 112],\n",
       "         [ 97, 124,  98],\n",
       "         [ 88, 117,  87],\n",
       "         ...,\n",
       "         [112, 130, 106],\n",
       "         [110, 129, 104],\n",
       "         [107, 126, 100]],\n",
       "\n",
       "        [[109, 133, 112],\n",
       "         [ 89, 114,  90],\n",
       "         [ 83, 111,  82],\n",
       "         ...,\n",
       "         [110, 128, 102],\n",
       "         [102, 122,  94],\n",
       "         [102, 122,  95]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[255, 255, 255],\n",
       "         [253, 253, 253],\n",
       "         [254, 255, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [254, 254, 254],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [253, 254, 253],\n",
       "         [254, 255, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [255, 255, 254],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        [[255, 255, 255],\n",
       "         [253, 254, 253],\n",
       "         [254, 255, 254],\n",
       "         ...,\n",
       "         [254, 254, 254],\n",
       "         [255, 255, 254],\n",
       "         [255, 255, 255]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[243, 242, 242],\n",
       "         [189, 187, 187],\n",
       "         [116, 115, 115],\n",
       "         ...,\n",
       "         [216, 214, 219],\n",
       "         [232, 230, 233],\n",
       "         [245, 245, 245]],\n",
       "\n",
       "        [[236, 234, 234],\n",
       "         [194, 193, 193],\n",
       "         [149, 148, 149],\n",
       "         ...,\n",
       "         [230, 228, 232],\n",
       "         [239, 238, 240],\n",
       "         [249, 248, 249]],\n",
       "\n",
       "        [[240, 238, 240],\n",
       "         [206, 204, 207],\n",
       "         [174, 172, 176],\n",
       "         ...,\n",
       "         [233, 231, 234],\n",
       "         [239, 237, 240],\n",
       "         [246, 245, 248]]],\n",
       "\n",
       "\n",
       "       [[[ 87,  87,  79],\n",
       "         [ 67,  68,  59],\n",
       "         [ 67,  68,  59],\n",
       "         ...,\n",
       "         [129, 124,  96],\n",
       "         [126, 129, 107],\n",
       "         [164, 172, 164]],\n",
       "\n",
       "        [[ 87,  86,  77],\n",
       "         [ 68,  67,  58],\n",
       "         [ 51,  50,  41],\n",
       "         ...,\n",
       "         [134, 128, 101],\n",
       "         [122, 122,  95],\n",
       "         [138, 144, 127]],\n",
       "\n",
       "        [[ 84,  82,  72],\n",
       "         [ 61,  59,  49],\n",
       "         [ 56,  53,  43],\n",
       "         ...,\n",
       "         [119, 111,  85],\n",
       "         [128, 126,  95],\n",
       "         [144, 148, 124]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[115, 126, 122],\n",
       "         [117, 127, 124],\n",
       "         [117, 125, 123],\n",
       "         ...,\n",
       "         [110, 124, 121],\n",
       "         [ 97, 111, 108],\n",
       "         [103, 118, 114]],\n",
       "\n",
       "        [[121, 133, 129],\n",
       "         [124, 136, 132],\n",
       "         [126, 137, 133],\n",
       "         ...,\n",
       "         [137, 153, 153],\n",
       "         [122, 137, 137],\n",
       "         [111, 127, 126]],\n",
       "\n",
       "        [[137, 153, 148],\n",
       "         [133, 151, 145],\n",
       "         [132, 151, 145],\n",
       "         ...,\n",
       "         [151, 168, 173],\n",
       "         [155, 172, 175],\n",
       "         [141, 160, 160]]],\n",
       "\n",
       "\n",
       "       [[[ 58,  76,  49],\n",
       "         [ 93, 115,  54],\n",
       "         [ 87,  97,  59],\n",
       "         ...,\n",
       "         [114, 122,  97],\n",
       "         [157, 162, 132],\n",
       "         [102, 111,  86]],\n",
       "\n",
       "        [[ 54,  72,  45],\n",
       "         [ 74,  96,  40],\n",
       "         [ 68,  81,  51],\n",
       "         ...,\n",
       "         [153, 160, 122],\n",
       "         [161, 169, 125],\n",
       "         [ 85,  94,  65]],\n",
       "\n",
       "        [[ 52,  73,  35],\n",
       "         [ 78,  96,  47],\n",
       "         [ 45,  57,  37],\n",
       "         ...,\n",
       "         [163, 171, 123],\n",
       "         [139, 148, 104],\n",
       "         [ 81,  92,  65]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[125,  86,  72],\n",
       "         [ 15,   8,   9],\n",
       "         [  3,  14,  11],\n",
       "         ...,\n",
       "         [ 59,  64,  60],\n",
       "         [ 58,  63,  58],\n",
       "         [ 75,  81,  75]],\n",
       "\n",
       "        [[112, 116, 114],\n",
       "         [  5,   9,   6],\n",
       "         [  7,  11,   8],\n",
       "         ...,\n",
       "         [167, 171, 159],\n",
       "         [187, 192, 180],\n",
       "         [205, 211, 201]],\n",
       "\n",
       "        [[ 81,  96,  93],\n",
       "         [ 47,  52,  47],\n",
       "         [ 20,  24,  21],\n",
       "         ...,\n",
       "         [168, 173, 162],\n",
       "         [175, 178, 170],\n",
       "         [185, 189, 182]]]], dtype=uint8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices shape: torch.Size([10])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "N = 10\n",
    "# Initializing tensors with specified shapes\n",
    "indices = torch.randint(0, 10, (N, ))\n",
    "print(\"indices shape:\", indices.shape)\n",
    "\n",
    "indices.shape[0]\n",
    "# clean_loss_val = torch.randn((N, ))\n",
    "# print(\"clean_loss_val shape:\", clean_loss_val.shape)\n",
    "\n",
    "# robust_loss_val = torch.randn((N, ))\n",
    "# print(\"robust_loss_val shape:\", robust_loss_val.shape)\n",
    "\n",
    "# clean_pred = torch.randn((N, 5))\n",
    "# print(\"clean_pred shape:\", clean_pred.shape)\n",
    "\n",
    "# robust_pred = torch.randn((N, 5))\n",
    "# print(\"robust_pred shape:\", robust_pred.shape)\n",
    "\n",
    "\n",
    "\n",
    "# # Concatenating all tensors along the column dimension (dim=1)\n",
    "# iv = torch.cat([indices_reshaped,\n",
    "#                 clean_loss_val_reshaped,\n",
    "#                 robust_loss_val_reshaped,\n",
    "#                 clean_pred,\n",
    "#                 robust_pred], dim=1)\n",
    "\n",
    "# print(\"iv shape:\", iv.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_values contains NaNs!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def check_for_nans(tensors, tensor_names):\n",
    "    for tensor, name in zip(tensors, tensor_names):\n",
    "        if torch.isnan(tensor).any():\n",
    "            print(f\"{name} contains NaNs!\")\n",
    "\n",
    "# Example tensors with potential NaN values\n",
    "loss_values = torch.randn((10, 1))\n",
    "clean_values = torch.randn((10,))\n",
    "robust_values = torch.randn((10,))\n",
    "logits_nat = torch.randn((10, 5))\n",
    "logits_adv = torch.randn((10, 5))\n",
    "\n",
    "# Introducing NaNs for testing purposes\n",
    "loss_values[0, 0] = float('nan')  # Introducing a NaN for demonstration\n",
    "\n",
    "# List of tensors and their names for easy reference in the check\n",
    "tensors = [loss_values, clean_values, robust_values, logits_nat, logits_adv]\n",
    "tensor_names = ['loss_values', 'clean_values', 'robust_values', 'logits_nat', 'logits_adv']\n",
    "\n",
    "check_for_nans(tensors, tensor_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.global_scores2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Creating a sample tensor with dimensions (10, 60000)\n",
    "# Each of the 10 rows represents an epoch, and each column represents a loss value for one of the 60,000 observations.\n",
    "np.random.seed(0)  # For reproducibility\n",
    "tensor = train_dataset.global_scores2 #np.random.rand(10, 60000)  # Simulating loss values\n",
    "\n",
    "# Sampling 1000 observations from the 60,000\n",
    "\n",
    "sample_indices = np.random.choice(tensor.shape[1], size=60000, replace=False)\n",
    "\n",
    "sampled_tensor = tensor[:, sample_indices]\n",
    "\n",
    "# Plotting the evolution of the loss for the 60,000 observations over 10 epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Plotting each observation's loss over the 10 epochs\n",
    "for i in tqdm(range(sampled_tensor.shape[1])):\n",
    "    plt.plot(range(10), sampled_tensor[:, i], alpha=0.25, linewidth=0.5)  # Plotting with low opacity and thin lines for clarity\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss Value')\n",
    "plt.yscale('log')  # Setting y-axis to log scale\n",
    "\n",
    "plt.title('Evolution of Loss for 60,000 Observations Over 10 Epochs')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for i in range(len(train_dataset)):\n",
    "#     print(train_dataset[i])\n",
    "import numpy as np\n",
    "\n",
    "def obtain_latent_dataset(model, dataset, batch_size=32):\n",
    "\n",
    "    # Assuming the dataset is a list or similar iterable with a known length\n",
    "    num_samples = len(dataset)\n",
    "\n",
    "    # Assume the dimensionality of the latent representation can be determined from one sample\n",
    "    image,label, idx = dataset[0]\n",
    "    image = torch.Tensor(image).to('cuda').unsqueeze(0)\n",
    "    print(image.shape)\n",
    "    first_latent_rep = model.get_latent_representation(image)\n",
    "    latent_dim = first_latent_rep.shape[1]\n",
    "    print(first_latent_rep.shape)\n",
    "        \n",
    "    # Preallocate the array for the latent representations\n",
    "    latent_dataset = torch.zeros((num_samples, latent_dim))\n",
    "\n",
    "\n",
    "    for i in tqdm( range(0, num_samples, batch_size) ):\n",
    "        # Get the current batch of data\n",
    "        batch_indices = list(range(i, min(i + batch_size, num_samples)))\n",
    "        images,labels,idxs = dataset[batch_indices]\n",
    "        images = images.to('cuda')\n",
    "            \n",
    "        # Process the batch to get latent representations\n",
    "        batch_latent_reps = model.get_latent_representation(images) \n",
    "            \n",
    "        # Store the results in the preallocated array\n",
    "        latent_dataset[i:i + batch_size] = batch_latent_reps.detach().cpu()\n",
    "\n",
    "    return latent_dataset\n",
    "\n",
    "features =  obtain_latent_dataset(model,train_dataset,64)\n",
    "train_dataset.define_latent_features(features)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
