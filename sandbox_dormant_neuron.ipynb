{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from datasets import IndexedDataset, load_data\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from utils import get_args\n",
    "from architectures import load_architecture\n",
    "\n",
    "from architectures import load_architecture, add_lora, set_lora_gradients  # load_statedict\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import math\n",
    "from functools import partial\n",
    "from typing import Union, Tuple  # Import Union and Tuple for type annotations\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _get_masks(activations, tau: float, ineq_type: str) -> torch.Tensor:\n",
    "    \"\"\"\n",
    "    Computes the mask for a given set of activations based on the inequality type.\n",
    "    The returned mask has True where neurons satisfy the condition and False otherwise.\n",
    "    \"\"\"\n",
    "    masks = []\n",
    "\n",
    "    for name, activation in activations.items():\n",
    "        # Calculate the mean activation per neuron\n",
    "        if activation.ndim == 4:\n",
    "            # Conv layer\n",
    "            score = activation.abs().mean(dim=(0, 2, 3))\n",
    "        else:\n",
    "            # Linear layer\n",
    "            score = activation.abs().mean(dim=0)\n",
    "\n",
    "        # Normalize the score\n",
    "        normalized_score = score / (score.mean() + 1e-9)\n",
    "        layer_mask = torch.zeros_like(normalized_score, dtype=torch.bool)\n",
    "\n",
    "        if ineq_type == 'leq':\n",
    "            layer_mask[normalized_score <= tau] = True\n",
    "        elif ineq_type == 'geq':\n",
    "            layer_mask[normalized_score >= tau] = True\n",
    "        elif ineq_type == 'eq':\n",
    "            layer_mask[torch.isclose(normalized_score, torch.zeros_like(normalized_score))] = True\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid inequality type: {ineq_type}\")\n",
    "\n",
    "        masks.append(layer_mask)\n",
    "\n",
    "    return masks\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _get_activation(name: str, activations):\n",
    "    \"\"\"Fetches and stores the activations of a network layer.\"\"\"\n",
    "\n",
    "    def hook(layer: Union[nn.Linear, nn.Conv2d], input: Tuple[torch.Tensor, ...], output: torch.Tensor) -> None:\n",
    "        \"\"\"\n",
    "        Get the activations of a layer with ReLU nonlinearity.\n",
    "        ReLU has to be called explicitly here because the hook is attached to the conv/linear layer.\n",
    "        \"\"\"\n",
    "        activations[name] = F.relu(output)\n",
    "\n",
    "    return hook\n",
    "\n",
    "@torch.inference_mode()\n",
    "def run_redo(\n",
    "    obs: torch.Tensor,\n",
    "    model: nn.Module,\n",
    "):\n",
    "    \"\"\"\n",
    "    Checks the number of zero, dormant, and overactive neurons for a given model.\n",
    "\n",
    "    Returns a dictionary containing the counts and fractions.\n",
    "    \"\"\"\n",
    "\n",
    "    activations = {}\n",
    "    activation_getter = partial(_get_activation, activations=activations)\n",
    "\n",
    "    # Register hooks for all Conv2d and Linear layers to calculate activations\n",
    "    handles = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, torch.nn.Conv2d) or isinstance(module, torch.nn.Linear):\n",
    "            handles.append(module.register_forward_hook(activation_getter(name)))\n",
    "\n",
    "    # Calculate activations\n",
    "    _ = model(obs)\n",
    "\n",
    "    # Compute zero masks (neurons with zero normalized activation)\n",
    "    zero_masks = _get_masks(activations, 0.0, 'eq')\n",
    "    zero_count = sum([torch.sum(mask).item() for mask in zero_masks])\n",
    "\n",
    "    # Compute dormant masks (excluding zero neurons)\n",
    "    dormant_masks = _get_masks(activations, 0.01, 'leq')\n",
    "    # Exclude zero neurons from dormant neurons\n",
    "    adjusted_dormant_masks = [dormant_mask & (~zero_mask) for dormant_mask, zero_mask in zip(dormant_masks, zero_masks)]\n",
    "    dormant_count = sum([torch.sum(mask).item() for mask in adjusted_dormant_masks])\n",
    "\n",
    "    # Compute overactive masks\n",
    "    overactive_masks = _get_masks(activations, 3.0, 'geq')\n",
    "    overactive_count = sum([torch.sum(mask).item() for mask in overactive_masks])\n",
    "\n",
    "    # Compute total neurons\n",
    "    total_neurons = sum([mask.numel() for mask in zero_masks])\n",
    "\n",
    "    # Compute fractions\n",
    "    zero_fraction = zero_count / total_neurons\n",
    "    dormant_fraction = dormant_count / total_neurons\n",
    "    overactive_fraction = overactive_count / total_neurons\n",
    "\n",
    "    # Remove the hooks\n",
    "    for handle in handles:\n",
    "        handle.remove()\n",
    "\n",
    "    return {\n",
    "        \"total_neurons\": total_neurons,\n",
    "        \"zero_fraction\": zero_fraction,\n",
    "        \"zero_count\": zero_count,\n",
    "        \"dormant_fraction\": dormant_fraction,\n",
    "        \"dormant_count\": dormant_count,\n",
    "        \"overactive_fraction\": overactive_fraction,\n",
    "        \"overactive_count\": overactive_count,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datadir /home/mheuillet/Desktop/robust_training/data\n",
      "convnext_base\n",
      "random {'total_neurons': 21280.0, 'zero_fraction': 0.21527255639097745, 'zero_count': 4581.0, 'dormant_fraction': 0.05996240601503759, 'dormant_count': 1276.0, 'overactive_fraction': 0.07664473684210527, 'overactive_count': 1631.0}\n",
      "image {'total_neurons': 21280.0, 'zero_fraction': 0.035473274771086145, 'zero_count': 754.8712871287129, 'dormant_fraction': 0.017965085982282438, 'dormant_count': 382.2970297029703, 'overactive_fraction': 0.0501549356063426, 'overactive_count': 1067.2970297029703}\n",
      "\n",
      "convnext_base.fb_in22k\n",
      "random {'total_neurons': 21280.0, 'zero_fraction': 0.22410714285714287, 'zero_count': 4769.0, 'dormant_fraction': 0.06024436090225564, 'dormant_count': 1282.0, 'overactive_fraction': 0.0787124060150376, 'overactive_count': 1675.0}\n",
      "image {'total_neurons': 21280.0, 'zero_fraction': 0.02866634407801682, 'zero_count': 610.019801980198, 'dormant_fraction': 0.016301738256532423, 'dormant_count': 346.9009900990099, 'overactive_fraction': 0.048281750167497986, 'overactive_count': 1027.4356435643565}\n",
      "\n",
      "robust_convnext_base\n",
      "random {'total_neurons': 21280.0, 'zero_fraction': 0.18265977443609022, 'zero_count': 3887.0, 'dormant_fraction': 0.0549812030075188, 'dormant_count': 1170.0, 'overactive_fraction': 0.07091165413533834, 'overactive_count': 1509.0}\n",
      "image {'total_neurons': 21280.0, 'zero_fraction': 0.06809070944688453, 'zero_count': 1448.970297029703, 'dormant_fraction': 0.03440035732896598, 'dormant_count': 732.039603960396, 'overactive_fraction': 0.05967068041390606, 'overactive_count': 1269.7920792079208}\n",
      "\n",
      "convnext_tiny\n",
      "random {'total_neurons': 8872.0, 'zero_fraction': 0.14190712353471596, 'zero_count': 1259.0, 'dormant_fraction': 0.04824165915238954, 'dormant_count': 428.0, 'overactive_fraction': 0.06909377817853922, 'overactive_count': 613.0}\n",
      "image {'total_neurons': 8872.0, 'zero_fraction': 0.023325134587399234, 'zero_count': 206.94059405940595, 'dormant_fraction': 0.012186520726013091, 'dormant_count': 108.11881188118812, 'overactive_fraction': 0.03818554758992581, 'overactive_count': 338.7821782178218}\n",
      "\n",
      "convnext_tiny.fb_in22k\n",
      "random {'total_neurons': 8872.0, 'zero_fraction': 0.21415689810640218, 'zero_count': 1900.0, 'dormant_fraction': 0.05004508566275924, 'dormant_count': 444.0, 'overactive_fraction': 0.07709648331830478, 'overactive_count': 684.0}\n",
      "image {'total_neurons': 8872.0, 'zero_fraction': 0.04548853217152194, 'zero_count': 403.5742574257426, 'dormant_fraction': 0.01555120570668429, 'dormant_count': 137.97029702970298, 'overactive_fraction': 0.048537394316528135, 'overactive_count': 430.6237623762376}\n",
      "\n",
      "robust_convnext_tiny\n",
      "random {'total_neurons': 8872.0, 'zero_fraction': 0.28043282236248873, 'zero_count': 2488.0, 'dormant_fraction': 0.0440712353471596, 'dormant_count': 391.0, 'overactive_fraction': 0.06266907123534717, 'overactive_count': 556.0}\n",
      "image {'total_neurons': 8872.0, 'zero_fraction': 0.0700512905212974, 'zero_count': 621.4950495049505, 'dormant_fraction': 0.014826933549982591, 'dormant_count': 131.54455445544554, 'overactive_fraction': 0.04430001160621023, 'overactive_count': 393.029702970297}\n",
      "\n",
      "deit_small_patch16_224.fb_in1k\n",
      "random {'total_neurons': 8170378.0, 'zero_fraction': 0.6815033527212572, 'zero_count': 5568140.0, 'dormant_fraction': 0.0010425466239138508, 'dormant_count': 8518.0, 'overactive_fraction': 0.08810204374877148, 'overactive_count': 719827.0}\n",
      "image {'total_neurons': 8170378.0, 'zero_fraction': 0.6865344238020868, 'zero_count': 5609245.752475248, 'dormant_fraction': 0.0010581075458028241, 'dormant_count': 8645.138613861385, 'overactive_fraction': 0.08775607771545858, 'overactive_count': 717000.3267326732}\n",
      "\n",
      "random_deit_small_patch16_224\n",
      "random {'total_neurons': 8170378.0, 'zero_fraction': 0.5004365771081828, 'zero_count': 4088756.0, 'dormant_fraction': 0.0015634527557966107, 'dormant_count': 12774.0, 'overactive_fraction': 0.11540163747625874, 'overactive_count': 942875.0}\n",
      "image {'total_neurons': 8170378.0, 'zero_fraction': 0.4998515768465882, 'zero_count': 4083976.326732673, 'dormant_fraction': 0.00158972491423855, 'dormant_count': 12988.653465346535, 'overactive_fraction': 0.11541304308305098, 'overactive_count': 942968.1881188119}\n",
      "\n",
      "vit_base_patch16_224.augreg_in1k\n",
      "random {'total_neurons': 16340746.0, 'zero_fraction': 0.6759673028391727, 'zero_count': 11045810.0, 'dormant_fraction': 0.0010310422792203, 'dormant_count': 16848.0, 'overactive_fraction': 0.09524461123133546, 'overactive_count': 1556368.0}\n",
      "image {'total_neurons': 16340746.0, 'zero_fraction': 0.6862725323931882, 'zero_count': 11214205.138613861, 'dormant_fraction': 0.001037921153697271, 'dormant_count': 16960.40594059406, 'overactive_fraction': 0.08997170158402054, 'overactive_count': 1470204.7227722772}\n",
      "\n",
      "vit_base_patch16_224.augreg_in21k\n",
      "random {'total_neurons': 16340746.0, 'zero_fraction': 0.6877398375814666, 'zero_count': 11238182.0, 'dormant_fraction': 0.0010717992923946068, 'dormant_count': 17514.0, 'overactive_fraction': 0.0867720482283979, 'overactive_count': 1417920.0}\n",
      "image {'total_neurons': 16340746.0, 'zero_fraction': 0.6947338739784111, 'zero_count': 11352469.772277229, 'dormant_fraction': 0.0011280602816207696, 'dormant_count': 18433.346534653465, 'overactive_fraction': 0.08398563448645975, 'overactive_count': 1372387.9207920793}\n",
      "\n",
      "robust_vit_base_patch16_224\n",
      "random {'total_neurons': 16340746.0, 'zero_fraction': 0.6809812110169267, 'zero_count': 11127741.0, 'dormant_fraction': 0.0011754665301082338, 'dormant_count': 19208.0, 'overactive_fraction': 0.08839767780491783, 'overactive_count': 1444484.0}\n",
      "image {'total_neurons': 16340746.0, 'zero_fraction': 0.681494926550447, 'zero_count': 11136135.495049505, 'dormant_fraction': 0.0013327845050224109, 'dormant_count': 21778.69306930693, 'overactive_fraction': 0.0867334112876093, 'overactive_count': 1417288.6435643565}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config.yaml\")\n",
    "\n",
    "# Create white and black images using NumPy\n",
    "# white_image = np.ones((224, 224, 3), dtype=np.uint8) * 255\n",
    "# black_image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "# white_tensor = torch.from_numpy(white_image).permute(2, 0, 1).float() / 255.0\n",
    "# black_tensor = torch.from_numpy(black_image).permute(2, 0, 1).float() / 255.0\n",
    "# white_tensor = white_tensor.unsqueeze(0)  # Shape: (1, 3, 224, 224)\n",
    "# black_tensor = black_tensor.unsqueeze(0)  # Shape: (1, 3, 224, 224)\n",
    "\n",
    "config.dataset = 'Imagenette'\n",
    "train_dataset, val_dataset, test_dataset, N, train_transform, transform = load_data(False, config) \n",
    "test_dataset = IndexedDataset(test_dataset, transform,  N,) \n",
    "testloader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=3, pin_memory=True)\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "def average_dicts(dicts):\n",
    "    accumulator = defaultdict(float)\n",
    "    count = defaultdict(int)\n",
    "\n",
    "    for d in dicts:\n",
    "        for key, value in d.items():\n",
    "            accumulator[key] += value\n",
    "            count[key] += 1\n",
    "\n",
    "    return {key: accumulator[key] / count[key] for key in accumulator}\n",
    "\n",
    "def generate_random_observations(batch_size, image_size, channels, value_range=(0, 1), apply_transforms=None):\n",
    "\n",
    "    # Generate random images within the specified range\n",
    "    min_val, max_val = value_range\n",
    "    random_images = torch.rand(batch_size, channels, image_size, image_size) * (max_val - min_val) + min_val\n",
    "\n",
    "    # Apply transforms if provided\n",
    "    if apply_transforms:\n",
    "        # Convert each image to a PIL Image, apply transforms, and stack them back together\n",
    "        random_images = torch.stack([\n",
    "            apply_transforms(transforms.ToPILImage()(img)) for img in random_images\n",
    "        ])\n",
    "\n",
    "    return random_images\n",
    "\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)),  # Resize images to 224x224\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] ),])\n",
    "\n",
    "\n",
    "backbones = [ 'convnext_base',  'convnext_base.fb_in22k', 'robust_convnext_base',\n",
    "              'convnext_tiny',  'convnext_tiny.fb_in22k', 'robust_convnext_tiny', \n",
    "              'deit_small_patch16_224.fb_in1k', 'random_deit_small_patch16_224' ,\n",
    "              'vit_base_patch16_224.augreg_in1k', 'vit_base_patch16_224.augreg_in21k', 'robust_vit_base_patch16_224'   ]\n",
    "\n",
    "#   'robust_wideresnet_28_10', 'wideresnet_28_10',\n",
    "\n",
    "backbones_result = {}\n",
    "for backbone_name in backbones:\n",
    "    # print(backbone_name)\n",
    "    print( backbone_name )\n",
    "\n",
    "    backbone_result = {\n",
    "        \"total_neurons\":[],\n",
    "        \"zero_fraction\": [],\n",
    "        \"zero_count\": [],\n",
    "        \"dormant_fraction\": [],\n",
    "        \"dormant_count\": [],\n",
    "        \"overactive_fraction\": [],\n",
    "        \"overactive_count\": [],\n",
    "    }\n",
    "\n",
    "    config.backbone = backbone_name\n",
    "    model = load_architecture(False, config, N = 10, )\n",
    "\n",
    "    # result = run_redo(white_tensor, model) # compute amount of zero, dormant and overactive neurons\n",
    "    # print('white', result)\n",
    "    # result = run_redo(black_tensor, model) # compute amount of zero, dormant and overactive neurons\n",
    "    # print('black', result)\n",
    "\n",
    "    result_random = []\n",
    "    for _ in range(1):\n",
    "\n",
    "        data = generate_random_observations(1, 224, 3, value_range=(0, 255), apply_transforms=transform)\n",
    "\n",
    "        result_random.append(  run_redo(data, model) )# compute amount of zero, dormant and overactive neurons\n",
    "\n",
    "\n",
    "        if batch_id == 100:\n",
    "            break\n",
    "\n",
    "    result_random = average_dicts(result_random)\n",
    "    print('random', result_random)\n",
    "    \n",
    "    result_image = []\n",
    "    for batch_id, batch in  enumerate(testloader) :\n",
    "\n",
    "        data, target, idxs = batch\n",
    "\n",
    "        result_image.append( run_redo(data, model) ) # compute amount of zero, dormant and overactive neurons\n",
    "\n",
    "        if batch_id == 100:\n",
    "            break\n",
    "\n",
    "    result_image = average_dicts(result_image)\n",
    "    print('image', result_image)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "{'total_neurons': 8872, 'zero_count': 1561, 'dormant_count': 401, 'overactive_count': 624}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from utils import ActivationTracker, register_hooks, compute_stats\n",
    "from architectures import load_architecture, CustomModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import torch.distributed as dist\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config.yaml\")\n",
    "\n",
    "\n",
    "N = 10\n",
    "B = 2  \n",
    "\n",
    "# Create a white image using NumPy\n",
    "white_image = np.ones((224, 224, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "white_tensor = torch.from_numpy(white_image).permute(2, 0, 1).float() / 255.0  # Shape: (3, 224, 224)\n",
    "\n",
    "# Add batch dimension and repeat for batch size B\n",
    "white_tensor = white_tensor.unsqueeze(0).repeat(B, 1, 1, 1)  # Shape: (B, 3, 224, 224)\n",
    "\n",
    "# Move the tensor to GPU\n",
    "white_tensor = white_tensor.to('cuda')\n",
    "\n",
    "print(white_tensor.shape)  # Verify shape: (B, 3, 224, 224)\n",
    "\n",
    "config.backbone = 'convnext_tiny'\n",
    "model = load_architecture(False, config, N, )\n",
    "model = CustomModel(config, model, )\n",
    "model.to('cuda')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tracker_nat = ActivationTracker()\n",
    "tracker_adv = ActivationTracker()\n",
    "\n",
    "handles = register_hooks(model, tracker_nat, tracker_adv)\n",
    "\n",
    "model.current_task = 'infer'\n",
    "model(white_tensor)\n",
    "\n",
    "# # Compute neuron statistics\n",
    "res_nat = compute_stats(tracker_nat.activations)\n",
    "# res_adv = compute_stats(tracker_adv.activations)\n",
    "\n",
    "print(res_nat)\n",
    "# print(res_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 7.9517e-01, 0.0000e+00, 4.1610e-01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 8.0445e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.3357e+00, 9.4621e-02, 0.0000e+00, 0.0000e+00, 2.5304e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3615e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.4487e+00, 2.3436e-02, 1.3762e-01, 2.2767e-01, 2.7563e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.3441e-03, 2.6298e-02, 0.0000e+00, 1.1334e-02,\n",
      "        0.0000e+00, 5.1408e-02, 1.3963e-01, 8.8616e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.9974e-02, 0.0000e+00, 1.5570e+00, 0.0000e+00, 3.9853e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 6.7071e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.4512e-02, 3.2202e+00, 5.1580e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.3391e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0213e-02, 0.0000e+00, 4.9442e-02,\n",
      "        0.0000e+00, 2.8809e-01, 0.0000e+00, 4.6919e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.4448e+00, 3.7264e-02, 0.0000e+00, 6.3292e-02, 1.9096e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([2.8526e-04, 1.4992e-04, 1.7503e-04, 2.4435e-04, 0.0000e+00, 7.6294e-04,\n",
      "        1.1145e-06, 5.8160e-04, 1.0649e-03, 0.0000e+00, 1.0513e-03, 4.7384e-04,\n",
      "        1.1443e-03, 1.2935e-04, 3.7553e-04, 5.1945e-04, 4.7589e-04, 8.6432e-05,\n",
      "        1.4067e-03, 3.8259e-04, 9.8869e-04, 2.1447e-05, 1.6764e-03, 2.3208e-06,\n",
      "        0.0000e+00, 2.7059e-04, 2.4191e-04, 1.7017e-05, 0.0000e+00, 2.1669e-04,\n",
      "        0.0000e+00, 1.0810e-03, 3.9838e-04, 7.6560e-04, 2.0000e-05, 1.9892e-04,\n",
      "        1.0981e-04, 2.6322e-04, 9.5027e-06, 1.7725e-04, 5.2351e-04, 2.8601e-04,\n",
      "        1.2928e-04, 2.5381e-04, 0.0000e+00, 3.2197e-04, 0.0000e+00, 3.0163e-04,\n",
      "        1.5093e-04, 1.5103e-04, 1.2703e-04, 6.4519e-04, 1.0550e-03, 5.2482e-04,\n",
      "        1.0745e-05, 1.0147e-03, 8.7828e-04, 0.0000e+00, 9.7995e-05, 1.1404e-02,\n",
      "        3.8912e-03, 0.0000e+00, 0.0000e+00, 1.6403e-04, 3.0533e-04, 1.2810e-04,\n",
      "        1.5122e-04, 0.0000e+00, 2.8581e-04, 8.7618e-03, 1.4532e-05, 0.0000e+00,\n",
      "        1.0740e-04, 3.2265e-04, 3.9301e-04, 1.8301e-04, 1.2370e-04, 0.0000e+00,\n",
      "        4.5634e-04, 1.4651e-05, 1.3540e-03, 7.2938e-04, 2.0420e-04, 1.3439e-03,\n",
      "        8.8494e-05, 0.0000e+00, 3.3476e-04, 7.8932e-06, 2.2645e-04, 1.0975e-04,\n",
      "        3.8917e-04, 1.3969e-04, 4.5168e-04, 4.9690e-04, 3.4995e-04, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0929, 0.0576, 0.0550, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0551,\n",
      "        0.0581, 0.2175], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0632, 0.0578, 0.0586, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0587,\n",
      "        0.0580, 0.0595], device='cuda:0') torch.Size([56])\n",
      "score tensor([6.6442e-04, 4.2174e-03, 6.8088e-03, 2.0169e-03, 1.3097e-02, 0.0000e+00,\n",
      "        1.6589e-04, 1.5179e-02, 1.7192e-03, 1.2147e-03, 0.0000e+00, 3.2143e-04,\n",
      "        2.4660e-03, 3.0125e-03, 4.2531e-03, 2.5678e-03, 2.3176e-08, 5.7961e-03,\n",
      "        1.7439e-03, 2.8081e-03, 7.0426e-05, 4.3377e-03, 3.5505e-03, 7.5497e-04,\n",
      "        2.5946e-03, 5.3912e-03, 2.3709e-03, 3.5204e-03, 2.1720e-03, 1.3273e-04,\n",
      "        6.7543e-03, 8.9609e-04, 2.6822e-03, 3.7706e-03, 3.0913e-03, 2.5290e-03,\n",
      "        2.6934e-03, 6.5049e-05, 3.4688e-03, 2.1489e-03, 4.8021e-03, 3.8761e-03,\n",
      "        4.6023e-05, 7.1323e-03, 7.4810e-03, 3.3002e-03, 3.5134e-03, 2.1284e-03,\n",
      "        3.4215e-03, 1.8869e-03, 4.6760e-03, 4.4040e-03, 3.3801e-02, 9.6786e-04,\n",
      "        1.0512e-03, 2.0367e-03, 2.8824e-03, 4.7415e-03, 0.0000e+00, 2.6054e-03,\n",
      "        3.1633e-04, 1.0997e-04, 2.5863e-03, 2.9005e-03, 1.2714e-03, 3.7026e-03,\n",
      "        3.9761e-03, 8.7920e-03, 1.7449e-03, 4.9377e-03, 4.6834e-03, 7.0173e-08,\n",
      "        7.3836e-04, 1.2476e-03, 1.8648e-03, 1.8448e-03, 1.6835e-03, 9.6715e-05,\n",
      "        4.0757e-03, 3.1098e-03, 9.5503e-03, 3.0235e-03, 3.4673e-04, 6.0244e-03,\n",
      "        2.0152e-03, 3.1148e-03, 1.4750e-03, 1.5805e-03, 1.6484e-03, 2.3807e-03,\n",
      "        2.2999e-03, 1.2437e-02, 2.4851e-03, 1.1322e-03, 2.1013e-04, 3.2665e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0260, 0.0228, 0.0168, 0.0168, 0.0154, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0153, 0.0154, 0.0174, 0.0167,\n",
      "        0.0243, 0.0369], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0373, 0.0385, 0.0360, 0.0359, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0362, 0.0371,\n",
      "        0.0408, 0.0424], device='cuda:0') torch.Size([56])\n",
      "score tensor([1.8201e-03, 1.1953e-02, 1.6332e-02, 1.0135e-03, 1.2222e-03, 0.0000e+00,\n",
      "        9.3536e-03, 4.4624e-02, 1.0057e-02, 1.1856e-02, 0.0000e+00, 2.1293e-02,\n",
      "        1.6234e-05, 9.6559e-03, 1.2067e-02, 2.5830e-02, 6.8715e-04, 3.5942e-04,\n",
      "        7.6328e-03, 7.1265e-03, 1.7196e-02, 5.2343e-03, 1.7601e-02, 1.2012e-03,\n",
      "        1.5630e-02, 1.2315e-02, 5.6379e-04, 1.5887e-02, 2.0259e-02, 2.2281e-02,\n",
      "        1.1063e-02, 1.1138e-02, 9.1796e-03, 5.5287e-03, 1.7371e-02, 2.5715e-02,\n",
      "        7.0968e-02, 2.0869e-03, 4.2323e-02, 7.2269e-03, 1.8224e-02, 4.2371e-03,\n",
      "        6.2002e-03, 2.2582e-02, 2.1482e-02, 3.3565e-02, 2.1233e-02, 1.0036e-02,\n",
      "        1.2726e-02, 0.0000e+00, 4.7546e-03, 2.0495e-02, 2.8849e-03, 5.8231e-04,\n",
      "        1.0670e-02, 1.2585e-02, 9.1994e-03, 4.1080e-03, 7.7554e-02, 8.7774e-02,\n",
      "        4.1278e-03, 1.0450e-02, 8.5825e-03, 7.4389e-03, 3.4659e-02, 0.0000e+00,\n",
      "        1.4106e-02, 6.1953e-03, 1.9497e-02, 1.5249e-02, 4.2964e-03, 0.0000e+00,\n",
      "        1.6211e-02, 4.8179e-02, 0.0000e+00, 6.7259e-03, 1.0320e-02, 2.5877e-02,\n",
      "        8.0800e-03, 7.1173e-03, 3.5631e-02, 8.8223e-04, 3.0127e-02, 1.1762e-02,\n",
      "        1.0051e-02, 8.7778e-03, 6.4477e-03, 1.3240e-02, 1.3787e-02, 6.8265e-03,\n",
      "        1.5901e-02, 2.3535e-02, 1.2305e-03, 5.9870e-03, 3.0122e-04, 1.5314e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0677, 0.0524, 0.0383, 0.0329, 0.0351, 0.0348, 0.0341, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0341, 0.0341, 0.0332, 0.0296, 0.0292,\n",
      "        0.0287, 0.0377], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0350, 0.0373, 0.0356, 0.0358, 0.0390, 0.0388, 0.0385, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0386, 0.0389, 0.0391, 0.0364, 0.0371,\n",
      "        0.0352, 0.0413], device='cuda:0') torch.Size([56])\n",
      "score tensor([2.1250e-03, 3.1641e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3549e-03,\n",
      "        1.4051e-02, 6.6495e-02, 1.5951e-01, 0.0000e+00, 2.9916e-02, 8.9347e-02,\n",
      "        1.1387e-01, 7.3310e-02, 9.6059e-02, 1.8380e-04, 6.8377e-04, 7.5983e-04,\n",
      "        4.1027e-04, 5.2199e-02, 5.3224e-07, 1.4187e-01, 0.0000e+00, 4.8534e-03,\n",
      "        0.0000e+00, 1.0056e-01, 1.7630e-02, 1.3116e-01, 1.0220e-05, 0.0000e+00,\n",
      "        2.4030e-02, 9.4485e-05, 2.8883e-02, 2.2338e-05, 5.1729e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.8656e-05, 1.2600e-03, 4.4448e-03, 8.4249e-02,\n",
      "        1.2208e-02, 1.0365e-01, 0.0000e+00, 1.6119e-01, 6.2706e-04, 0.0000e+00,\n",
      "        1.6805e-03, 3.7975e-02, 0.0000e+00, 3.0407e-05, 0.0000e+00, 1.5388e-03,\n",
      "        1.0652e-02, 7.8128e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7612e-02,\n",
      "        9.1774e-06, 0.0000e+00, 1.3563e-01, 0.0000e+00, 4.5076e-02, 1.5460e-02,\n",
      "        3.7007e-02, 0.0000e+00, 3.8308e-02, 0.0000e+00, 0.0000e+00, 2.3529e-02,\n",
      "        1.0126e-01, 7.4645e-05, 0.0000e+00, 0.0000e+00, 3.0436e-01, 5.1260e-01,\n",
      "        5.2831e-04, 1.2802e-01, 0.0000e+00, 4.3526e-03, 0.0000e+00, 0.0000e+00,\n",
      "        5.5922e-03, 7.0205e-02, 1.3235e-01, 0.0000e+00, 8.1418e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.6592e-03, 2.2746e+00, 1.0241e-01, 8.0940e-02, 0.0000e+00,\n",
      "        1.1053e-01, 3.6541e-02, 7.6549e-06, 1.1757e-03, 1.3681e-01, 8.1139e-02,\n",
      "        2.7346e-04, 1.5179e-01, 0.0000e+00, 1.5594e-01, 3.3839e-02, 1.2029e-02,\n",
      "        2.9469e-01, 0.0000e+00, 1.7261e-05, 0.0000e+00, 3.0063e-05, 0.0000e+00,\n",
      "        5.3294e-02, 8.4536e-02, 9.3722e-04, 1.2829e-02, 0.0000e+00, 9.6902e-04,\n",
      "        1.0758e-05, 9.3815e-04, 0.0000e+00, 4.8115e-04, 4.2528e-03, 2.5944e-05,\n",
      "        1.2047e-01, 0.0000e+00, 2.5061e-02, 8.9163e-05, 3.1186e-03, 3.2195e-01,\n",
      "        2.5566e-01, 5.8715e-03, 0.0000e+00, 2.8526e-02, 3.6987e-03, 3.2692e-06,\n",
      "        2.7234e-04, 2.4497e-02, 1.9821e-04, 1.4833e-01, 9.1543e-02, 0.0000e+00,\n",
      "        2.0457e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0787e-03, 3.4822e-04,\n",
      "        1.1057e-01, 6.0902e-04, 6.6985e-02, 2.2191e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.1348e-01, 1.9196e-03, 0.0000e+00, 1.4901e-01, 1.6753e-05,\n",
      "        3.5947e-02, 1.4364e-01, 2.7948e-01, 0.0000e+00, 1.3598e-03, 0.0000e+00,\n",
      "        0.0000e+00, 3.5900e-03, 0.0000e+00, 1.0359e-03, 2.2143e-02, 5.8714e-04,\n",
      "        1.1901e-02, 0.0000e+00, 2.6048e-03, 2.4130e-02, 1.1394e-03, 0.0000e+00,\n",
      "        6.3744e-03, 0.0000e+00, 3.4061e-03, 1.1123e-03, 1.4930e-01, 4.3058e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.8804e-04, 4.5933e-02, 3.1749e-02, 3.2862e-05],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([1.1398e-04, 4.7708e-03, 1.2853e-02, 5.2054e-04, 0.0000e+00, 1.0851e-03,\n",
      "        1.4297e-04, 8.1036e-04, 1.1764e-03, 4.2036e-06, 3.5694e-03, 0.0000e+00,\n",
      "        4.9244e-03, 2.2074e-05, 5.3207e-06, 1.4056e-04, 6.0984e-04, 7.5830e-04,\n",
      "        6.1275e-03, 1.3493e-04, 9.7206e-03, 4.2004e-05, 4.1519e-03, 4.8450e-03,\n",
      "        2.7574e-03, 8.6861e-05, 1.1847e-04, 0.0000e+00, 1.0745e-04, 9.9571e-04,\n",
      "        4.6017e-04, 2.4858e-02, 1.5393e-05, 1.6569e-03, 6.4316e-04, 2.9642e-03,\n",
      "        9.4376e-04, 1.4952e-02, 1.2886e-04, 4.5493e-07, 1.3504e-04, 4.8785e-03,\n",
      "        6.9863e-04, 1.2067e-03, 1.5495e-04, 3.2480e-03, 6.0674e-06, 3.2526e-02,\n",
      "        8.9191e-03, 5.2787e-05, 6.1864e-04, 3.8029e-04, 1.4021e-03, 2.0067e-04,\n",
      "        7.7498e-04, 3.4461e-03, 1.7967e-03, 2.7483e-04, 1.5815e-04, 3.2127e-02,\n",
      "        3.2051e-04, 3.7298e-03, 6.7843e-03, 2.6266e-04, 3.8136e-04, 2.0562e-03,\n",
      "        3.6438e-04, 2.2635e-03, 0.0000e+00, 1.8645e-02, 0.0000e+00, 2.3223e-05,\n",
      "        1.5041e-05, 9.5529e-05, 0.0000e+00, 1.1022e-03, 2.0979e-03, 4.7658e-03,\n",
      "        6.5896e-05, 7.9812e-04, 5.3670e-05, 2.3269e-02, 3.1270e-04, 6.1543e-04,\n",
      "        0.0000e+00, 2.9472e-04, 1.1604e-03, 2.8044e-03, 4.7813e-05, 4.0630e-03,\n",
      "        1.7346e-03, 1.4615e-02, 1.2362e-02, 1.6982e-03, 1.6581e-02, 0.0000e+00,\n",
      "        0.0000e+00, 5.3713e-03, 8.1687e-04, 0.0000e+00, 1.0709e-03, 0.0000e+00,\n",
      "        1.4239e-04, 3.3438e-02, 1.2497e-03, 1.0786e-04, 2.0330e-02, 1.1047e-03,\n",
      "        4.3298e-03, 2.2247e-03, 0.0000e+00, 0.0000e+00, 8.2172e-03, 1.2658e-04,\n",
      "        5.4252e-04, 1.2356e-03, 1.1873e-03, 1.1370e-06, 5.0737e-03, 4.0171e-03,\n",
      "        3.9690e-05, 2.3254e-04, 5.0354e-03, 0.0000e+00, 3.8263e-04, 1.3243e-04,\n",
      "        3.3230e-02, 2.3676e-03, 8.8254e-03, 1.6509e-02, 9.6839e-03, 1.1573e-03,\n",
      "        1.2999e-03, 7.4647e-04, 4.9026e-03, 4.7943e-04, 2.8784e-04, 8.1321e-04,\n",
      "        1.4185e-02, 1.1939e-02, 2.2381e-05, 4.6478e-04, 2.8349e-04, 8.0140e-05,\n",
      "        1.1773e-03, 1.4378e-02, 1.2813e-04, 1.1124e-03, 5.8977e-04, 4.7173e-03,\n",
      "        4.6463e-07, 3.0078e-03, 3.2807e-04, 4.8494e-03, 3.5239e-03, 0.0000e+00,\n",
      "        8.8148e-03, 1.8530e-03, 7.6473e-03, 1.9041e-04, 6.8844e-04, 1.3382e-04,\n",
      "        5.1625e-03, 1.2200e-03, 1.5350e-03, 0.0000e+00, 4.9860e-03, 2.4760e-02,\n",
      "        5.6660e-03, 5.9850e-06, 1.9886e-03, 1.0606e-03, 6.0488e-03, 2.1275e-03,\n",
      "        9.4599e-05, 3.1348e-04, 1.8316e-04, 3.4494e-03, 0.0000e+00, 2.5743e-04,\n",
      "        3.6949e-03, 7.7493e-06, 1.3794e-04, 2.1395e-03, 1.5456e-03, 7.7880e-04,\n",
      "        1.0849e-05, 1.7391e-05, 1.3524e-07, 4.1007e-03, 7.2610e-06, 4.1321e-03],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0170, 0.0141, 0.0117, 0.0112, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0112, 0.0122, 0.0171,\n",
      "        0.0190], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0300, 0.0309, 0.0297, 0.0294, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292,\n",
      "        0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292,\n",
      "        0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0291, 0.0292, 0.0303, 0.0338,\n",
      "        0.0323], device='cuda:0') torch.Size([28])\n",
      "score tensor([1.2822e-02, 1.5388e-04, 1.7542e-01, 0.0000e+00, 8.1747e-05, 1.1079e-03,\n",
      "        2.1358e-05, 2.7842e-06, 0.0000e+00, 4.2787e-02, 5.9599e-03, 0.0000e+00,\n",
      "        0.0000e+00, 9.8163e-03, 7.2272e-04, 5.2414e-04, 0.0000e+00, 2.0504e-03,\n",
      "        0.0000e+00, 2.5707e-04, 2.2552e-04, 7.9327e-05, 9.7219e-02, 7.4776e-04,\n",
      "        3.7142e-03, 0.0000e+00, 7.2798e-04, 0.0000e+00, 1.0853e-04, 7.4608e-04,\n",
      "        2.2975e-02, 1.0940e-04, 0.0000e+00, 2.7693e-02, 0.0000e+00, 1.3142e-02,\n",
      "        0.0000e+00, 3.8636e-02, 6.8152e-04, 8.9760e-03, 6.4065e-04, 1.7096e-03,\n",
      "        4.6669e-07, 0.0000e+00, 7.9368e-03, 0.0000e+00, 5.0859e-03, 3.2397e-02,\n",
      "        0.0000e+00, 2.9600e-03, 2.4231e-03, 1.3762e-02, 0.0000e+00, 1.0094e-04,\n",
      "        0.0000e+00, 3.2297e-02, 4.5528e-03, 3.2010e-02, 0.0000e+00, 1.2798e-03,\n",
      "        0.0000e+00, 8.3866e-06, 1.0675e-04, 0.0000e+00, 2.2208e-02, 5.5800e-06,\n",
      "        7.6584e-03, 0.0000e+00, 3.1666e-02, 4.7974e-05, 7.5318e-02, 8.7454e-05,\n",
      "        1.1764e-03, 0.0000e+00, 6.7835e-03, 0.0000e+00, 6.9392e-03, 3.0259e-04,\n",
      "        2.6940e-05, 1.0261e-04, 6.8576e-03, 0.0000e+00, 4.4101e-02, 1.9438e-03,\n",
      "        2.3622e-02, 1.6609e-04, 0.0000e+00, 0.0000e+00, 7.0736e-04, 3.3841e-04,\n",
      "        3.0459e-04, 1.0267e-03, 2.8238e-02, 1.5958e-04, 1.7340e-06, 1.2577e-02,\n",
      "        7.3481e-03, 9.4268e-05, 1.7361e-04, 0.0000e+00, 4.2074e-03, 3.8741e-04,\n",
      "        3.5795e-04, 2.2044e-06, 4.8092e-03, 1.3364e-02, 4.0164e-03, 3.3110e-03,\n",
      "        6.5631e-02, 4.5335e-04, 7.0436e-03, 9.0593e-03, 2.5654e-02, 0.0000e+00,\n",
      "        1.2611e-03, 1.1948e-02, 1.7847e-04, 3.3939e-04, 3.0702e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8848e-02, 0.0000e+00, 0.0000e+00, 1.3224e-04, 5.8075e-03,\n",
      "        0.0000e+00, 3.7460e-04, 1.0521e-01, 3.8152e-04, 2.2624e-02, 4.7928e-04,\n",
      "        1.4597e-03, 1.9866e-02, 0.0000e+00, 4.8555e-02, 2.4622e-04, 5.5955e-04,\n",
      "        0.0000e+00, 0.0000e+00, 7.4639e-03, 1.5312e-03, 1.9397e-03, 2.0711e-03,\n",
      "        4.9414e-03, 0.0000e+00, 4.5460e-03, 0.0000e+00, 0.0000e+00, 1.4746e-03,\n",
      "        0.0000e+00, 2.3630e-05, 1.4651e-02, 1.9066e-03, 2.2127e-06, 0.0000e+00,\n",
      "        3.6122e-02, 1.3878e-02, 0.0000e+00, 2.4852e-03, 1.8051e-02, 0.0000e+00,\n",
      "        1.4990e-03, 1.6129e-03, 2.1192e-03, 1.9821e-03, 8.1403e-04, 0.0000e+00,\n",
      "        4.7232e-02, 9.8164e-07, 0.0000e+00, 3.8782e-02, 1.0382e-04, 2.3042e-02,\n",
      "        0.0000e+00, 1.7700e-06, 6.3670e-05, 0.0000e+00, 3.2516e-04, 0.0000e+00,\n",
      "        5.3431e-04, 9.0467e-03, 1.4388e-03, 0.0000e+00, 2.1793e-03, 0.0000e+00,\n",
      "        4.7829e-02, 4.1291e-02, 2.7325e-06, 2.4147e-06, 1.7621e-03, 5.2388e-02],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0552, 0.0377, 0.0333, 0.0326, 0.0330, 0.0335, 0.0337, 0.0338, 0.0338,\n",
      "        0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338,\n",
      "        0.0338, 0.0338, 0.0338, 0.0337, 0.0335, 0.0328, 0.0319, 0.0321, 0.0330,\n",
      "        0.0482], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0726, 0.0601, 0.0559, 0.0584, 0.0587, 0.0600, 0.0605, 0.0607, 0.0607,\n",
      "        0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607,\n",
      "        0.0607, 0.0607, 0.0607, 0.0606, 0.0601, 0.0587, 0.0581, 0.0566, 0.0553,\n",
      "        0.0664], device='cuda:0') torch.Size([28])\n",
      "score tensor([5.5413e-04, 6.8330e-03, 2.0432e-05, 5.0336e-04, 1.5844e-02, 3.9921e-04,\n",
      "        3.4608e-04, 0.0000e+00, 3.0729e-04, 8.2974e-03, 6.5116e-03, 2.6519e-03,\n",
      "        3.0610e-02, 4.3852e-02, 1.0570e-02, 3.3981e-04, 6.1594e-03, 3.4320e-04,\n",
      "        4.3444e-04, 1.6094e-06, 9.0837e-04, 1.5457e-03, 4.0368e-02, 6.6796e-05,\n",
      "        1.6516e-02, 1.2750e-04, 1.0239e-03, 6.5637e-03, 7.5800e-03, 4.2697e-03,\n",
      "        1.0639e-04, 0.0000e+00, 1.0236e-03, 3.8928e-04, 5.2788e-04, 7.4852e-03,\n",
      "        0.0000e+00, 9.4600e-02, 6.0816e-04, 5.9468e-03, 1.1103e-04, 3.5347e-03,\n",
      "        1.3342e-02, 0.0000e+00, 1.0830e-03, 2.0382e-05, 6.1601e-02, 2.5056e-05,\n",
      "        9.6671e-03, 7.9740e-03, 8.1990e-05, 6.5808e-05, 1.0823e-03, 1.6365e-03,\n",
      "        1.4503e-02, 2.0038e-03, 3.1397e-03, 3.9409e-03, 1.2166e-02, 7.6018e-03,\n",
      "        2.0354e-03, 4.0363e-02, 5.0881e-05, 1.1206e-04, 0.0000e+00, 0.0000e+00,\n",
      "        2.8651e-05, 4.6968e-03, 3.4266e-03, 9.1793e-04, 2.1662e-03, 1.1928e-02,\n",
      "        2.1372e-03, 3.2016e-02, 0.0000e+00, 1.3422e-03, 1.1529e-03, 2.1344e-03,\n",
      "        4.0395e-04, 0.0000e+00, 1.4230e-02, 1.0560e-04, 2.4957e-03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9636e-03, 2.6980e-04, 0.0000e+00,\n",
      "        0.0000e+00, 4.3649e-02, 2.8041e-03, 4.9503e-05, 0.0000e+00, 0.0000e+00,\n",
      "        5.5329e-04, 0.0000e+00, 4.8413e-02, 1.8805e-05, 7.8960e-04, 1.4648e-03,\n",
      "        1.4919e-02, 1.0736e-02, 0.0000e+00, 1.5621e-03, 1.4369e-03, 7.1651e-04,\n",
      "        4.2166e-07, 1.2695e-02, 3.6258e-03, 1.6923e-04, 1.9858e-03, 4.2114e-02,\n",
      "        4.1617e-04, 1.6579e-03, 0.0000e+00, 2.1062e-03, 0.0000e+00, 9.8010e-03,\n",
      "        7.5761e-05, 6.7155e-06, 0.0000e+00, 6.1723e-03, 1.0694e-03, 1.6106e-02,\n",
      "        1.1187e-02, 8.9274e-03, 7.0994e-04, 1.1703e-03, 1.3672e-03, 1.8904e-04,\n",
      "        2.3841e-03, 3.2589e-06, 1.5965e-03, 0.0000e+00, 1.5458e-03, 9.3663e-04,\n",
      "        4.1003e-03, 1.8531e-04, 4.2283e-02, 4.5336e-03, 4.2899e-05, 0.0000e+00,\n",
      "        5.9865e-05, 6.4761e-03, 4.0760e-02, 1.4530e-02, 4.3186e-04, 0.0000e+00,\n",
      "        8.9921e-04, 3.2293e-04, 2.6279e-04, 6.4053e-03, 1.0055e-06, 2.1881e-03,\n",
      "        1.1002e-02, 2.6266e-03, 1.3236e-03, 3.2389e-03, 6.9216e-06, 2.3727e-02,\n",
      "        9.0596e-04, 1.4073e-03, 5.6701e-05, 5.0390e-06, 4.9078e-04, 0.0000e+00,\n",
      "        0.0000e+00, 3.3891e-02, 4.0206e-04, 1.8996e-02, 1.4516e-02, 0.0000e+00,\n",
      "        8.8666e-03, 6.0496e-05, 0.0000e+00, 9.5113e-04, 5.2393e-03, 0.0000e+00,\n",
      "        1.1837e-03, 2.7810e-03, 0.0000e+00, 4.6149e-04, 2.3168e-04, 2.0603e-03,\n",
      "        0.0000e+00, 9.2794e-04, 8.3138e-03, 3.2302e-05, 2.3485e-05, 1.4717e-03],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0187, 0.0237, 0.0192, 0.0179, 0.0193, 0.0188, 0.0190, 0.0192, 0.0194,\n",
      "        0.0194, 0.0194, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
      "        0.0194, 0.0194, 0.0194, 0.0194, 0.0199, 0.0237, 0.0211, 0.0284, 0.0268,\n",
      "        0.0259], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0489, 0.0685, 0.0664, 0.0732, 0.0728, 0.0738, 0.0746, 0.0750, 0.0752,\n",
      "        0.0753, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
      "        0.0754, 0.0754, 0.0753, 0.0750, 0.0748, 0.0749, 0.0721, 0.0751, 0.0575,\n",
      "        0.0532], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 5.9939e-02, 1.4309e-03, 1.0027e-01, 4.8641e-02,\n",
      "        6.5916e-03, 0.0000e+00, 1.2390e+00, 6.2512e-02, 4.3132e-02, 1.2420e-01,\n",
      "        1.7758e-02, 3.0780e-04, 0.0000e+00, 3.4033e-02, 0.0000e+00, 5.0831e-03,\n",
      "        0.0000e+00, 1.2698e-02, 4.0941e-04, 8.1152e-04, 1.2890e-03, 3.6835e-01,\n",
      "        1.0736e-01, 0.0000e+00, 6.9568e-02, 2.4073e-03, 4.1617e-02, 4.0763e-02,\n",
      "        2.7098e-02, 1.2543e-02, 1.6956e-03, 7.5609e-02, 5.1857e-02, 3.0407e-03,\n",
      "        1.3258e-01, 2.1829e-03, 6.6288e-03, 1.5926e-02, 7.1224e-02, 0.0000e+00,\n",
      "        3.3037e-02, 3.3585e-02, 0.0000e+00, 2.4734e-03, 7.1781e-05, 4.1354e-03,\n",
      "        2.1474e-04, 5.3668e-01, 1.5307e-02, 3.3986e-02, 1.5004e-02, 3.7625e-02,\n",
      "        4.7761e-04, 4.4108e-02, 0.0000e+00, 2.9319e-05, 5.4076e-01, 0.0000e+00,\n",
      "        7.3015e-02, 1.0927e-02, 1.2747e-01, 3.7130e-02, 2.8096e-02, 0.0000e+00,\n",
      "        0.0000e+00, 7.2544e-03, 2.4315e-02, 4.1096e-02, 2.5836e-02, 4.2162e-02,\n",
      "        0.0000e+00, 1.3818e-02, 6.4579e-03, 7.7382e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.5399e-05, 0.0000e+00, 1.6720e-02, 4.0701e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.9635e-02, 6.5796e-03, 4.2719e-02, 8.9107e-02, 3.0547e-06,\n",
      "        2.7840e-02, 1.2318e-01, 0.0000e+00, 2.3794e-02, 5.4032e-03, 1.2424e-02,\n",
      "        1.1559e-03, 4.6927e-04, 0.0000e+00, 0.0000e+00, 5.7728e-02, 9.9951e-06,\n",
      "        0.0000e+00, 0.0000e+00, 1.2745e-01, 0.0000e+00, 0.0000e+00, 1.6641e-02,\n",
      "        8.2857e-03, 4.0786e-02, 4.6745e-02, 7.7926e-03, 1.7212e-02, 0.0000e+00,\n",
      "        1.7010e-01, 2.9829e-02, 1.8263e-01, 4.6542e-02, 1.4895e-02, 3.2480e-02,\n",
      "        0.0000e+00, 7.3839e-03, 5.1982e-04, 3.5019e-02, 2.9117e-04, 0.0000e+00,\n",
      "        9.3821e-03, 5.9954e-03, 6.6747e-02, 2.8804e-03, 8.5007e-03, 0.0000e+00,\n",
      "        6.7314e-03, 1.5924e-02, 2.5119e-02, 1.1197e-01, 2.3941e-02, 1.3398e-02,\n",
      "        9.8055e-02, 0.0000e+00, 3.4514e-02, 0.0000e+00, 1.1831e-03, 0.0000e+00,\n",
      "        9.5380e-03, 5.4282e-04, 3.1455e-03, 0.0000e+00, 1.3040e-02, 2.0323e-03,\n",
      "        0.0000e+00, 1.0756e-03, 0.0000e+00, 8.7447e-02, 6.3563e-03, 0.0000e+00,\n",
      "        2.2283e-01, 2.5711e-04, 8.5837e-04, 0.0000e+00, 5.5984e-03, 2.5180e-03,\n",
      "        5.0748e-03, 0.0000e+00, 6.9174e-02, 5.5268e-03, 0.0000e+00, 0.0000e+00,\n",
      "        1.7101e-03, 0.0000e+00, 3.8029e-04, 3.4988e-02, 5.6030e-05, 6.8634e-03,\n",
      "        1.1994e-04, 5.2013e-02, 7.2985e-03, 4.8626e-03, 0.0000e+00, 1.0617e-03,\n",
      "        0.0000e+00, 8.0935e-05, 1.8486e-02, 5.4259e-02, 6.8909e-02, 1.4231e-03,\n",
      "        0.0000e+00, 8.9129e-04, 0.0000e+00, 2.4443e-03, 4.4216e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.9199e-03, 2.4851e-02, 2.2650e-02, 9.6908e-03, 6.6064e-02,\n",
      "        2.7041e-02, 3.1352e-01, 8.5635e-02, 1.9966e-02, 1.3417e-02, 3.0733e-02,\n",
      "        2.8351e-02, 5.6757e-02, 1.9236e-03, 0.0000e+00, 6.9152e-02, 0.0000e+00,\n",
      "        1.5910e-02, 1.1006e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6106e-02,\n",
      "        5.2779e-03, 3.5424e-02, 0.0000e+00, 8.8567e-03, 1.1576e-02, 6.9350e-02,\n",
      "        3.1475e-03, 0.0000e+00, 5.0239e-02, 2.3555e-02, 4.2826e-03, 1.9418e-02,\n",
      "        3.6116e-03, 5.8238e-02, 2.2729e-04, 3.6831e-02, 1.5128e-03, 5.4066e-03,\n",
      "        1.0019e-02, 3.7981e-02, 2.2184e+00, 6.8897e-02, 0.0000e+00, 3.3698e-01,\n",
      "        5.2541e-03, 0.0000e+00, 2.5828e-06, 0.0000e+00, 9.8688e-06, 3.1989e-01,\n",
      "        2.3165e-02, 2.8681e-02, 9.0928e-03, 2.0590e-02, 1.2818e-03, 7.3104e-02,\n",
      "        1.1438e-01, 0.0000e+00, 5.2542e-02, 4.2370e-01, 0.0000e+00, 0.0000e+00,\n",
      "        2.0401e-02, 2.5091e-01, 0.0000e+00, 1.0394e-02, 0.0000e+00, 3.4031e-02,\n",
      "        2.2529e-02, 4.6920e-02, 8.3188e-02, 5.1544e-02, 1.7570e-02, 4.0793e-04,\n",
      "        0.0000e+00, 1.1200e-01, 2.4691e-02, 1.1567e-03, 1.4999e-03, 2.3040e-02,\n",
      "        3.2260e-02, 2.7740e-04, 1.0932e-03, 1.0773e-03, 1.3356e-04, 1.8627e-02,\n",
      "        5.4099e-03, 0.0000e+00, 9.2388e-02, 6.2580e-04, 2.4447e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.4963e-03, 0.0000e+00, 6.1041e-02, 0.0000e+00,\n",
      "        1.3946e-02, 8.2258e-05, 1.4412e-02, 0.0000e+00, 5.0635e-02, 2.2284e-01,\n",
      "        6.1962e-03, 8.1627e-02, 6.5597e-03, 0.0000e+00, 4.0545e-02, 4.8748e-03,\n",
      "        5.5871e-02, 2.9698e-02, 0.0000e+00, 5.3374e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.9877e-03, 7.9872e-02, 3.9953e-02, 1.8329e-05, 5.3370e-03,\n",
      "        3.4343e-03, 8.0117e-03, 0.0000e+00, 3.0698e-02, 1.8670e-04, 0.0000e+00,\n",
      "        4.0309e-02, 5.5036e-02, 1.1180e-02, 3.5491e-02, 0.0000e+00, 5.1335e-02,\n",
      "        9.6536e-02, 0.0000e+00, 6.5535e-02, 0.0000e+00, 2.6232e-06, 0.0000e+00,\n",
      "        0.0000e+00, 1.0001e-02, 6.9291e-02, 2.2234e-03, 1.6376e-01, 7.7700e-04,\n",
      "        4.0994e-02, 8.8364e-02, 3.3583e-03, 0.0000e+00, 2.6016e-02, 2.2681e-02,\n",
      "        4.9233e-02, 0.0000e+00, 3.9178e-02, 9.3144e-03, 0.0000e+00, 3.5825e-03,\n",
      "        5.4976e-03, 0.0000e+00, 7.8567e-03, 1.6480e-02, 8.9949e-03, 4.1107e-05,\n",
      "        4.3018e-02, 2.9189e-04, 5.5808e-03, 0.0000e+00, 1.6812e-03, 7.2220e-03,\n",
      "        9.7682e-03, 9.0559e-02, 1.4006e-03, 1.5341e-03, 2.2336e-04, 3.6217e-04,\n",
      "        1.1276e-02, 6.2781e-02, 0.0000e+00, 3.1922e-02, 3.5792e-02, 0.0000e+00,\n",
      "        0.0000e+00, 7.1726e-06, 8.1727e-02, 0.0000e+00, 2.0042e-03, 1.3470e-05],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([5.7125e-03, 1.2607e-03, 9.1151e-05, 0.0000e+00, 2.0622e-02, 1.0712e-03,\n",
      "        0.0000e+00, 9.6046e-05, 4.9116e-02, 4.8091e-04, 0.0000e+00, 1.5276e-03,\n",
      "        1.1440e-02, 0.0000e+00, 0.0000e+00, 1.9492e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.4408e-03, 1.2114e-04, 2.5482e-03, 8.8223e-03, 2.4755e-03, 1.6903e-02,\n",
      "        4.3950e-02, 3.9545e-05, 5.0666e-02, 1.4132e-02, 4.4898e-06, 7.5141e-03,\n",
      "        3.1656e-03, 1.9736e-03, 3.1743e-03, 1.9808e-03, 3.3505e-03, 1.7040e-04,\n",
      "        1.2176e-02, 0.0000e+00, 0.0000e+00, 4.3202e-03, 1.2111e-05, 3.0712e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5313e-06, 3.5532e-03, 2.7679e-05,\n",
      "        6.3935e-04, 2.4570e-04, 0.0000e+00, 5.0473e-04, 5.4964e-04, 5.6284e-03,\n",
      "        1.3735e-01, 0.0000e+00, 3.6311e-03, 2.0056e-04, 1.2449e-02, 0.0000e+00,\n",
      "        1.0162e-02, 0.0000e+00, 1.0325e-02, 1.0350e-02, 3.2303e-05, 1.0274e-02,\n",
      "        1.4586e-04, 1.4728e-03, 0.0000e+00, 1.3837e-03, 0.0000e+00, 0.0000e+00,\n",
      "        6.3964e-03, 0.0000e+00, 6.1285e-04, 0.0000e+00, 1.1992e-04, 0.0000e+00,\n",
      "        1.1274e-02, 7.1528e-04, 1.7521e-02, 3.7453e-05, 2.9709e-02, 3.4007e-05,\n",
      "        0.0000e+00, 2.7425e-04, 1.7770e-02, 1.3054e-02, 0.0000e+00, 3.5212e-02,\n",
      "        0.0000e+00, 8.2884e-03, 2.0899e-02, 5.1334e-03, 8.9995e-04, 0.0000e+00,\n",
      "        7.3090e-05, 0.0000e+00, 1.7742e-03, 2.5929e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.8768e-03, 0.0000e+00, 1.1170e-03, 1.9680e-02, 8.3362e-05, 0.0000e+00,\n",
      "        4.0408e-03, 8.5923e-04, 0.0000e+00, 2.8903e-03, 4.6467e-03, 5.9679e-04,\n",
      "        6.7584e-03, 0.0000e+00, 1.1843e-02, 4.9982e-04, 6.9943e-04, 1.1160e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8320e-03, 8.0298e-05, 4.0204e-03,\n",
      "        5.3676e-03, 3.9472e-03, 7.8494e-03, 0.0000e+00, 0.0000e+00, 6.9861e-03,\n",
      "        0.0000e+00, 2.5432e-02, 0.0000e+00, 5.0532e-03, 2.1005e-03, 8.7459e-05,\n",
      "        0.0000e+00, 8.7627e-04, 0.0000e+00, 1.3555e-03, 0.0000e+00, 2.4638e-04,\n",
      "        9.8443e-04, 2.5472e-03, 9.4158e-06, 0.0000e+00, 1.7542e-02, 3.2168e-03,\n",
      "        1.9522e-02, 0.0000e+00, 1.3986e-03, 6.3272e-03, 2.9292e-03, 2.4728e-03,\n",
      "        6.5725e-03, 6.6802e-03, 7.0889e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.7189e-02, 1.4569e-04, 0.0000e+00, 1.7224e-03, 5.0027e-03,\n",
      "        3.6220e-03, 0.0000e+00, 3.6017e-03, 1.8512e-04, 7.6791e-04, 1.0622e-02,\n",
      "        0.0000e+00, 2.3025e-03, 2.6488e-03, 3.6256e-05, 9.1798e-06, 0.0000e+00,\n",
      "        4.8312e-03, 2.2637e-02, 2.0247e-04, 0.0000e+00, 4.7766e-05, 1.7106e-02,\n",
      "        1.0155e-02, 6.9611e-04, 2.5413e-03, 1.0183e-03, 1.3670e-06, 0.0000e+00,\n",
      "        1.5863e-04, 7.5562e-03, 7.0913e-04, 0.0000e+00, 7.9979e-04, 1.0720e-03,\n",
      "        0.0000e+00, 0.0000e+00, 4.2877e-05, 1.9825e-02, 8.0252e-07, 1.5024e-05,\n",
      "        4.8428e-04, 0.0000e+00, 9.3134e-04, 8.5038e-06, 1.0228e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.5693e-04, 1.7827e-03, 8.5351e-03, 0.0000e+00, 1.4165e-05,\n",
      "        0.0000e+00, 1.5932e-05, 0.0000e+00, 0.0000e+00, 6.4898e-04, 9.2327e-03,\n",
      "        8.3661e-03, 2.3608e-04, 2.4220e-03, 3.7757e-06, 1.9317e-02, 3.4314e-03,\n",
      "        7.6608e-04, 1.1936e-04, 0.0000e+00, 1.1551e-02, 0.0000e+00, 7.4790e-03,\n",
      "        6.1151e-04, 1.0678e-03, 1.5910e-02, 8.1428e-05, 1.7744e-02, 2.2216e-03,\n",
      "        4.9887e-03, 0.0000e+00, 0.0000e+00, 1.6743e-05, 0.0000e+00, 6.7831e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9671e-05, 5.3237e-03,\n",
      "        3.7971e-04, 2.4400e-02, 1.0646e-02, 3.1288e-03, 1.2967e-02, 2.3432e-02,\n",
      "        0.0000e+00, 1.0958e-02, 0.0000e+00, 1.0543e-03, 1.1333e-05, 0.0000e+00,\n",
      "        1.5402e-03, 8.3685e-04, 1.8014e-03, 0.0000e+00, 1.1920e-02, 2.0972e-03,\n",
      "        2.0185e-03, 1.2611e-02, 0.0000e+00, 2.6110e-05, 6.5749e-04, 3.1599e-03,\n",
      "        1.5204e-03, 1.5995e-03, 5.5611e-05, 1.0559e-03, 8.4016e-04, 8.6758e-05,\n",
      "        0.0000e+00, 0.0000e+00, 8.7813e-04, 0.0000e+00, 0.0000e+00, 2.3144e-03,\n",
      "        8.4532e-05, 2.3728e-03, 0.0000e+00, 6.9395e-05, 1.6949e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.2852e-03, 3.7883e-03, 1.9843e-02, 0.0000e+00, 7.0955e-03,\n",
      "        1.6243e-05, 1.0345e-02, 5.6562e-04, 4.1200e-04, 1.7934e-04, 1.8261e-04,\n",
      "        4.4127e-03, 0.0000e+00, 1.4013e-02, 0.0000e+00, 3.8851e-03, 0.0000e+00,\n",
      "        2.2591e-03, 2.5168e-02, 1.3308e-02, 1.7781e-03, 6.0263e-03, 0.0000e+00,\n",
      "        0.0000e+00, 3.2102e-04, 5.6538e-04, 1.7701e-04, 2.4468e-03, 3.6925e-04,\n",
      "        0.0000e+00, 2.7930e-03, 0.0000e+00, 3.4614e-04, 1.2609e-03, 4.0343e-04,\n",
      "        1.8535e-04, 1.8462e-03, 0.0000e+00, 6.5062e-03, 1.0207e-03, 1.4370e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.2308e-04, 1.3802e-03, 1.8356e-02, 0.0000e+00,\n",
      "        4.4950e-04, 8.3973e-06, 0.0000e+00, 7.1917e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.4936e-03, 9.6255e-04, 3.1658e-04, 1.4495e-02, 1.5322e-03,\n",
      "        6.4198e-05, 5.6230e-04, 4.4231e-05, 6.0349e-04, 2.6837e-04, 4.9510e-04,\n",
      "        0.0000e+00, 0.0000e+00, 7.1808e-04, 0.0000e+00, 1.0748e-02, 3.0739e-05,\n",
      "        0.0000e+00, 0.0000e+00, 1.2292e-04, 0.0000e+00, 5.3514e-03, 3.4958e-02,\n",
      "        2.9561e-03, 1.1885e-03, 1.3908e-03, 2.0835e-04, 1.0890e-02, 2.0770e-02,\n",
      "        7.2944e-03, 0.0000e+00, 2.2378e-03, 2.7448e-03, 1.0027e-03, 2.2551e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0285, 0.0268, 0.0250, 0.0274, 0.0274, 0.0275, 0.0276, 0.0276, 0.0276,\n",
      "        0.0280, 0.0289, 0.0280, 0.0304, 0.0318], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0513, 0.0479, 0.0443, 0.0472, 0.0462, 0.0459, 0.0459, 0.0458, 0.0457,\n",
      "        0.0459, 0.0475, 0.0457, 0.0481, 0.0524], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 4.6745e-03, 2.6597e-04, 2.6717e-05, 0.0000e+00, 2.0946e-02,\n",
      "        0.0000e+00, 1.0664e-03, 3.2328e-02, 0.0000e+00, 0.0000e+00, 1.3169e-03,\n",
      "        2.8878e-02, 1.9358e-03, 0.0000e+00, 7.9156e-03, 1.9341e-02, 8.0617e-03,\n",
      "        4.8927e-05, 0.0000e+00, 4.1716e-03, 2.4092e-04, 6.2555e-03, 2.0531e-03,\n",
      "        3.4284e-03, 0.0000e+00, 2.7117e-02, 4.7614e-03, 4.6149e-04, 9.4217e-03,\n",
      "        1.7789e-02, 0.0000e+00, 0.0000e+00, 3.1835e-03, 1.6255e-04, 1.9513e-03,\n",
      "        1.9506e-03, 0.0000e+00, 2.2338e-02, 5.9406e-03, 3.3988e-03, 6.1774e-04,\n",
      "        4.0845e-04, 1.1829e-04, 3.8214e-05, 0.0000e+00, 1.4485e-05, 2.1258e-02,\n",
      "        0.0000e+00, 4.4967e-03, 2.1662e-03, 1.1694e-03, 4.0650e-03, 1.1209e-04,\n",
      "        3.7110e-03, 2.2200e-05, 1.0801e-03, 1.1807e-02, 6.1359e-02, 2.7224e-03,\n",
      "        2.7524e-02, 2.8121e-03, 1.1144e-02, 1.8534e-02, 8.2834e-05, 2.0431e-02,\n",
      "        1.1177e-03, 5.6134e-03, 0.0000e+00, 4.1671e-03, 1.0375e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.1840e-03, 0.0000e+00, 0.0000e+00, 2.5912e-03,\n",
      "        7.3365e-03, 3.4423e-04, 0.0000e+00, 1.1456e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.0217e-02, 6.4206e-03, 7.0376e-03, 0.0000e+00, 2.8415e-04, 1.1130e-04,\n",
      "        4.6423e-03, 8.1524e-03, 2.3881e-02, 7.2211e-05, 0.0000e+00, 1.5159e-02,\n",
      "        3.0108e-04, 1.0430e-05, 1.3174e-02, 1.3304e-02, 1.3476e-04, 0.0000e+00,\n",
      "        6.1122e-07, 3.6134e-02, 2.2869e-03, 1.3793e-02, 5.0233e-03, 0.0000e+00,\n",
      "        4.4869e-03, 3.1570e-02, 1.4572e-02, 1.3085e-03, 7.2458e-04, 6.4862e-03,\n",
      "        2.6861e-02, 1.1852e-02, 2.0519e-02, 5.9833e-04, 1.4038e-02, 3.2950e-03,\n",
      "        1.2249e-02, 2.7036e-03, 1.0181e-02, 3.8134e-04, 2.4904e-03, 3.1029e-03,\n",
      "        7.3449e-04, 2.6685e-03, 0.0000e+00, 4.3607e-04, 0.0000e+00, 8.9997e-04,\n",
      "        2.6799e-04, 1.3063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1068e-04,\n",
      "        2.5750e-02, 2.2846e-06, 3.3831e-04, 0.0000e+00, 6.7338e-04, 2.1899e-02,\n",
      "        8.6071e-04, 1.5713e-02, 3.9733e-04, 1.0045e-02, 6.6497e-05, 1.4681e-02,\n",
      "        0.0000e+00, 1.7921e-03, 6.3228e-03, 3.8396e-03, 3.4047e-03, 1.8055e-03,\n",
      "        1.9728e-02, 0.0000e+00, 1.7048e-03, 1.3336e-02, 4.7503e-05, 6.9176e-05,\n",
      "        8.0599e-04, 8.6580e-03, 1.1714e-03, 3.6999e-05, 3.0691e-02, 1.9296e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.3476e-02, 1.4999e-02, 1.7978e-05, 0.0000e+00,\n",
      "        1.4901e-03, 3.4628e-06, 5.9802e-04, 8.1351e-07, 3.1071e-04, 0.0000e+00,\n",
      "        5.5287e-04, 3.0620e-03, 3.6025e-05, 7.1813e-04, 5.8363e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.3087e-03, 7.2932e-03, 1.6007e-02, 7.3673e-03,\n",
      "        5.6059e-03, 2.6953e-02, 2.1821e-03, 4.3543e-02, 0.0000e+00, 2.5933e-03,\n",
      "        1.3671e-02, 1.2803e-02, 8.1155e-03, 3.3397e-03, 0.0000e+00, 3.2248e-04,\n",
      "        1.0330e-07, 2.0373e-02, 2.7790e-03, 2.6782e-02, 7.8897e-02, 2.4596e-02,\n",
      "        2.4166e-02, 8.2353e-03, 1.1187e-03, 4.4246e-03, 7.2238e-03, 6.2135e-03,\n",
      "        2.1861e-04, 5.7809e-04, 2.6853e-04, 1.2292e-02, 2.7085e-04, 1.0133e-02,\n",
      "        2.3530e-04, 1.1033e-03, 3.7287e-03, 4.6723e-04, 5.8914e-04, 1.7463e-03,\n",
      "        1.8697e-03, 6.6236e-05, 0.0000e+00, 0.0000e+00, 8.8786e-05, 8.6022e-05,\n",
      "        6.2103e-04, 1.8165e-03, 8.0932e-02, 9.5162e-04, 9.2355e-03, 5.0575e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9287e-06, 1.3486e-03, 0.0000e+00, 7.0314e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.5304e-02, 3.2588e-03, 2.2743e-04, 2.7346e-03,\n",
      "        1.9287e-03, 2.4664e-02, 1.1320e-03, 1.4079e-02, 3.0632e-03, 0.0000e+00,\n",
      "        3.1815e-03, 1.6891e-04, 7.5444e-05, 5.7147e-03, 5.1613e-03, 2.0813e-03,\n",
      "        1.2746e-02, 0.0000e+00, 0.0000e+00, 3.0653e-02, 4.1010e-03, 0.0000e+00,\n",
      "        2.0897e-04, 1.5309e-02, 2.7911e-03, 2.8494e-04, 4.0578e-03, 0.0000e+00,\n",
      "        7.1999e-03, 6.4295e-05, 6.1889e-02, 6.5530e-04, 9.7356e-03, 5.7994e-03,\n",
      "        0.0000e+00, 2.4270e-02, 3.5449e-04, 2.5063e-05, 0.0000e+00, 0.0000e+00,\n",
      "        8.7292e-06, 3.5487e-03, 1.0471e-02, 7.9731e-03, 1.2049e-02, 6.4458e-04,\n",
      "        6.8623e-03, 4.2847e-03, 4.6301e-05, 2.6903e-02, 3.9952e-03, 4.9840e-03,\n",
      "        3.1645e-05, 7.8987e-03, 3.0482e-03, 4.3564e-03, 0.0000e+00, 2.5203e-04,\n",
      "        6.4148e-03, 3.3204e-02, 2.1345e-05, 2.8447e-03, 0.0000e+00, 6.2561e-03,\n",
      "        2.9820e-03, 3.7249e-05, 6.3659e-04, 8.0041e-03, 3.9439e-04, 4.4365e-03,\n",
      "        4.4582e-03, 7.6291e-05, 1.3007e-02, 1.0691e-03, 1.6678e-03, 1.7513e-03,\n",
      "        1.0440e-02, 1.5539e-02, 1.0992e-02, 0.0000e+00, 0.0000e+00, 1.6875e-02,\n",
      "        9.2300e-03, 8.8064e-05, 1.0245e-03, 0.0000e+00, 1.2908e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.3878e-03, 3.6739e-05, 2.9997e-03, 7.2364e-03, 0.0000e+00,\n",
      "        1.6247e-03, 1.6531e-02, 1.5070e-03, 2.7541e-05, 6.4449e-05, 4.6371e-03,\n",
      "        0.0000e+00, 9.0442e-03, 1.0567e-03, 0.0000e+00, 8.0521e-03, 3.4868e-05,\n",
      "        1.3697e-03, 6.6510e-03, 5.8345e-04, 0.0000e+00, 5.8541e-03, 1.6770e-04,\n",
      "        1.8458e-04, 1.4252e-02, 2.7422e-03, 8.1324e-04, 7.4996e-04, 1.0527e-03,\n",
      "        5.4143e-04, 7.7863e-06, 0.0000e+00, 1.0961e-04, 2.2530e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.1457e-03, 8.0208e-05, 6.7151e-05, 0.0000e+00, 4.3559e-03,\n",
      "        0.0000e+00, 1.3253e-02, 2.7569e-02, 8.8086e-03, 8.4187e-03, 6.3316e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0211, 0.0143, 0.0141, 0.0131, 0.0148, 0.0144, 0.0156, 0.0154, 0.0140,\n",
      "        0.0136, 0.0132, 0.0139, 0.0165, 0.0174], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0494, 0.0368, 0.0362, 0.0354, 0.0356, 0.0354, 0.0367, 0.0363, 0.0350,\n",
      "        0.0347, 0.0342, 0.0362, 0.0388, 0.0498], device='cuda:0') torch.Size([14])\n",
      "score tensor([4.4557e-03, 5.4947e-03, 5.5124e-03, 1.4664e-03, 5.0942e-03, 2.2741e-03,\n",
      "        9.9161e-04, 8.4766e-03, 3.9167e-02, 2.3999e-03, 8.6893e-03, 7.3236e-03,\n",
      "        5.3546e-03, 4.6143e-04, 3.1448e-03, 7.6715e-03, 2.9346e-03, 1.9472e-03,\n",
      "        8.1154e-02, 2.9176e-03, 1.6562e-03, 5.5000e-03, 1.3538e-03, 1.4821e-03,\n",
      "        5.0774e-03, 2.8379e-03, 3.9478e-03, 5.1609e-03, 1.2222e-02, 1.5644e-03,\n",
      "        8.5693e-06, 2.3580e-03, 1.1008e-02, 1.9227e-02, 3.3948e-02, 3.3086e-03,\n",
      "        3.1721e-03, 3.1059e-03, 7.0120e-03, 5.3150e-03, 2.9119e-03, 1.1136e-03,\n",
      "        4.2727e-03, 2.6573e-03, 2.9058e-03, 1.9495e-03, 4.7448e-03, 5.7283e-03,\n",
      "        4.3896e-03, 7.5025e-02, 2.3113e-03, 5.3954e-03, 4.4692e-03, 6.3506e-03,\n",
      "        3.0917e-02, 4.8740e-03, 8.7453e-03, 3.7310e-03, 0.0000e+00, 3.7457e-03,\n",
      "        7.4415e-03, 7.6675e-04, 5.6517e-03, 5.4661e-03, 8.6256e-04, 4.9694e-03,\n",
      "        4.2654e-03, 1.6886e-03, 4.8779e-03, 6.3019e-02, 1.6855e-03, 6.3362e-03,\n",
      "        1.0148e-04, 2.5674e-03, 4.1521e-03, 6.8664e-03, 6.6675e-03, 1.5161e-02,\n",
      "        3.3973e-04, 4.2321e-03, 0.0000e+00, 5.3253e-03, 3.3636e-03, 7.6979e-03,\n",
      "        1.0069e-02, 0.0000e+00, 4.0879e-02, 1.9284e-03, 8.9011e-03, 3.0536e-03,\n",
      "        4.8379e-03, 7.3128e-02, 0.0000e+00, 1.4199e-03, 6.6803e-04, 2.6927e-03,\n",
      "        5.1197e-03, 0.0000e+00, 5.3841e-03, 3.0998e-03, 5.6694e-03, 1.5687e-02,\n",
      "        5.2377e-03, 3.4630e-02, 5.7868e-03, 2.4535e-03, 5.4920e-03, 1.7476e-05,\n",
      "        1.5788e-03, 7.8130e-03, 8.8914e-02, 1.0430e-02, 6.7769e-05, 3.4713e-03,\n",
      "        0.0000e+00, 2.8634e-03, 1.0292e-02, 1.2277e-03, 6.8624e-04, 2.6932e-03,\n",
      "        5.3409e-03, 0.0000e+00, 1.0143e-03, 8.1865e-03, 5.6125e-03, 6.2648e-03,\n",
      "        5.3250e-03, 5.1486e-03, 0.0000e+00, 1.7400e-03, 6.7085e-03, 1.2627e-02,\n",
      "        5.0952e-03, 5.9216e-04, 1.9703e-03, 5.4687e-03, 5.5371e-03, 4.8949e-03,\n",
      "        7.5712e-03, 7.2030e-03, 2.8801e-03, 7.2323e-03, 2.7032e-03, 5.6510e-03,\n",
      "        3.3768e-03, 4.3548e-03, 4.3028e-03, 6.2069e-03, 3.5787e-03, 4.9272e-02,\n",
      "        6.7589e-02, 2.0905e-03, 8.1806e-03, 0.0000e+00, 4.6824e-03, 6.1190e-03,\n",
      "        0.0000e+00, 4.0100e-03, 2.5969e-02, 0.0000e+00, 5.6219e-03, 5.5368e-03,\n",
      "        2.0169e-03, 5.0771e-03, 1.4772e-03, 8.0760e-03, 2.5446e-03, 2.6974e-03,\n",
      "        1.1790e-03, 2.2984e-03, 8.5244e-04, 2.1158e-03, 5.3251e-04, 5.0297e-03,\n",
      "        3.2858e-03, 2.9728e-03, 2.0506e-03, 4.2531e-03, 6.1230e-03, 4.3518e-03,\n",
      "        2.1743e-03, 7.7757e-02, 7.2028e-03, 2.5072e-03, 2.5733e-03, 4.1414e-03,\n",
      "        6.8577e-03, 4.4448e-03, 4.1760e-03, 2.9233e-03, 6.4134e-03, 4.9301e-03,\n",
      "        8.6453e-03, 1.1907e-02, 1.3578e-03, 7.6980e-03, 3.6179e-03, 1.1474e-03,\n",
      "        3.4168e-03, 0.0000e+00, 3.0775e-04, 3.9459e-02, 2.5067e-04, 3.7831e-03,\n",
      "        1.4480e-03, 3.6651e-04, 6.8080e-03, 1.6154e-02, 1.9773e-02, 2.2155e-03,\n",
      "        3.0109e-03, 7.4544e-03, 2.1323e-02, 3.2288e-03, 1.2542e-02, 0.0000e+00,\n",
      "        1.2562e-03, 3.2509e-03, 2.4992e-03, 2.7707e-03, 2.4566e-04, 2.0630e-02,\n",
      "        5.5301e-04, 6.6474e-03, 1.7403e-03, 4.8011e-03, 1.1987e-03, 2.4143e-04,\n",
      "        2.1748e-03, 1.1981e-03, 1.2598e-03, 3.8612e-03, 2.3702e-03, 2.6128e-03,\n",
      "        3.3157e-03, 8.4045e-03, 3.2781e-02, 0.0000e+00, 5.4057e-04, 3.8763e-02,\n",
      "        6.4455e-04, 1.0948e-02, 1.6593e-03, 5.6094e-03, 4.4996e-04, 0.0000e+00,\n",
      "        0.0000e+00, 1.7265e-03, 1.7207e-03, 4.1648e-03, 6.5666e-03, 4.1382e-03,\n",
      "        3.0134e-03, 6.4426e-03, 1.5090e-03, 1.2966e-02, 4.1092e-03, 0.0000e+00,\n",
      "        2.8643e-03, 0.0000e+00, 2.8252e-03, 4.4207e-03, 4.9882e-03, 3.3149e-03,\n",
      "        1.6640e-02, 8.3129e-03, 4.6418e-02, 3.8658e-03, 0.0000e+00, 2.8503e-03,\n",
      "        5.4100e-03, 6.4783e-03, 3.8287e-03, 2.4342e-03, 5.0570e-03, 1.9990e-03,\n",
      "        3.4901e-03, 1.0138e-03, 0.0000e+00, 9.6978e-04, 8.7815e-03, 2.4300e-03,\n",
      "        3.9000e-03, 5.5206e-02, 5.2052e-03, 0.0000e+00, 5.2654e-03, 2.4026e-03,\n",
      "        4.5757e-03, 2.3685e-02, 2.4603e-02, 2.9497e-03, 9.9581e-03, 5.2037e-03,\n",
      "        1.6026e-03, 1.6334e-02, 1.6030e-03, 1.9452e-02, 1.0067e-02, 5.3757e-03,\n",
      "        1.1749e-04, 1.6475e-03, 6.5999e-03, 0.0000e+00, 0.0000e+00, 1.4585e-02,\n",
      "        1.0489e-02, 7.0810e-03, 1.8975e-03, 1.2927e-03, 3.3233e-03, 3.8138e-03,\n",
      "        5.9912e-03, 4.2486e-03, 9.0713e-03, 1.6758e-03, 1.0004e-03, 1.6475e-02,\n",
      "        9.5293e-04, 3.2775e-03, 0.0000e+00, 1.4551e-02, 1.4081e-03, 1.7764e-03,\n",
      "        4.6463e-06, 4.2015e-03, 2.9649e-03, 1.5799e-03, 2.8096e-03, 6.1725e-02,\n",
      "        1.4404e-02, 4.3846e-03, 1.0490e-03, 2.4966e-03, 3.0498e-03, 8.3430e-04,\n",
      "        1.0693e-02, 1.8782e-03, 5.7117e-04, 3.0295e-03, 1.0537e-02, 7.2160e-04,\n",
      "        1.7039e-03, 7.1719e-04, 1.7242e-03, 2.6511e-03, 6.9537e-03, 4.2655e-03,\n",
      "        3.8905e-03, 1.9634e-02, 6.9369e-03, 2.1338e-03, 3.0847e-02, 3.1493e-03,\n",
      "        1.2812e-03, 3.6454e-03, 1.5766e-03, 1.8116e-03, 4.6335e-03, 9.2601e-04,\n",
      "        5.6415e-03, 3.6132e-03, 8.7068e-04, 1.4302e-03, 1.4936e-04, 3.6785e-03,\n",
      "        9.2214e-04, 4.7115e-03, 2.2817e-02, 8.7129e-03, 3.4223e-03, 1.0440e-03,\n",
      "        5.0372e-03, 7.0065e-03, 1.9830e-03, 3.6822e-03, 6.5570e-03, 7.4150e-03,\n",
      "        6.5066e-03, 5.2277e-03, 8.6263e-03, 1.7035e-03, 5.2685e-04, 8.0637e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0112, 0.0103, 0.0108, 0.0123, 0.0122, 0.0126, 0.0127, 0.0128, 0.0130,\n",
      "        0.0125, 0.0122, 0.0111, 0.0103, 0.0103], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0386, 0.0338, 0.0336, 0.0352, 0.0348, 0.0347, 0.0353, 0.0355, 0.0354,\n",
      "        0.0354, 0.0354, 0.0343, 0.0345, 0.0398], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 2.6689e-03, 2.5336e-02, 8.3615e-04, 1.9458e-02, 7.4745e-04,\n",
      "        1.7481e-02, 4.2833e-02, 4.6842e-02, 1.8717e-04, 1.0158e-01, 4.2858e-03,\n",
      "        4.8560e-04, 4.9385e-03, 1.8597e-03, 2.2003e-02, 5.4729e-03, 1.9183e-03,\n",
      "        7.4352e-03, 7.9635e-03, 1.2384e-02, 8.4327e-02, 5.3830e-02, 0.0000e+00,\n",
      "        1.1848e-02, 0.0000e+00, 0.0000e+00, 1.3931e-02, 8.2363e-02, 1.9356e-03,\n",
      "        1.5403e-04, 1.6508e-02, 1.2750e-03, 4.9081e-02, 1.2092e-03, 2.4771e-02,\n",
      "        6.2458e-02, 2.8474e-02, 2.4604e-02, 0.0000e+00, 4.5405e-03, 1.1369e-02,\n",
      "        9.3954e-04, 1.8424e-03, 6.5185e-03, 6.2110e-04, 5.8982e-03, 1.0174e-01,\n",
      "        1.6863e-02, 1.0556e-02, 0.0000e+00, 1.2181e-02, 1.6299e-04, 9.5049e-03,\n",
      "        2.1542e-02, 3.0415e-02, 1.6511e-01, 1.0471e-04, 2.5972e-02, 4.2119e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.8260e-02, 1.3484e-02, 6.8043e-02, 3.7766e-04,\n",
      "        2.6542e-03, 7.9632e-03, 2.7912e-02, 4.2929e-02, 0.0000e+00, 3.9534e-02,\n",
      "        1.1538e-02, 1.3426e-02, 2.9524e-03, 0.0000e+00, 3.7379e-02, 3.2841e-02,\n",
      "        0.0000e+00, 4.6464e-02, 2.0827e-01, 3.4753e-02, 0.0000e+00, 1.4731e-03,\n",
      "        1.6923e-03, 9.3103e-03, 5.4403e-04, 2.9668e-02, 9.4968e-03, 1.2867e-02,\n",
      "        0.0000e+00, 1.7300e-02, 2.2010e-02, 1.3531e-02, 3.1216e-02, 2.9723e-03,\n",
      "        0.0000e+00, 1.2760e-02, 2.5466e-02, 7.7356e-03, 1.2493e-02, 2.5327e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9203e-02, 6.3480e-03, 3.9787e-03, 3.3802e-02,\n",
      "        8.5286e-02, 3.7372e-02, 1.4002e-02, 3.6718e-02, 2.1643e-02, 3.9246e-02,\n",
      "        5.0768e-02, 3.0069e-02, 2.2603e-02, 1.3187e-01, 2.8959e-02, 5.8008e-02,\n",
      "        1.4267e-02, 1.4711e-02, 3.1737e-04, 1.3629e-03, 2.5704e-02, 3.6547e-02,\n",
      "        7.9408e-04, 4.4466e-03, 0.0000e+00, 5.1627e-04, 1.3215e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.3806e-04, 0.0000e+00, 4.6132e-02, 2.4613e-02, 8.2743e-03,\n",
      "        0.0000e+00, 3.8323e-02, 5.1955e-04, 2.0915e-02, 4.3322e-04, 0.0000e+00,\n",
      "        8.6459e-03, 1.5365e-02, 2.7464e-02, 0.0000e+00, 1.5052e-02, 2.3854e-02,\n",
      "        1.2147e-01, 5.1010e-04, 5.0755e-03, 6.6018e-02, 8.4173e-03, 2.7793e-02,\n",
      "        0.0000e+00, 1.1236e-01, 7.1203e-03, 3.4227e-01, 4.9300e-02, 5.2812e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.6944e-02, 4.2151e-02, 4.9672e-02, 3.2431e-02,\n",
      "        1.1574e-02, 1.1197e-02, 5.8115e-03, 0.0000e+00, 2.5398e-02, 2.5671e-04,\n",
      "        1.0572e-04, 2.7758e-02, 2.5662e-03, 1.2152e-02, 2.1727e-02, 9.2462e-02,\n",
      "        2.5600e-04, 1.6209e-02, 5.7773e-03, 3.2391e-02, 1.3195e-02, 0.0000e+00,\n",
      "        2.4131e-02, 4.4236e-02, 1.4625e-02, 0.0000e+00, 0.0000e+00, 3.8061e-04,\n",
      "        0.0000e+00, 1.8903e-01, 0.0000e+00, 4.0356e-02, 2.4001e-02, 1.2609e-02,\n",
      "        1.2749e-02, 2.7808e-02, 1.5095e-02, 6.4214e-04, 1.3059e-03, 2.5149e-02,\n",
      "        2.0559e-02, 2.8884e-02, 4.0045e-02, 0.0000e+00, 4.6177e-02, 1.2497e-02,\n",
      "        2.9941e-02, 0.0000e+00, 8.2987e-02, 5.0506e-03, 4.4823e-02, 0.0000e+00,\n",
      "        2.4865e-02, 5.0060e-02, 4.9062e-02, 1.2662e-03, 6.2416e-02, 1.9856e-03,\n",
      "        2.6742e-02, 7.6265e-03, 0.0000e+00, 6.0419e-02, 3.5644e-04, 4.5404e-03,\n",
      "        3.5126e-02, 0.0000e+00, 1.5517e-03, 2.8533e-02, 2.2139e-03, 1.2890e-03,\n",
      "        2.6526e-02, 2.8783e-02, 1.5379e-02, 2.5924e-05, 4.3656e-03, 0.0000e+00,\n",
      "        3.1559e-03, 1.8942e-02, 1.7868e-02, 8.3266e-03, 0.0000e+00, 6.4803e-02,\n",
      "        9.5841e-03, 2.9461e-02, 1.5694e-02, 6.2291e-03, 0.0000e+00, 1.3331e-02,\n",
      "        9.2468e-02, 0.0000e+00, 1.0965e-02, 5.9389e-03, 0.0000e+00, 6.7797e-02,\n",
      "        2.3708e-02, 1.5262e-01, 0.0000e+00, 1.9873e-02, 1.2909e-06, 4.4037e-02,\n",
      "        1.7762e-02, 0.0000e+00, 2.8740e-02, 3.8076e-02, 2.1083e-03, 1.8048e-04,\n",
      "        3.2053e-04, 7.3038e-02, 0.0000e+00, 2.6590e-03, 1.0868e-02, 1.5882e-02,\n",
      "        1.0233e-02, 3.6876e-05, 0.0000e+00, 9.5398e-03, 0.0000e+00, 0.0000e+00,\n",
      "        5.2205e-05, 0.0000e+00, 6.2993e-03, 3.0867e-02, 5.0105e-03, 9.5083e-02,\n",
      "        1.1607e-03, 9.2571e-02, 4.8152e-03, 1.0181e-02, 0.0000e+00, 3.4635e-02,\n",
      "        2.4883e-03, 5.7265e-02, 8.4603e-03, 8.8665e-04, 9.4024e-02, 3.9247e-02,\n",
      "        2.5660e-02, 3.0419e-02, 4.7998e-03, 9.0142e-02, 0.0000e+00, 8.0658e-03,\n",
      "        9.8969e-02, 3.1879e-02, 4.7361e-02, 1.9952e-02, 0.0000e+00, 4.1888e-04,\n",
      "        1.7475e-05, 3.2284e-04, 1.5510e-02, 8.1034e-03, 1.1179e-03, 8.2994e-05,\n",
      "        5.7973e-02, 4.1771e-03, 3.8456e-02, 0.0000e+00, 2.1142e-02, 2.1451e-03,\n",
      "        1.5174e-02, 1.2404e-02, 0.0000e+00, 0.0000e+00, 3.5776e-04, 0.0000e+00,\n",
      "        5.7078e-02, 5.6767e-03, 2.3517e-02, 5.9321e-02, 3.6584e-02, 4.5578e-02,\n",
      "        2.7149e-03, 7.1914e-05, 1.2363e-02, 2.8732e-03, 0.0000e+00, 3.8089e-02,\n",
      "        2.3903e-02, 2.7742e-02, 0.0000e+00, 3.8504e-03, 2.6159e-02, 1.6124e-02,\n",
      "        5.8100e-03, 0.0000e+00, 1.9921e-02, 6.8734e-02, 2.7792e-02, 1.1021e-04,\n",
      "        0.0000e+00, 0.0000e+00, 1.0046e-02, 2.5809e-03, 0.0000e+00, 1.9423e-02,\n",
      "        2.3542e-02, 0.0000e+00, 4.9490e-03, 3.2016e-03, 6.4935e-03, 2.1264e-02,\n",
      "        9.3415e-02, 4.9732e-04, 6.4118e-03, 1.2864e-04, 6.5626e-02, 1.4158e-02,\n",
      "        5.8824e-03, 5.8854e-03, 0.0000e+00, 3.4105e-02, 1.6355e-03, 1.0190e-02,\n",
      "        6.8399e-04, 3.5320e-05, 2.9544e-02, 1.5293e-02, 2.9226e-02, 1.2577e-01],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0191, 0.0192, 0.0226, 0.0256, 0.0263, 0.0268, 0.0264, 0.0265, 0.0268,\n",
      "        0.0266, 0.0252, 0.0222, 0.0200, 0.0179], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0389, 0.0375, 0.0382, 0.0408, 0.0395, 0.0405, 0.0403, 0.0409, 0.0416,\n",
      "        0.0408, 0.0424, 0.0401, 0.0410, 0.0423], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 1.2695e-02, 4.1139e-03, 4.0144e-03, 5.0402e-02, 3.0981e-02,\n",
      "        1.3109e-02, 1.4703e-02, 6.3367e-02, 4.6618e-03, 1.1496e-03, 1.6106e-02,\n",
      "        8.3149e-03, 3.9773e-03, 6.6425e-03, 6.3571e-03, 0.0000e+00, 4.3011e-04,\n",
      "        2.6972e-02, 6.9600e-04, 2.4752e-03, 2.2531e-03, 2.8793e-02, 3.3077e-02,\n",
      "        1.1936e-02, 1.3995e-03, 1.6271e-02, 1.5300e-02, 1.4273e-02, 4.1360e-06,\n",
      "        2.9705e-03, 1.4091e-02, 3.3365e-02, 1.4812e-05, 2.9477e-03, 1.2447e-02,\n",
      "        2.1707e-02, 1.8362e-02, 4.7117e-03, 1.1928e-02, 8.0865e-03, 2.2891e-02,\n",
      "        3.6897e-03, 5.3855e-03, 5.4203e-03, 0.0000e+00, 4.3925e-03, 0.0000e+00,\n",
      "        1.0600e-03, 1.6817e-02, 1.1089e-03, 8.5972e-05, 1.7863e-03, 8.9439e-02,\n",
      "        3.3413e-03, 9.6029e-07, 0.0000e+00, 3.8683e-03, 1.2463e-02, 3.1487e-02,\n",
      "        1.1270e-02, 0.0000e+00, 4.8812e-02, 1.8501e-02, 4.9424e-03, 2.4499e-02,\n",
      "        2.6720e-02, 1.1121e-04, 8.8108e-03, 0.0000e+00, 1.4452e-02, 5.6405e-06,\n",
      "        1.1827e-03, 1.4418e-03, 3.0254e-03, 5.1742e-03, 4.3004e-03, 0.0000e+00,\n",
      "        2.2609e-02, 3.1814e-02, 1.1832e-01, 2.5572e-02, 6.3627e-04, 1.6753e-03,\n",
      "        1.0000e-02, 4.1955e-03, 1.9317e-02, 1.6068e-02, 7.4428e-03, 2.5641e-03,\n",
      "        2.8307e-03, 2.3880e-03, 6.5279e-04, 2.5148e-02, 5.0386e-03, 1.2288e-02,\n",
      "        1.1265e-02, 1.0064e-02, 8.1882e-03, 1.9966e-02, 8.9576e-03, 1.3042e-02,\n",
      "        1.8801e-02, 6.8769e-02, 3.1709e-03, 7.8435e-05, 1.8202e-02, 7.3866e-03,\n",
      "        0.0000e+00, 1.5129e-03, 4.4290e-02, 1.5716e-02, 3.4370e-03, 7.4198e-03,\n",
      "        0.0000e+00, 6.4591e-03, 7.3562e-03, 0.0000e+00, 8.9977e-06, 1.2574e-02,\n",
      "        3.1512e-03, 5.2059e-02, 1.8774e-02, 1.8796e-03, 1.1619e-02, 1.3611e-02,\n",
      "        5.0782e-03, 0.0000e+00, 3.8976e-02, 8.2799e-03, 3.8926e-02, 0.0000e+00,\n",
      "        2.1586e-03, 1.2355e-03, 1.5916e-03, 7.3722e-03, 7.3137e-03, 3.0095e-03,\n",
      "        3.6389e-02, 9.1647e-03, 1.2614e-02, 3.5059e-02, 7.7256e-04, 0.0000e+00,\n",
      "        2.2386e-05, 1.0209e-02, 3.4149e-03, 1.6169e-02, 2.0306e-03, 1.1170e-01,\n",
      "        1.0835e-01, 1.5316e-02, 9.6715e-04, 5.4319e-02, 4.1469e-03, 0.0000e+00,\n",
      "        1.7470e-01, 7.4674e-03, 4.2666e-02, 0.0000e+00, 6.4821e-03, 2.0465e-03,\n",
      "        8.0424e-03, 6.7837e-03, 2.6360e-02, 2.0322e-02, 7.4731e-02, 6.3980e-03,\n",
      "        8.3565e-03, 6.2985e-03, 3.1391e-02, 8.7906e-03, 2.0054e-02, 1.9024e-02,\n",
      "        1.3835e-02, 4.7903e-03, 2.3065e-03, 6.9792e-02, 6.1961e-03, 2.5716e-02,\n",
      "        1.9199e-02, 2.1838e-01, 1.8540e-04, 1.0993e-02, 9.1722e-03, 4.2045e-02,\n",
      "        7.0196e-03, 5.1490e-04, 9.7048e-03, 3.2843e-03, 2.6795e-04, 1.0798e-04,\n",
      "        1.8088e-03, 4.6878e-03, 1.9719e-03, 7.3589e-03, 1.7731e-03, 1.3199e-02,\n",
      "        1.3919e-03, 8.4436e-03, 7.4861e-03, 0.0000e+00, 1.4666e-02, 5.9419e-02,\n",
      "        2.8433e-02, 1.4729e-02, 4.4781e-02, 1.0143e-02, 1.2111e-02, 5.9383e-04,\n",
      "        2.7357e-02, 7.7654e-03, 1.4602e-02, 7.3993e-04, 8.6573e-03, 0.0000e+00,\n",
      "        2.9925e-03, 3.2404e-03, 3.6181e-03, 1.9120e-03, 2.4033e-03, 4.1378e-03,\n",
      "        2.4799e-02, 1.4504e-02, 1.8542e-03, 2.7143e-03, 2.2463e-03, 7.9697e-05,\n",
      "        2.8861e-03, 9.0622e-05, 1.3740e-02, 4.2739e-04, 4.0719e-02, 1.8270e-02,\n",
      "        4.2642e-03, 4.2287e-03, 3.5060e-02, 2.3069e-03, 4.4722e-03, 8.5825e-02,\n",
      "        1.4522e-02, 3.4565e-03, 2.3008e-03, 3.9654e-03, 1.1229e-02, 2.9097e-03,\n",
      "        1.6356e-03, 6.9016e-03, 1.4522e-02, 1.2452e-02, 3.1259e-03, 1.1678e-02,\n",
      "        1.0593e-02, 1.6796e-02, 0.0000e+00, 3.0116e-02, 0.0000e+00, 6.4266e-02,\n",
      "        1.4925e-02, 6.9147e-03, 0.0000e+00, 2.0571e-02, 2.3369e-02, 1.1872e-02,\n",
      "        6.6482e-03, 0.0000e+00, 1.5742e-03, 2.2726e-02, 1.2744e-02, 5.3909e-03,\n",
      "        2.6558e-05, 1.3029e-02, 1.7243e-04, 2.0402e-03, 1.3160e-02, 1.5979e-02,\n",
      "        4.5040e-03, 1.8994e-03, 8.4964e-02, 3.0887e-03, 6.5624e-03, 5.8101e-06,\n",
      "        8.4040e-03, 0.0000e+00, 8.5111e-03, 2.0816e-04, 1.7814e-02, 1.3797e-02,\n",
      "        1.1949e-02, 5.0685e-02, 2.8712e-02, 3.0055e-03, 0.0000e+00, 1.4062e-02,\n",
      "        0.0000e+00, 3.5563e-03, 1.7636e-03, 3.4471e-03, 2.1095e-02, 3.6360e-02,\n",
      "        1.4937e-01, 2.3007e-02, 1.9527e-02, 1.9320e-02, 7.2969e-03, 7.0246e-05,\n",
      "        0.0000e+00, 1.3744e-03, 7.2300e-02, 7.2144e-04, 9.0210e-04, 5.6310e-03,\n",
      "        3.6472e-03, 7.9892e-03, 1.7538e-02, 2.6349e-05, 0.0000e+00, 2.7893e-03,\n",
      "        1.8665e-02, 9.7350e-03, 2.1447e-03, 4.5728e-03, 1.0924e-03, 1.7814e-03,\n",
      "        9.3441e-03, 5.7397e-03, 6.3655e-03, 4.1043e-04, 1.4970e-03, 1.4414e-03,\n",
      "        8.8257e-03, 7.6797e-03, 2.7627e-02, 2.3399e-03, 6.2111e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.0961e-02, 1.1999e-03, 1.9054e-02, 8.9930e-03, 3.8041e-02,\n",
      "        2.5908e-02, 0.0000e+00, 3.0360e-05, 5.7382e-05, 1.3175e-02, 7.7407e-03,\n",
      "        3.6949e-05, 2.0463e-02, 1.9305e-02, 1.1158e-03, 1.1872e-02, 0.0000e+00,\n",
      "        1.5616e-02, 3.8053e-03, 2.2219e-03, 2.3015e-03, 3.0887e-03, 3.7790e-03,\n",
      "        1.3097e-02, 2.0239e-02, 1.0540e-02, 8.6964e-03, 2.7380e-03, 1.2184e-02,\n",
      "        4.4963e-02, 5.0731e-04, 1.8701e-02, 1.1420e-02, 1.1048e-04, 2.3165e-02,\n",
      "        1.2613e-02, 2.3249e-04, 1.7205e-02, 1.1847e-02, 1.3675e-02, 2.0138e-02,\n",
      "        4.3044e-02, 1.2207e-02, 1.2142e-02, 3.5063e-02, 3.2856e-03, 5.0405e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0044, 0.0049, 0.0063, 0.0091, 0.0089, 0.0110, 0.0090, 0.0107, 0.0093,\n",
      "        0.0100, 0.0068, 0.0088, 0.0061, 0.0053], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0293, 0.0315, 0.0307, 0.0318, 0.0321, 0.0328, 0.0316, 0.0309, 0.0308,\n",
      "        0.0298, 0.0309, 0.0305, 0.0316, 0.0300], device='cuda:0') torch.Size([14])\n",
      "score tensor([3.3324e-02, 6.8126e-03, 5.2239e-03, 3.5220e-03, 1.7367e-01, 3.2148e-03,\n",
      "        6.4482e-04, 9.2635e-05, 2.5804e-02, 3.4904e-03, 7.4063e-02, 9.1362e-04,\n",
      "        1.7444e-02, 7.0046e-02, 1.2288e-02, 1.8418e-02, 3.3933e-04, 5.3747e-04,\n",
      "        4.2587e-02, 1.0948e-02, 2.3407e-03, 2.9490e-02, 8.2055e-03, 2.7085e-03,\n",
      "        3.2274e-03, 2.7077e-02, 3.5460e-02, 5.1597e-03, 3.2357e-02, 4.7361e-04,\n",
      "        7.0468e-02, 2.6870e-02, 4.3720e-03, 3.3042e-02, 4.3948e-02, 1.1550e-05,\n",
      "        2.1404e-02, 2.4334e-02, 8.2348e-02, 2.8163e-04, 3.2684e-03, 2.1595e-02,\n",
      "        7.1875e-03, 4.0543e-03, 6.7028e-03, 1.1059e-04, 3.6415e-03, 1.5004e-02,\n",
      "        6.0382e-04, 7.5865e-03, 4.0285e-03, 1.5187e-02, 4.1997e-03, 1.6719e-01,\n",
      "        2.1783e-02, 2.7922e-03, 1.3957e-01, 2.1356e-02, 9.2109e-03, 1.4264e-03,\n",
      "        2.7555e-02, 5.3310e-02, 4.9753e-02, 4.6133e-02, 0.0000e+00, 2.4946e-04,\n",
      "        9.9907e-03, 1.5879e-03, 7.5878e-05, 1.7093e-01, 1.9827e-02, 2.0630e-04,\n",
      "        0.0000e+00, 8.9429e-05, 2.8181e-03, 1.1375e-02, 8.5491e-03, 1.1454e-02,\n",
      "        4.4218e-02, 0.0000e+00, 1.5847e-01, 1.9270e-02, 6.2671e-02, 2.5841e-03,\n",
      "        1.6530e-03, 4.1415e-02, 0.0000e+00, 2.5649e-02, 1.1880e-02, 6.1112e-03,\n",
      "        3.0144e-02, 1.6522e-03, 2.2313e-04, 2.8625e-03, 4.3958e-03, 3.4780e-02,\n",
      "        1.6904e-02, 1.0663e-02, 8.5633e-04, 1.1782e-02, 1.3709e-02, 3.3392e-03,\n",
      "        2.1525e-02, 5.2474e-04, 0.0000e+00, 3.8057e-05, 1.6925e-05, 8.5892e-02,\n",
      "        0.0000e+00, 9.6851e-03, 2.3571e-03, 1.2847e-02, 1.7748e-02, 7.4114e-03,\n",
      "        5.2512e-02, 1.0755e-02, 1.7426e-02, 7.9346e-04, 0.0000e+00, 3.8129e-02,\n",
      "        1.8849e-02, 0.0000e+00, 2.6922e-02, 3.8645e-03, 1.5270e-03, 0.0000e+00,\n",
      "        1.8995e-02, 0.0000e+00, 2.0362e-01, 1.5732e-05, 2.3907e-05, 1.4139e-01,\n",
      "        3.2550e-04, 2.0918e-03, 0.0000e+00, 2.1274e-02, 5.8136e-05, 2.5788e-02,\n",
      "        0.0000e+00, 8.2425e-03, 0.0000e+00, 7.0439e-03, 1.1465e-04, 2.1039e-04,\n",
      "        0.0000e+00, 1.0064e-02, 1.1957e-02, 8.4846e-03, 2.2196e-02, 2.6935e-02,\n",
      "        1.2647e-01, 5.7092e-03, 1.8948e-02, 3.8131e-02, 1.7149e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.5714e-02, 1.8920e-02, 0.0000e+00, 4.9768e-03, 6.0657e-02,\n",
      "        2.4904e-04, 1.4156e-02, 5.0674e-03, 3.5141e-02, 0.0000e+00, 8.4283e-03,\n",
      "        7.1997e-03, 1.0180e-03, 2.9863e-03, 1.1004e-03, 3.3665e-03, 9.9392e-04,\n",
      "        1.9200e-02, 7.8673e-03, 2.7280e-03, 0.0000e+00, 5.9487e-03, 1.7279e-02,\n",
      "        2.0314e-03, 0.0000e+00, 4.7225e-03, 1.2447e-02, 1.4969e-02, 1.0659e-04,\n",
      "        8.3514e-03, 1.1234e-03, 1.1020e-02, 2.0255e-02, 7.6465e-03, 1.6223e-02,\n",
      "        9.5935e-02, 3.7742e-02, 1.6267e-03, 5.2813e-04, 0.0000e+00, 1.4515e-03,\n",
      "        2.1612e-03, 4.1085e-02, 6.2907e-02, 3.8673e-02, 1.1074e-04, 0.0000e+00,\n",
      "        2.6083e-03, 6.4781e-04, 2.1281e-02, 5.2451e-02, 2.1688e-04, 1.4585e-05,\n",
      "        2.2731e-02, 3.6715e-02, 0.0000e+00, 1.3026e-02, 4.4775e-04, 1.2975e-01,\n",
      "        9.7493e-03, 1.5385e-03, 6.6796e-03, 1.2223e-02, 9.1296e-04, 1.3741e-02,\n",
      "        3.7478e-05, 1.1803e-02, 2.3570e-04, 2.6642e-02, 2.9846e-03, 9.3374e-04,\n",
      "        2.9748e-03, 2.7460e-04, 2.5426e-02, 2.6172e-03, 7.1453e-05, 1.0839e-02,\n",
      "        7.6412e-03, 2.3416e-02, 1.9068e-01, 9.5803e-03, 1.4107e-02, 1.0264e-03,\n",
      "        3.4755e-05, 5.7192e-02, 1.9244e-03, 2.7072e-02, 0.0000e+00, 1.5618e-01,\n",
      "        1.2882e-02, 1.1886e-02, 1.7232e-03, 2.5303e-02, 2.8262e-02, 8.1482e-03,\n",
      "        6.9595e-02, 6.0319e-04, 0.0000e+00, 1.0533e-02, 0.0000e+00, 6.9479e-02,\n",
      "        4.0068e-03, 3.7610e-03, 0.0000e+00, 2.8270e-06, 7.7607e-03, 3.2818e-02,\n",
      "        2.7700e-02, 0.0000e+00, 4.0634e-04, 1.6046e-03, 4.0983e-03, 7.6447e-04,\n",
      "        1.8712e-02, 7.7591e-03, 2.7574e-05, 2.6241e-03, 2.6550e-02, 6.0214e-03,\n",
      "        1.5246e-03, 9.2630e-03, 0.0000e+00, 1.3700e-02, 3.4090e-02, 2.7377e-02,\n",
      "        2.3123e-02, 1.3132e-01, 1.1707e-02, 2.3758e-02, 2.2481e-04, 8.3240e-03,\n",
      "        1.6872e-02, 0.0000e+00, 2.8344e-02, 6.2066e-03, 3.0471e-03, 2.5937e-03,\n",
      "        1.7645e-02, 2.2804e-02, 1.3605e-04, 3.4213e-03, 0.0000e+00, 9.6286e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.2601e-02, 1.2398e-02, 2.3888e-02, 2.6650e-02,\n",
      "        0.0000e+00, 1.1935e-02, 0.0000e+00, 1.3371e-02, 7.4474e-02, 2.3322e-04,\n",
      "        7.0888e-03, 9.6852e-03, 7.8987e-03, 0.0000e+00, 9.1749e-04, 1.1031e-02,\n",
      "        1.6898e-02, 3.1865e-02, 2.7402e-03, 0.0000e+00, 1.7288e-02, 1.8810e-03,\n",
      "        9.1943e-03, 1.3557e-02, 0.0000e+00, 2.3482e-02, 7.2978e-04, 1.0286e-02,\n",
      "        6.1511e-04, 1.9700e-01, 0.0000e+00, 1.9752e-02, 1.2399e-02, 4.4470e-06,\n",
      "        0.0000e+00, 1.3737e-02, 8.6720e-03, 3.0686e-02, 6.6730e-05, 0.0000e+00,\n",
      "        1.4409e-02, 1.3415e-05, 2.3762e-02, 3.5344e-03, 2.7937e-02, 5.3942e-02,\n",
      "        1.3529e-02, 3.2980e-02, 6.2986e-02, 6.2284e-02, 8.4154e-03, 8.3450e-02,\n",
      "        5.8253e-04, 1.8635e-02, 4.5916e-03, 2.8729e-03, 1.2910e-03, 3.8816e-04,\n",
      "        6.8306e-03, 0.0000e+00, 4.1070e-04, 1.2870e-03, 1.5488e-02, 5.4794e-03,\n",
      "        0.0000e+00, 8.6242e-03, 2.5362e-02, 2.7842e-03, 7.3923e-02, 5.7004e-04,\n",
      "        1.3522e-02, 7.6246e-04, 6.8921e-03, 4.1025e-02, 2.9295e-02, 3.4918e-03,\n",
      "        7.5244e-02, 1.3239e-02, 4.4719e-03, 4.3975e-04, 6.2531e-03, 5.8747e-02],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0087, 0.0077, 0.0103, 0.0101, 0.0108, 0.0108, 0.0108, 0.0111, 0.0105,\n",
      "        0.0107, 0.0087, 0.0088, 0.0076, 0.0065], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0240, 0.0221, 0.0237, 0.0233, 0.0230, 0.0241, 0.0237, 0.0256, 0.0241,\n",
      "        0.0263, 0.0224, 0.0249, 0.0216, 0.0205], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.3465e-01, 1.6568e-02, 1.0338e-03, 3.6575e-02, 0.0000e+00, 1.2237e-02,\n",
      "        1.2954e-03, 1.2392e-03, 1.4076e-03, 9.8839e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.5837e-01, 1.0329e-02, 0.0000e+00, 4.5475e-02, 2.7309e-04, 3.4738e-03,\n",
      "        0.0000e+00, 4.2199e-05, 4.0801e-02, 3.0496e-03, 2.7777e-02, 0.0000e+00,\n",
      "        3.0199e-02, 0.0000e+00, 0.0000e+00, 4.4045e-02, 6.0588e-05, 0.0000e+00,\n",
      "        0.0000e+00, 4.2602e-03, 0.0000e+00, 6.8118e-02, 1.5294e-01, 7.2322e-02,\n",
      "        2.6584e-01, 1.5200e-01, 0.0000e+00, 1.4985e-01, 1.9541e-02, 6.4256e-04,\n",
      "        4.5762e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.9284e-03, 3.4436e-03, 0.0000e+00, 0.0000e+00, 2.7895e-04, 2.6271e-01,\n",
      "        1.0577e-01, 0.0000e+00, 0.0000e+00, 9.9632e-02, 9.9674e-04, 2.4579e-01,\n",
      "        8.5257e-02, 2.6767e-01, 1.8400e-01, 2.5393e-01, 3.2788e-02, 2.4143e-01,\n",
      "        4.2973e-02, 6.6226e-02, 1.5880e-03, 0.0000e+00, 0.0000e+00, 1.5162e-01,\n",
      "        1.2661e-03, 3.9626e-02, 8.2094e-02, 6.3620e-05, 0.0000e+00, 8.6146e-03,\n",
      "        0.0000e+00, 3.6562e-04, 2.7813e-01, 3.1138e-02, 0.0000e+00, 1.9312e-01,\n",
      "        7.7148e-02, 6.9765e-02, 1.6878e-01, 0.0000e+00, 1.4523e-02, 7.5658e-02,\n",
      "        0.0000e+00, 1.8383e-02, 4.9740e-02, 3.0853e-01, 0.0000e+00, 0.0000e+00,\n",
      "        3.0451e-01, 1.5587e-01, 0.0000e+00, 4.7468e-02, 2.4270e-03, 6.4941e-02,\n",
      "        6.2361e-02, 1.6384e-03, 0.0000e+00, 1.6001e-03, 6.9777e-02, 8.3293e-03,\n",
      "        0.0000e+00, 4.1927e-02, 4.1351e-02, 1.5834e-01, 0.0000e+00, 2.8790e-02,\n",
      "        1.1480e-01, 1.5310e-04, 0.0000e+00, 2.5362e-01, 4.7630e-02, 1.6698e-02,\n",
      "        4.0719e-03, 4.6743e-02, 0.0000e+00, 1.0335e-02, 2.1969e-02, 0.0000e+00,\n",
      "        4.7368e-02, 4.8346e-03, 0.0000e+00, 9.6225e-02, 5.5122e-02, 0.0000e+00,\n",
      "        6.7836e-03, 1.8834e-02, 0.0000e+00, 7.5038e-02, 1.8671e-03, 1.4017e-01,\n",
      "        0.0000e+00, 9.3177e-03, 4.0843e-02, 4.3713e-03, 9.6623e-02, 2.9699e-01,\n",
      "        3.2215e-05, 4.0915e-03, 2.2249e-02, 4.1583e-02, 3.3215e-04, 6.3620e-01,\n",
      "        0.0000e+00, 2.8466e-02, 2.0213e-02, 2.0560e-01, 1.7667e-04, 1.9874e-01,\n",
      "        2.1839e-01, 5.8994e-02, 2.4357e-02, 1.4713e-02, 9.7682e-03, 0.0000e+00,\n",
      "        1.3588e-01, 0.0000e+00, 0.0000e+00, 7.3588e-02, 3.0108e-02, 2.5203e-02,\n",
      "        3.3224e-02, 1.5977e-02, 0.0000e+00, 3.7573e-02, 0.0000e+00, 1.8753e-04,\n",
      "        1.4836e-01, 0.0000e+00, 0.0000e+00, 1.2357e-01, 1.6030e-01, 0.0000e+00,\n",
      "        6.1669e-02, 0.0000e+00, 0.0000e+00, 5.4745e-02, 2.3585e-02, 6.5624e-02,\n",
      "        0.0000e+00, 1.1694e-01, 1.1759e-01, 1.4988e-02, 0.0000e+00, 5.5965e-02,\n",
      "        1.0565e+00, 6.4331e-02, 0.0000e+00, 0.0000e+00, 7.0051e-02, 3.3810e-04,\n",
      "        5.9556e-02, 3.8427e-02, 4.9827e-02, 8.8555e-02, 3.6299e-02, 0.0000e+00,\n",
      "        9.3225e-02, 5.9792e-06, 2.3066e-01, 2.2727e-01, 0.0000e+00, 8.2415e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0227e-01, 8.5063e-02, 1.7908e-01,\n",
      "        4.3308e-03, 3.4049e-02, 4.2643e-02, 4.1548e-03, 8.8921e-03, 2.4988e-03,\n",
      "        0.0000e+00, 4.0702e-02, 0.0000e+00, 6.3499e-05, 1.2909e-01, 3.5941e-03,\n",
      "        0.0000e+00, 3.3365e-03, 5.1371e-02, 6.1530e-03, 0.0000e+00, 0.0000e+00,\n",
      "        4.7577e-03, 0.0000e+00, 4.9901e-02, 4.3761e-03, 2.0306e-05, 6.4977e-03,\n",
      "        3.5430e-01, 2.5868e-02, 3.1041e-03, 1.5061e-01, 4.6751e-01, 0.0000e+00,\n",
      "        1.2888e-01, 2.4079e-02, 7.7512e-03, 0.0000e+00, 0.0000e+00, 1.7331e-02,\n",
      "        4.5670e-02, 9.1728e-02, 4.1038e-02, 2.8805e-01, 2.6272e-01, 1.4482e-01,\n",
      "        6.6691e-02, 0.0000e+00, 5.4272e-02, 5.6171e-02, 1.5554e-02, 3.2385e-02,\n",
      "        1.4853e-01, 0.0000e+00, 1.1655e-01, 1.3684e-01, 2.1116e-01, 7.7517e-04,\n",
      "        2.6422e-03, 7.9858e-02, 0.0000e+00, 1.0332e-01, 2.3018e-03, 0.0000e+00,\n",
      "        6.8876e-02, 4.0369e-04, 4.1411e-01, 1.6079e-02, 5.3138e-02, 0.0000e+00,\n",
      "        4.6817e-02, 4.7394e-01, 6.5133e-02, 0.0000e+00, 1.2349e-01, 6.8775e-02,\n",
      "        2.4564e-02, 4.0765e-02, 1.9886e-02, 6.9182e-03, 2.4011e-02, 1.8738e-02,\n",
      "        1.7895e-02, 1.7996e-02, 2.9494e-02, 3.3333e-01, 0.0000e+00, 1.3249e-02,\n",
      "        3.5332e-01, 2.2861e-01, 8.1477e-02, 1.5508e-01, 6.6553e-03, 4.9125e-05,\n",
      "        4.4504e-01, 3.3485e-03, 0.0000e+00, 9.9612e-03, 2.6382e-02, 5.2087e-02,\n",
      "        2.0584e-02, 6.3441e-02, 1.0944e-02, 0.0000e+00, 3.7867e-02, 5.5961e-06,\n",
      "        2.2434e-01, 2.2627e-02, 7.6459e-02, 3.1366e-01, 0.0000e+00, 1.4948e-01,\n",
      "        0.0000e+00, 9.5770e-02, 1.2813e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        9.1032e-02, 5.6811e-01, 0.0000e+00, 8.3634e-03, 2.4729e-02, 2.5431e-01,\n",
      "        2.7989e-01, 0.0000e+00, 8.5586e-03, 1.8380e-02, 1.1236e-01, 1.0115e-01,\n",
      "        6.7305e-03, 0.0000e+00, 3.1267e-01, 3.5159e-03, 0.0000e+00, 3.4208e-02,\n",
      "        3.4146e-02, 1.8499e-01, 6.1924e-02, 0.0000e+00, 2.0915e-02, 1.2002e-03,\n",
      "        1.4219e-01, 5.7664e-02, 1.8451e-02, 0.0000e+00, 6.2333e-02, 7.4260e-02,\n",
      "        5.1527e-02, 1.0502e-01, 4.4507e-04, 2.3705e-02, 0.0000e+00, 3.9820e-02,\n",
      "        9.6006e-02, 5.0882e-02, 3.2485e-02, 2.0779e-02, 2.4816e-01, 4.8979e-03,\n",
      "        1.4488e-01, 2.8293e-02, 1.1210e-03, 6.6210e-02, 0.0000e+00, 1.2973e-01,\n",
      "        1.2650e-01, 1.9964e-03, 1.6415e-03, 2.4257e-02, 5.3329e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0108, 0.0131, 0.0142, 0.0160, 0.0141, 0.0145, 0.0143, 0.0146, 0.0145,\n",
      "        0.0143, 0.0156, 0.0136, 0.0130, 0.0103], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0368, 0.0316, 0.0319, 0.0324, 0.0320, 0.0324, 0.0327, 0.0328, 0.0334,\n",
      "        0.0329, 0.0333, 0.0324, 0.0334, 0.0362], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.7048e-02, 1.8785e-02, 2.7665e-02, 1.1318e-02, 3.8623e-01, 1.2910e-01,\n",
      "        2.2277e-03, 0.0000e+00, 0.0000e+00, 3.5444e-02, 1.6433e-01, 0.0000e+00,\n",
      "        0.0000e+00, 3.5881e-02, 3.8419e-03, 2.2856e-03, 5.1910e-02, 1.2427e-01,\n",
      "        1.4074e-01, 3.0595e-04, 4.7437e-03, 2.4286e-02, 4.5902e-01, 0.0000e+00,\n",
      "        3.1246e-02, 9.6340e-03, 8.0691e-02, 3.0272e-04, 2.7081e-02, 1.9545e-03,\n",
      "        9.8708e-02, 3.4667e-04, 1.3837e-03, 6.9724e-02, 0.0000e+00, 1.7901e-02,\n",
      "        0.0000e+00, 6.2407e-02, 0.0000e+00, 1.9316e-02, 3.6550e-02, 6.0780e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.4015e-02, 0.0000e+00, 1.0588e-03, 5.3217e-03,\n",
      "        8.3038e-02, 3.0742e-02, 1.1905e-01, 4.0193e-03, 6.3805e-03, 3.3470e-01,\n",
      "        8.1757e-02, 3.4473e-02, 2.2937e-01, 5.6816e-02, 1.0641e-02, 1.1917e-01,\n",
      "        0.0000e+00, 1.6116e-01, 0.0000e+00, 1.2544e-01, 3.5744e-03, 0.0000e+00,\n",
      "        3.8078e-02, 8.8628e-04, 4.9854e-02, 0.0000e+00, 8.1176e-02, 1.9214e-02,\n",
      "        6.3633e-02, 4.5962e-03, 2.3225e-02, 5.0210e-04, 3.3532e-02, 3.0156e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.9295e-01, 0.0000e+00, 7.2902e-06, 7.2273e-02,\n",
      "        0.0000e+00, 1.1471e-01, 0.0000e+00, 5.4099e-02, 3.8753e-02, 3.6548e-02,\n",
      "        6.3444e-02, 3.5751e-02, 3.8812e-04, 3.0087e-02, 3.8214e-02, 1.5871e-03,\n",
      "        0.0000e+00, 4.5740e-02, 4.7011e-02, 4.5984e-03, 2.1087e-03, 3.4801e-02,\n",
      "        8.8147e-06, 2.5149e-02, 0.0000e+00, 1.7272e-02, 1.6529e-01, 4.1149e-02,\n",
      "        0.0000e+00, 3.8212e-03, 7.1445e-02, 8.6406e-03, 6.2135e-02, 4.9596e-03,\n",
      "        8.1470e-04, 7.0935e-02, 0.0000e+00, 6.3008e-04, 4.4365e-02, 7.6496e-05,\n",
      "        1.0113e-03, 1.4397e-02, 0.0000e+00, 6.7813e-04, 8.8482e-02, 6.7423e-02,\n",
      "        8.6641e-02, 2.5592e-02, 0.0000e+00, 0.0000e+00, 5.6565e-02, 1.2950e-01,\n",
      "        6.7493e-05, 7.5650e-02, 0.0000e+00, 1.1134e-03, 7.4377e-03, 8.6017e-02,\n",
      "        0.0000e+00, 7.7230e-02, 3.3514e-05, 1.2596e-02, 1.9490e-02, 8.4402e-02,\n",
      "        3.7338e-03, 5.8981e-03, 2.0303e-02, 6.8169e-02, 2.0358e-01, 0.0000e+00,\n",
      "        0.0000e+00, 8.9788e-02, 5.1393e-02, 0.0000e+00, 1.0814e-03, 3.7009e-05,\n",
      "        2.7770e-01, 0.0000e+00, 8.1650e-02, 0.0000e+00, 9.7992e-03, 1.1454e-02,\n",
      "        3.8849e-03, 1.1976e-02, 7.6466e-02, 1.0349e-03, 8.2537e-02, 3.4902e-02,\n",
      "        5.3694e-02, 3.8978e-03, 1.0480e-01, 2.9784e-02, 1.6125e-02, 4.4775e-02,\n",
      "        4.9772e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5786e-03,\n",
      "        3.4827e-03, 5.6369e-01, 0.0000e+00, 6.4055e-03, 1.5614e-02, 6.7906e-02,\n",
      "        1.9772e-02, 8.8253e-02, 3.1324e-02, 9.7846e-03, 0.0000e+00, 2.9332e-02,\n",
      "        2.5312e-01, 2.3092e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5343e-02,\n",
      "        1.9519e-02, 1.4288e-02, 5.1669e-02, 4.8448e-02, 3.2059e-04, 0.0000e+00,\n",
      "        7.1143e-02, 4.0267e-02, 1.8087e-03, 0.0000e+00, 1.3847e-02, 5.7318e-03,\n",
      "        0.0000e+00, 7.2871e-02, 1.4708e-01, 4.1283e-02, 1.5174e-03, 9.4019e-03,\n",
      "        0.0000e+00, 3.1344e-02, 1.0943e-02, 1.3251e-02, 2.1553e-01, 2.0537e-02,\n",
      "        0.0000e+00, 8.3576e-03, 4.4156e-04, 0.0000e+00, 2.5893e-02, 3.6936e-02,\n",
      "        1.6446e-02, 1.9882e-02, 3.4049e-02, 2.8917e-02, 1.6611e-02, 0.0000e+00,\n",
      "        8.3673e-03, 2.8487e-02, 8.7212e-02, 2.7364e-02, 4.4652e-02, 4.2044e-03,\n",
      "        2.7112e-01, 0.0000e+00, 8.1542e-03, 6.1982e-02, 1.5458e-01, 3.1608e-01,\n",
      "        4.2312e-01, 2.3086e-02, 2.4148e-02, 1.2809e-01, 0.0000e+00, 4.1898e-03,\n",
      "        1.2633e-01, 3.7604e-02, 0.0000e+00, 1.9517e-02, 0.0000e+00, 3.6381e-02,\n",
      "        4.1828e-03, 2.7459e-02, 9.2722e-02, 4.3920e-06, 4.2615e-02, 4.2553e-03,\n",
      "        2.1998e-02, 1.0238e-01, 2.8781e-02, 5.9323e-03, 4.1294e-03, 1.3097e-03,\n",
      "        2.3099e-03, 4.4549e-02, 0.0000e+00, 1.3203e-01, 3.7900e-05, 0.0000e+00,\n",
      "        4.4226e-02, 8.2845e-04, 1.3980e-01, 1.4209e-02, 3.0857e-05, 4.0815e-02,\n",
      "        4.8960e-02, 4.1560e-01, 2.1295e-02, 1.0150e-01, 3.6373e-03, 2.3901e-02,\n",
      "        5.1163e-03, 4.2300e-01, 3.9892e-02, 9.3946e-03, 6.1344e-02, 7.9082e-03,\n",
      "        9.9964e-03, 1.2329e-02, 1.4553e-02, 0.0000e+00, 3.0513e-01, 1.6358e-01,\n",
      "        2.9000e-01, 1.9193e-02, 1.0505e-03, 0.0000e+00, 4.4625e-02, 1.6645e-01,\n",
      "        0.0000e+00, 7.4191e-02, 0.0000e+00, 2.5385e-02, 0.0000e+00, 3.4047e-02,\n",
      "        2.1538e-02, 1.0320e-02, 1.4807e-02, 1.3877e-04, 9.2735e-03, 2.7729e-02,\n",
      "        0.0000e+00, 2.5529e-02, 8.3813e-03, 0.0000e+00, 8.4297e-02, 2.3296e-02,\n",
      "        1.4327e-02, 2.0587e-02, 5.0994e-03, 1.6513e-02, 1.4448e-03, 7.3321e-02,\n",
      "        4.0629e-03, 4.0363e-01, 1.4458e-01, 1.4784e-03, 5.9046e-03, 1.2997e-01,\n",
      "        4.6922e-02, 3.8500e-02, 1.0423e-02, 0.0000e+00, 4.6521e-02, 2.0887e-02,\n",
      "        4.5741e-02, 0.0000e+00, 0.0000e+00, 1.0620e-02, 8.4871e-02, 4.5812e-02,\n",
      "        3.7779e-02, 1.3640e-02, 7.5452e-02, 1.5774e-01, 3.3268e-03, 5.4691e-02,\n",
      "        1.5575e-03, 2.5863e-04, 7.4741e-03, 6.0682e-02, 8.0132e-04, 2.9925e-04,\n",
      "        1.2468e-02, 6.0845e-02, 7.9913e-04, 1.1753e-01, 1.8908e-01, 1.5074e-02,\n",
      "        8.4336e-03, 1.2249e-06, 5.3688e-02, 0.0000e+00, 1.9769e-01, 1.3801e-02,\n",
      "        0.0000e+00, 5.4673e-03, 5.5612e-02, 7.5322e-03, 0.0000e+00, 0.0000e+00,\n",
      "        1.1017e-03, 1.6631e-03, 4.6131e-02, 1.7582e-02, 4.2941e-02, 6.5812e-02],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0073, 0.0103, 0.0126, 0.0110, 0.0104, 0.0101, 0.0107, 0.0111, 0.0105,\n",
      "        0.0115, 0.0103, 0.0129, 0.0095, 0.0072], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0372, 0.0412, 0.0403, 0.0393, 0.0404, 0.0404, 0.0399, 0.0397, 0.0402,\n",
      "        0.0400, 0.0376, 0.0392, 0.0382, 0.0334], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 3.0989e-02, 2.0407e-03, 0.0000e+00, 6.3836e-01, 2.3158e-02,\n",
      "        1.1003e-02, 0.0000e+00, 0.0000e+00, 8.4548e-02, 2.3230e-01, 3.3102e-03,\n",
      "        0.0000e+00, 3.3687e-01, 4.3942e-02, 3.9098e-02, 3.2153e-02, 3.0337e-01,\n",
      "        0.0000e+00, 0.0000e+00, 5.2413e-02, 9.7694e-02, 8.7143e-03, 7.7113e-01,\n",
      "        3.2357e-02, 3.2413e-02, 1.8637e-01, 1.2489e-02, 2.1831e-02, 0.0000e+00,\n",
      "        6.5921e-02, 9.1672e-03, 4.3294e-03, 6.1975e-02, 2.0247e-02, 5.4838e-02,\n",
      "        1.9771e-01, 5.4234e-01, 3.4021e-01, 3.7835e-02, 3.5411e-02, 1.9630e-01,\n",
      "        0.0000e+00, 1.0800e-01, 0.0000e+00, 0.0000e+00, 4.7166e-03, 1.9439e-01,\n",
      "        1.0453e-01, 6.9322e-02, 2.0814e-02, 3.0106e-02, 3.8711e-02, 1.2020e-04,\n",
      "        8.0378e-01, 1.3481e-01, 5.1876e-01, 1.6719e-02, 0.0000e+00, 0.0000e+00,\n",
      "        8.3521e-02, 7.6305e-02, 5.9881e-01, 0.0000e+00, 4.4678e-03, 0.0000e+00,\n",
      "        2.0578e-01, 4.7130e-02, 1.5575e-02, 3.2440e-03, 4.6817e-02, 5.1611e-03,\n",
      "        7.9265e-02, 4.4990e-02, 0.0000e+00, 8.4287e-02, 1.1114e-02, 3.0422e-01,\n",
      "        0.0000e+00, 2.4333e-01, 0.0000e+00, 0.0000e+00, 3.4092e-01, 2.4346e-01,\n",
      "        5.7604e-04, 2.2269e-01, 4.2840e-02, 0.0000e+00, 1.4733e-01, 0.0000e+00,\n",
      "        0.0000e+00, 3.8578e-02, 8.3714e-02, 2.7716e-02, 0.0000e+00, 0.0000e+00,\n",
      "        3.0074e-01, 3.3924e-02, 1.5281e-01, 5.4232e-02, 2.5266e-02, 1.6492e-02,\n",
      "        1.0540e-01, 0.0000e+00, 3.4348e-01, 2.4113e-02, 1.7678e-01, 2.7367e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.2488e-02, 2.8082e-01, 1.3714e-04, 0.0000e+00,\n",
      "        7.9381e-02, 0.0000e+00, 0.0000e+00, 2.8166e-01, 0.0000e+00, 1.2021e-01,\n",
      "        3.2565e-02, 0.0000e+00, 2.6303e-01, 2.5187e-02, 2.8019e-01, 2.0413e-01,\n",
      "        1.7000e-01, 4.0631e-02, 0.0000e+00, 2.8180e-01, 5.1326e-02, 4.1020e-02,\n",
      "        2.5754e-02, 2.0346e-01, 2.9305e-01, 7.2781e-03, 1.1004e-01, 1.0455e-04,\n",
      "        0.0000e+00, 0.0000e+00, 2.4382e-01, 1.0595e-01, 7.7716e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.3143e-02, 7.1072e-02, 3.1073e-01, 0.0000e+00, 6.7579e-01,\n",
      "        1.6173e-01, 1.4309e-03, 1.8743e-02, 3.2643e-01, 1.6147e-01, 0.0000e+00,\n",
      "        2.8245e-01, 6.4809e-01, 1.2471e-02, 2.7968e-03, 1.4497e-01, 0.0000e+00,\n",
      "        2.8714e-02, 9.0029e-02, 1.0011e-01, 1.3770e-01, 1.5178e-01, 1.8945e-02,\n",
      "        5.7660e-02, 1.8993e-01, 2.9131e-01, 8.8730e-03, 2.4839e-02, 3.8034e-04,\n",
      "        0.0000e+00, 2.0803e-01, 3.7651e-01, 2.4608e-01, 1.4071e-01, 2.6272e-02,\n",
      "        3.1621e-02, 0.0000e+00, 0.0000e+00, 2.4580e-02, 1.4730e-01, 8.3182e-02,\n",
      "        2.1375e-01, 1.8284e-01, 8.6288e-03, 5.2352e-04, 6.8362e-02, 1.5574e-01,\n",
      "        1.5870e-01, 4.5463e-02, 3.2435e-01, 2.3021e-01, 0.0000e+00, 1.6230e-01,\n",
      "        0.0000e+00, 0.0000e+00, 6.7373e-02, 4.6644e-03, 6.6516e-02, 0.0000e+00,\n",
      "        1.1527e-01, 1.0098e-01, 3.6342e-01, 2.2588e-01, 0.0000e+00, 8.9093e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.7797e-01, 1.1494e-01, 3.5206e-03, 6.9853e-02,\n",
      "        0.0000e+00, 6.9294e-02, 6.7737e-03, 3.3966e-02, 0.0000e+00, 2.8761e-02,\n",
      "        2.4147e-01, 1.3133e-01, 1.8517e-01, 1.7204e-01, 1.6141e-04, 8.9062e-03,\n",
      "        5.5365e-02, 1.4196e-01, 0.0000e+00, 6.2781e-02, 2.8628e-02, 2.7880e-01,\n",
      "        1.6482e-03, 0.0000e+00, 1.1562e-01, 3.5212e-05, 1.3303e-03, 5.2033e-02,\n",
      "        3.5658e-01, 0.0000e+00, 5.4827e-02, 0.0000e+00, 4.8172e-05, 0.0000e+00,\n",
      "        5.2275e-01, 6.2377e-02, 6.2795e-03, 0.0000e+00, 4.0579e-01, 0.0000e+00,\n",
      "        1.7793e-01, 7.4505e-02, 8.0676e-01, 5.1530e-01, 1.9192e-02, 3.5034e-03,\n",
      "        1.3858e-02, 0.0000e+00, 5.0528e-02, 3.2497e-03, 5.1210e-02, 2.4403e-02,\n",
      "        2.5377e-01, 3.4993e-01, 8.5574e-02, 3.3712e-02, 3.2760e-02, 1.2925e-02,\n",
      "        7.2352e-02, 2.1821e-02, 3.0649e-02, 0.0000e+00, 3.3951e-04, 0.0000e+00,\n",
      "        0.0000e+00, 4.4010e-02, 2.3931e-01, 3.8403e-02, 2.1266e-02, 2.9660e-02,\n",
      "        2.6263e-01, 5.8061e-01, 2.0163e-02, 2.2812e-01, 1.1337e-02, 3.6985e-02,\n",
      "        1.2918e-01, 2.9133e-01, 1.5289e-01, 3.1886e-04, 8.5703e-02, 0.0000e+00,\n",
      "        7.2257e-02, 8.0528e-03, 7.9395e-03, 0.0000e+00, 0.0000e+00, 9.9087e-02,\n",
      "        3.1978e-01, 1.8969e-03, 1.1029e-01, 4.7661e-02, 3.5263e-02, 3.1048e-01,\n",
      "        4.7206e-01, 2.0878e-01, 4.4022e-02, 8.7068e-02, 6.2066e-03, 0.0000e+00,\n",
      "        1.8681e-02, 7.4711e-04, 1.2368e-02, 2.6336e-01, 1.9007e-01, 6.3821e-02,\n",
      "        2.0293e-01, 8.1583e-02, 1.0094e-03, 4.4240e-01, 9.4601e-02, 1.3318e-02,\n",
      "        1.7402e-01, 1.4578e-02, 4.5973e-03, 2.2027e-02, 1.1830e-02, 6.4029e-02,\n",
      "        4.1373e-02, 0.0000e+00, 1.5888e-01, 2.3051e-01, 1.1510e-01, 4.4374e-01,\n",
      "        0.0000e+00, 1.3635e-01, 1.0039e-02, 0.0000e+00, 7.5259e-02, 1.5326e-01,\n",
      "        2.0804e-01, 2.7600e-01, 0.0000e+00, 7.9630e-02, 0.0000e+00, 1.0740e-02,\n",
      "        1.3830e-02, 1.7698e-01, 2.7131e-01, 2.8492e-01, 1.0560e-01, 3.5702e-01,\n",
      "        1.3482e-01, 8.4496e-02, 1.0736e-02, 2.4471e-02, 5.0942e-05, 0.0000e+00,\n",
      "        4.7797e-02, 2.7562e-01, 1.9811e-02, 2.8773e-01, 1.7734e-01, 1.4094e-01,\n",
      "        1.1372e-03, 0.0000e+00, 0.0000e+00, 1.4582e-01, 0.0000e+00, 1.0585e-01,\n",
      "        1.2732e-02, 5.3433e-02, 2.9651e-01, 6.0066e-02, 0.0000e+00, 0.0000e+00,\n",
      "        3.5176e-02, 2.3914e-03, 0.0000e+00, 0.0000e+00, 1.3371e-03, 6.8017e-04],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0133, 0.0169, 0.0155, 0.0154, 0.0158, 0.0162, 0.0150, 0.0151, 0.0159,\n",
      "        0.0154, 0.0145, 0.0143, 0.0155, 0.0122], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0535, 0.0685, 0.0556, 0.0590, 0.0568, 0.0613, 0.0554, 0.0537, 0.0583,\n",
      "        0.0527, 0.0576, 0.0499, 0.0615, 0.0463], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.7809e-02, 2.2836e-04, 7.0299e-02, 6.4064e-02, 9.6654e-03, 1.9679e-03,\n",
      "        1.0920e-03, 9.0548e-02, 0.0000e+00, 5.2483e-02, 9.1681e-02, 1.5332e-02,\n",
      "        6.7431e-03, 1.6121e-03, 1.5877e-04, 0.0000e+00, 1.0437e-01, 3.8002e-03,\n",
      "        1.1037e-02, 8.2759e-02, 5.3839e-03, 1.3275e-02, 1.0188e-01, 4.2145e-02,\n",
      "        4.7549e-02, 1.6771e-03, 0.0000e+00, 0.0000e+00, 4.0295e-01, 4.7832e-02,\n",
      "        1.0484e-01, 3.5464e-03, 3.0145e-02, 1.3074e-02, 3.4111e-02, 1.0660e-01,\n",
      "        0.0000e+00, 6.7881e-02, 2.7598e-02, 4.1234e-02, 5.5274e-02, 8.5020e-02,\n",
      "        2.3296e-02, 4.1712e-02, 1.2686e-01, 4.8531e-02, 4.6782e-02, 5.3093e-02,\n",
      "        1.9317e-01, 4.0304e-02, 5.4259e-04, 5.1621e-02, 4.7941e-05, 0.0000e+00,\n",
      "        3.9403e-02, 1.5903e-01, 0.0000e+00, 0.0000e+00, 3.2528e-02, 1.2245e-01,\n",
      "        1.1932e-02, 2.3141e-02, 4.7116e-04, 1.1675e-01, 1.8334e-02, 5.6019e-04,\n",
      "        1.7660e-01, 3.6687e-02, 3.3301e-02, 8.4994e-02, 9.7863e-03, 2.0047e-02,\n",
      "        2.8255e-02, 3.6752e-02, 2.0489e-04, 0.0000e+00, 8.5874e-02, 0.0000e+00,\n",
      "        2.2437e-02, 7.6110e-02, 3.4233e-03, 5.9491e-03, 7.3973e-05, 7.4787e-02,\n",
      "        5.0600e-02, 7.0555e-02, 3.9282e-02, 5.0658e-02, 1.6568e-03, 1.1551e-01,\n",
      "        4.1795e-02, 4.6773e-02, 2.2170e-02, 4.2238e-03, 5.0571e-03, 7.3771e-03,\n",
      "        1.6106e-02, 1.1226e-02, 3.9517e-03, 5.5790e-02, 4.3871e-02, 2.0691e-02,\n",
      "        8.8991e-02, 6.9732e-03, 5.4185e-02, 2.1573e-04, 5.0427e-02, 5.9885e-02,\n",
      "        3.9586e-02, 9.1450e-03, 4.8411e-02, 5.5633e-02, 2.1687e-02, 4.3647e-02,\n",
      "        0.0000e+00, 1.5974e-02, 1.1639e-01, 3.7790e-02, 1.0359e-02, 2.0262e-03,\n",
      "        1.4378e-02, 4.6830e-03, 2.3495e-01, 4.5544e-02, 4.4893e-02, 7.1242e-03,\n",
      "        6.7450e-03, 9.2081e-03, 1.1570e-03, 3.3926e-03, 0.0000e+00, 4.4497e-02,\n",
      "        6.0432e-02, 3.9501e-02, 2.6376e-03, 4.1677e-05, 8.7571e-03, 1.2497e-02,\n",
      "        9.1195e-02, 7.6853e-03, 8.0769e-04, 1.4642e-03, 5.3550e-02, 2.7024e-02,\n",
      "        5.7486e-03, 8.7607e-02, 5.2917e-02, 5.9077e-02, 1.9644e-02, 1.6364e-02,\n",
      "        8.4011e-02, 6.5438e-02, 1.4778e-02, 1.3462e-01, 7.2223e-02, 5.3792e-02,\n",
      "        1.1989e-01, 1.8598e-02, 4.5856e-02, 1.2972e-03, 1.0997e-02, 1.0910e-02,\n",
      "        3.2199e-02, 6.5831e-02, 9.8046e-02, 0.0000e+00, 1.3968e-02, 9.2849e-03,\n",
      "        4.3986e-02, 1.3875e-03, 0.0000e+00, 1.9038e-01, 1.2648e-01, 1.7150e-01,\n",
      "        1.1216e-01, 0.0000e+00, 7.9166e-02, 5.0083e-02, 1.7913e-03, 0.0000e+00,\n",
      "        9.5367e-03, 1.4678e-01, 1.9191e-02, 2.4511e-02, 1.2057e-01, 5.9762e-01,\n",
      "        1.5188e-02, 0.0000e+00, 2.5520e-02, 7.8250e-02, 8.4694e-03, 0.0000e+00,\n",
      "        4.9611e-02, 3.4202e-02, 5.7766e-02, 1.1326e-02, 0.0000e+00, 7.4749e-03,\n",
      "        1.9131e-02, 2.9935e-02, 8.3465e-02, 1.5956e-02, 1.9727e-02, 1.0130e-03,\n",
      "        2.7782e-03, 8.1788e-02, 2.3184e-02, 8.0661e-05, 6.3083e-02, 2.6845e-03,\n",
      "        1.3198e-01, 1.9666e-03, 5.8882e-02, 3.6393e-02, 6.8898e-02, 8.7264e-02,\n",
      "        0.0000e+00, 2.2246e-03, 3.1823e-02, 1.1223e-01, 2.5745e-02, 0.0000e+00,\n",
      "        1.7628e-02, 6.0239e-02, 0.0000e+00, 1.7676e-02, 7.5185e-02, 5.0408e-02,\n",
      "        1.2278e-03, 7.0532e-02, 9.8849e-02, 1.9578e-03, 4.3106e-02, 1.2228e-01,\n",
      "        1.4109e-02, 9.8603e-02, 3.2151e-03, 5.2346e-03, 2.9790e-02, 1.4923e-03,\n",
      "        2.1844e-02, 7.9939e-02, 5.2453e-02, 1.6582e-01, 1.3276e-02, 1.0279e-02,\n",
      "        8.8584e-03, 0.0000e+00, 3.0868e-02, 2.3546e-02, 3.0367e-02, 1.2309e-02,\n",
      "        8.8883e-03, 5.8539e-02, 2.0553e-02, 3.3419e-04, 4.0033e-02, 6.0548e-02,\n",
      "        8.9710e-02, 2.6544e-02, 0.0000e+00, 2.0236e-03, 2.1847e-02, 3.1286e-02,\n",
      "        1.8578e-02, 5.7765e-02, 6.5280e-02, 8.4003e-02, 1.7862e-02, 1.4843e-02,\n",
      "        0.0000e+00, 8.3406e-02, 9.4554e-02, 4.3291e-02, 8.2936e-02, 4.3062e-03,\n",
      "        7.4684e-04, 3.2823e-02, 1.2919e-01, 4.1484e-02, 6.4981e-02, 7.0636e-02,\n",
      "        1.3813e-02, 2.5364e-02, 6.0765e-03, 0.0000e+00, 8.8266e-02, 1.2418e-04,\n",
      "        9.7279e-02, 2.0352e-05, 6.6425e-02, 2.2667e-02, 1.7498e-02, 2.4773e-02,\n",
      "        3.1901e-02, 1.2798e-02, 2.0304e-01, 4.9691e-02, 1.1598e-01, 2.8223e-02,\n",
      "        1.1363e-01, 3.2501e-03, 7.9869e-02, 6.4804e-02, 5.4303e-02, 9.4389e-02,\n",
      "        0.0000e+00, 6.7097e-04, 0.0000e+00, 8.6140e-02, 6.2070e-02, 2.0649e-01,\n",
      "        5.5191e-02, 3.7284e-03, 4.1508e-02, 1.9534e-02, 1.0315e-01, 2.7346e-02,\n",
      "        1.1296e-02, 4.8519e-03, 6.9884e-05, 2.5708e-03, 0.0000e+00, 1.3545e-02,\n",
      "        1.4548e-02, 4.6580e-02, 3.0194e-04, 1.2871e-03, 5.2369e-03, 4.7136e-02,\n",
      "        1.1823e-01, 2.2551e-03, 1.6987e-01, 1.6664e-02, 1.3597e-01, 4.5500e-02,\n",
      "        2.1853e-02, 1.0762e-01, 9.1896e-02, 6.1738e-02, 2.2410e-02, 2.7274e-02,\n",
      "        4.5268e-02, 8.4218e-02, 4.1350e-02, 9.1227e-03, 3.4061e-03, 3.5246e-02,\n",
      "        3.2385e-02, 6.6635e-03, 1.1760e-02, 3.9431e-02, 6.5670e-03, 2.2131e-02,\n",
      "        7.5195e-02, 0.0000e+00, 4.5312e-03, 3.2232e-02, 4.4057e-02, 1.0907e-02,\n",
      "        1.7005e-01, 6.4092e-03, 4.3930e-03, 1.3243e-02, 1.2942e-02, 9.1248e-02,\n",
      "        5.6794e-02, 1.3485e-01, 7.2986e-02, 4.2383e-02, 2.1091e-02, 4.1488e-02,\n",
      "        0.0000e+00, 8.0491e-03, 1.1988e-03, 3.8240e-02, 3.2338e-02, 1.2697e-02,\n",
      "        1.1847e-01, 2.8879e-02, 0.0000e+00, 7.5031e-02, 6.3470e-02, 2.5168e-02,\n",
      "        1.5025e-03, 6.0693e-02, 9.7382e-02, 9.9822e-02, 7.4460e-05, 2.5886e-03,\n",
      "        4.2661e-05, 0.0000e+00, 9.6299e-02, 1.2936e-01, 6.1443e-02, 3.2648e-02,\n",
      "        0.0000e+00, 1.8609e-03, 6.1221e-02, 2.2176e-02, 3.4409e-02, 3.5780e-03,\n",
      "        4.6678e-04, 3.4464e-02, 4.6692e-03, 2.3507e-01, 6.5146e-02, 6.6340e-03,\n",
      "        3.5544e-03, 4.9080e-02, 3.4320e-02, 8.7291e-02, 1.0494e-01, 1.6225e-01,\n",
      "        3.9857e-02, 0.0000e+00, 7.2403e-02, 1.0842e-02, 3.6273e-03, 2.7328e-02,\n",
      "        0.0000e+00, 2.5533e-02, 6.3217e-04, 2.4550e-02, 1.1977e-01, 2.7399e-02,\n",
      "        1.9699e-02, 2.3953e-02, 4.5078e-03, 6.8263e-03, 4.3419e-02, 1.0506e-01,\n",
      "        0.0000e+00, 7.6058e-02, 2.4794e-02, 3.1777e-02, 3.1996e-02, 0.0000e+00,\n",
      "        8.7080e-02, 1.1457e-01, 3.4355e-02, 2.1760e-01, 2.4103e-02, 4.5301e-02,\n",
      "        1.8534e-02, 2.9902e-02, 3.3083e-02, 0.0000e+00, 6.6791e-02, 2.3561e-02,\n",
      "        1.5287e-02, 1.1934e-02, 7.4850e-02, 3.5846e-02, 9.3368e-02, 0.0000e+00,\n",
      "        4.1905e-02, 1.4009e-01, 2.4972e-03, 7.5983e-02, 7.0078e-02, 3.6229e-03,\n",
      "        7.2929e-02, 0.0000e+00, 4.8558e-02, 9.1083e-02, 1.3109e-03, 1.0339e-01,\n",
      "        4.7628e-03, 5.3280e-02, 9.0081e-02, 2.6073e-03, 9.9779e-02, 4.7099e-02,\n",
      "        2.3171e-03, 6.4161e-02, 2.4590e-03, 5.0286e-03, 9.3648e-03, 8.2079e-02,\n",
      "        1.3749e-03, 2.8687e-02, 5.3161e-03, 1.6879e-02, 5.4143e-02, 6.6667e-02,\n",
      "        4.2346e-02, 4.1945e-03, 1.0163e-01, 1.8323e-03, 2.1994e-02, 0.0000e+00,\n",
      "        2.5874e-03, 3.7612e-03, 1.7352e-02, 7.0004e-02, 2.0352e-02, 4.0188e-02,\n",
      "        6.2422e-02, 9.7528e-02, 7.4811e-02, 1.1819e-03, 8.0254e-02, 2.4291e-02,\n",
      "        7.4338e-02, 5.3345e-02, 2.4412e-02, 8.0064e-02, 3.7334e-03, 2.6564e-03,\n",
      "        8.7024e-03, 7.1829e-02, 2.7429e-02, 5.7267e-02, 1.2167e-03, 1.0398e-01,\n",
      "        2.0994e-02, 2.6025e-02, 1.9866e-01, 4.1333e-02, 8.9048e-02, 1.2646e-03,\n",
      "        0.0000e+00, 9.0643e-02, 1.6102e-02, 4.8082e-03, 4.5220e-02, 1.6456e-02,\n",
      "        6.7989e-02, 1.5899e-03, 0.0000e+00, 1.0778e-02, 3.1341e-03, 3.6899e-02,\n",
      "        7.1910e-04, 4.1362e-02, 0.0000e+00, 5.2377e-03, 1.4139e-01, 6.5037e-02,\n",
      "        2.9120e-02, 6.4752e-05, 2.1105e-04, 8.6584e-02, 9.0152e-02, 2.8970e-02,\n",
      "        0.0000e+00, 3.9266e-02, 1.8744e-02, 5.2589e-02, 4.4427e-04, 4.1617e-02,\n",
      "        9.7809e-02, 1.8897e-03, 9.8436e-03, 2.0967e-02, 5.7903e-03, 2.1151e-02,\n",
      "        1.0459e-01, 1.4229e-04, 9.4145e-02, 3.6567e-02, 7.3112e-02, 4.1157e-03,\n",
      "        4.3387e-02, 1.1996e-02, 4.8574e-02, 5.0169e-02, 2.8337e-03, 1.1598e-03,\n",
      "        4.7763e-03, 1.2911e-02, 2.7641e-01, 7.0117e-02, 1.4177e-02, 1.0045e-01,\n",
      "        3.5690e-03, 1.6091e-02, 3.4451e-04, 0.0000e+00, 4.6418e-03, 3.4779e-02,\n",
      "        4.8337e-02, 3.7802e-02, 6.6973e-04, 7.2473e-02, 1.4440e-03, 1.1044e-01,\n",
      "        0.0000e+00, 1.0222e-01, 4.6983e-02, 5.1051e-02, 0.0000e+00, 8.1054e-02,\n",
      "        1.3621e-01, 8.8411e-02, 0.0000e+00, 1.2885e-02, 5.1382e-02, 6.1308e-02,\n",
      "        2.7645e-03, 2.6644e-03, 5.5333e-02, 1.8297e-02, 1.3830e-01, 1.1099e-03,\n",
      "        3.3436e-04, 2.3978e-02, 7.2426e-02, 9.1232e-02, 6.5354e-02, 6.1794e-02,\n",
      "        7.9554e-02, 0.0000e+00, 0.0000e+00, 3.1518e-02, 5.1516e-04, 7.7872e-02,\n",
      "        2.3348e-02, 2.2849e-03, 1.8386e-02, 0.0000e+00, 6.8116e-03, 1.5321e-02,\n",
      "        8.5302e-02, 4.0384e-02, 4.7430e-03, 1.2801e-04, 3.3925e-02, 0.0000e+00,\n",
      "        1.6508e-01, 2.0790e-02, 1.7392e-02, 7.7801e-02, 8.2093e-03, 1.5449e-02,\n",
      "        2.7990e-02, 1.7018e-02, 4.9587e-03, 3.3201e-02, 9.8676e-02, 2.0624e-02,\n",
      "        2.9658e-02, 8.6450e-03, 3.6150e-02, 8.7534e-02, 6.5142e-02, 5.7436e-02,\n",
      "        1.8159e-03, 5.6869e-05, 7.5300e-02, 1.2530e-01, 9.8438e-02, 0.0000e+00,\n",
      "        6.4313e-02, 1.5310e-02, 5.0328e-02, 3.7865e-02, 4.8117e-02, 7.3274e-03,\n",
      "        3.9181e-02, 0.0000e+00, 3.9125e-02, 2.3325e-02, 2.2866e-03, 4.3693e-02,\n",
      "        1.5795e-02, 5.2958e-02, 9.1955e-02, 1.5582e-02, 1.1586e-01, 2.0809e-02,\n",
      "        9.7260e-03, 1.3796e-04, 8.8139e-03, 2.6259e-02, 2.7762e-02, 2.7279e-02,\n",
      "        1.0136e-01, 4.4353e-05, 1.1226e-01, 1.2905e-01, 5.4665e-02, 7.2012e-03,\n",
      "        1.0222e-04, 0.0000e+00, 0.0000e+00, 6.4288e-02, 6.2392e-02, 3.5535e-02,\n",
      "        1.3761e-02, 1.4819e-02, 2.1231e-02, 2.9662e-03, 4.6251e-02, 2.3971e-01,\n",
      "        0.0000e+00, 8.7672e-02, 2.0501e-05, 4.7418e-02, 6.4748e-03, 3.0477e-02,\n",
      "        3.2649e-03, 1.6587e-02, 2.1197e-02, 6.5835e-02, 2.3927e-01, 1.6310e-02,\n",
      "        2.7929e-02, 1.2765e-02, 1.6898e-02, 2.5435e-03, 5.5618e-03, 1.3538e-02,\n",
      "        1.4733e-02, 4.6375e-02, 3.4984e-02, 9.0994e-05, 1.2528e-02, 5.2308e-02,\n",
      "        6.5495e-03, 2.5373e-04, 1.0582e-01, 3.3616e-02, 0.0000e+00, 1.7039e-01,\n",
      "        4.8592e-02, 1.2201e-02, 1.1060e-01, 2.7335e-03, 2.4765e-02, 0.0000e+00,\n",
      "        9.6197e-03, 1.1531e-03, 0.0000e+00, 9.6956e-02, 1.9297e-02, 3.9631e-03,\n",
      "        1.2695e-02, 1.2063e-02, 1.6414e-01, 1.2339e-03, 0.0000e+00, 3.1070e-01,\n",
      "        0.0000e+00, 1.6434e-02, 1.2582e-01, 3.5327e-03, 1.4505e-02, 6.9718e-02,\n",
      "        2.4622e-03, 4.6459e-02, 1.4674e-01, 2.2080e-02, 9.8616e-03, 2.6445e-02,\n",
      "        9.6880e-03, 4.2828e-02, 4.3473e-02, 3.5029e-02, 8.5993e-02, 1.2118e-02,\n",
      "        1.3390e-01, 9.8678e-03, 3.7153e-02, 2.5109e-02, 1.0950e-02, 1.9155e-01],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([2.4278e-04, 5.1044e-03, 3.3143e-03, 3.6523e-03, 4.9908e-03, 9.7630e-03,\n",
      "        7.5587e-03, 1.6542e-02, 4.5667e-03, 2.8923e-02, 2.8044e-04, 1.4578e-03,\n",
      "        2.4479e-04, 0.0000e+00, 7.1044e-04, 3.8785e-02, 2.9593e-04, 5.2250e-03,\n",
      "        9.9377e-03, 6.2623e-03, 2.3844e-03, 1.6565e-04, 6.6878e-03, 6.7779e-03,\n",
      "        2.0442e-03, 3.8049e-03, 1.4390e-02, 0.0000e+00, 1.6078e-02, 9.9481e-03,\n",
      "        1.4673e-02, 1.3248e-02, 4.5070e-02, 0.0000e+00, 1.5640e-03, 1.8938e-03,\n",
      "        0.0000e+00, 1.2431e-02, 0.0000e+00, 1.4103e-02, 3.9567e-05, 3.3599e-05,\n",
      "        8.5581e-02, 1.7049e-03, 2.9829e-02, 0.0000e+00, 9.7835e-04, 4.5622e-03,\n",
      "        3.9496e-05, 1.4508e-04, 1.3014e-03, 0.0000e+00, 0.0000e+00, 4.7488e-03,\n",
      "        9.5142e-04, 3.1166e-02, 1.1679e-02, 0.0000e+00, 1.1520e-03, 3.0738e-03,\n",
      "        2.1934e-03, 1.1762e-02, 4.4330e-03, 2.0977e-02, 4.5314e-03, 3.5125e-03,\n",
      "        3.2991e-04, 7.3299e-03, 0.0000e+00, 1.2792e-02, 2.9346e-03, 3.2622e-06,\n",
      "        3.6997e-03, 0.0000e+00, 8.8225e-03, 1.1080e-02, 1.3268e-02, 2.7838e-01,\n",
      "        9.5373e-03, 2.7126e-03, 5.5634e-03, 1.7990e-02, 4.9594e-03, 0.0000e+00,\n",
      "        2.0021e-03, 8.7774e-04, 3.1889e-02, 0.0000e+00, 3.9032e-03, 1.0616e-05,\n",
      "        0.0000e+00, 7.1561e-03, 1.1010e-02, 0.0000e+00, 0.0000e+00, 2.6327e-04,\n",
      "        2.5475e-02, 6.1791e-04, 0.0000e+00, 1.2030e-02, 4.7874e-03, 3.9819e-02,\n",
      "        0.0000e+00, 1.3322e-02, 1.6905e-02, 0.0000e+00, 5.0473e-02, 5.1173e-03,\n",
      "        9.4797e-03, 0.0000e+00, 5.2384e-03, 0.0000e+00, 0.0000e+00, 3.5063e-03,\n",
      "        1.4966e-01, 1.2882e-02, 9.4720e-03, 0.0000e+00, 9.2518e-03, 5.1919e-02,\n",
      "        5.6167e-03, 1.4628e-02, 7.8886e-03, 3.9339e-02, 0.0000e+00, 2.8408e-03,\n",
      "        8.3713e-04, 2.2892e-02, 2.8246e-02, 1.6707e-02, 2.6575e-02, 4.6919e-03,\n",
      "        0.0000e+00, 3.8422e-04, 2.0819e-04, 0.0000e+00, 1.5884e-02, 8.5726e-04,\n",
      "        7.7136e-03, 3.4012e-03, 2.1688e-02, 1.0418e-02, 4.8289e-03, 1.0630e-03,\n",
      "        1.5868e-03, 5.3362e-03, 3.1715e-05, 0.0000e+00, 7.3320e-04, 6.6777e-03,\n",
      "        5.2447e-04, 5.3782e-07, 8.5243e-03, 1.1528e-06, 2.2823e-02, 4.5334e-02,\n",
      "        1.1489e-02, 2.8082e-03, 1.7476e-02, 1.4813e-02, 5.1529e-03, 3.7355e-03,\n",
      "        2.8235e-03, 7.6874e-05, 7.8412e-03, 1.0566e-02, 6.2936e-03, 4.1473e-04,\n",
      "        2.1021e-02, 3.4801e-03, 4.1376e-03, 1.3684e-03, 7.6317e-02, 1.5259e-03,\n",
      "        1.5069e-02, 9.7388e-03, 1.1554e-03, 2.3930e-03, 2.3012e-05, 6.5631e-03,\n",
      "        0.0000e+00, 2.3510e-02, 1.1216e-04, 8.6390e-02, 2.6230e-02, 4.0374e-02,\n",
      "        3.7009e-04, 0.0000e+00, 1.2101e-02, 3.6417e-03, 1.3667e-02, 1.3945e-03,\n",
      "        8.2513e-03, 8.4804e-03, 1.2560e-04, 5.0493e-03, 1.1478e-02, 9.4356e-03,\n",
      "        5.2750e-03, 3.3723e-03, 4.8625e-04, 0.0000e+00, 2.2050e-02, 1.6185e-03,\n",
      "        8.2414e-03, 4.0892e-02, 4.2901e-02, 1.4023e-04, 0.0000e+00, 8.3830e-03,\n",
      "        1.3090e-02, 3.3989e-03, 0.0000e+00, 3.2532e-03, 4.1420e-03, 2.2883e-03,\n",
      "        0.0000e+00, 1.1764e-03, 7.2217e-03, 4.0045e-03, 1.5619e-03, 1.4726e-03,\n",
      "        4.9903e-03, 5.9048e-03, 1.3293e-03, 0.0000e+00, 2.4819e-02, 0.0000e+00,\n",
      "        7.4300e-03, 1.8708e-02, 4.7925e-05, 0.0000e+00, 0.0000e+00, 1.1703e-01,\n",
      "        7.6852e-03, 3.1772e-03, 6.9120e-03, 1.8492e-02, 3.6225e-02, 4.0710e-03,\n",
      "        0.0000e+00, 2.8545e-02, 3.2552e-03, 8.3530e-04, 0.0000e+00, 1.7421e-03,\n",
      "        9.1782e-03, 6.7153e-03, 7.3065e-04, 1.9536e-04, 6.0511e-03, 4.4361e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2212e-03, 5.3095e-02, 1.6680e-02,\n",
      "        0.0000e+00, 3.2336e-02, 9.4331e-02, 0.0000e+00, 0.0000e+00, 1.2620e-02,\n",
      "        3.9121e-03, 0.0000e+00, 1.2121e-02, 2.1214e-05, 4.5559e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.5129e-05, 0.0000e+00, 3.5453e-03, 6.5371e-02,\n",
      "        8.1437e-03, 5.8671e-03, 5.2592e-02, 1.6830e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.5683e-02, 2.9349e-03, 3.0014e-03, 0.0000e+00, 6.7260e-02, 1.2225e-01,\n",
      "        2.6221e-02, 3.0706e-03, 6.9473e-03, 1.7702e-03, 0.0000e+00, 7.6959e-03,\n",
      "        8.6478e-02, 7.8340e-03, 9.3918e-03, 4.7018e-03, 0.0000e+00, 7.5717e-03,\n",
      "        1.3191e-02, 7.3181e-03, 9.9033e-02, 4.9566e-03, 0.0000e+00, 0.0000e+00,\n",
      "        8.2987e-02, 1.3523e-02, 0.0000e+00, 2.5845e-02, 4.7726e-02, 1.8729e-03,\n",
      "        1.3483e-03, 3.4728e-02, 8.5692e-03, 5.0989e-03, 4.2929e-02, 2.6465e-02,\n",
      "        7.3457e-06, 3.6361e-03, 1.7697e-01, 2.9485e-03, 3.0082e-02, 3.8738e-03,\n",
      "        1.1009e-02, 2.1159e-02, 0.0000e+00, 6.5681e-04, 3.1904e-01, 4.6082e-02,\n",
      "        5.5371e-03, 4.5005e-03, 1.9667e-02, 3.1932e-01, 1.1810e-03, 4.7412e-02,\n",
      "        0.0000e+00, 4.6440e-03, 2.6095e-02, 2.6231e-02, 1.0581e-01, 0.0000e+00,\n",
      "        9.7942e-03, 7.6683e-03, 1.1068e-03, 6.3916e-04, 5.4849e-03, 0.0000e+00,\n",
      "        2.8744e-02, 0.0000e+00, 1.4259e-04, 0.0000e+00, 9.2950e-03, 1.9554e-03,\n",
      "        4.0546e-03, 0.0000e+00, 2.1225e-04, 6.2274e-03, 8.6318e-02, 0.0000e+00,\n",
      "        0.0000e+00, 4.6263e-03, 4.1468e-03, 6.2075e-04, 5.0688e-02, 5.3549e-02,\n",
      "        4.9904e-02, 6.1214e-03, 1.5224e-02, 1.9496e-03, 9.2062e-06, 9.3868e-02,\n",
      "        4.6855e-03, 8.1572e-03, 0.0000e+00, 6.2683e-03, 3.0497e-02, 0.0000e+00,\n",
      "        4.9883e-02, 0.0000e+00, 2.2970e-03, 6.2135e-04, 7.5417e-03, 3.7474e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.5983e-02, 7.5080e-04, 3.0909e-02, 2.8437e-02,\n",
      "        3.3757e-03, 1.7294e-02, 4.5295e-03, 1.5028e-03, 5.9574e-03, 1.9315e-04,\n",
      "        0.0000e+00, 1.6576e-02, 1.6405e-02, 4.1333e-03, 1.8489e-03, 1.6864e-02,\n",
      "        1.1450e-02, 9.7205e-03, 0.0000e+00, 7.5544e-05, 7.3815e-03, 0.0000e+00,\n",
      "        4.2640e-01, 2.0734e-04, 1.0446e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0992e-03, 2.1122e-02, 1.6844e-03, 1.4715e-02, 1.5803e-03, 1.3562e-03,\n",
      "        0.0000e+00, 1.7764e-03, 2.4939e-02, 2.9864e-03, 5.4563e-02, 0.0000e+00,\n",
      "        2.6414e-02, 4.1691e-02, 4.4202e-03, 2.2234e-03, 8.8392e-03, 2.7729e-03,\n",
      "        2.7733e-03, 2.8818e-02, 0.0000e+00, 1.6832e-02, 9.7898e-03, 5.7128e-02,\n",
      "        0.0000e+00, 1.1900e-02, 0.0000e+00, 2.1192e-02, 6.2120e-02, 0.0000e+00,\n",
      "        5.7548e-03, 4.8024e-02, 5.2667e-03, 7.9865e-03, 1.9016e-02, 1.6774e-04,\n",
      "        1.2918e-02, 1.3932e-02, 3.6617e-04, 0.0000e+00, 8.3164e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.2462e-03, 3.5702e-03, 4.7261e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.6326e-03, 1.4801e-03, 7.5340e-03, 1.9873e-02, 1.1641e-03, 8.7477e-02,\n",
      "        5.7734e-03, 1.7651e-03, 2.5033e-03, 1.1908e-02, 7.2080e-03, 1.2773e-02,\n",
      "        2.5740e-03, 0.0000e+00, 0.0000e+00, 1.5564e-02, 2.0229e-02, 8.9851e-03,\n",
      "        1.6587e-02, 1.5879e-02, 5.8510e-04, 1.1226e-02, 2.9143e-02, 2.0524e-02,\n",
      "        1.3262e-02, 0.0000e+00, 2.6437e-04, 1.0169e-01, 5.7651e-03, 1.0600e-02,\n",
      "        1.1902e-02, 8.3135e-04, 3.8323e-02, 1.7399e-02, 8.0217e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.1388e-02, 0.0000e+00, 1.0681e-02, 4.6153e-02, 2.2553e-04,\n",
      "        6.5413e-02, 2.0469e-02, 4.2118e-03, 8.2115e-03, 2.7153e-03, 1.5451e-04,\n",
      "        5.4711e-04, 6.1846e-03, 0.0000e+00, 5.0543e-02, 2.4058e-03, 3.6187e-03,\n",
      "        2.9387e-02, 0.0000e+00, 5.4032e-05, 1.2980e-02, 6.8929e-02, 2.7811e-05,\n",
      "        4.0419e-02, 2.1762e-02, 0.0000e+00, 1.6533e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.8922e-02, 2.9040e-03, 6.4413e-02, 3.5667e-03, 3.0119e-03, 1.1068e-03,\n",
      "        1.5706e-04, 3.3316e-03, 4.8928e-02, 8.3346e-03, 1.1873e-02, 0.0000e+00,\n",
      "        1.1479e-02, 4.2874e-02, 2.6937e-03, 5.0642e-03, 2.3866e-02, 1.7883e-03,\n",
      "        2.1339e-03, 1.2750e-04, 4.0818e-03, 4.1618e-04, 1.3778e-04, 5.0260e-03,\n",
      "        1.1281e-02, 3.1652e-03, 8.0314e-04, 5.7138e-03, 1.6757e-02, 6.1096e-03,\n",
      "        0.0000e+00, 3.1810e-03, 3.9845e-03, 1.4137e-03, 1.4881e-04, 2.0341e-03,\n",
      "        4.6564e-03, 5.0936e-03, 1.1292e-02, 1.3496e-02, 4.5071e-03, 4.9213e-05,\n",
      "        5.2711e-03, 3.2937e-02, 4.4623e-02, 0.0000e+00, 1.0925e-02, 5.8128e-02,\n",
      "        0.0000e+00, 5.8653e-03, 1.2929e-03, 3.8930e-03, 3.6961e-03, 1.7534e-02,\n",
      "        0.0000e+00, 2.1144e-03, 6.3577e-03, 4.8114e-02, 1.5837e-02, 0.0000e+00,\n",
      "        1.7047e-02, 3.5375e-02, 0.0000e+00, 6.3424e-03, 0.0000e+00, 1.5670e-02,\n",
      "        2.9854e-04, 0.0000e+00, 2.2256e-02, 0.0000e+00, 1.6216e-04, 0.0000e+00,\n",
      "        3.8624e-03, 1.2792e-02, 2.0002e-02, 7.5376e-03, 5.3974e-04, 1.6150e-02,\n",
      "        3.8876e-03, 1.2321e-04, 2.4647e-03, 3.8848e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.2994e-02, 0.0000e+00, 0.0000e+00, 3.8724e-05, 4.0559e-02, 8.4475e-04,\n",
      "        9.6931e-04, 0.0000e+00, 1.5984e-02, 0.0000e+00, 5.2222e-03, 2.4175e-03,\n",
      "        7.1591e-05, 9.8953e-03, 2.7119e-03, 5.4636e-03, 1.4134e-02, 1.4308e-03,\n",
      "        0.0000e+00, 5.5885e-04, 1.0142e-02, 2.6396e-02, 3.7138e-03, 5.6750e-04,\n",
      "        3.1366e-03, 1.1138e-02, 2.3524e-03, 8.0976e-03, 3.0903e-04, 1.8703e-03,\n",
      "        0.0000e+00, 1.5833e-02, 1.5364e-03, 1.2833e-02, 1.0055e-02, 1.8746e-02,\n",
      "        1.5080e-02, 1.8722e-03, 4.2536e-04, 3.9119e-03, 1.0810e-02, 3.4816e-03,\n",
      "        3.6567e-02, 1.3183e-02, 0.0000e+00, 0.0000e+00, 1.0503e-02, 7.4193e-04,\n",
      "        7.1408e-03, 1.1085e-02, 4.8446e-03, 1.3459e-02, 4.3721e-03, 6.7320e-03,\n",
      "        2.1486e-04, 0.0000e+00, 0.0000e+00, 4.7521e-03, 7.2077e-03, 2.5880e-03,\n",
      "        5.2960e-03, 1.1221e-01, 6.4171e-03, 4.4467e-04, 0.0000e+00, 1.2596e-03,\n",
      "        1.8876e-02, 1.0545e-02, 7.1286e-03, 2.5127e-02, 0.0000e+00, 2.4397e-03,\n",
      "        3.0102e-02, 2.3397e-03, 6.6618e-03, 3.8044e-03, 0.0000e+00, 4.8345e-03,\n",
      "        8.9462e-03, 2.8137e-02, 6.6974e-03, 4.0243e-02, 4.0903e-03, 3.7897e-02,\n",
      "        0.0000e+00, 1.0476e-02, 2.1785e-04, 1.0040e-02, 1.6332e-03, 6.1285e-05,\n",
      "        9.3941e-04, 2.5244e-02, 1.3727e-03, 3.2693e-03, 0.0000e+00, 2.5494e-04,\n",
      "        5.1664e-03, 3.8807e-03, 1.7851e-03, 4.2174e-03, 3.4660e-03, 2.7296e-03,\n",
      "        1.8040e-03, 1.8805e-02, 3.6845e-03, 6.1308e-03, 1.4358e-02, 0.0000e+00,\n",
      "        5.7121e-03, 4.9343e-04, 0.0000e+00, 9.9235e-03, 4.5949e-03, 4.5990e-02,\n",
      "        3.7583e-04, 1.3810e-02, 0.0000e+00, 0.0000e+00, 9.1023e-03, 7.0518e-03,\n",
      "        5.7912e-02, 7.2649e-05, 0.0000e+00, 1.3115e-02, 2.0280e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.9907e-02, 0.0000e+00, 2.0774e-02, 1.5939e-02, 0.0000e+00,\n",
      "        4.3494e-04, 1.8543e-03, 2.4788e-02, 0.0000e+00, 1.3067e-01, 7.6943e-03,\n",
      "        1.2078e-02, 3.8631e-03, 1.5455e-02, 2.0650e-02, 2.5496e-03, 1.1534e-02,\n",
      "        2.6192e-03, 1.0172e-02, 2.0839e-03, 4.9008e-03, 2.7261e-04, 3.7234e-04,\n",
      "        0.0000e+00, 1.9195e-02, 9.8980e-04, 9.5165e-02, 2.1461e-02, 3.7886e-02],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0019, 0.0050, 0.0027, 0.0048, 0.0033, 0.0057, 0.0019],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0181, 0.0291, 0.0235, 0.0266, 0.0256, 0.0322, 0.0187],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 5.9943e-02, 0.0000e+00, 0.0000e+00, 1.6286e-02,\n",
      "        2.3551e-02, 1.2615e-02, 2.6209e-04, 0.0000e+00, 2.5662e-02, 8.3667e-02,\n",
      "        3.9897e-02, 5.2478e-02, 1.7567e-03, 1.6009e-01, 7.7202e-02, 5.0780e-03,\n",
      "        7.1820e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4074e-05, 2.5239e-02,\n",
      "        4.3830e-02, 3.8737e-02, 8.0018e-01, 0.0000e+00, 5.7425e-01, 1.9697e-02,\n",
      "        1.0055e-02, 7.9088e-02, 3.2181e-02, 6.1297e-03, 6.5116e-03, 0.0000e+00,\n",
      "        3.1339e-02, 3.5630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1779e-02,\n",
      "        1.8597e-01, 8.4470e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.4098e-02, 5.7339e-03, 6.8445e-02, 1.7734e-02, 0.0000e+00, 4.2070e-03,\n",
      "        5.6631e-04, 1.8672e-02, 5.6263e-07, 0.0000e+00, 5.6881e-04, 1.6426e-03,\n",
      "        3.2966e-02, 2.7413e-02, 0.0000e+00, 1.5940e-02, 0.0000e+00, 8.1894e-03,\n",
      "        3.5779e-05, 0.0000e+00, 0.0000e+00, 1.6638e-02, 1.2108e-02, 1.3640e-02,\n",
      "        7.2265e-05, 5.7118e-02, 5.7784e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.7006e-03, 3.0460e-03, 2.2728e-03, 1.0511e-02, 4.2951e-02,\n",
      "        6.7418e-02, 1.0577e-01, 3.1372e-02, 7.7870e-02, 1.7138e-02, 4.1799e-02,\n",
      "        1.0787e-03, 8.3885e-04, 0.0000e+00, 0.0000e+00, 2.2275e-05, 1.8153e-02,\n",
      "        1.2316e-01, 1.5091e-01, 2.7224e-03, 1.4441e-03, 5.0080e-02, 5.5739e-02,\n",
      "        1.5611e-02, 5.4855e-02, 2.8687e-05, 1.9735e-01, 3.6872e-02, 3.6161e-03,\n",
      "        8.1065e-05, 1.0277e-01, 1.6100e-02, 7.3366e-02, 4.3457e-03, 7.8365e-03,\n",
      "        1.1247e-01, 0.0000e+00, 4.2248e-03, 1.1471e-01, 0.0000e+00, 2.4531e-03,\n",
      "        7.6433e-03, 0.0000e+00, 9.3546e-02, 0.0000e+00, 1.0666e-01, 6.4656e-03,\n",
      "        1.0315e-02, 2.2474e-02, 5.0593e-04, 1.9915e-02, 1.3778e-03, 1.4198e-02,\n",
      "        3.9503e-02, 0.0000e+00, 2.7359e-02, 4.5407e-02, 6.5793e-02, 2.8488e-03,\n",
      "        1.5244e-03, 1.9784e-02, 3.0674e-02, 4.5476e-02, 3.0981e-02, 2.3204e-02,\n",
      "        2.3101e-01, 4.1876e-03, 3.8336e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.3804e-05, 5.8011e-02, 5.5821e-03, 6.4116e-02, 1.3342e-02, 1.3130e-02,\n",
      "        1.2418e-02, 7.3459e-02, 5.0757e-02, 6.6954e-02, 0.0000e+00, 2.2526e-02,\n",
      "        0.0000e+00, 1.0357e-02, 1.8806e-03, 1.5832e-05, 1.1982e-02, 4.4165e-03,\n",
      "        7.6746e-02, 5.0241e-02, 9.7457e-02, 1.0645e-02, 9.6303e-02, 0.0000e+00,\n",
      "        3.5780e-02, 7.8977e-02, 0.0000e+00, 1.8060e-04, 4.4244e-03, 4.2546e-03,\n",
      "        3.4848e-03, 0.0000e+00, 1.4777e-02, 0.0000e+00, 9.8186e-05, 1.0167e-01,\n",
      "        9.1418e-03, 5.0914e-03, 4.0980e-02, 2.0898e-03, 8.1458e-03, 1.2382e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1858e-02, 0.0000e+00, 0.0000e+00, 7.7620e-03,\n",
      "        3.9609e-02, 1.1001e-02, 3.6325e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.5477e-02, 4.3714e-02, 4.1266e-02, 6.8925e-02, 1.0629e-02, 8.3237e-02,\n",
      "        1.0465e-02, 7.4013e-03, 9.2723e-02, 0.0000e+00, 1.0319e-02, 0.0000e+00,\n",
      "        6.8833e-02, 7.8601e-03, 3.6393e-02, 6.6940e-02, 0.0000e+00, 5.0425e-02,\n",
      "        0.0000e+00, 7.1944e-02, 2.8044e-02, 4.4815e-02, 1.4784e-02, 4.5018e-02,\n",
      "        5.1088e-02, 6.6371e-03, 3.0748e-02, 0.0000e+00, 8.0645e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 9.7447e-03, 1.0180e-01, 0.0000e+00, 9.7657e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0693e-02, 0.0000e+00,\n",
      "        4.2269e-03, 5.2464e-02, 2.6993e-03, 2.9715e-02, 1.4671e-03, 1.0924e-01,\n",
      "        1.7943e-01, 0.0000e+00, 0.0000e+00, 4.7159e-02, 6.9755e-02, 8.3962e-02,\n",
      "        0.0000e+00, 4.7372e-02, 0.0000e+00, 1.0326e-03, 8.3498e-03, 6.0103e-02,\n",
      "        1.8167e-02, 0.0000e+00, 8.7941e-03, 1.1536e-01, 8.1876e-03, 1.1448e-01,\n",
      "        8.3785e-02, 4.6515e-04, 1.4866e-02, 6.1441e-03, 1.5160e-02, 1.5703e-01,\n",
      "        2.3207e-03, 9.0622e-03, 4.6953e-02, 0.0000e+00, 0.0000e+00, 3.1039e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.5827e-02, 7.1598e-02, 7.3359e-02, 0.0000e+00,\n",
      "        2.1534e-04, 0.0000e+00, 9.0540e-03, 0.0000e+00, 3.0266e-04, 0.0000e+00,\n",
      "        4.0609e-03, 9.9626e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1933e-05,\n",
      "        7.9976e-02, 2.0701e-01, 2.7265e-03, 7.2063e-02, 8.3513e-02, 0.0000e+00,\n",
      "        0.0000e+00, 1.4926e-03, 0.0000e+00, 0.0000e+00, 4.7690e-02, 5.9247e-01,\n",
      "        4.3958e-02, 4.8789e-02, 4.8173e-02, 2.8221e-02, 1.0968e-01, 1.6009e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1038e-01, 6.2581e-03, 0.0000e+00, 6.5896e-02,\n",
      "        5.4223e-02, 0.0000e+00, 8.3299e-02, 2.8212e-02, 5.9779e-01, 0.0000e+00,\n",
      "        4.3285e-05, 0.0000e+00, 0.0000e+00, 1.2890e-01, 1.0104e-03, 1.4929e-01,\n",
      "        0.0000e+00, 0.0000e+00, 4.0761e-02, 2.8143e-03, 0.0000e+00, 0.0000e+00,\n",
      "        2.1148e-04, 0.0000e+00, 3.8980e-03, 2.5496e-03, 2.5740e-01, 8.8188e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.1052e-03, 0.0000e+00, 2.1655e-02, 0.0000e+00,\n",
      "        1.7464e-02, 1.8965e-03, 0.0000e+00, 1.7861e-02, 2.6702e-02, 6.0438e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.9852e-02, 0.0000e+00, 0.0000e+00, 7.5807e-04,\n",
      "        0.0000e+00, 6.1640e-04, 4.0067e-02, 2.4529e-02, 0.0000e+00, 6.4308e-03,\n",
      "        0.0000e+00, 2.1119e-03, 1.2802e-01, 0.0000e+00, 6.2461e-02, 1.7086e-01,\n",
      "        0.0000e+00, 2.4320e-02, 1.6803e-02, 1.0858e-02, 6.7643e-03, 9.2623e-03,\n",
      "        1.3820e-03, 4.2794e-02, 2.8081e-02, 1.7113e-02, 5.8526e-03, 4.3167e-02,\n",
      "        0.0000e+00, 2.2719e-01, 9.2247e-02, 1.1692e-04, 1.0261e-01, 2.9566e-02,\n",
      "        1.2365e-02, 0.0000e+00, 2.3237e-02, 1.7788e-02, 6.1130e-02, 8.0902e-02,\n",
      "        2.2345e-04, 5.0093e-02, 0.0000e+00, 6.8581e-02, 7.1084e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8372e-02, 0.0000e+00, 2.5466e-02,\n",
      "        2.3482e-02, 0.0000e+00, 7.6725e-03, 2.6897e-02, 0.0000e+00, 3.6913e-02,\n",
      "        8.5075e-02, 0.0000e+00, 0.0000e+00, 6.7031e-02, 6.8549e-02, 1.4984e-02,\n",
      "        8.5824e-04, 6.0790e-02, 3.8499e-03, 2.2925e-02, 3.0191e-02, 3.6790e-04,\n",
      "        2.7028e-02, 6.5319e-02, 0.0000e+00, 2.4923e-01, 6.2350e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.8623e-02, 0.0000e+00, 8.1745e-03, 1.3652e-01, 3.5094e-02,\n",
      "        1.8699e-02, 2.0652e-02, 0.0000e+00, 3.1322e-02, 4.0868e-02, 0.0000e+00,\n",
      "        0.0000e+00, 3.3946e-03, 1.8752e-01, 0.0000e+00, 1.5357e-02, 3.4038e-03,\n",
      "        0.0000e+00, 3.0598e-02, 4.3158e-02, 5.2211e-02, 0.0000e+00, 9.0517e-02,\n",
      "        6.2415e-03, 0.0000e+00, 1.2053e-02, 1.2415e-03, 0.0000e+00, 1.2414e-02,\n",
      "        0.0000e+00, 2.6608e-02, 3.3202e-01, 0.0000e+00, 0.0000e+00, 3.7025e-02,\n",
      "        1.1547e-01, 1.9563e-03, 5.5737e-02, 8.7883e-02, 9.3717e-03, 3.6051e-02,\n",
      "        7.5522e-02, 0.0000e+00, 2.1759e-04, 3.7899e-02, 3.3679e-02, 3.0900e-02,\n",
      "        5.3396e-03, 0.0000e+00, 2.6530e-02, 8.2790e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.3211e-03, 0.0000e+00, 0.0000e+00, 9.9806e-03, 1.2348e-01,\n",
      "        6.6634e-03, 2.1123e-02, 5.6950e-02, 2.4545e-03, 0.0000e+00, 3.1597e-03,\n",
      "        1.2926e-02, 3.4584e-02, 5.0209e-02, 1.0093e-01, 2.4244e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.7863e-02, 4.2965e-03, 1.8308e-02, 1.1488e-02, 9.6212e-04,\n",
      "        3.7088e-03, 1.5307e-02, 8.6630e-02, 5.3903e-03, 0.0000e+00, 0.0000e+00,\n",
      "        9.7315e-03, 2.7618e-02, 4.1141e-02, 2.5161e-02, 7.2626e-02, 0.0000e+00,\n",
      "        1.2246e-02, 8.1083e-02, 9.2837e-02, 2.3371e-04, 3.4417e-02, 2.5099e-02,\n",
      "        7.3490e-02, 4.3060e-02, 2.1955e-02, 2.3163e-03, 0.0000e+00, 2.0539e-02,\n",
      "        0.0000e+00, 0.0000e+00, 7.8203e-02, 4.6618e-02, 1.5667e-02, 4.0337e-02,\n",
      "        8.6750e-02, 3.2280e-02, 6.9234e-03, 2.9053e-03, 1.9711e-03, 0.0000e+00,\n",
      "        3.1639e-03, 5.8108e-03, 0.0000e+00, 0.0000e+00, 8.1797e-02, 3.0479e-02,\n",
      "        0.0000e+00, 2.9357e-03, 1.2628e-03, 1.7371e-02, 1.3012e-04, 8.5721e-02,\n",
      "        0.0000e+00, 1.4390e-02, 1.4412e-03, 0.0000e+00, 3.7365e-04, 0.0000e+00,\n",
      "        1.7851e-01, 3.2110e-03, 2.4949e-01, 5.0983e-02, 3.7123e-02, 0.0000e+00,\n",
      "        1.6746e-02, 3.4827e-02, 4.0365e-03, 0.0000e+00, 1.0966e-02, 4.1497e-02,\n",
      "        1.5384e-02, 1.2249e-02, 5.7169e-03, 2.9536e-02, 6.4967e-02, 2.3311e-02,\n",
      "        8.3700e-03, 6.3103e-02, 3.4438e-02, 5.1629e-03, 8.6082e-02, 0.0000e+00,\n",
      "        4.7637e-02, 3.6515e-02, 0.0000e+00, 4.7051e-02, 1.5746e-02, 0.0000e+00,\n",
      "        0.0000e+00, 1.7090e-02, 2.3064e-02, 0.0000e+00, 1.7867e-03, 2.4968e-02,\n",
      "        2.5722e-04, 1.1235e-02, 3.0817e-02, 1.7380e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.3064e-02, 1.3576e-03, 1.7146e-02, 3.1119e-02, 1.7243e-02, 1.4618e-02,\n",
      "        0.0000e+00, 4.2510e-05, 2.5834e-04, 5.1965e-04, 0.0000e+00, 1.2147e-01,\n",
      "        0.0000e+00, 4.9587e-03, 2.4134e-02, 1.0048e-01, 4.1509e-05, 1.8265e-02,\n",
      "        1.1182e-02, 0.0000e+00, 0.0000e+00, 5.4824e-03, 1.4443e-02, 8.0759e-03,\n",
      "        3.6249e-02, 2.3204e-03, 0.0000e+00, 5.8446e-02, 0.0000e+00, 2.4226e-02,\n",
      "        0.0000e+00, 7.8437e-03, 2.8008e-02, 2.5521e-01, 3.8892e-03, 3.8419e-02,\n",
      "        2.1629e-02, 1.1944e-03, 9.0501e-02, 3.6714e-02, 3.2502e-02, 1.3723e-01,\n",
      "        0.0000e+00, 0.0000e+00, 1.3162e-01, 0.0000e+00, 7.5190e-03, 1.2600e-03,\n",
      "        7.4168e-04, 0.0000e+00, 1.6863e-02, 4.7268e-02, 1.5501e-02, 0.0000e+00,\n",
      "        9.4444e-04, 6.9034e-03, 1.4126e-01, 2.9240e-02, 6.9034e-03, 1.5196e-02,\n",
      "        3.7869e-02, 1.4373e-01, 2.3230e-04, 7.4230e-04, 7.6364e-02, 3.1720e-03,\n",
      "        3.6406e-02, 6.7137e-02, 3.6066e-02, 3.4310e-03, 2.3679e-04, 2.4268e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7573e-03, 2.1680e-02, 0.0000e+00,\n",
      "        1.9899e-03, 0.0000e+00, 1.0517e-02, 0.0000e+00, 0.0000e+00, 2.8335e-04,\n",
      "        5.3403e-02, 1.6408e-02, 3.7136e-04, 1.6485e-02, 1.6714e-03, 0.0000e+00,\n",
      "        8.2176e-02, 0.0000e+00, 2.2841e-02, 1.3766e-02, 3.6215e-02, 3.9774e-04,\n",
      "        1.9314e-03, 2.5508e-03, 2.5368e-02, 2.0977e-02, 0.0000e+00, 0.0000e+00,\n",
      "        6.5108e-02, 6.7999e-02, 3.6592e-02, 0.0000e+00, 3.5041e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.6023e-04, 5.0848e-02, 0.0000e+00, 0.0000e+00, 8.1712e-02,\n",
      "        3.7267e-02, 2.1916e-03, 4.7731e-02, 1.8447e-02, 5.2180e-03, 6.4504e-02,\n",
      "        2.9042e-05, 1.6485e-03, 0.0000e+00, 1.3382e-02, 1.1106e-01, 0.0000e+00,\n",
      "        9.0855e-03, 2.0869e-03, 4.1500e-02, 0.0000e+00, 3.3022e-02, 5.1082e-02,\n",
      "        0.0000e+00, 1.5586e-03, 1.0006e-01, 3.6060e-03, 0.0000e+00, 3.9735e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1341e-03,\n",
      "        6.6574e-02, 2.5575e-02, 2.0521e-04, 3.3598e-02, 0.0000e+00, 7.3818e-02,\n",
      "        0.0000e+00, 0.0000e+00, 8.7895e-02, 0.0000e+00, 4.3592e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0014, 0.0164, 0.0017, 0.0082, 0.0019, 0.0173, 0.0018],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0178, 0.0446, 0.0219, 0.0336, 0.0225, 0.0454, 0.0188],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([1.8856e-02, 6.8049e-02, 0.0000e+00, 0.0000e+00, 2.0476e-02, 1.7816e-03,\n",
      "        5.9230e-03, 3.7255e-04, 7.0556e-02, 9.7829e-02, 9.4868e-04, 1.8745e-01,\n",
      "        1.7575e-02, 4.3309e-02, 4.4252e-03, 1.6984e-01, 0.0000e+00, 3.5434e-03,\n",
      "        0.0000e+00, 6.7484e-02, 7.0448e-02, 0.0000e+00, 1.1717e-02, 1.6988e-02,\n",
      "        2.7139e-03, 1.2062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1779e-03,\n",
      "        2.3660e-02, 0.0000e+00, 1.7891e-02, 4.2171e-02, 7.3583e-03, 1.6863e-01,\n",
      "        0.0000e+00, 1.3764e-02, 0.0000e+00, 0.0000e+00, 4.6859e-02, 2.6315e-02,\n",
      "        1.4986e-01, 6.1279e-02, 3.9956e-01, 2.7012e-02, 0.0000e+00, 0.0000e+00,\n",
      "        5.8391e-02, 0.0000e+00, 8.8342e-02, 1.1383e-02, 5.5877e-01, 3.2241e-02,\n",
      "        9.8563e-03, 9.0106e-03, 2.4318e-02, 0.0000e+00, 4.2678e-02, 2.5351e-03,\n",
      "        1.7266e-02, 0.0000e+00, 7.3493e-04, 3.5154e-02, 0.0000e+00, 2.6570e-02,\n",
      "        2.9522e-04, 1.0562e-02, 0.0000e+00, 3.7622e-03, 0.0000e+00, 6.7561e-05,\n",
      "        2.5168e-03, 9.0988e-03, 3.5714e-02, 1.5936e-01, 9.9770e-03, 0.0000e+00,\n",
      "        6.8619e-02, 7.5164e-04, 2.2681e-03, 8.9800e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.5913e-02, 4.3244e-02, 0.0000e+00, 2.3174e-03, 9.0090e-02,\n",
      "        0.0000e+00, 4.9470e-02, 0.0000e+00, 4.2606e-03, 6.2701e-03, 7.7243e-02,\n",
      "        1.3978e-01, 6.7144e-02, 9.5422e-04, 1.3670e-02, 5.5151e-03, 4.8894e-02,\n",
      "        3.2441e-02, 3.9453e-03, 0.0000e+00, 0.0000e+00, 1.2518e-03, 1.2416e-02,\n",
      "        4.8234e-03, 0.0000e+00, 3.9172e-02, 0.0000e+00, 0.0000e+00, 8.2042e-02,\n",
      "        3.6427e-02, 1.2356e-01, 1.6475e-02, 9.2305e-02, 1.1418e-01, 0.0000e+00,\n",
      "        4.9599e-03, 4.2599e-02, 1.7085e-01, 1.9862e-01, 9.7098e-02, 1.2176e-02,\n",
      "        1.7421e-02, 5.6907e-03, 0.0000e+00, 1.4681e-03, 5.6838e-03, 1.4243e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.6690e-03, 4.0214e-03, 3.9573e-02, 2.2151e-05,\n",
      "        6.5842e-03, 0.0000e+00, 2.8944e-02, 6.9978e-02, 4.3780e-02, 7.7891e-03,\n",
      "        6.3584e-05, 1.0295e-02, 0.0000e+00, 3.0635e-02, 2.3118e-03, 1.0685e-02,\n",
      "        4.7010e-03, 5.8204e-02, 3.1998e-04, 0.0000e+00, 1.3043e-02, 4.6338e-04,\n",
      "        1.2184e-02, 5.3564e-02, 6.2269e-02, 0.0000e+00, 1.2713e-01, 8.9674e-02,\n",
      "        1.8720e-02, 1.1174e-02, 7.8672e-03, 6.3747e-04, 2.9608e-02, 6.6813e-03,\n",
      "        5.8198e-02, 5.1570e-02, 5.2172e-03, 7.4541e-03, 8.7879e-02, 2.4663e-02,\n",
      "        2.4213e-02, 0.0000e+00, 6.3950e-02, 0.0000e+00, 3.4887e-03, 3.5289e-02,\n",
      "        1.1870e-02, 1.6638e-02, 6.3054e-04, 1.2287e-01, 3.0763e-02, 1.8467e-01,\n",
      "        4.5916e-03, 3.4766e-03, 5.3571e-02, 1.4339e-02, 2.9778e-02, 3.4686e-04,\n",
      "        0.0000e+00, 3.8697e-04, 0.0000e+00, 7.6711e-04, 3.7952e-02, 3.8421e-03,\n",
      "        4.0166e-03, 6.6200e-04, 0.0000e+00, 8.5362e-02, 8.4913e-02, 7.1346e-02,\n",
      "        0.0000e+00, 3.8982e-02, 0.0000e+00, 2.6286e-02, 1.5568e-02, 0.0000e+00,\n",
      "        1.0395e-03, 1.5876e-04, 0.0000e+00, 0.0000e+00, 2.4832e-03, 1.6186e-01,\n",
      "        5.3718e-02, 1.6228e-02, 1.4335e-03, 6.5232e-05, 1.3081e-01, 7.4725e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.1589e-02, 3.9701e-02, 0.0000e+00, 1.3331e-03,\n",
      "        9.8684e-03, 2.8948e-02, 6.8151e-02, 1.1853e-01, 0.0000e+00, 1.2298e-01,\n",
      "        4.3817e-02, 4.8752e-02, 2.1044e-02, 8.7395e-02, 3.1817e-02, 1.1129e-02,\n",
      "        1.4320e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.7302e-02, 4.9702e-04, 1.0968e-02, 1.6340e-03, 2.3004e-02, 1.3053e-01,\n",
      "        4.9998e-03, 9.1564e-03, 0.0000e+00, 7.6039e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.8574e-02, 8.3037e-02, 1.7172e-02, 1.4525e-02, 4.1259e-02,\n",
      "        4.9230e-02, 0.0000e+00, 7.3622e-03, 0.0000e+00, 1.4926e-02, 1.8826e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.1095e-05, 8.5414e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.2418e-02, 6.7533e-04, 8.1700e-04, 2.2639e-02, 1.9995e-01, 3.7409e-02,\n",
      "        2.6858e-02, 1.7225e-01, 3.8203e-02, 7.0534e-02, 0.0000e+00, 1.7700e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.1692e-03, 1.8837e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.2669e-02, 3.6507e-03, 0.0000e+00, 4.3384e-04, 4.8959e-03,\n",
      "        4.6774e-02, 1.8405e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.8576e-01, 8.1085e-02, 9.6545e-02, 5.4175e-03, 4.5498e-02, 7.0886e-01,\n",
      "        2.0914e-01, 1.4524e-03, 3.2899e-02, 2.3581e-02, 0.0000e+00, 2.1014e-02,\n",
      "        1.0816e-01, 0.0000e+00, 1.3466e-01, 7.5558e-04, 2.0319e-02, 3.5794e-02,\n",
      "        0.0000e+00, 6.1361e-02, 0.0000e+00, 1.4648e-03, 0.0000e+00, 3.0271e-02,\n",
      "        1.2691e-02, 7.9539e-03, 0.0000e+00, 2.4657e-01, 1.3660e-02, 9.0333e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1600e-04, 9.3181e-02, 0.0000e+00,\n",
      "        1.7765e-03, 7.7275e-02, 0.0000e+00, 1.1499e-03, 1.9656e-01, 7.9537e-02,\n",
      "        2.1216e-03, 1.6235e-01, 7.6840e-04, 1.7797e-01, 9.8664e-03, 0.0000e+00,\n",
      "        1.3076e-02, 5.5986e-02, 6.8053e-02, 1.2206e-01, 1.9686e-03, 7.5793e-02,\n",
      "        3.0566e-01, 1.3025e-01, 2.2527e-02, 0.0000e+00, 1.2718e-03, 9.7637e-03,\n",
      "        0.0000e+00, 2.3960e-02, 0.0000e+00, 0.0000e+00, 1.8235e-02, 1.9085e-02,\n",
      "        9.1370e-02, 1.2184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6074e-01,\n",
      "        5.5437e-02, 7.4676e-03, 6.9592e-02, 5.6659e-03, 0.0000e+00, 5.3552e-03,\n",
      "        0.0000e+00, 1.1240e-02, 0.0000e+00, 6.8023e-02, 2.6320e-04, 2.4104e-02,\n",
      "        7.3516e-02, 3.9484e-01, 5.2762e-02, 4.6914e-02, 0.0000e+00, 6.0037e-02,\n",
      "        1.4666e-03, 0.0000e+00, 3.3208e-03, 9.5113e-03, 0.0000e+00, 1.2561e-01,\n",
      "        9.5358e-02, 6.1873e-02, 5.4605e-04, 2.8474e-02, 2.8746e-02, 4.7839e-02,\n",
      "        3.7914e-01, 8.0460e-02, 1.6509e-04, 9.2886e-03, 5.4665e-02, 9.8555e-04,\n",
      "        2.6915e-03, 0.0000e+00, 2.1187e-02, 1.3245e-02, 3.5090e-04, 7.9288e-02,\n",
      "        0.0000e+00, 2.8665e-02, 2.9600e-02, 0.0000e+00, 7.5330e-02, 2.3163e-02,\n",
      "        1.2067e-01, 1.8233e-02, 1.3270e-02, 0.0000e+00, 0.0000e+00, 1.9888e-03,\n",
      "        9.3870e-03, 7.2769e-06, 1.4263e-02, 0.0000e+00, 2.8884e-05, 1.1490e-01,\n",
      "        0.0000e+00, 1.2777e-02, 3.5041e-02, 1.0408e-02, 1.5820e-01, 3.6547e-05,\n",
      "        1.1255e-02, 0.0000e+00, 4.7746e-02, 2.2743e-03, 0.0000e+00, 1.0974e-02,\n",
      "        5.9283e-02, 4.9719e-03, 0.0000e+00, 0.0000e+00, 8.3583e-03, 2.1484e-03,\n",
      "        0.0000e+00, 5.8690e-02, 7.8863e-02, 4.4335e-02, 0.0000e+00, 3.6801e-01,\n",
      "        0.0000e+00, 6.5851e-02, 2.6106e-03, 1.3309e-02, 1.0471e-02, 2.7515e-02,\n",
      "        2.2656e-03, 4.4894e-03, 0.0000e+00, 0.0000e+00, 3.9294e-02, 2.3758e-02,\n",
      "        0.0000e+00, 7.6152e-03, 3.2912e-02, 0.0000e+00, 6.9485e-03, 0.0000e+00,\n",
      "        7.8188e-02, 7.2355e-02, 0.0000e+00, 2.5006e-03, 1.5909e-01, 5.7272e-02,\n",
      "        5.7697e-02, 4.1426e+00, 5.9152e-02, 0.0000e+00, 0.0000e+00, 2.1557e-02,\n",
      "        0.0000e+00, 2.6557e-03, 1.4881e-01, 0.0000e+00, 1.0816e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.5204e-02, 8.1523e-04, 8.1811e-02, 2.0928e-01, 0.0000e+00,\n",
      "        7.3549e-03, 4.6818e-05, 0.0000e+00, 0.0000e+00, 1.7948e-04, 7.3495e-03,\n",
      "        2.0873e-03, 7.0197e-03, 1.9592e-03, 2.0224e-02, 0.0000e+00, 9.3225e-03,\n",
      "        7.9042e-03, 0.0000e+00, 3.2701e-02, 4.1086e-04, 0.0000e+00, 0.0000e+00,\n",
      "        2.7410e-03, 6.6049e-02, 9.6679e-03, 7.9725e-03, 2.5136e-01, 1.7286e-02,\n",
      "        0.0000e+00, 7.5205e-02, 7.8390e-02, 0.0000e+00, 0.0000e+00, 1.7890e-03,\n",
      "        7.8329e-02, 9.2353e-02, 3.6210e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.7152e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        5.0970e-02, 0.0000e+00, 1.9744e-02, 6.7501e-03, 6.6811e-03, 4.8244e-02,\n",
      "        0.0000e+00, 1.7889e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.8367e-04, 2.5222e-02, 7.1550e-03, 4.4258e-05, 0.0000e+00,\n",
      "        5.8129e-02, 1.9962e-04, 0.0000e+00, 2.3246e-02, 0.0000e+00, 7.3310e-05,\n",
      "        0.0000e+00, 0.0000e+00, 1.3686e-01, 4.4674e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.4277e-02, 2.7142e-04, 1.4597e-01, 1.1267e-03, 2.1415e-02,\n",
      "        1.7125e-02, 4.1659e-02, 3.8450e-02, 4.1900e-02, 8.0726e-02, 6.3398e-02,\n",
      "        3.1145e-02, 1.1539e-01, 1.4110e-02, 2.9522e-02, 0.0000e+00, 1.0533e-01,\n",
      "        1.9104e-03, 6.7551e-04, 0.0000e+00, 0.0000e+00, 2.1001e-02, 2.8298e-02,\n",
      "        1.6112e-02, 2.6445e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9483e-04,\n",
      "        5.6487e-03, 0.0000e+00, 5.3480e-04, 9.6919e-03, 8.8464e-03, 0.0000e+00,\n",
      "        1.0508e-02, 2.9146e-03, 2.8319e-02, 3.5206e-02, 1.3664e-03, 0.0000e+00,\n",
      "        4.7376e-02, 3.8703e-02, 8.4929e-04, 5.8882e-02, 0.0000e+00, 2.6645e-01,\n",
      "        9.4148e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3904e-02, 3.5755e-03,\n",
      "        0.0000e+00, 5.7055e-02, 9.5513e-02, 5.9988e-03, 5.8256e-03, 2.4508e-04,\n",
      "        0.0000e+00, 1.0678e-03, 3.7473e-02, 6.9391e-02, 0.0000e+00, 1.8564e-02,\n",
      "        0.0000e+00, 1.9100e-02, 0.0000e+00, 6.3514e-01, 0.0000e+00, 0.0000e+00,\n",
      "        1.9046e-02, 1.1204e-02, 0.0000e+00, 5.9437e-02, 4.7983e-02, 1.4648e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2869e-01, 1.0489e-01, 1.8663e-02,\n",
      "        2.9177e-03, 9.1538e-02, 2.8024e-02, 1.7241e-03, 7.5718e-03, 0.0000e+00,\n",
      "        2.0638e-04, 3.2593e-02, 0.0000e+00, 0.0000e+00, 4.8200e-02, 2.2022e-04,\n",
      "        4.1300e-04, 1.5607e-03, 7.0045e-03, 8.6415e-04, 1.3914e-01, 9.5273e-03,\n",
      "        2.3637e-02, 4.3219e-02, 3.8082e-03, 2.4686e-02, 0.0000e+00, 8.5043e-02,\n",
      "        3.7161e-03, 8.9510e-02, 1.9015e-01, 0.0000e+00, 5.8785e-03, 7.2330e-02,\n",
      "        1.3066e-03, 3.8819e-02, 1.1140e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0114e-02, 1.0452e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7732e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3891e-03, 0.0000e+00, 1.5012e-03,\n",
      "        8.1950e-02, 3.4401e-03, 1.4870e-03, 0.0000e+00, 0.0000e+00, 5.0956e-05,\n",
      "        8.0866e-02, 0.0000e+00, 0.0000e+00, 6.7076e-02, 4.6576e-03, 5.9930e-02,\n",
      "        0.0000e+00, 4.8452e-02, 6.2841e-06, 4.0155e-02, 5.9374e-03, 2.2678e-02,\n",
      "        0.0000e+00, 1.2831e-02, 1.2954e-02, 4.7025e-02, 2.4259e-03, 0.0000e+00,\n",
      "        1.6385e-02, 0.0000e+00, 3.9955e-03, 2.0784e-02, 9.1169e-02, 8.0446e-02,\n",
      "        4.7175e-04, 8.1356e-04, 9.4545e-02, 0.0000e+00, 1.6094e-02, 1.0382e-01,\n",
      "        2.9890e-04, 0.0000e+00, 1.0230e-01, 1.2274e-02, 0.0000e+00, 1.1495e-02,\n",
      "        3.9553e-03, 4.9165e-03, 2.0706e-01, 3.4394e-03, 1.1448e-01, 6.3313e-04,\n",
      "        0.0000e+00, 2.9415e-05, 0.0000e+00, 8.5533e-02, 5.2927e-02, 8.7695e-02,\n",
      "        6.3140e-03, 0.0000e+00, 4.5193e-02, 1.2357e-04, 8.8427e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0003, 0.0328, 0.0015, 0.0085, 0.0014, 0.0369, 0.0004],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0121, 0.0476, 0.0156, 0.0317, 0.0159, 0.0511, 0.0128],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0000, 0.0000, 0.1705, 0.3687, 0.9242, 0.0000, 0.0000, 0.5029, 0.0000,\n",
      "        0.0000], device='cuda:0') torch.Size([10])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 7.9517e-01, 0.0000e+00, 4.1610e-01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 8.0445e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.3357e+00, 9.4621e-02, 0.0000e+00, 0.0000e+00, 2.5304e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3615e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.4487e+00, 2.3436e-02, 1.3762e-01, 2.2767e-01, 2.7563e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.3441e-03, 2.6298e-02, 0.0000e+00, 1.1334e-02,\n",
      "        0.0000e+00, 5.1408e-02, 1.3963e-01, 8.8616e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.9974e-02, 0.0000e+00, 1.5570e+00, 0.0000e+00, 3.9853e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 6.7071e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.4512e-02, 3.2202e+00, 5.1580e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.3391e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0213e-02, 0.0000e+00, 4.9442e-02,\n",
      "        0.0000e+00, 2.8809e-01, 0.0000e+00, 4.6919e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.4448e+00, 3.7264e-02, 0.0000e+00, 6.3292e-02, 1.9096e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([2.8526e-04, 1.4992e-04, 1.7503e-04, 2.4435e-04, 0.0000e+00, 7.6294e-04,\n",
      "        1.1145e-06, 5.8160e-04, 1.0649e-03, 0.0000e+00, 1.0513e-03, 4.7384e-04,\n",
      "        1.1443e-03, 1.2935e-04, 3.7553e-04, 5.1945e-04, 4.7589e-04, 8.6432e-05,\n",
      "        1.4067e-03, 3.8259e-04, 9.8869e-04, 2.1447e-05, 1.6764e-03, 2.3208e-06,\n",
      "        0.0000e+00, 2.7059e-04, 2.4191e-04, 1.7017e-05, 0.0000e+00, 2.1669e-04,\n",
      "        0.0000e+00, 1.0810e-03, 3.9838e-04, 7.6560e-04, 2.0000e-05, 1.9892e-04,\n",
      "        1.0981e-04, 2.6322e-04, 9.5027e-06, 1.7725e-04, 5.2351e-04, 2.8601e-04,\n",
      "        1.2928e-04, 2.5381e-04, 0.0000e+00, 3.2197e-04, 0.0000e+00, 3.0163e-04,\n",
      "        1.5093e-04, 1.5103e-04, 1.2703e-04, 6.4519e-04, 1.0550e-03, 5.2482e-04,\n",
      "        1.0745e-05, 1.0147e-03, 8.7828e-04, 0.0000e+00, 9.7995e-05, 1.1404e-02,\n",
      "        3.8912e-03, 0.0000e+00, 0.0000e+00, 1.6403e-04, 3.0533e-04, 1.2810e-04,\n",
      "        1.5122e-04, 0.0000e+00, 2.8581e-04, 8.7618e-03, 1.4532e-05, 0.0000e+00,\n",
      "        1.0740e-04, 3.2265e-04, 3.9301e-04, 1.8301e-04, 1.2370e-04, 0.0000e+00,\n",
      "        4.5634e-04, 1.4651e-05, 1.3540e-03, 7.2938e-04, 2.0420e-04, 1.3439e-03,\n",
      "        8.8494e-05, 0.0000e+00, 3.3476e-04, 7.8932e-06, 2.2645e-04, 1.0975e-04,\n",
      "        3.8917e-04, 1.3969e-04, 4.5168e-04, 4.9690e-04, 3.4995e-04, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0929, 0.0576, 0.0550, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0551,\n",
      "        0.0581, 0.2175], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0632, 0.0578, 0.0586, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0587,\n",
      "        0.0580, 0.0595], device='cuda:0') torch.Size([56])\n",
      "score tensor([6.6442e-04, 4.2174e-03, 6.8088e-03, 2.0169e-03, 1.3097e-02, 0.0000e+00,\n",
      "        1.6589e-04, 1.5179e-02, 1.7192e-03, 1.2147e-03, 0.0000e+00, 3.2143e-04,\n",
      "        2.4660e-03, 3.0125e-03, 4.2531e-03, 2.5678e-03, 2.3176e-08, 5.7961e-03,\n",
      "        1.7439e-03, 2.8081e-03, 7.0426e-05, 4.3377e-03, 3.5505e-03, 7.5497e-04,\n",
      "        2.5946e-03, 5.3912e-03, 2.3709e-03, 3.5204e-03, 2.1720e-03, 1.3273e-04,\n",
      "        6.7543e-03, 8.9609e-04, 2.6822e-03, 3.7706e-03, 3.0913e-03, 2.5290e-03,\n",
      "        2.6934e-03, 6.5049e-05, 3.4688e-03, 2.1489e-03, 4.8021e-03, 3.8761e-03,\n",
      "        4.6023e-05, 7.1323e-03, 7.4810e-03, 3.3002e-03, 3.5134e-03, 2.1284e-03,\n",
      "        3.4215e-03, 1.8869e-03, 4.6760e-03, 4.4040e-03, 3.3801e-02, 9.6786e-04,\n",
      "        1.0512e-03, 2.0367e-03, 2.8824e-03, 4.7415e-03, 0.0000e+00, 2.6054e-03,\n",
      "        3.1633e-04, 1.0997e-04, 2.5863e-03, 2.9005e-03, 1.2714e-03, 3.7026e-03,\n",
      "        3.9761e-03, 8.7920e-03, 1.7449e-03, 4.9377e-03, 4.6834e-03, 7.0173e-08,\n",
      "        7.3836e-04, 1.2476e-03, 1.8648e-03, 1.8448e-03, 1.6835e-03, 9.6715e-05,\n",
      "        4.0757e-03, 3.1098e-03, 9.5503e-03, 3.0235e-03, 3.4673e-04, 6.0244e-03,\n",
      "        2.0152e-03, 3.1148e-03, 1.4750e-03, 1.5805e-03, 1.6484e-03, 2.3807e-03,\n",
      "        2.2999e-03, 1.2437e-02, 2.4851e-03, 1.1322e-03, 2.1013e-04, 3.2665e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0260, 0.0228, 0.0168, 0.0168, 0.0154, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0153, 0.0154, 0.0174, 0.0167,\n",
      "        0.0243, 0.0369], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0373, 0.0385, 0.0360, 0.0359, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0362, 0.0371,\n",
      "        0.0408, 0.0424], device='cuda:0') torch.Size([56])\n",
      "score tensor([1.8201e-03, 1.1953e-02, 1.6332e-02, 1.0135e-03, 1.2222e-03, 0.0000e+00,\n",
      "        9.3536e-03, 4.4624e-02, 1.0057e-02, 1.1856e-02, 0.0000e+00, 2.1293e-02,\n",
      "        1.6234e-05, 9.6559e-03, 1.2067e-02, 2.5830e-02, 6.8715e-04, 3.5942e-04,\n",
      "        7.6328e-03, 7.1265e-03, 1.7196e-02, 5.2343e-03, 1.7601e-02, 1.2012e-03,\n",
      "        1.5630e-02, 1.2315e-02, 5.6379e-04, 1.5887e-02, 2.0259e-02, 2.2281e-02,\n",
      "        1.1063e-02, 1.1138e-02, 9.1796e-03, 5.5287e-03, 1.7371e-02, 2.5715e-02,\n",
      "        7.0968e-02, 2.0869e-03, 4.2323e-02, 7.2269e-03, 1.8224e-02, 4.2371e-03,\n",
      "        6.2002e-03, 2.2582e-02, 2.1482e-02, 3.3565e-02, 2.1233e-02, 1.0036e-02,\n",
      "        1.2726e-02, 0.0000e+00, 4.7546e-03, 2.0495e-02, 2.8849e-03, 5.8231e-04,\n",
      "        1.0670e-02, 1.2585e-02, 9.1994e-03, 4.1080e-03, 7.7554e-02, 8.7774e-02,\n",
      "        4.1278e-03, 1.0450e-02, 8.5825e-03, 7.4389e-03, 3.4659e-02, 0.0000e+00,\n",
      "        1.4106e-02, 6.1953e-03, 1.9497e-02, 1.5249e-02, 4.2964e-03, 0.0000e+00,\n",
      "        1.6211e-02, 4.8179e-02, 0.0000e+00, 6.7259e-03, 1.0320e-02, 2.5877e-02,\n",
      "        8.0800e-03, 7.1173e-03, 3.5631e-02, 8.8223e-04, 3.0127e-02, 1.1762e-02,\n",
      "        1.0051e-02, 8.7778e-03, 6.4477e-03, 1.3240e-02, 1.3787e-02, 6.8265e-03,\n",
      "        1.5901e-02, 2.3535e-02, 1.2305e-03, 5.9870e-03, 3.0122e-04, 1.5314e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0677, 0.0524, 0.0383, 0.0329, 0.0351, 0.0348, 0.0341, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0341, 0.0341, 0.0332, 0.0296, 0.0292,\n",
      "        0.0287, 0.0377], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0350, 0.0373, 0.0356, 0.0358, 0.0390, 0.0388, 0.0385, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0386, 0.0389, 0.0391, 0.0364, 0.0371,\n",
      "        0.0352, 0.0413], device='cuda:0') torch.Size([56])\n",
      "score tensor([2.1250e-03, 3.1641e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3549e-03,\n",
      "        1.4051e-02, 6.6495e-02, 1.5951e-01, 0.0000e+00, 2.9916e-02, 8.9347e-02,\n",
      "        1.1387e-01, 7.3310e-02, 9.6059e-02, 1.8380e-04, 6.8377e-04, 7.5983e-04,\n",
      "        4.1027e-04, 5.2199e-02, 5.3224e-07, 1.4187e-01, 0.0000e+00, 4.8534e-03,\n",
      "        0.0000e+00, 1.0056e-01, 1.7630e-02, 1.3116e-01, 1.0220e-05, 0.0000e+00,\n",
      "        2.4030e-02, 9.4485e-05, 2.8883e-02, 2.2338e-05, 5.1729e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.8656e-05, 1.2600e-03, 4.4448e-03, 8.4249e-02,\n",
      "        1.2208e-02, 1.0365e-01, 0.0000e+00, 1.6119e-01, 6.2706e-04, 0.0000e+00,\n",
      "        1.6805e-03, 3.7975e-02, 0.0000e+00, 3.0407e-05, 0.0000e+00, 1.5388e-03,\n",
      "        1.0652e-02, 7.8128e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7612e-02,\n",
      "        9.1774e-06, 0.0000e+00, 1.3563e-01, 0.0000e+00, 4.5076e-02, 1.5460e-02,\n",
      "        3.7007e-02, 0.0000e+00, 3.8308e-02, 0.0000e+00, 0.0000e+00, 2.3529e-02,\n",
      "        1.0126e-01, 7.4645e-05, 0.0000e+00, 0.0000e+00, 3.0436e-01, 5.1260e-01,\n",
      "        5.2831e-04, 1.2802e-01, 0.0000e+00, 4.3526e-03, 0.0000e+00, 0.0000e+00,\n",
      "        5.5922e-03, 7.0205e-02, 1.3235e-01, 0.0000e+00, 8.1418e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.6592e-03, 2.2746e+00, 1.0241e-01, 8.0940e-02, 0.0000e+00,\n",
      "        1.1053e-01, 3.6541e-02, 7.6549e-06, 1.1757e-03, 1.3681e-01, 8.1139e-02,\n",
      "        2.7346e-04, 1.5179e-01, 0.0000e+00, 1.5594e-01, 3.3839e-02, 1.2029e-02,\n",
      "        2.9469e-01, 0.0000e+00, 1.7261e-05, 0.0000e+00, 3.0063e-05, 0.0000e+00,\n",
      "        5.3294e-02, 8.4536e-02, 9.3722e-04, 1.2829e-02, 0.0000e+00, 9.6902e-04,\n",
      "        1.0758e-05, 9.3815e-04, 0.0000e+00, 4.8115e-04, 4.2528e-03, 2.5944e-05,\n",
      "        1.2047e-01, 0.0000e+00, 2.5061e-02, 8.9163e-05, 3.1186e-03, 3.2195e-01,\n",
      "        2.5566e-01, 5.8715e-03, 0.0000e+00, 2.8526e-02, 3.6987e-03, 3.2692e-06,\n",
      "        2.7234e-04, 2.4497e-02, 1.9821e-04, 1.4833e-01, 9.1543e-02, 0.0000e+00,\n",
      "        2.0457e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0787e-03, 3.4822e-04,\n",
      "        1.1057e-01, 6.0902e-04, 6.6985e-02, 2.2191e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.1348e-01, 1.9196e-03, 0.0000e+00, 1.4901e-01, 1.6753e-05,\n",
      "        3.5947e-02, 1.4364e-01, 2.7948e-01, 0.0000e+00, 1.3598e-03, 0.0000e+00,\n",
      "        0.0000e+00, 3.5900e-03, 0.0000e+00, 1.0359e-03, 2.2143e-02, 5.8714e-04,\n",
      "        1.1901e-02, 0.0000e+00, 2.6048e-03, 2.4130e-02, 1.1394e-03, 0.0000e+00,\n",
      "        6.3744e-03, 0.0000e+00, 3.4061e-03, 1.1123e-03, 1.4930e-01, 4.3058e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.8804e-04, 4.5933e-02, 3.1749e-02, 3.2862e-05],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([1.1398e-04, 4.7708e-03, 1.2853e-02, 5.2054e-04, 0.0000e+00, 1.0851e-03,\n",
      "        1.4297e-04, 8.1036e-04, 1.1764e-03, 4.2036e-06, 3.5694e-03, 0.0000e+00,\n",
      "        4.9244e-03, 2.2074e-05, 5.3207e-06, 1.4056e-04, 6.0984e-04, 7.5830e-04,\n",
      "        6.1275e-03, 1.3493e-04, 9.7206e-03, 4.2004e-05, 4.1519e-03, 4.8450e-03,\n",
      "        2.7574e-03, 8.6861e-05, 1.1847e-04, 0.0000e+00, 1.0745e-04, 9.9571e-04,\n",
      "        4.6017e-04, 2.4858e-02, 1.5393e-05, 1.6569e-03, 6.4316e-04, 2.9642e-03,\n",
      "        9.4376e-04, 1.4952e-02, 1.2886e-04, 4.5493e-07, 1.3504e-04, 4.8785e-03,\n",
      "        6.9863e-04, 1.2067e-03, 1.5495e-04, 3.2480e-03, 6.0674e-06, 3.2526e-02,\n",
      "        8.9191e-03, 5.2787e-05, 6.1864e-04, 3.8029e-04, 1.4021e-03, 2.0067e-04,\n",
      "        7.7498e-04, 3.4461e-03, 1.7967e-03, 2.7483e-04, 1.5815e-04, 3.2127e-02,\n",
      "        3.2051e-04, 3.7298e-03, 6.7843e-03, 2.6266e-04, 3.8136e-04, 2.0562e-03,\n",
      "        3.6438e-04, 2.2635e-03, 0.0000e+00, 1.8645e-02, 0.0000e+00, 2.3223e-05,\n",
      "        1.5041e-05, 9.5529e-05, 0.0000e+00, 1.1022e-03, 2.0979e-03, 4.7658e-03,\n",
      "        6.5896e-05, 7.9812e-04, 5.3670e-05, 2.3269e-02, 3.1270e-04, 6.1543e-04,\n",
      "        0.0000e+00, 2.9472e-04, 1.1604e-03, 2.8044e-03, 4.7813e-05, 4.0630e-03,\n",
      "        1.7346e-03, 1.4615e-02, 1.2362e-02, 1.6982e-03, 1.6581e-02, 0.0000e+00,\n",
      "        0.0000e+00, 5.3713e-03, 8.1687e-04, 0.0000e+00, 1.0709e-03, 0.0000e+00,\n",
      "        1.4239e-04, 3.3438e-02, 1.2497e-03, 1.0786e-04, 2.0330e-02, 1.1047e-03,\n",
      "        4.3298e-03, 2.2247e-03, 0.0000e+00, 0.0000e+00, 8.2172e-03, 1.2658e-04,\n",
      "        5.4252e-04, 1.2356e-03, 1.1873e-03, 1.1370e-06, 5.0737e-03, 4.0171e-03,\n",
      "        3.9690e-05, 2.3254e-04, 5.0354e-03, 0.0000e+00, 3.8263e-04, 1.3243e-04,\n",
      "        3.3230e-02, 2.3676e-03, 8.8254e-03, 1.6509e-02, 9.6839e-03, 1.1573e-03,\n",
      "        1.2999e-03, 7.4647e-04, 4.9026e-03, 4.7943e-04, 2.8784e-04, 8.1321e-04,\n",
      "        1.4185e-02, 1.1939e-02, 2.2381e-05, 4.6478e-04, 2.8349e-04, 8.0140e-05,\n",
      "        1.1773e-03, 1.4378e-02, 1.2813e-04, 1.1124e-03, 5.8977e-04, 4.7173e-03,\n",
      "        4.6463e-07, 3.0078e-03, 3.2807e-04, 4.8494e-03, 3.5239e-03, 0.0000e+00,\n",
      "        8.8148e-03, 1.8530e-03, 7.6473e-03, 1.9041e-04, 6.8844e-04, 1.3382e-04,\n",
      "        5.1625e-03, 1.2200e-03, 1.5350e-03, 0.0000e+00, 4.9860e-03, 2.4760e-02,\n",
      "        5.6660e-03, 5.9850e-06, 1.9886e-03, 1.0606e-03, 6.0488e-03, 2.1275e-03,\n",
      "        9.4599e-05, 3.1348e-04, 1.8316e-04, 3.4494e-03, 0.0000e+00, 2.5743e-04,\n",
      "        3.6949e-03, 7.7493e-06, 1.3794e-04, 2.1395e-03, 1.5456e-03, 7.7880e-04,\n",
      "        1.0849e-05, 1.7391e-05, 1.3524e-07, 4.1007e-03, 7.2610e-06, 4.1321e-03],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0170, 0.0141, 0.0117, 0.0112, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0112, 0.0122, 0.0171,\n",
      "        0.0190], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0300, 0.0309, 0.0297, 0.0294, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292,\n",
      "        0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292,\n",
      "        0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0291, 0.0292, 0.0303, 0.0338,\n",
      "        0.0323], device='cuda:0') torch.Size([28])\n",
      "score tensor([1.2822e-02, 1.5388e-04, 1.7542e-01, 0.0000e+00, 8.1747e-05, 1.1079e-03,\n",
      "        2.1358e-05, 2.7842e-06, 0.0000e+00, 4.2787e-02, 5.9599e-03, 0.0000e+00,\n",
      "        0.0000e+00, 9.8163e-03, 7.2272e-04, 5.2414e-04, 0.0000e+00, 2.0504e-03,\n",
      "        0.0000e+00, 2.5707e-04, 2.2552e-04, 7.9327e-05, 9.7219e-02, 7.4776e-04,\n",
      "        3.7142e-03, 0.0000e+00, 7.2798e-04, 0.0000e+00, 1.0853e-04, 7.4608e-04,\n",
      "        2.2975e-02, 1.0940e-04, 0.0000e+00, 2.7693e-02, 0.0000e+00, 1.3142e-02,\n",
      "        0.0000e+00, 3.8636e-02, 6.8152e-04, 8.9760e-03, 6.4065e-04, 1.7096e-03,\n",
      "        4.6669e-07, 0.0000e+00, 7.9368e-03, 0.0000e+00, 5.0859e-03, 3.2397e-02,\n",
      "        0.0000e+00, 2.9600e-03, 2.4231e-03, 1.3762e-02, 0.0000e+00, 1.0094e-04,\n",
      "        0.0000e+00, 3.2297e-02, 4.5528e-03, 3.2010e-02, 0.0000e+00, 1.2798e-03,\n",
      "        0.0000e+00, 8.3866e-06, 1.0675e-04, 0.0000e+00, 2.2208e-02, 5.5800e-06,\n",
      "        7.6584e-03, 0.0000e+00, 3.1666e-02, 4.7974e-05, 7.5318e-02, 8.7454e-05,\n",
      "        1.1764e-03, 0.0000e+00, 6.7835e-03, 0.0000e+00, 6.9392e-03, 3.0259e-04,\n",
      "        2.6940e-05, 1.0261e-04, 6.8576e-03, 0.0000e+00, 4.4101e-02, 1.9438e-03,\n",
      "        2.3622e-02, 1.6609e-04, 0.0000e+00, 0.0000e+00, 7.0736e-04, 3.3841e-04,\n",
      "        3.0459e-04, 1.0267e-03, 2.8238e-02, 1.5958e-04, 1.7340e-06, 1.2577e-02,\n",
      "        7.3481e-03, 9.4268e-05, 1.7361e-04, 0.0000e+00, 4.2074e-03, 3.8741e-04,\n",
      "        3.5795e-04, 2.2044e-06, 4.8092e-03, 1.3364e-02, 4.0164e-03, 3.3110e-03,\n",
      "        6.5631e-02, 4.5335e-04, 7.0436e-03, 9.0593e-03, 2.5654e-02, 0.0000e+00,\n",
      "        1.2611e-03, 1.1948e-02, 1.7847e-04, 3.3939e-04, 3.0702e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8848e-02, 0.0000e+00, 0.0000e+00, 1.3224e-04, 5.8075e-03,\n",
      "        0.0000e+00, 3.7460e-04, 1.0521e-01, 3.8152e-04, 2.2624e-02, 4.7928e-04,\n",
      "        1.4597e-03, 1.9866e-02, 0.0000e+00, 4.8555e-02, 2.4622e-04, 5.5955e-04,\n",
      "        0.0000e+00, 0.0000e+00, 7.4639e-03, 1.5312e-03, 1.9397e-03, 2.0711e-03,\n",
      "        4.9414e-03, 0.0000e+00, 4.5460e-03, 0.0000e+00, 0.0000e+00, 1.4746e-03,\n",
      "        0.0000e+00, 2.3630e-05, 1.4651e-02, 1.9066e-03, 2.2127e-06, 0.0000e+00,\n",
      "        3.6122e-02, 1.3878e-02, 0.0000e+00, 2.4852e-03, 1.8051e-02, 0.0000e+00,\n",
      "        1.4990e-03, 1.6129e-03, 2.1192e-03, 1.9821e-03, 8.1403e-04, 0.0000e+00,\n",
      "        4.7232e-02, 9.8164e-07, 0.0000e+00, 3.8782e-02, 1.0382e-04, 2.3042e-02,\n",
      "        0.0000e+00, 1.7700e-06, 6.3670e-05, 0.0000e+00, 3.2516e-04, 0.0000e+00,\n",
      "        5.3431e-04, 9.0467e-03, 1.4388e-03, 0.0000e+00, 2.1793e-03, 0.0000e+00,\n",
      "        4.7829e-02, 4.1291e-02, 2.7325e-06, 2.4147e-06, 1.7621e-03, 5.2388e-02],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0552, 0.0377, 0.0333, 0.0326, 0.0330, 0.0335, 0.0337, 0.0338, 0.0338,\n",
      "        0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338,\n",
      "        0.0338, 0.0338, 0.0338, 0.0337, 0.0335, 0.0328, 0.0319, 0.0321, 0.0330,\n",
      "        0.0482], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0726, 0.0601, 0.0559, 0.0584, 0.0587, 0.0600, 0.0605, 0.0607, 0.0607,\n",
      "        0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607,\n",
      "        0.0607, 0.0607, 0.0607, 0.0606, 0.0601, 0.0587, 0.0581, 0.0566, 0.0553,\n",
      "        0.0664], device='cuda:0') torch.Size([28])\n",
      "score tensor([5.5413e-04, 6.8330e-03, 2.0432e-05, 5.0336e-04, 1.5844e-02, 3.9921e-04,\n",
      "        3.4608e-04, 0.0000e+00, 3.0729e-04, 8.2974e-03, 6.5116e-03, 2.6519e-03,\n",
      "        3.0610e-02, 4.3852e-02, 1.0570e-02, 3.3981e-04, 6.1594e-03, 3.4320e-04,\n",
      "        4.3444e-04, 1.6094e-06, 9.0837e-04, 1.5457e-03, 4.0368e-02, 6.6796e-05,\n",
      "        1.6516e-02, 1.2750e-04, 1.0239e-03, 6.5637e-03, 7.5800e-03, 4.2697e-03,\n",
      "        1.0639e-04, 0.0000e+00, 1.0236e-03, 3.8928e-04, 5.2788e-04, 7.4852e-03,\n",
      "        0.0000e+00, 9.4600e-02, 6.0816e-04, 5.9468e-03, 1.1103e-04, 3.5347e-03,\n",
      "        1.3342e-02, 0.0000e+00, 1.0830e-03, 2.0382e-05, 6.1601e-02, 2.5056e-05,\n",
      "        9.6671e-03, 7.9740e-03, 8.1990e-05, 6.5808e-05, 1.0823e-03, 1.6365e-03,\n",
      "        1.4503e-02, 2.0038e-03, 3.1397e-03, 3.9409e-03, 1.2166e-02, 7.6018e-03,\n",
      "        2.0354e-03, 4.0363e-02, 5.0881e-05, 1.1206e-04, 0.0000e+00, 0.0000e+00,\n",
      "        2.8651e-05, 4.6968e-03, 3.4266e-03, 9.1793e-04, 2.1662e-03, 1.1928e-02,\n",
      "        2.1372e-03, 3.2016e-02, 0.0000e+00, 1.3422e-03, 1.1529e-03, 2.1344e-03,\n",
      "        4.0395e-04, 0.0000e+00, 1.4230e-02, 1.0560e-04, 2.4957e-03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9636e-03, 2.6980e-04, 0.0000e+00,\n",
      "        0.0000e+00, 4.3649e-02, 2.8041e-03, 4.9503e-05, 0.0000e+00, 0.0000e+00,\n",
      "        5.5329e-04, 0.0000e+00, 4.8413e-02, 1.8805e-05, 7.8960e-04, 1.4648e-03,\n",
      "        1.4919e-02, 1.0736e-02, 0.0000e+00, 1.5621e-03, 1.4369e-03, 7.1651e-04,\n",
      "        4.2166e-07, 1.2695e-02, 3.6258e-03, 1.6923e-04, 1.9858e-03, 4.2114e-02,\n",
      "        4.1617e-04, 1.6579e-03, 0.0000e+00, 2.1062e-03, 0.0000e+00, 9.8010e-03,\n",
      "        7.5761e-05, 6.7155e-06, 0.0000e+00, 6.1723e-03, 1.0694e-03, 1.6106e-02,\n",
      "        1.1187e-02, 8.9274e-03, 7.0994e-04, 1.1703e-03, 1.3672e-03, 1.8904e-04,\n",
      "        2.3841e-03, 3.2589e-06, 1.5965e-03, 0.0000e+00, 1.5458e-03, 9.3663e-04,\n",
      "        4.1003e-03, 1.8531e-04, 4.2283e-02, 4.5336e-03, 4.2899e-05, 0.0000e+00,\n",
      "        5.9865e-05, 6.4761e-03, 4.0760e-02, 1.4530e-02, 4.3186e-04, 0.0000e+00,\n",
      "        8.9921e-04, 3.2293e-04, 2.6279e-04, 6.4053e-03, 1.0055e-06, 2.1881e-03,\n",
      "        1.1002e-02, 2.6266e-03, 1.3236e-03, 3.2389e-03, 6.9216e-06, 2.3727e-02,\n",
      "        9.0596e-04, 1.4073e-03, 5.6701e-05, 5.0390e-06, 4.9078e-04, 0.0000e+00,\n",
      "        0.0000e+00, 3.3891e-02, 4.0206e-04, 1.8996e-02, 1.4516e-02, 0.0000e+00,\n",
      "        8.8666e-03, 6.0496e-05, 0.0000e+00, 9.5113e-04, 5.2393e-03, 0.0000e+00,\n",
      "        1.1837e-03, 2.7810e-03, 0.0000e+00, 4.6149e-04, 2.3168e-04, 2.0603e-03,\n",
      "        0.0000e+00, 9.2794e-04, 8.3138e-03, 3.2302e-05, 2.3485e-05, 1.4717e-03],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0187, 0.0237, 0.0192, 0.0179, 0.0193, 0.0188, 0.0190, 0.0192, 0.0194,\n",
      "        0.0194, 0.0194, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
      "        0.0194, 0.0194, 0.0194, 0.0194, 0.0199, 0.0237, 0.0211, 0.0284, 0.0268,\n",
      "        0.0259], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0489, 0.0685, 0.0664, 0.0732, 0.0728, 0.0738, 0.0746, 0.0750, 0.0752,\n",
      "        0.0753, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
      "        0.0754, 0.0754, 0.0753, 0.0750, 0.0748, 0.0749, 0.0721, 0.0751, 0.0575,\n",
      "        0.0532], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 5.9939e-02, 1.4309e-03, 1.0027e-01, 4.8641e-02,\n",
      "        6.5916e-03, 0.0000e+00, 1.2390e+00, 6.2512e-02, 4.3132e-02, 1.2420e-01,\n",
      "        1.7758e-02, 3.0780e-04, 0.0000e+00, 3.4033e-02, 0.0000e+00, 5.0831e-03,\n",
      "        0.0000e+00, 1.2698e-02, 4.0941e-04, 8.1152e-04, 1.2890e-03, 3.6835e-01,\n",
      "        1.0736e-01, 0.0000e+00, 6.9568e-02, 2.4073e-03, 4.1617e-02, 4.0763e-02,\n",
      "        2.7098e-02, 1.2543e-02, 1.6956e-03, 7.5609e-02, 5.1857e-02, 3.0407e-03,\n",
      "        1.3258e-01, 2.1829e-03, 6.6288e-03, 1.5926e-02, 7.1224e-02, 0.0000e+00,\n",
      "        3.3037e-02, 3.3585e-02, 0.0000e+00, 2.4734e-03, 7.1781e-05, 4.1354e-03,\n",
      "        2.1474e-04, 5.3668e-01, 1.5307e-02, 3.3986e-02, 1.5004e-02, 3.7625e-02,\n",
      "        4.7761e-04, 4.4108e-02, 0.0000e+00, 2.9319e-05, 5.4076e-01, 0.0000e+00,\n",
      "        7.3015e-02, 1.0927e-02, 1.2747e-01, 3.7130e-02, 2.8096e-02, 0.0000e+00,\n",
      "        0.0000e+00, 7.2544e-03, 2.4315e-02, 4.1096e-02, 2.5836e-02, 4.2162e-02,\n",
      "        0.0000e+00, 1.3818e-02, 6.4579e-03, 7.7382e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.5399e-05, 0.0000e+00, 1.6720e-02, 4.0701e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.9635e-02, 6.5796e-03, 4.2719e-02, 8.9107e-02, 3.0547e-06,\n",
      "        2.7840e-02, 1.2318e-01, 0.0000e+00, 2.3794e-02, 5.4032e-03, 1.2424e-02,\n",
      "        1.1559e-03, 4.6927e-04, 0.0000e+00, 0.0000e+00, 5.7728e-02, 9.9951e-06,\n",
      "        0.0000e+00, 0.0000e+00, 1.2745e-01, 0.0000e+00, 0.0000e+00, 1.6641e-02,\n",
      "        8.2857e-03, 4.0786e-02, 4.6745e-02, 7.7926e-03, 1.7212e-02, 0.0000e+00,\n",
      "        1.7010e-01, 2.9829e-02, 1.8263e-01, 4.6542e-02, 1.4895e-02, 3.2480e-02,\n",
      "        0.0000e+00, 7.3839e-03, 5.1982e-04, 3.5019e-02, 2.9117e-04, 0.0000e+00,\n",
      "        9.3821e-03, 5.9954e-03, 6.6747e-02, 2.8804e-03, 8.5007e-03, 0.0000e+00,\n",
      "        6.7314e-03, 1.5924e-02, 2.5119e-02, 1.1197e-01, 2.3941e-02, 1.3398e-02,\n",
      "        9.8055e-02, 0.0000e+00, 3.4514e-02, 0.0000e+00, 1.1831e-03, 0.0000e+00,\n",
      "        9.5380e-03, 5.4282e-04, 3.1455e-03, 0.0000e+00, 1.3040e-02, 2.0323e-03,\n",
      "        0.0000e+00, 1.0756e-03, 0.0000e+00, 8.7447e-02, 6.3563e-03, 0.0000e+00,\n",
      "        2.2283e-01, 2.5711e-04, 8.5837e-04, 0.0000e+00, 5.5984e-03, 2.5180e-03,\n",
      "        5.0748e-03, 0.0000e+00, 6.9174e-02, 5.5268e-03, 0.0000e+00, 0.0000e+00,\n",
      "        1.7101e-03, 0.0000e+00, 3.8029e-04, 3.4988e-02, 5.6030e-05, 6.8634e-03,\n",
      "        1.1994e-04, 5.2013e-02, 7.2985e-03, 4.8626e-03, 0.0000e+00, 1.0617e-03,\n",
      "        0.0000e+00, 8.0935e-05, 1.8486e-02, 5.4259e-02, 6.8909e-02, 1.4231e-03,\n",
      "        0.0000e+00, 8.9129e-04, 0.0000e+00, 2.4443e-03, 4.4216e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.9199e-03, 2.4851e-02, 2.2650e-02, 9.6908e-03, 6.6064e-02,\n",
      "        2.7041e-02, 3.1352e-01, 8.5635e-02, 1.9966e-02, 1.3417e-02, 3.0733e-02,\n",
      "        2.8351e-02, 5.6757e-02, 1.9236e-03, 0.0000e+00, 6.9152e-02, 0.0000e+00,\n",
      "        1.5910e-02, 1.1006e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6106e-02,\n",
      "        5.2779e-03, 3.5424e-02, 0.0000e+00, 8.8567e-03, 1.1576e-02, 6.9350e-02,\n",
      "        3.1475e-03, 0.0000e+00, 5.0239e-02, 2.3555e-02, 4.2826e-03, 1.9418e-02,\n",
      "        3.6116e-03, 5.8238e-02, 2.2729e-04, 3.6831e-02, 1.5128e-03, 5.4066e-03,\n",
      "        1.0019e-02, 3.7981e-02, 2.2184e+00, 6.8897e-02, 0.0000e+00, 3.3698e-01,\n",
      "        5.2541e-03, 0.0000e+00, 2.5828e-06, 0.0000e+00, 9.8688e-06, 3.1989e-01,\n",
      "        2.3165e-02, 2.8681e-02, 9.0928e-03, 2.0590e-02, 1.2818e-03, 7.3104e-02,\n",
      "        1.1438e-01, 0.0000e+00, 5.2542e-02, 4.2370e-01, 0.0000e+00, 0.0000e+00,\n",
      "        2.0401e-02, 2.5091e-01, 0.0000e+00, 1.0394e-02, 0.0000e+00, 3.4031e-02,\n",
      "        2.2529e-02, 4.6920e-02, 8.3188e-02, 5.1544e-02, 1.7570e-02, 4.0793e-04,\n",
      "        0.0000e+00, 1.1200e-01, 2.4691e-02, 1.1567e-03, 1.4999e-03, 2.3040e-02,\n",
      "        3.2260e-02, 2.7740e-04, 1.0932e-03, 1.0773e-03, 1.3356e-04, 1.8627e-02,\n",
      "        5.4099e-03, 0.0000e+00, 9.2388e-02, 6.2580e-04, 2.4447e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.4963e-03, 0.0000e+00, 6.1041e-02, 0.0000e+00,\n",
      "        1.3946e-02, 8.2258e-05, 1.4412e-02, 0.0000e+00, 5.0635e-02, 2.2284e-01,\n",
      "        6.1962e-03, 8.1627e-02, 6.5597e-03, 0.0000e+00, 4.0545e-02, 4.8748e-03,\n",
      "        5.5871e-02, 2.9698e-02, 0.0000e+00, 5.3374e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.9877e-03, 7.9872e-02, 3.9953e-02, 1.8329e-05, 5.3370e-03,\n",
      "        3.4343e-03, 8.0117e-03, 0.0000e+00, 3.0698e-02, 1.8670e-04, 0.0000e+00,\n",
      "        4.0309e-02, 5.5036e-02, 1.1180e-02, 3.5491e-02, 0.0000e+00, 5.1335e-02,\n",
      "        9.6536e-02, 0.0000e+00, 6.5535e-02, 0.0000e+00, 2.6232e-06, 0.0000e+00,\n",
      "        0.0000e+00, 1.0001e-02, 6.9291e-02, 2.2234e-03, 1.6376e-01, 7.7700e-04,\n",
      "        4.0994e-02, 8.8364e-02, 3.3583e-03, 0.0000e+00, 2.6016e-02, 2.2681e-02,\n",
      "        4.9233e-02, 0.0000e+00, 3.9178e-02, 9.3144e-03, 0.0000e+00, 3.5825e-03,\n",
      "        5.4976e-03, 0.0000e+00, 7.8567e-03, 1.6480e-02, 8.9949e-03, 4.1107e-05,\n",
      "        4.3018e-02, 2.9189e-04, 5.5808e-03, 0.0000e+00, 1.6812e-03, 7.2220e-03,\n",
      "        9.7682e-03, 9.0559e-02, 1.4006e-03, 1.5341e-03, 2.2336e-04, 3.6217e-04,\n",
      "        1.1276e-02, 6.2781e-02, 0.0000e+00, 3.1922e-02, 3.5792e-02, 0.0000e+00,\n",
      "        0.0000e+00, 7.1726e-06, 8.1727e-02, 0.0000e+00, 2.0042e-03, 1.3470e-05],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([5.7125e-03, 1.2607e-03, 9.1151e-05, 0.0000e+00, 2.0622e-02, 1.0712e-03,\n",
      "        0.0000e+00, 9.6046e-05, 4.9116e-02, 4.8091e-04, 0.0000e+00, 1.5276e-03,\n",
      "        1.1440e-02, 0.0000e+00, 0.0000e+00, 1.9492e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.4408e-03, 1.2114e-04, 2.5482e-03, 8.8223e-03, 2.4755e-03, 1.6903e-02,\n",
      "        4.3950e-02, 3.9545e-05, 5.0666e-02, 1.4132e-02, 4.4898e-06, 7.5141e-03,\n",
      "        3.1656e-03, 1.9736e-03, 3.1743e-03, 1.9808e-03, 3.3505e-03, 1.7040e-04,\n",
      "        1.2176e-02, 0.0000e+00, 0.0000e+00, 4.3202e-03, 1.2111e-05, 3.0712e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5313e-06, 3.5532e-03, 2.7679e-05,\n",
      "        6.3935e-04, 2.4570e-04, 0.0000e+00, 5.0473e-04, 5.4964e-04, 5.6284e-03,\n",
      "        1.3735e-01, 0.0000e+00, 3.6311e-03, 2.0056e-04, 1.2449e-02, 0.0000e+00,\n",
      "        1.0162e-02, 0.0000e+00, 1.0325e-02, 1.0350e-02, 3.2303e-05, 1.0274e-02,\n",
      "        1.4586e-04, 1.4728e-03, 0.0000e+00, 1.3837e-03, 0.0000e+00, 0.0000e+00,\n",
      "        6.3964e-03, 0.0000e+00, 6.1285e-04, 0.0000e+00, 1.1992e-04, 0.0000e+00,\n",
      "        1.1274e-02, 7.1528e-04, 1.7521e-02, 3.7453e-05, 2.9709e-02, 3.4007e-05,\n",
      "        0.0000e+00, 2.7425e-04, 1.7770e-02, 1.3054e-02, 0.0000e+00, 3.5212e-02,\n",
      "        0.0000e+00, 8.2884e-03, 2.0899e-02, 5.1334e-03, 8.9995e-04, 0.0000e+00,\n",
      "        7.3090e-05, 0.0000e+00, 1.7742e-03, 2.5929e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.8768e-03, 0.0000e+00, 1.1170e-03, 1.9680e-02, 8.3362e-05, 0.0000e+00,\n",
      "        4.0408e-03, 8.5923e-04, 0.0000e+00, 2.8903e-03, 4.6467e-03, 5.9679e-04,\n",
      "        6.7584e-03, 0.0000e+00, 1.1843e-02, 4.9982e-04, 6.9943e-04, 1.1160e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8320e-03, 8.0298e-05, 4.0204e-03,\n",
      "        5.3676e-03, 3.9472e-03, 7.8494e-03, 0.0000e+00, 0.0000e+00, 6.9861e-03,\n",
      "        0.0000e+00, 2.5432e-02, 0.0000e+00, 5.0532e-03, 2.1005e-03, 8.7459e-05,\n",
      "        0.0000e+00, 8.7627e-04, 0.0000e+00, 1.3555e-03, 0.0000e+00, 2.4638e-04,\n",
      "        9.8443e-04, 2.5472e-03, 9.4158e-06, 0.0000e+00, 1.7542e-02, 3.2168e-03,\n",
      "        1.9522e-02, 0.0000e+00, 1.3986e-03, 6.3272e-03, 2.9292e-03, 2.4728e-03,\n",
      "        6.5725e-03, 6.6802e-03, 7.0889e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.7189e-02, 1.4569e-04, 0.0000e+00, 1.7224e-03, 5.0027e-03,\n",
      "        3.6220e-03, 0.0000e+00, 3.6017e-03, 1.8512e-04, 7.6791e-04, 1.0622e-02,\n",
      "        0.0000e+00, 2.3025e-03, 2.6488e-03, 3.6256e-05, 9.1798e-06, 0.0000e+00,\n",
      "        4.8312e-03, 2.2637e-02, 2.0247e-04, 0.0000e+00, 4.7766e-05, 1.7106e-02,\n",
      "        1.0155e-02, 6.9611e-04, 2.5413e-03, 1.0183e-03, 1.3670e-06, 0.0000e+00,\n",
      "        1.5863e-04, 7.5562e-03, 7.0913e-04, 0.0000e+00, 7.9979e-04, 1.0720e-03,\n",
      "        0.0000e+00, 0.0000e+00, 4.2877e-05, 1.9825e-02, 8.0252e-07, 1.5024e-05,\n",
      "        4.8428e-04, 0.0000e+00, 9.3134e-04, 8.5038e-06, 1.0228e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.5693e-04, 1.7827e-03, 8.5351e-03, 0.0000e+00, 1.4165e-05,\n",
      "        0.0000e+00, 1.5932e-05, 0.0000e+00, 0.0000e+00, 6.4898e-04, 9.2327e-03,\n",
      "        8.3661e-03, 2.3608e-04, 2.4220e-03, 3.7757e-06, 1.9317e-02, 3.4314e-03,\n",
      "        7.6608e-04, 1.1936e-04, 0.0000e+00, 1.1551e-02, 0.0000e+00, 7.4790e-03,\n",
      "        6.1151e-04, 1.0678e-03, 1.5910e-02, 8.1428e-05, 1.7744e-02, 2.2216e-03,\n",
      "        4.9887e-03, 0.0000e+00, 0.0000e+00, 1.6743e-05, 0.0000e+00, 6.7831e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9671e-05, 5.3237e-03,\n",
      "        3.7971e-04, 2.4400e-02, 1.0646e-02, 3.1288e-03, 1.2967e-02, 2.3432e-02,\n",
      "        0.0000e+00, 1.0958e-02, 0.0000e+00, 1.0543e-03, 1.1333e-05, 0.0000e+00,\n",
      "        1.5402e-03, 8.3685e-04, 1.8014e-03, 0.0000e+00, 1.1920e-02, 2.0972e-03,\n",
      "        2.0185e-03, 1.2611e-02, 0.0000e+00, 2.6110e-05, 6.5749e-04, 3.1599e-03,\n",
      "        1.5204e-03, 1.5995e-03, 5.5611e-05, 1.0559e-03, 8.4016e-04, 8.6758e-05,\n",
      "        0.0000e+00, 0.0000e+00, 8.7813e-04, 0.0000e+00, 0.0000e+00, 2.3144e-03,\n",
      "        8.4532e-05, 2.3728e-03, 0.0000e+00, 6.9395e-05, 1.6949e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.2852e-03, 3.7883e-03, 1.9843e-02, 0.0000e+00, 7.0955e-03,\n",
      "        1.6243e-05, 1.0345e-02, 5.6562e-04, 4.1200e-04, 1.7934e-04, 1.8261e-04,\n",
      "        4.4127e-03, 0.0000e+00, 1.4013e-02, 0.0000e+00, 3.8851e-03, 0.0000e+00,\n",
      "        2.2591e-03, 2.5168e-02, 1.3308e-02, 1.7781e-03, 6.0263e-03, 0.0000e+00,\n",
      "        0.0000e+00, 3.2102e-04, 5.6538e-04, 1.7701e-04, 2.4468e-03, 3.6925e-04,\n",
      "        0.0000e+00, 2.7930e-03, 0.0000e+00, 3.4614e-04, 1.2609e-03, 4.0343e-04,\n",
      "        1.8535e-04, 1.8462e-03, 0.0000e+00, 6.5062e-03, 1.0207e-03, 1.4370e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.2308e-04, 1.3802e-03, 1.8356e-02, 0.0000e+00,\n",
      "        4.4950e-04, 8.3973e-06, 0.0000e+00, 7.1917e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.4936e-03, 9.6255e-04, 3.1658e-04, 1.4495e-02, 1.5322e-03,\n",
      "        6.4198e-05, 5.6230e-04, 4.4231e-05, 6.0349e-04, 2.6837e-04, 4.9510e-04,\n",
      "        0.0000e+00, 0.0000e+00, 7.1808e-04, 0.0000e+00, 1.0748e-02, 3.0739e-05,\n",
      "        0.0000e+00, 0.0000e+00, 1.2292e-04, 0.0000e+00, 5.3514e-03, 3.4958e-02,\n",
      "        2.9561e-03, 1.1885e-03, 1.3908e-03, 2.0835e-04, 1.0890e-02, 2.0770e-02,\n",
      "        7.2944e-03, 0.0000e+00, 2.2378e-03, 2.7448e-03, 1.0027e-03, 2.2551e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0285, 0.0268, 0.0250, 0.0274, 0.0274, 0.0275, 0.0276, 0.0276, 0.0276,\n",
      "        0.0280, 0.0289, 0.0280, 0.0304, 0.0318], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0513, 0.0479, 0.0443, 0.0472, 0.0462, 0.0459, 0.0459, 0.0458, 0.0457,\n",
      "        0.0459, 0.0475, 0.0457, 0.0481, 0.0524], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 4.6745e-03, 2.6597e-04, 2.6717e-05, 0.0000e+00, 2.0946e-02,\n",
      "        0.0000e+00, 1.0664e-03, 3.2328e-02, 0.0000e+00, 0.0000e+00, 1.3169e-03,\n",
      "        2.8878e-02, 1.9358e-03, 0.0000e+00, 7.9156e-03, 1.9341e-02, 8.0617e-03,\n",
      "        4.8927e-05, 0.0000e+00, 4.1716e-03, 2.4092e-04, 6.2555e-03, 2.0531e-03,\n",
      "        3.4284e-03, 0.0000e+00, 2.7117e-02, 4.7614e-03, 4.6149e-04, 9.4217e-03,\n",
      "        1.7789e-02, 0.0000e+00, 0.0000e+00, 3.1835e-03, 1.6255e-04, 1.9513e-03,\n",
      "        1.9506e-03, 0.0000e+00, 2.2338e-02, 5.9406e-03, 3.3988e-03, 6.1774e-04,\n",
      "        4.0845e-04, 1.1829e-04, 3.8214e-05, 0.0000e+00, 1.4485e-05, 2.1258e-02,\n",
      "        0.0000e+00, 4.4967e-03, 2.1662e-03, 1.1694e-03, 4.0650e-03, 1.1209e-04,\n",
      "        3.7110e-03, 2.2200e-05, 1.0801e-03, 1.1807e-02, 6.1359e-02, 2.7224e-03,\n",
      "        2.7524e-02, 2.8121e-03, 1.1144e-02, 1.8534e-02, 8.2834e-05, 2.0431e-02,\n",
      "        1.1177e-03, 5.6134e-03, 0.0000e+00, 4.1671e-03, 1.0375e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.1840e-03, 0.0000e+00, 0.0000e+00, 2.5912e-03,\n",
      "        7.3365e-03, 3.4423e-04, 0.0000e+00, 1.1456e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.0217e-02, 6.4206e-03, 7.0376e-03, 0.0000e+00, 2.8415e-04, 1.1130e-04,\n",
      "        4.6423e-03, 8.1524e-03, 2.3881e-02, 7.2211e-05, 0.0000e+00, 1.5159e-02,\n",
      "        3.0108e-04, 1.0430e-05, 1.3174e-02, 1.3304e-02, 1.3476e-04, 0.0000e+00,\n",
      "        6.1122e-07, 3.6134e-02, 2.2869e-03, 1.3793e-02, 5.0233e-03, 0.0000e+00,\n",
      "        4.4869e-03, 3.1570e-02, 1.4572e-02, 1.3085e-03, 7.2458e-04, 6.4862e-03,\n",
      "        2.6861e-02, 1.1852e-02, 2.0519e-02, 5.9833e-04, 1.4038e-02, 3.2950e-03,\n",
      "        1.2249e-02, 2.7036e-03, 1.0181e-02, 3.8134e-04, 2.4904e-03, 3.1029e-03,\n",
      "        7.3449e-04, 2.6685e-03, 0.0000e+00, 4.3607e-04, 0.0000e+00, 8.9997e-04,\n",
      "        2.6799e-04, 1.3063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1068e-04,\n",
      "        2.5750e-02, 2.2846e-06, 3.3831e-04, 0.0000e+00, 6.7338e-04, 2.1899e-02,\n",
      "        8.6071e-04, 1.5713e-02, 3.9733e-04, 1.0045e-02, 6.6497e-05, 1.4681e-02,\n",
      "        0.0000e+00, 1.7921e-03, 6.3228e-03, 3.8396e-03, 3.4047e-03, 1.8055e-03,\n",
      "        1.9728e-02, 0.0000e+00, 1.7048e-03, 1.3336e-02, 4.7503e-05, 6.9176e-05,\n",
      "        8.0599e-04, 8.6580e-03, 1.1714e-03, 3.6999e-05, 3.0691e-02, 1.9296e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.3476e-02, 1.4999e-02, 1.7978e-05, 0.0000e+00,\n",
      "        1.4901e-03, 3.4628e-06, 5.9802e-04, 8.1351e-07, 3.1071e-04, 0.0000e+00,\n",
      "        5.5287e-04, 3.0620e-03, 3.6025e-05, 7.1813e-04, 5.8363e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.3087e-03, 7.2932e-03, 1.6007e-02, 7.3673e-03,\n",
      "        5.6059e-03, 2.6953e-02, 2.1821e-03, 4.3543e-02, 0.0000e+00, 2.5933e-03,\n",
      "        1.3671e-02, 1.2803e-02, 8.1155e-03, 3.3397e-03, 0.0000e+00, 3.2248e-04,\n",
      "        1.0330e-07, 2.0373e-02, 2.7790e-03, 2.6782e-02, 7.8897e-02, 2.4596e-02,\n",
      "        2.4166e-02, 8.2353e-03, 1.1187e-03, 4.4246e-03, 7.2238e-03, 6.2135e-03,\n",
      "        2.1861e-04, 5.7809e-04, 2.6853e-04, 1.2292e-02, 2.7085e-04, 1.0133e-02,\n",
      "        2.3530e-04, 1.1033e-03, 3.7287e-03, 4.6723e-04, 5.8914e-04, 1.7463e-03,\n",
      "        1.8697e-03, 6.6236e-05, 0.0000e+00, 0.0000e+00, 8.8786e-05, 8.6022e-05,\n",
      "        6.2103e-04, 1.8165e-03, 8.0932e-02, 9.5162e-04, 9.2355e-03, 5.0575e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9287e-06, 1.3486e-03, 0.0000e+00, 7.0314e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.5304e-02, 3.2588e-03, 2.2743e-04, 2.7346e-03,\n",
      "        1.9287e-03, 2.4664e-02, 1.1320e-03, 1.4079e-02, 3.0632e-03, 0.0000e+00,\n",
      "        3.1815e-03, 1.6891e-04, 7.5444e-05, 5.7147e-03, 5.1613e-03, 2.0813e-03,\n",
      "        1.2746e-02, 0.0000e+00, 0.0000e+00, 3.0653e-02, 4.1010e-03, 0.0000e+00,\n",
      "        2.0897e-04, 1.5309e-02, 2.7911e-03, 2.8494e-04, 4.0578e-03, 0.0000e+00,\n",
      "        7.1999e-03, 6.4295e-05, 6.1889e-02, 6.5530e-04, 9.7356e-03, 5.7994e-03,\n",
      "        0.0000e+00, 2.4270e-02, 3.5449e-04, 2.5063e-05, 0.0000e+00, 0.0000e+00,\n",
      "        8.7292e-06, 3.5487e-03, 1.0471e-02, 7.9731e-03, 1.2049e-02, 6.4458e-04,\n",
      "        6.8623e-03, 4.2847e-03, 4.6301e-05, 2.6903e-02, 3.9952e-03, 4.9840e-03,\n",
      "        3.1645e-05, 7.8987e-03, 3.0482e-03, 4.3564e-03, 0.0000e+00, 2.5203e-04,\n",
      "        6.4148e-03, 3.3204e-02, 2.1345e-05, 2.8447e-03, 0.0000e+00, 6.2561e-03,\n",
      "        2.9820e-03, 3.7249e-05, 6.3659e-04, 8.0041e-03, 3.9439e-04, 4.4365e-03,\n",
      "        4.4582e-03, 7.6291e-05, 1.3007e-02, 1.0691e-03, 1.6678e-03, 1.7513e-03,\n",
      "        1.0440e-02, 1.5539e-02, 1.0992e-02, 0.0000e+00, 0.0000e+00, 1.6875e-02,\n",
      "        9.2300e-03, 8.8064e-05, 1.0245e-03, 0.0000e+00, 1.2908e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.3878e-03, 3.6739e-05, 2.9997e-03, 7.2364e-03, 0.0000e+00,\n",
      "        1.6247e-03, 1.6531e-02, 1.5070e-03, 2.7541e-05, 6.4449e-05, 4.6371e-03,\n",
      "        0.0000e+00, 9.0442e-03, 1.0567e-03, 0.0000e+00, 8.0521e-03, 3.4868e-05,\n",
      "        1.3697e-03, 6.6510e-03, 5.8345e-04, 0.0000e+00, 5.8541e-03, 1.6770e-04,\n",
      "        1.8458e-04, 1.4252e-02, 2.7422e-03, 8.1324e-04, 7.4996e-04, 1.0527e-03,\n",
      "        5.4143e-04, 7.7863e-06, 0.0000e+00, 1.0961e-04, 2.2530e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.1457e-03, 8.0208e-05, 6.7151e-05, 0.0000e+00, 4.3559e-03,\n",
      "        0.0000e+00, 1.3253e-02, 2.7569e-02, 8.8086e-03, 8.4187e-03, 6.3316e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0211, 0.0143, 0.0141, 0.0131, 0.0148, 0.0144, 0.0156, 0.0154, 0.0140,\n",
      "        0.0136, 0.0132, 0.0139, 0.0165, 0.0174], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0494, 0.0368, 0.0362, 0.0354, 0.0356, 0.0354, 0.0367, 0.0363, 0.0350,\n",
      "        0.0347, 0.0342, 0.0362, 0.0388, 0.0498], device='cuda:0') torch.Size([14])\n",
      "score tensor([4.4557e-03, 5.4947e-03, 5.5124e-03, 1.4664e-03, 5.0942e-03, 2.2741e-03,\n",
      "        9.9161e-04, 8.4766e-03, 3.9167e-02, 2.3999e-03, 8.6893e-03, 7.3236e-03,\n",
      "        5.3546e-03, 4.6143e-04, 3.1448e-03, 7.6715e-03, 2.9346e-03, 1.9472e-03,\n",
      "        8.1154e-02, 2.9176e-03, 1.6562e-03, 5.5000e-03, 1.3538e-03, 1.4821e-03,\n",
      "        5.0774e-03, 2.8379e-03, 3.9478e-03, 5.1609e-03, 1.2222e-02, 1.5644e-03,\n",
      "        8.5693e-06, 2.3580e-03, 1.1008e-02, 1.9227e-02, 3.3948e-02, 3.3086e-03,\n",
      "        3.1721e-03, 3.1059e-03, 7.0120e-03, 5.3150e-03, 2.9119e-03, 1.1136e-03,\n",
      "        4.2727e-03, 2.6573e-03, 2.9058e-03, 1.9495e-03, 4.7448e-03, 5.7283e-03,\n",
      "        4.3896e-03, 7.5025e-02, 2.3113e-03, 5.3954e-03, 4.4692e-03, 6.3506e-03,\n",
      "        3.0917e-02, 4.8740e-03, 8.7453e-03, 3.7310e-03, 0.0000e+00, 3.7457e-03,\n",
      "        7.4415e-03, 7.6675e-04, 5.6517e-03, 5.4661e-03, 8.6256e-04, 4.9694e-03,\n",
      "        4.2654e-03, 1.6886e-03, 4.8779e-03, 6.3019e-02, 1.6855e-03, 6.3362e-03,\n",
      "        1.0148e-04, 2.5674e-03, 4.1521e-03, 6.8664e-03, 6.6675e-03, 1.5161e-02,\n",
      "        3.3973e-04, 4.2321e-03, 0.0000e+00, 5.3253e-03, 3.3636e-03, 7.6979e-03,\n",
      "        1.0069e-02, 0.0000e+00, 4.0879e-02, 1.9284e-03, 8.9011e-03, 3.0536e-03,\n",
      "        4.8379e-03, 7.3128e-02, 0.0000e+00, 1.4199e-03, 6.6803e-04, 2.6927e-03,\n",
      "        5.1197e-03, 0.0000e+00, 5.3841e-03, 3.0998e-03, 5.6694e-03, 1.5687e-02,\n",
      "        5.2377e-03, 3.4630e-02, 5.7868e-03, 2.4535e-03, 5.4920e-03, 1.7476e-05,\n",
      "        1.5788e-03, 7.8130e-03, 8.8914e-02, 1.0430e-02, 6.7769e-05, 3.4713e-03,\n",
      "        0.0000e+00, 2.8634e-03, 1.0292e-02, 1.2277e-03, 6.8624e-04, 2.6932e-03,\n",
      "        5.3409e-03, 0.0000e+00, 1.0143e-03, 8.1865e-03, 5.6125e-03, 6.2648e-03,\n",
      "        5.3250e-03, 5.1486e-03, 0.0000e+00, 1.7400e-03, 6.7085e-03, 1.2627e-02,\n",
      "        5.0952e-03, 5.9216e-04, 1.9703e-03, 5.4687e-03, 5.5371e-03, 4.8949e-03,\n",
      "        7.5712e-03, 7.2030e-03, 2.8801e-03, 7.2323e-03, 2.7032e-03, 5.6510e-03,\n",
      "        3.3768e-03, 4.3548e-03, 4.3028e-03, 6.2069e-03, 3.5787e-03, 4.9272e-02,\n",
      "        6.7589e-02, 2.0905e-03, 8.1806e-03, 0.0000e+00, 4.6824e-03, 6.1190e-03,\n",
      "        0.0000e+00, 4.0100e-03, 2.5969e-02, 0.0000e+00, 5.6219e-03, 5.5368e-03,\n",
      "        2.0169e-03, 5.0771e-03, 1.4772e-03, 8.0760e-03, 2.5446e-03, 2.6974e-03,\n",
      "        1.1790e-03, 2.2984e-03, 8.5244e-04, 2.1158e-03, 5.3251e-04, 5.0297e-03,\n",
      "        3.2858e-03, 2.9728e-03, 2.0506e-03, 4.2531e-03, 6.1230e-03, 4.3518e-03,\n",
      "        2.1743e-03, 7.7757e-02, 7.2028e-03, 2.5072e-03, 2.5733e-03, 4.1414e-03,\n",
      "        6.8577e-03, 4.4448e-03, 4.1760e-03, 2.9233e-03, 6.4134e-03, 4.9301e-03,\n",
      "        8.6453e-03, 1.1907e-02, 1.3578e-03, 7.6980e-03, 3.6179e-03, 1.1474e-03,\n",
      "        3.4168e-03, 0.0000e+00, 3.0775e-04, 3.9459e-02, 2.5067e-04, 3.7831e-03,\n",
      "        1.4480e-03, 3.6651e-04, 6.8080e-03, 1.6154e-02, 1.9773e-02, 2.2155e-03,\n",
      "        3.0109e-03, 7.4544e-03, 2.1323e-02, 3.2288e-03, 1.2542e-02, 0.0000e+00,\n",
      "        1.2562e-03, 3.2509e-03, 2.4992e-03, 2.7707e-03, 2.4566e-04, 2.0630e-02,\n",
      "        5.5301e-04, 6.6474e-03, 1.7403e-03, 4.8011e-03, 1.1987e-03, 2.4143e-04,\n",
      "        2.1748e-03, 1.1981e-03, 1.2598e-03, 3.8612e-03, 2.3702e-03, 2.6128e-03,\n",
      "        3.3157e-03, 8.4045e-03, 3.2781e-02, 0.0000e+00, 5.4057e-04, 3.8763e-02,\n",
      "        6.4455e-04, 1.0948e-02, 1.6593e-03, 5.6094e-03, 4.4996e-04, 0.0000e+00,\n",
      "        0.0000e+00, 1.7265e-03, 1.7207e-03, 4.1648e-03, 6.5666e-03, 4.1382e-03,\n",
      "        3.0134e-03, 6.4426e-03, 1.5090e-03, 1.2966e-02, 4.1092e-03, 0.0000e+00,\n",
      "        2.8643e-03, 0.0000e+00, 2.8252e-03, 4.4207e-03, 4.9882e-03, 3.3149e-03,\n",
      "        1.6640e-02, 8.3129e-03, 4.6418e-02, 3.8658e-03, 0.0000e+00, 2.8503e-03,\n",
      "        5.4100e-03, 6.4783e-03, 3.8287e-03, 2.4342e-03, 5.0570e-03, 1.9990e-03,\n",
      "        3.4901e-03, 1.0138e-03, 0.0000e+00, 9.6978e-04, 8.7815e-03, 2.4300e-03,\n",
      "        3.9000e-03, 5.5206e-02, 5.2052e-03, 0.0000e+00, 5.2654e-03, 2.4026e-03,\n",
      "        4.5757e-03, 2.3685e-02, 2.4603e-02, 2.9497e-03, 9.9581e-03, 5.2037e-03,\n",
      "        1.6026e-03, 1.6334e-02, 1.6030e-03, 1.9452e-02, 1.0067e-02, 5.3757e-03,\n",
      "        1.1749e-04, 1.6475e-03, 6.5999e-03, 0.0000e+00, 0.0000e+00, 1.4585e-02,\n",
      "        1.0489e-02, 7.0810e-03, 1.8975e-03, 1.2927e-03, 3.3233e-03, 3.8138e-03,\n",
      "        5.9912e-03, 4.2486e-03, 9.0713e-03, 1.6758e-03, 1.0004e-03, 1.6475e-02,\n",
      "        9.5293e-04, 3.2775e-03, 0.0000e+00, 1.4551e-02, 1.4081e-03, 1.7764e-03,\n",
      "        4.6463e-06, 4.2015e-03, 2.9649e-03, 1.5799e-03, 2.8096e-03, 6.1725e-02,\n",
      "        1.4404e-02, 4.3846e-03, 1.0490e-03, 2.4966e-03, 3.0498e-03, 8.3430e-04,\n",
      "        1.0693e-02, 1.8782e-03, 5.7117e-04, 3.0295e-03, 1.0537e-02, 7.2160e-04,\n",
      "        1.7039e-03, 7.1719e-04, 1.7242e-03, 2.6511e-03, 6.9537e-03, 4.2655e-03,\n",
      "        3.8905e-03, 1.9634e-02, 6.9369e-03, 2.1338e-03, 3.0847e-02, 3.1493e-03,\n",
      "        1.2812e-03, 3.6454e-03, 1.5766e-03, 1.8116e-03, 4.6335e-03, 9.2601e-04,\n",
      "        5.6415e-03, 3.6132e-03, 8.7068e-04, 1.4302e-03, 1.4936e-04, 3.6785e-03,\n",
      "        9.2214e-04, 4.7115e-03, 2.2817e-02, 8.7129e-03, 3.4223e-03, 1.0440e-03,\n",
      "        5.0372e-03, 7.0065e-03, 1.9830e-03, 3.6822e-03, 6.5570e-03, 7.4150e-03,\n",
      "        6.5066e-03, 5.2277e-03, 8.6263e-03, 1.7035e-03, 5.2685e-04, 8.0637e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0112, 0.0103, 0.0108, 0.0123, 0.0122, 0.0126, 0.0127, 0.0128, 0.0130,\n",
      "        0.0125, 0.0122, 0.0111, 0.0103, 0.0103], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0386, 0.0338, 0.0336, 0.0352, 0.0348, 0.0347, 0.0353, 0.0355, 0.0354,\n",
      "        0.0354, 0.0354, 0.0343, 0.0345, 0.0398], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 2.6689e-03, 2.5336e-02, 8.3615e-04, 1.9458e-02, 7.4745e-04,\n",
      "        1.7481e-02, 4.2833e-02, 4.6842e-02, 1.8717e-04, 1.0158e-01, 4.2858e-03,\n",
      "        4.8560e-04, 4.9385e-03, 1.8597e-03, 2.2003e-02, 5.4729e-03, 1.9183e-03,\n",
      "        7.4352e-03, 7.9635e-03, 1.2384e-02, 8.4327e-02, 5.3830e-02, 0.0000e+00,\n",
      "        1.1848e-02, 0.0000e+00, 0.0000e+00, 1.3931e-02, 8.2363e-02, 1.9356e-03,\n",
      "        1.5403e-04, 1.6508e-02, 1.2750e-03, 4.9081e-02, 1.2092e-03, 2.4771e-02,\n",
      "        6.2458e-02, 2.8474e-02, 2.4604e-02, 0.0000e+00, 4.5405e-03, 1.1369e-02,\n",
      "        9.3954e-04, 1.8424e-03, 6.5185e-03, 6.2110e-04, 5.8982e-03, 1.0174e-01,\n",
      "        1.6863e-02, 1.0556e-02, 0.0000e+00, 1.2181e-02, 1.6299e-04, 9.5049e-03,\n",
      "        2.1542e-02, 3.0415e-02, 1.6511e-01, 1.0471e-04, 2.5972e-02, 4.2119e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.8260e-02, 1.3484e-02, 6.8043e-02, 3.7766e-04,\n",
      "        2.6542e-03, 7.9632e-03, 2.7912e-02, 4.2929e-02, 0.0000e+00, 3.9534e-02,\n",
      "        1.1538e-02, 1.3426e-02, 2.9524e-03, 0.0000e+00, 3.7379e-02, 3.2841e-02,\n",
      "        0.0000e+00, 4.6464e-02, 2.0827e-01, 3.4753e-02, 0.0000e+00, 1.4731e-03,\n",
      "        1.6923e-03, 9.3103e-03, 5.4403e-04, 2.9668e-02, 9.4968e-03, 1.2867e-02,\n",
      "        0.0000e+00, 1.7300e-02, 2.2010e-02, 1.3531e-02, 3.1216e-02, 2.9723e-03,\n",
      "        0.0000e+00, 1.2760e-02, 2.5466e-02, 7.7356e-03, 1.2493e-02, 2.5327e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9203e-02, 6.3480e-03, 3.9787e-03, 3.3802e-02,\n",
      "        8.5286e-02, 3.7372e-02, 1.4002e-02, 3.6718e-02, 2.1643e-02, 3.9246e-02,\n",
      "        5.0768e-02, 3.0069e-02, 2.2603e-02, 1.3187e-01, 2.8959e-02, 5.8008e-02,\n",
      "        1.4267e-02, 1.4711e-02, 3.1737e-04, 1.3629e-03, 2.5704e-02, 3.6547e-02,\n",
      "        7.9408e-04, 4.4466e-03, 0.0000e+00, 5.1627e-04, 1.3215e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.3806e-04, 0.0000e+00, 4.6132e-02, 2.4613e-02, 8.2743e-03,\n",
      "        0.0000e+00, 3.8323e-02, 5.1955e-04, 2.0915e-02, 4.3322e-04, 0.0000e+00,\n",
      "        8.6459e-03, 1.5365e-02, 2.7464e-02, 0.0000e+00, 1.5052e-02, 2.3854e-02,\n",
      "        1.2147e-01, 5.1010e-04, 5.0755e-03, 6.6018e-02, 8.4173e-03, 2.7793e-02,\n",
      "        0.0000e+00, 1.1236e-01, 7.1203e-03, 3.4227e-01, 4.9300e-02, 5.2812e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.6944e-02, 4.2151e-02, 4.9672e-02, 3.2431e-02,\n",
      "        1.1574e-02, 1.1197e-02, 5.8115e-03, 0.0000e+00, 2.5398e-02, 2.5671e-04,\n",
      "        1.0572e-04, 2.7758e-02, 2.5662e-03, 1.2152e-02, 2.1727e-02, 9.2462e-02,\n",
      "        2.5600e-04, 1.6209e-02, 5.7773e-03, 3.2391e-02, 1.3195e-02, 0.0000e+00,\n",
      "        2.4131e-02, 4.4236e-02, 1.4625e-02, 0.0000e+00, 0.0000e+00, 3.8061e-04,\n",
      "        0.0000e+00, 1.8903e-01, 0.0000e+00, 4.0356e-02, 2.4001e-02, 1.2609e-02,\n",
      "        1.2749e-02, 2.7808e-02, 1.5095e-02, 6.4214e-04, 1.3059e-03, 2.5149e-02,\n",
      "        2.0559e-02, 2.8884e-02, 4.0045e-02, 0.0000e+00, 4.6177e-02, 1.2497e-02,\n",
      "        2.9941e-02, 0.0000e+00, 8.2987e-02, 5.0506e-03, 4.4823e-02, 0.0000e+00,\n",
      "        2.4865e-02, 5.0060e-02, 4.9062e-02, 1.2662e-03, 6.2416e-02, 1.9856e-03,\n",
      "        2.6742e-02, 7.6265e-03, 0.0000e+00, 6.0419e-02, 3.5644e-04, 4.5404e-03,\n",
      "        3.5126e-02, 0.0000e+00, 1.5517e-03, 2.8533e-02, 2.2139e-03, 1.2890e-03,\n",
      "        2.6526e-02, 2.8783e-02, 1.5379e-02, 2.5924e-05, 4.3656e-03, 0.0000e+00,\n",
      "        3.1559e-03, 1.8942e-02, 1.7868e-02, 8.3266e-03, 0.0000e+00, 6.4803e-02,\n",
      "        9.5841e-03, 2.9461e-02, 1.5694e-02, 6.2291e-03, 0.0000e+00, 1.3331e-02,\n",
      "        9.2468e-02, 0.0000e+00, 1.0965e-02, 5.9389e-03, 0.0000e+00, 6.7797e-02,\n",
      "        2.3708e-02, 1.5262e-01, 0.0000e+00, 1.9873e-02, 1.2909e-06, 4.4037e-02,\n",
      "        1.7762e-02, 0.0000e+00, 2.8740e-02, 3.8076e-02, 2.1083e-03, 1.8048e-04,\n",
      "        3.2053e-04, 7.3038e-02, 0.0000e+00, 2.6590e-03, 1.0868e-02, 1.5882e-02,\n",
      "        1.0233e-02, 3.6876e-05, 0.0000e+00, 9.5398e-03, 0.0000e+00, 0.0000e+00,\n",
      "        5.2205e-05, 0.0000e+00, 6.2993e-03, 3.0867e-02, 5.0105e-03, 9.5083e-02,\n",
      "        1.1607e-03, 9.2571e-02, 4.8152e-03, 1.0181e-02, 0.0000e+00, 3.4635e-02,\n",
      "        2.4883e-03, 5.7265e-02, 8.4603e-03, 8.8665e-04, 9.4024e-02, 3.9247e-02,\n",
      "        2.5660e-02, 3.0419e-02, 4.7998e-03, 9.0142e-02, 0.0000e+00, 8.0658e-03,\n",
      "        9.8969e-02, 3.1879e-02, 4.7361e-02, 1.9952e-02, 0.0000e+00, 4.1888e-04,\n",
      "        1.7475e-05, 3.2284e-04, 1.5510e-02, 8.1034e-03, 1.1179e-03, 8.2994e-05,\n",
      "        5.7973e-02, 4.1771e-03, 3.8456e-02, 0.0000e+00, 2.1142e-02, 2.1451e-03,\n",
      "        1.5174e-02, 1.2404e-02, 0.0000e+00, 0.0000e+00, 3.5776e-04, 0.0000e+00,\n",
      "        5.7078e-02, 5.6767e-03, 2.3517e-02, 5.9321e-02, 3.6584e-02, 4.5578e-02,\n",
      "        2.7149e-03, 7.1914e-05, 1.2363e-02, 2.8732e-03, 0.0000e+00, 3.8089e-02,\n",
      "        2.3903e-02, 2.7742e-02, 0.0000e+00, 3.8504e-03, 2.6159e-02, 1.6124e-02,\n",
      "        5.8100e-03, 0.0000e+00, 1.9921e-02, 6.8734e-02, 2.7792e-02, 1.1021e-04,\n",
      "        0.0000e+00, 0.0000e+00, 1.0046e-02, 2.5809e-03, 0.0000e+00, 1.9423e-02,\n",
      "        2.3542e-02, 0.0000e+00, 4.9490e-03, 3.2016e-03, 6.4935e-03, 2.1264e-02,\n",
      "        9.3415e-02, 4.9732e-04, 6.4118e-03, 1.2864e-04, 6.5626e-02, 1.4158e-02,\n",
      "        5.8824e-03, 5.8854e-03, 0.0000e+00, 3.4105e-02, 1.6355e-03, 1.0190e-02,\n",
      "        6.8399e-04, 3.5320e-05, 2.9544e-02, 1.5293e-02, 2.9226e-02, 1.2577e-01],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0191, 0.0192, 0.0226, 0.0256, 0.0263, 0.0268, 0.0264, 0.0265, 0.0268,\n",
      "        0.0266, 0.0252, 0.0222, 0.0200, 0.0179], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0389, 0.0375, 0.0382, 0.0408, 0.0395, 0.0405, 0.0403, 0.0409, 0.0416,\n",
      "        0.0408, 0.0424, 0.0401, 0.0410, 0.0423], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 1.2695e-02, 4.1139e-03, 4.0144e-03, 5.0402e-02, 3.0981e-02,\n",
      "        1.3109e-02, 1.4703e-02, 6.3367e-02, 4.6618e-03, 1.1496e-03, 1.6106e-02,\n",
      "        8.3149e-03, 3.9773e-03, 6.6425e-03, 6.3571e-03, 0.0000e+00, 4.3011e-04,\n",
      "        2.6972e-02, 6.9600e-04, 2.4752e-03, 2.2531e-03, 2.8793e-02, 3.3077e-02,\n",
      "        1.1936e-02, 1.3995e-03, 1.6271e-02, 1.5300e-02, 1.4273e-02, 4.1360e-06,\n",
      "        2.9705e-03, 1.4091e-02, 3.3365e-02, 1.4812e-05, 2.9477e-03, 1.2447e-02,\n",
      "        2.1707e-02, 1.8362e-02, 4.7117e-03, 1.1928e-02, 8.0865e-03, 2.2891e-02,\n",
      "        3.6897e-03, 5.3855e-03, 5.4203e-03, 0.0000e+00, 4.3925e-03, 0.0000e+00,\n",
      "        1.0600e-03, 1.6817e-02, 1.1089e-03, 8.5972e-05, 1.7863e-03, 8.9439e-02,\n",
      "        3.3413e-03, 9.6029e-07, 0.0000e+00, 3.8683e-03, 1.2463e-02, 3.1487e-02,\n",
      "        1.1270e-02, 0.0000e+00, 4.8812e-02, 1.8501e-02, 4.9424e-03, 2.4499e-02,\n",
      "        2.6720e-02, 1.1121e-04, 8.8108e-03, 0.0000e+00, 1.4452e-02, 5.6405e-06,\n",
      "        1.1827e-03, 1.4418e-03, 3.0254e-03, 5.1742e-03, 4.3004e-03, 0.0000e+00,\n",
      "        2.2609e-02, 3.1814e-02, 1.1832e-01, 2.5572e-02, 6.3627e-04, 1.6753e-03,\n",
      "        1.0000e-02, 4.1955e-03, 1.9317e-02, 1.6068e-02, 7.4428e-03, 2.5641e-03,\n",
      "        2.8307e-03, 2.3880e-03, 6.5279e-04, 2.5148e-02, 5.0386e-03, 1.2288e-02,\n",
      "        1.1265e-02, 1.0064e-02, 8.1882e-03, 1.9966e-02, 8.9576e-03, 1.3042e-02,\n",
      "        1.8801e-02, 6.8769e-02, 3.1709e-03, 7.8435e-05, 1.8202e-02, 7.3866e-03,\n",
      "        0.0000e+00, 1.5129e-03, 4.4290e-02, 1.5716e-02, 3.4370e-03, 7.4198e-03,\n",
      "        0.0000e+00, 6.4591e-03, 7.3562e-03, 0.0000e+00, 8.9977e-06, 1.2574e-02,\n",
      "        3.1512e-03, 5.2059e-02, 1.8774e-02, 1.8796e-03, 1.1619e-02, 1.3611e-02,\n",
      "        5.0782e-03, 0.0000e+00, 3.8976e-02, 8.2799e-03, 3.8926e-02, 0.0000e+00,\n",
      "        2.1586e-03, 1.2355e-03, 1.5916e-03, 7.3722e-03, 7.3137e-03, 3.0095e-03,\n",
      "        3.6389e-02, 9.1647e-03, 1.2614e-02, 3.5059e-02, 7.7256e-04, 0.0000e+00,\n",
      "        2.2386e-05, 1.0209e-02, 3.4149e-03, 1.6169e-02, 2.0306e-03, 1.1170e-01,\n",
      "        1.0835e-01, 1.5316e-02, 9.6715e-04, 5.4319e-02, 4.1469e-03, 0.0000e+00,\n",
      "        1.7470e-01, 7.4674e-03, 4.2666e-02, 0.0000e+00, 6.4821e-03, 2.0465e-03,\n",
      "        8.0424e-03, 6.7837e-03, 2.6360e-02, 2.0322e-02, 7.4731e-02, 6.3980e-03,\n",
      "        8.3565e-03, 6.2985e-03, 3.1391e-02, 8.7906e-03, 2.0054e-02, 1.9024e-02,\n",
      "        1.3835e-02, 4.7903e-03, 2.3065e-03, 6.9792e-02, 6.1961e-03, 2.5716e-02,\n",
      "        1.9199e-02, 2.1838e-01, 1.8540e-04, 1.0993e-02, 9.1722e-03, 4.2045e-02,\n",
      "        7.0196e-03, 5.1490e-04, 9.7048e-03, 3.2843e-03, 2.6795e-04, 1.0798e-04,\n",
      "        1.8088e-03, 4.6878e-03, 1.9719e-03, 7.3589e-03, 1.7731e-03, 1.3199e-02,\n",
      "        1.3919e-03, 8.4436e-03, 7.4861e-03, 0.0000e+00, 1.4666e-02, 5.9419e-02,\n",
      "        2.8433e-02, 1.4729e-02, 4.4781e-02, 1.0143e-02, 1.2111e-02, 5.9383e-04,\n",
      "        2.7357e-02, 7.7654e-03, 1.4602e-02, 7.3993e-04, 8.6573e-03, 0.0000e+00,\n",
      "        2.9925e-03, 3.2404e-03, 3.6181e-03, 1.9120e-03, 2.4033e-03, 4.1378e-03,\n",
      "        2.4799e-02, 1.4504e-02, 1.8542e-03, 2.7143e-03, 2.2463e-03, 7.9697e-05,\n",
      "        2.8861e-03, 9.0622e-05, 1.3740e-02, 4.2739e-04, 4.0719e-02, 1.8270e-02,\n",
      "        4.2642e-03, 4.2287e-03, 3.5060e-02, 2.3069e-03, 4.4722e-03, 8.5825e-02,\n",
      "        1.4522e-02, 3.4565e-03, 2.3008e-03, 3.9654e-03, 1.1229e-02, 2.9097e-03,\n",
      "        1.6356e-03, 6.9016e-03, 1.4522e-02, 1.2452e-02, 3.1259e-03, 1.1678e-02,\n",
      "        1.0593e-02, 1.6796e-02, 0.0000e+00, 3.0116e-02, 0.0000e+00, 6.4266e-02,\n",
      "        1.4925e-02, 6.9147e-03, 0.0000e+00, 2.0571e-02, 2.3369e-02, 1.1872e-02,\n",
      "        6.6482e-03, 0.0000e+00, 1.5742e-03, 2.2726e-02, 1.2744e-02, 5.3909e-03,\n",
      "        2.6558e-05, 1.3029e-02, 1.7243e-04, 2.0402e-03, 1.3160e-02, 1.5979e-02,\n",
      "        4.5040e-03, 1.8994e-03, 8.4964e-02, 3.0887e-03, 6.5624e-03, 5.8101e-06,\n",
      "        8.4040e-03, 0.0000e+00, 8.5111e-03, 2.0816e-04, 1.7814e-02, 1.3797e-02,\n",
      "        1.1949e-02, 5.0685e-02, 2.8712e-02, 3.0055e-03, 0.0000e+00, 1.4062e-02,\n",
      "        0.0000e+00, 3.5563e-03, 1.7636e-03, 3.4471e-03, 2.1095e-02, 3.6360e-02,\n",
      "        1.4937e-01, 2.3007e-02, 1.9527e-02, 1.9320e-02, 7.2969e-03, 7.0246e-05,\n",
      "        0.0000e+00, 1.3744e-03, 7.2300e-02, 7.2144e-04, 9.0210e-04, 5.6310e-03,\n",
      "        3.6472e-03, 7.9892e-03, 1.7538e-02, 2.6349e-05, 0.0000e+00, 2.7893e-03,\n",
      "        1.8665e-02, 9.7350e-03, 2.1447e-03, 4.5728e-03, 1.0924e-03, 1.7814e-03,\n",
      "        9.3441e-03, 5.7397e-03, 6.3655e-03, 4.1043e-04, 1.4970e-03, 1.4414e-03,\n",
      "        8.8257e-03, 7.6797e-03, 2.7627e-02, 2.3399e-03, 6.2111e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.0961e-02, 1.1999e-03, 1.9054e-02, 8.9930e-03, 3.8041e-02,\n",
      "        2.5908e-02, 0.0000e+00, 3.0360e-05, 5.7382e-05, 1.3175e-02, 7.7407e-03,\n",
      "        3.6949e-05, 2.0463e-02, 1.9305e-02, 1.1158e-03, 1.1872e-02, 0.0000e+00,\n",
      "        1.5616e-02, 3.8053e-03, 2.2219e-03, 2.3015e-03, 3.0887e-03, 3.7790e-03,\n",
      "        1.3097e-02, 2.0239e-02, 1.0540e-02, 8.6964e-03, 2.7380e-03, 1.2184e-02,\n",
      "        4.4963e-02, 5.0731e-04, 1.8701e-02, 1.1420e-02, 1.1048e-04, 2.3165e-02,\n",
      "        1.2613e-02, 2.3249e-04, 1.7205e-02, 1.1847e-02, 1.3675e-02, 2.0138e-02,\n",
      "        4.3044e-02, 1.2207e-02, 1.2142e-02, 3.5063e-02, 3.2856e-03, 5.0405e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0044, 0.0049, 0.0063, 0.0091, 0.0089, 0.0110, 0.0090, 0.0107, 0.0093,\n",
      "        0.0100, 0.0068, 0.0088, 0.0061, 0.0053], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0293, 0.0315, 0.0307, 0.0318, 0.0321, 0.0328, 0.0316, 0.0309, 0.0308,\n",
      "        0.0298, 0.0309, 0.0305, 0.0316, 0.0300], device='cuda:0') torch.Size([14])\n",
      "score tensor([3.3324e-02, 6.8126e-03, 5.2239e-03, 3.5220e-03, 1.7367e-01, 3.2148e-03,\n",
      "        6.4482e-04, 9.2635e-05, 2.5804e-02, 3.4904e-03, 7.4063e-02, 9.1362e-04,\n",
      "        1.7444e-02, 7.0046e-02, 1.2288e-02, 1.8418e-02, 3.3933e-04, 5.3747e-04,\n",
      "        4.2587e-02, 1.0948e-02, 2.3407e-03, 2.9490e-02, 8.2055e-03, 2.7085e-03,\n",
      "        3.2274e-03, 2.7077e-02, 3.5460e-02, 5.1597e-03, 3.2357e-02, 4.7361e-04,\n",
      "        7.0468e-02, 2.6870e-02, 4.3720e-03, 3.3042e-02, 4.3948e-02, 1.1550e-05,\n",
      "        2.1404e-02, 2.4334e-02, 8.2348e-02, 2.8163e-04, 3.2684e-03, 2.1595e-02,\n",
      "        7.1875e-03, 4.0543e-03, 6.7028e-03, 1.1059e-04, 3.6415e-03, 1.5004e-02,\n",
      "        6.0382e-04, 7.5865e-03, 4.0285e-03, 1.5187e-02, 4.1997e-03, 1.6719e-01,\n",
      "        2.1783e-02, 2.7922e-03, 1.3957e-01, 2.1356e-02, 9.2109e-03, 1.4264e-03,\n",
      "        2.7555e-02, 5.3310e-02, 4.9753e-02, 4.6133e-02, 0.0000e+00, 2.4946e-04,\n",
      "        9.9907e-03, 1.5879e-03, 7.5878e-05, 1.7093e-01, 1.9827e-02, 2.0630e-04,\n",
      "        0.0000e+00, 8.9429e-05, 2.8181e-03, 1.1375e-02, 8.5491e-03, 1.1454e-02,\n",
      "        4.4218e-02, 0.0000e+00, 1.5847e-01, 1.9270e-02, 6.2671e-02, 2.5841e-03,\n",
      "        1.6530e-03, 4.1415e-02, 0.0000e+00, 2.5649e-02, 1.1880e-02, 6.1112e-03,\n",
      "        3.0144e-02, 1.6522e-03, 2.2313e-04, 2.8625e-03, 4.3958e-03, 3.4780e-02,\n",
      "        1.6904e-02, 1.0663e-02, 8.5633e-04, 1.1782e-02, 1.3709e-02, 3.3392e-03,\n",
      "        2.1525e-02, 5.2474e-04, 0.0000e+00, 3.8057e-05, 1.6925e-05, 8.5892e-02,\n",
      "        0.0000e+00, 9.6851e-03, 2.3571e-03, 1.2847e-02, 1.7748e-02, 7.4114e-03,\n",
      "        5.2512e-02, 1.0755e-02, 1.7426e-02, 7.9346e-04, 0.0000e+00, 3.8129e-02,\n",
      "        1.8849e-02, 0.0000e+00, 2.6922e-02, 3.8645e-03, 1.5270e-03, 0.0000e+00,\n",
      "        1.8995e-02, 0.0000e+00, 2.0362e-01, 1.5732e-05, 2.3907e-05, 1.4139e-01,\n",
      "        3.2550e-04, 2.0918e-03, 0.0000e+00, 2.1274e-02, 5.8136e-05, 2.5788e-02,\n",
      "        0.0000e+00, 8.2425e-03, 0.0000e+00, 7.0439e-03, 1.1465e-04, 2.1039e-04,\n",
      "        0.0000e+00, 1.0064e-02, 1.1957e-02, 8.4846e-03, 2.2196e-02, 2.6935e-02,\n",
      "        1.2647e-01, 5.7092e-03, 1.8948e-02, 3.8131e-02, 1.7149e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.5714e-02, 1.8920e-02, 0.0000e+00, 4.9768e-03, 6.0657e-02,\n",
      "        2.4904e-04, 1.4156e-02, 5.0674e-03, 3.5141e-02, 0.0000e+00, 8.4283e-03,\n",
      "        7.1997e-03, 1.0180e-03, 2.9863e-03, 1.1004e-03, 3.3665e-03, 9.9392e-04,\n",
      "        1.9200e-02, 7.8673e-03, 2.7280e-03, 0.0000e+00, 5.9487e-03, 1.7279e-02,\n",
      "        2.0314e-03, 0.0000e+00, 4.7225e-03, 1.2447e-02, 1.4969e-02, 1.0659e-04,\n",
      "        8.3514e-03, 1.1234e-03, 1.1020e-02, 2.0255e-02, 7.6465e-03, 1.6223e-02,\n",
      "        9.5935e-02, 3.7742e-02, 1.6267e-03, 5.2813e-04, 0.0000e+00, 1.4515e-03,\n",
      "        2.1612e-03, 4.1085e-02, 6.2907e-02, 3.8673e-02, 1.1074e-04, 0.0000e+00,\n",
      "        2.6083e-03, 6.4781e-04, 2.1281e-02, 5.2451e-02, 2.1688e-04, 1.4585e-05,\n",
      "        2.2731e-02, 3.6715e-02, 0.0000e+00, 1.3026e-02, 4.4775e-04, 1.2975e-01,\n",
      "        9.7493e-03, 1.5385e-03, 6.6796e-03, 1.2223e-02, 9.1296e-04, 1.3741e-02,\n",
      "        3.7478e-05, 1.1803e-02, 2.3570e-04, 2.6642e-02, 2.9846e-03, 9.3374e-04,\n",
      "        2.9748e-03, 2.7460e-04, 2.5426e-02, 2.6172e-03, 7.1453e-05, 1.0839e-02,\n",
      "        7.6412e-03, 2.3416e-02, 1.9068e-01, 9.5803e-03, 1.4107e-02, 1.0264e-03,\n",
      "        3.4755e-05, 5.7192e-02, 1.9244e-03, 2.7072e-02, 0.0000e+00, 1.5618e-01,\n",
      "        1.2882e-02, 1.1886e-02, 1.7232e-03, 2.5303e-02, 2.8262e-02, 8.1482e-03,\n",
      "        6.9595e-02, 6.0319e-04, 0.0000e+00, 1.0533e-02, 0.0000e+00, 6.9479e-02,\n",
      "        4.0068e-03, 3.7610e-03, 0.0000e+00, 2.8270e-06, 7.7607e-03, 3.2818e-02,\n",
      "        2.7700e-02, 0.0000e+00, 4.0634e-04, 1.6046e-03, 4.0983e-03, 7.6447e-04,\n",
      "        1.8712e-02, 7.7591e-03, 2.7574e-05, 2.6241e-03, 2.6550e-02, 6.0214e-03,\n",
      "        1.5246e-03, 9.2630e-03, 0.0000e+00, 1.3700e-02, 3.4090e-02, 2.7377e-02,\n",
      "        2.3123e-02, 1.3132e-01, 1.1707e-02, 2.3758e-02, 2.2481e-04, 8.3240e-03,\n",
      "        1.6872e-02, 0.0000e+00, 2.8344e-02, 6.2066e-03, 3.0471e-03, 2.5937e-03,\n",
      "        1.7645e-02, 2.2804e-02, 1.3605e-04, 3.4213e-03, 0.0000e+00, 9.6286e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.2601e-02, 1.2398e-02, 2.3888e-02, 2.6650e-02,\n",
      "        0.0000e+00, 1.1935e-02, 0.0000e+00, 1.3371e-02, 7.4474e-02, 2.3322e-04,\n",
      "        7.0888e-03, 9.6852e-03, 7.8987e-03, 0.0000e+00, 9.1749e-04, 1.1031e-02,\n",
      "        1.6898e-02, 3.1865e-02, 2.7402e-03, 0.0000e+00, 1.7288e-02, 1.8810e-03,\n",
      "        9.1943e-03, 1.3557e-02, 0.0000e+00, 2.3482e-02, 7.2978e-04, 1.0286e-02,\n",
      "        6.1511e-04, 1.9700e-01, 0.0000e+00, 1.9752e-02, 1.2399e-02, 4.4470e-06,\n",
      "        0.0000e+00, 1.3737e-02, 8.6720e-03, 3.0686e-02, 6.6730e-05, 0.0000e+00,\n",
      "        1.4409e-02, 1.3415e-05, 2.3762e-02, 3.5344e-03, 2.7937e-02, 5.3942e-02,\n",
      "        1.3529e-02, 3.2980e-02, 6.2986e-02, 6.2284e-02, 8.4154e-03, 8.3450e-02,\n",
      "        5.8253e-04, 1.8635e-02, 4.5916e-03, 2.8729e-03, 1.2910e-03, 3.8816e-04,\n",
      "        6.8306e-03, 0.0000e+00, 4.1070e-04, 1.2870e-03, 1.5488e-02, 5.4794e-03,\n",
      "        0.0000e+00, 8.6242e-03, 2.5362e-02, 2.7842e-03, 7.3923e-02, 5.7004e-04,\n",
      "        1.3522e-02, 7.6246e-04, 6.8921e-03, 4.1025e-02, 2.9295e-02, 3.4918e-03,\n",
      "        7.5244e-02, 1.3239e-02, 4.4719e-03, 4.3975e-04, 6.2531e-03, 5.8747e-02],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0087, 0.0077, 0.0103, 0.0101, 0.0108, 0.0108, 0.0108, 0.0111, 0.0105,\n",
      "        0.0107, 0.0087, 0.0088, 0.0076, 0.0065], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0240, 0.0221, 0.0237, 0.0233, 0.0230, 0.0241, 0.0237, 0.0256, 0.0241,\n",
      "        0.0263, 0.0224, 0.0249, 0.0216, 0.0205], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.3465e-01, 1.6568e-02, 1.0338e-03, 3.6575e-02, 0.0000e+00, 1.2237e-02,\n",
      "        1.2954e-03, 1.2392e-03, 1.4076e-03, 9.8839e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.5837e-01, 1.0329e-02, 0.0000e+00, 4.5475e-02, 2.7309e-04, 3.4738e-03,\n",
      "        0.0000e+00, 4.2199e-05, 4.0801e-02, 3.0496e-03, 2.7777e-02, 0.0000e+00,\n",
      "        3.0199e-02, 0.0000e+00, 0.0000e+00, 4.4045e-02, 6.0588e-05, 0.0000e+00,\n",
      "        0.0000e+00, 4.2602e-03, 0.0000e+00, 6.8118e-02, 1.5294e-01, 7.2322e-02,\n",
      "        2.6584e-01, 1.5200e-01, 0.0000e+00, 1.4985e-01, 1.9541e-02, 6.4256e-04,\n",
      "        4.5762e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.9284e-03, 3.4436e-03, 0.0000e+00, 0.0000e+00, 2.7895e-04, 2.6271e-01,\n",
      "        1.0577e-01, 0.0000e+00, 0.0000e+00, 9.9632e-02, 9.9674e-04, 2.4579e-01,\n",
      "        8.5257e-02, 2.6767e-01, 1.8400e-01, 2.5393e-01, 3.2788e-02, 2.4143e-01,\n",
      "        4.2973e-02, 6.6226e-02, 1.5880e-03, 0.0000e+00, 0.0000e+00, 1.5162e-01,\n",
      "        1.2661e-03, 3.9626e-02, 8.2094e-02, 6.3620e-05, 0.0000e+00, 8.6146e-03,\n",
      "        0.0000e+00, 3.6562e-04, 2.7813e-01, 3.1138e-02, 0.0000e+00, 1.9312e-01,\n",
      "        7.7148e-02, 6.9765e-02, 1.6878e-01, 0.0000e+00, 1.4523e-02, 7.5658e-02,\n",
      "        0.0000e+00, 1.8383e-02, 4.9740e-02, 3.0853e-01, 0.0000e+00, 0.0000e+00,\n",
      "        3.0451e-01, 1.5587e-01, 0.0000e+00, 4.7468e-02, 2.4270e-03, 6.4941e-02,\n",
      "        6.2361e-02, 1.6384e-03, 0.0000e+00, 1.6001e-03, 6.9777e-02, 8.3293e-03,\n",
      "        0.0000e+00, 4.1927e-02, 4.1351e-02, 1.5834e-01, 0.0000e+00, 2.8790e-02,\n",
      "        1.1480e-01, 1.5310e-04, 0.0000e+00, 2.5362e-01, 4.7630e-02, 1.6698e-02,\n",
      "        4.0719e-03, 4.6743e-02, 0.0000e+00, 1.0335e-02, 2.1969e-02, 0.0000e+00,\n",
      "        4.7368e-02, 4.8346e-03, 0.0000e+00, 9.6225e-02, 5.5122e-02, 0.0000e+00,\n",
      "        6.7836e-03, 1.8834e-02, 0.0000e+00, 7.5038e-02, 1.8671e-03, 1.4017e-01,\n",
      "        0.0000e+00, 9.3177e-03, 4.0843e-02, 4.3713e-03, 9.6623e-02, 2.9699e-01,\n",
      "        3.2215e-05, 4.0915e-03, 2.2249e-02, 4.1583e-02, 3.3215e-04, 6.3620e-01,\n",
      "        0.0000e+00, 2.8466e-02, 2.0213e-02, 2.0560e-01, 1.7667e-04, 1.9874e-01,\n",
      "        2.1839e-01, 5.8994e-02, 2.4357e-02, 1.4713e-02, 9.7682e-03, 0.0000e+00,\n",
      "        1.3588e-01, 0.0000e+00, 0.0000e+00, 7.3588e-02, 3.0108e-02, 2.5203e-02,\n",
      "        3.3224e-02, 1.5977e-02, 0.0000e+00, 3.7573e-02, 0.0000e+00, 1.8753e-04,\n",
      "        1.4836e-01, 0.0000e+00, 0.0000e+00, 1.2357e-01, 1.6030e-01, 0.0000e+00,\n",
      "        6.1669e-02, 0.0000e+00, 0.0000e+00, 5.4745e-02, 2.3585e-02, 6.5624e-02,\n",
      "        0.0000e+00, 1.1694e-01, 1.1759e-01, 1.4988e-02, 0.0000e+00, 5.5965e-02,\n",
      "        1.0565e+00, 6.4331e-02, 0.0000e+00, 0.0000e+00, 7.0051e-02, 3.3810e-04,\n",
      "        5.9556e-02, 3.8427e-02, 4.9827e-02, 8.8555e-02, 3.6299e-02, 0.0000e+00,\n",
      "        9.3225e-02, 5.9792e-06, 2.3066e-01, 2.2727e-01, 0.0000e+00, 8.2415e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0227e-01, 8.5063e-02, 1.7908e-01,\n",
      "        4.3308e-03, 3.4049e-02, 4.2643e-02, 4.1548e-03, 8.8921e-03, 2.4988e-03,\n",
      "        0.0000e+00, 4.0702e-02, 0.0000e+00, 6.3499e-05, 1.2909e-01, 3.5941e-03,\n",
      "        0.0000e+00, 3.3365e-03, 5.1371e-02, 6.1530e-03, 0.0000e+00, 0.0000e+00,\n",
      "        4.7577e-03, 0.0000e+00, 4.9901e-02, 4.3761e-03, 2.0306e-05, 6.4977e-03,\n",
      "        3.5430e-01, 2.5868e-02, 3.1041e-03, 1.5061e-01, 4.6751e-01, 0.0000e+00,\n",
      "        1.2888e-01, 2.4079e-02, 7.7512e-03, 0.0000e+00, 0.0000e+00, 1.7331e-02,\n",
      "        4.5670e-02, 9.1728e-02, 4.1038e-02, 2.8805e-01, 2.6272e-01, 1.4482e-01,\n",
      "        6.6691e-02, 0.0000e+00, 5.4272e-02, 5.6171e-02, 1.5554e-02, 3.2385e-02,\n",
      "        1.4853e-01, 0.0000e+00, 1.1655e-01, 1.3684e-01, 2.1116e-01, 7.7517e-04,\n",
      "        2.6422e-03, 7.9858e-02, 0.0000e+00, 1.0332e-01, 2.3018e-03, 0.0000e+00,\n",
      "        6.8876e-02, 4.0369e-04, 4.1411e-01, 1.6079e-02, 5.3138e-02, 0.0000e+00,\n",
      "        4.6817e-02, 4.7394e-01, 6.5133e-02, 0.0000e+00, 1.2349e-01, 6.8775e-02,\n",
      "        2.4564e-02, 4.0765e-02, 1.9886e-02, 6.9182e-03, 2.4011e-02, 1.8738e-02,\n",
      "        1.7895e-02, 1.7996e-02, 2.9494e-02, 3.3333e-01, 0.0000e+00, 1.3249e-02,\n",
      "        3.5332e-01, 2.2861e-01, 8.1477e-02, 1.5508e-01, 6.6553e-03, 4.9125e-05,\n",
      "        4.4504e-01, 3.3485e-03, 0.0000e+00, 9.9612e-03, 2.6382e-02, 5.2087e-02,\n",
      "        2.0584e-02, 6.3441e-02, 1.0944e-02, 0.0000e+00, 3.7867e-02, 5.5961e-06,\n",
      "        2.2434e-01, 2.2627e-02, 7.6459e-02, 3.1366e-01, 0.0000e+00, 1.4948e-01,\n",
      "        0.0000e+00, 9.5770e-02, 1.2813e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        9.1032e-02, 5.6811e-01, 0.0000e+00, 8.3634e-03, 2.4729e-02, 2.5431e-01,\n",
      "        2.7989e-01, 0.0000e+00, 8.5586e-03, 1.8380e-02, 1.1236e-01, 1.0115e-01,\n",
      "        6.7305e-03, 0.0000e+00, 3.1267e-01, 3.5159e-03, 0.0000e+00, 3.4208e-02,\n",
      "        3.4146e-02, 1.8499e-01, 6.1924e-02, 0.0000e+00, 2.0915e-02, 1.2002e-03,\n",
      "        1.4219e-01, 5.7664e-02, 1.8451e-02, 0.0000e+00, 6.2333e-02, 7.4260e-02,\n",
      "        5.1527e-02, 1.0502e-01, 4.4507e-04, 2.3705e-02, 0.0000e+00, 3.9820e-02,\n",
      "        9.6006e-02, 5.0882e-02, 3.2485e-02, 2.0779e-02, 2.4816e-01, 4.8979e-03,\n",
      "        1.4488e-01, 2.8293e-02, 1.1210e-03, 6.6210e-02, 0.0000e+00, 1.2973e-01,\n",
      "        1.2650e-01, 1.9964e-03, 1.6415e-03, 2.4257e-02, 5.3329e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0108, 0.0131, 0.0142, 0.0160, 0.0141, 0.0145, 0.0143, 0.0146, 0.0145,\n",
      "        0.0143, 0.0156, 0.0136, 0.0130, 0.0103], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0368, 0.0316, 0.0319, 0.0324, 0.0320, 0.0324, 0.0327, 0.0328, 0.0334,\n",
      "        0.0329, 0.0333, 0.0324, 0.0334, 0.0362], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.7048e-02, 1.8785e-02, 2.7665e-02, 1.1318e-02, 3.8623e-01, 1.2910e-01,\n",
      "        2.2277e-03, 0.0000e+00, 0.0000e+00, 3.5444e-02, 1.6433e-01, 0.0000e+00,\n",
      "        0.0000e+00, 3.5881e-02, 3.8419e-03, 2.2856e-03, 5.1910e-02, 1.2427e-01,\n",
      "        1.4074e-01, 3.0595e-04, 4.7437e-03, 2.4286e-02, 4.5902e-01, 0.0000e+00,\n",
      "        3.1246e-02, 9.6340e-03, 8.0691e-02, 3.0272e-04, 2.7081e-02, 1.9545e-03,\n",
      "        9.8708e-02, 3.4667e-04, 1.3837e-03, 6.9724e-02, 0.0000e+00, 1.7901e-02,\n",
      "        0.0000e+00, 6.2407e-02, 0.0000e+00, 1.9316e-02, 3.6550e-02, 6.0780e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.4015e-02, 0.0000e+00, 1.0588e-03, 5.3217e-03,\n",
      "        8.3038e-02, 3.0742e-02, 1.1905e-01, 4.0193e-03, 6.3805e-03, 3.3470e-01,\n",
      "        8.1757e-02, 3.4473e-02, 2.2937e-01, 5.6816e-02, 1.0641e-02, 1.1917e-01,\n",
      "        0.0000e+00, 1.6116e-01, 0.0000e+00, 1.2544e-01, 3.5744e-03, 0.0000e+00,\n",
      "        3.8078e-02, 8.8628e-04, 4.9854e-02, 0.0000e+00, 8.1176e-02, 1.9214e-02,\n",
      "        6.3633e-02, 4.5962e-03, 2.3225e-02, 5.0210e-04, 3.3532e-02, 3.0156e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.9295e-01, 0.0000e+00, 7.2902e-06, 7.2273e-02,\n",
      "        0.0000e+00, 1.1471e-01, 0.0000e+00, 5.4099e-02, 3.8753e-02, 3.6548e-02,\n",
      "        6.3444e-02, 3.5751e-02, 3.8812e-04, 3.0087e-02, 3.8214e-02, 1.5871e-03,\n",
      "        0.0000e+00, 4.5740e-02, 4.7011e-02, 4.5984e-03, 2.1087e-03, 3.4801e-02,\n",
      "        8.8147e-06, 2.5149e-02, 0.0000e+00, 1.7272e-02, 1.6529e-01, 4.1149e-02,\n",
      "        0.0000e+00, 3.8212e-03, 7.1445e-02, 8.6406e-03, 6.2135e-02, 4.9596e-03,\n",
      "        8.1470e-04, 7.0935e-02, 0.0000e+00, 6.3008e-04, 4.4365e-02, 7.6496e-05,\n",
      "        1.0113e-03, 1.4397e-02, 0.0000e+00, 6.7813e-04, 8.8482e-02, 6.7423e-02,\n",
      "        8.6641e-02, 2.5592e-02, 0.0000e+00, 0.0000e+00, 5.6565e-02, 1.2950e-01,\n",
      "        6.7493e-05, 7.5650e-02, 0.0000e+00, 1.1134e-03, 7.4377e-03, 8.6017e-02,\n",
      "        0.0000e+00, 7.7230e-02, 3.3514e-05, 1.2596e-02, 1.9490e-02, 8.4402e-02,\n",
      "        3.7338e-03, 5.8981e-03, 2.0303e-02, 6.8169e-02, 2.0358e-01, 0.0000e+00,\n",
      "        0.0000e+00, 8.9788e-02, 5.1393e-02, 0.0000e+00, 1.0814e-03, 3.7009e-05,\n",
      "        2.7770e-01, 0.0000e+00, 8.1650e-02, 0.0000e+00, 9.7992e-03, 1.1454e-02,\n",
      "        3.8849e-03, 1.1976e-02, 7.6466e-02, 1.0349e-03, 8.2537e-02, 3.4902e-02,\n",
      "        5.3694e-02, 3.8978e-03, 1.0480e-01, 2.9784e-02, 1.6125e-02, 4.4775e-02,\n",
      "        4.9772e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5786e-03,\n",
      "        3.4827e-03, 5.6369e-01, 0.0000e+00, 6.4055e-03, 1.5614e-02, 6.7906e-02,\n",
      "        1.9772e-02, 8.8253e-02, 3.1324e-02, 9.7846e-03, 0.0000e+00, 2.9332e-02,\n",
      "        2.5312e-01, 2.3092e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5343e-02,\n",
      "        1.9519e-02, 1.4288e-02, 5.1669e-02, 4.8448e-02, 3.2059e-04, 0.0000e+00,\n",
      "        7.1143e-02, 4.0267e-02, 1.8087e-03, 0.0000e+00, 1.3847e-02, 5.7318e-03,\n",
      "        0.0000e+00, 7.2871e-02, 1.4708e-01, 4.1283e-02, 1.5174e-03, 9.4019e-03,\n",
      "        0.0000e+00, 3.1344e-02, 1.0943e-02, 1.3251e-02, 2.1553e-01, 2.0537e-02,\n",
      "        0.0000e+00, 8.3576e-03, 4.4156e-04, 0.0000e+00, 2.5893e-02, 3.6936e-02,\n",
      "        1.6446e-02, 1.9882e-02, 3.4049e-02, 2.8917e-02, 1.6611e-02, 0.0000e+00,\n",
      "        8.3673e-03, 2.8487e-02, 8.7212e-02, 2.7364e-02, 4.4652e-02, 4.2044e-03,\n",
      "        2.7112e-01, 0.0000e+00, 8.1542e-03, 6.1982e-02, 1.5458e-01, 3.1608e-01,\n",
      "        4.2312e-01, 2.3086e-02, 2.4148e-02, 1.2809e-01, 0.0000e+00, 4.1898e-03,\n",
      "        1.2633e-01, 3.7604e-02, 0.0000e+00, 1.9517e-02, 0.0000e+00, 3.6381e-02,\n",
      "        4.1828e-03, 2.7459e-02, 9.2722e-02, 4.3920e-06, 4.2615e-02, 4.2553e-03,\n",
      "        2.1998e-02, 1.0238e-01, 2.8781e-02, 5.9323e-03, 4.1294e-03, 1.3097e-03,\n",
      "        2.3099e-03, 4.4549e-02, 0.0000e+00, 1.3203e-01, 3.7900e-05, 0.0000e+00,\n",
      "        4.4226e-02, 8.2845e-04, 1.3980e-01, 1.4209e-02, 3.0857e-05, 4.0815e-02,\n",
      "        4.8960e-02, 4.1560e-01, 2.1295e-02, 1.0150e-01, 3.6373e-03, 2.3901e-02,\n",
      "        5.1163e-03, 4.2300e-01, 3.9892e-02, 9.3946e-03, 6.1344e-02, 7.9082e-03,\n",
      "        9.9964e-03, 1.2329e-02, 1.4553e-02, 0.0000e+00, 3.0513e-01, 1.6358e-01,\n",
      "        2.9000e-01, 1.9193e-02, 1.0505e-03, 0.0000e+00, 4.4625e-02, 1.6645e-01,\n",
      "        0.0000e+00, 7.4191e-02, 0.0000e+00, 2.5385e-02, 0.0000e+00, 3.4047e-02,\n",
      "        2.1538e-02, 1.0320e-02, 1.4807e-02, 1.3877e-04, 9.2735e-03, 2.7729e-02,\n",
      "        0.0000e+00, 2.5529e-02, 8.3813e-03, 0.0000e+00, 8.4297e-02, 2.3296e-02,\n",
      "        1.4327e-02, 2.0587e-02, 5.0994e-03, 1.6513e-02, 1.4448e-03, 7.3321e-02,\n",
      "        4.0629e-03, 4.0363e-01, 1.4458e-01, 1.4784e-03, 5.9046e-03, 1.2997e-01,\n",
      "        4.6922e-02, 3.8500e-02, 1.0423e-02, 0.0000e+00, 4.6521e-02, 2.0887e-02,\n",
      "        4.5741e-02, 0.0000e+00, 0.0000e+00, 1.0620e-02, 8.4871e-02, 4.5812e-02,\n",
      "        3.7779e-02, 1.3640e-02, 7.5452e-02, 1.5774e-01, 3.3268e-03, 5.4691e-02,\n",
      "        1.5575e-03, 2.5863e-04, 7.4741e-03, 6.0682e-02, 8.0132e-04, 2.9925e-04,\n",
      "        1.2468e-02, 6.0845e-02, 7.9913e-04, 1.1753e-01, 1.8908e-01, 1.5074e-02,\n",
      "        8.4336e-03, 1.2249e-06, 5.3688e-02, 0.0000e+00, 1.9769e-01, 1.3801e-02,\n",
      "        0.0000e+00, 5.4673e-03, 5.5612e-02, 7.5322e-03, 0.0000e+00, 0.0000e+00,\n",
      "        1.1017e-03, 1.6631e-03, 4.6131e-02, 1.7582e-02, 4.2941e-02, 6.5812e-02],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0073, 0.0103, 0.0126, 0.0110, 0.0104, 0.0101, 0.0107, 0.0111, 0.0105,\n",
      "        0.0115, 0.0103, 0.0129, 0.0095, 0.0072], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0372, 0.0412, 0.0403, 0.0393, 0.0404, 0.0404, 0.0399, 0.0397, 0.0402,\n",
      "        0.0400, 0.0376, 0.0392, 0.0382, 0.0334], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 3.0989e-02, 2.0407e-03, 0.0000e+00, 6.3836e-01, 2.3158e-02,\n",
      "        1.1003e-02, 0.0000e+00, 0.0000e+00, 8.4548e-02, 2.3230e-01, 3.3102e-03,\n",
      "        0.0000e+00, 3.3687e-01, 4.3942e-02, 3.9098e-02, 3.2153e-02, 3.0337e-01,\n",
      "        0.0000e+00, 0.0000e+00, 5.2413e-02, 9.7694e-02, 8.7143e-03, 7.7113e-01,\n",
      "        3.2357e-02, 3.2413e-02, 1.8637e-01, 1.2489e-02, 2.1831e-02, 0.0000e+00,\n",
      "        6.5921e-02, 9.1672e-03, 4.3294e-03, 6.1975e-02, 2.0247e-02, 5.4838e-02,\n",
      "        1.9771e-01, 5.4234e-01, 3.4021e-01, 3.7835e-02, 3.5411e-02, 1.9630e-01,\n",
      "        0.0000e+00, 1.0800e-01, 0.0000e+00, 0.0000e+00, 4.7166e-03, 1.9439e-01,\n",
      "        1.0453e-01, 6.9322e-02, 2.0814e-02, 3.0106e-02, 3.8711e-02, 1.2020e-04,\n",
      "        8.0378e-01, 1.3481e-01, 5.1876e-01, 1.6719e-02, 0.0000e+00, 0.0000e+00,\n",
      "        8.3521e-02, 7.6305e-02, 5.9881e-01, 0.0000e+00, 4.4678e-03, 0.0000e+00,\n",
      "        2.0578e-01, 4.7130e-02, 1.5575e-02, 3.2440e-03, 4.6817e-02, 5.1611e-03,\n",
      "        7.9265e-02, 4.4990e-02, 0.0000e+00, 8.4287e-02, 1.1114e-02, 3.0422e-01,\n",
      "        0.0000e+00, 2.4333e-01, 0.0000e+00, 0.0000e+00, 3.4092e-01, 2.4346e-01,\n",
      "        5.7604e-04, 2.2269e-01, 4.2840e-02, 0.0000e+00, 1.4733e-01, 0.0000e+00,\n",
      "        0.0000e+00, 3.8578e-02, 8.3714e-02, 2.7716e-02, 0.0000e+00, 0.0000e+00,\n",
      "        3.0074e-01, 3.3924e-02, 1.5281e-01, 5.4232e-02, 2.5266e-02, 1.6492e-02,\n",
      "        1.0540e-01, 0.0000e+00, 3.4348e-01, 2.4113e-02, 1.7678e-01, 2.7367e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.2488e-02, 2.8082e-01, 1.3714e-04, 0.0000e+00,\n",
      "        7.9381e-02, 0.0000e+00, 0.0000e+00, 2.8166e-01, 0.0000e+00, 1.2021e-01,\n",
      "        3.2565e-02, 0.0000e+00, 2.6303e-01, 2.5187e-02, 2.8019e-01, 2.0413e-01,\n",
      "        1.7000e-01, 4.0631e-02, 0.0000e+00, 2.8180e-01, 5.1326e-02, 4.1020e-02,\n",
      "        2.5754e-02, 2.0346e-01, 2.9305e-01, 7.2781e-03, 1.1004e-01, 1.0455e-04,\n",
      "        0.0000e+00, 0.0000e+00, 2.4382e-01, 1.0595e-01, 7.7716e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.3143e-02, 7.1072e-02, 3.1073e-01, 0.0000e+00, 6.7579e-01,\n",
      "        1.6173e-01, 1.4309e-03, 1.8743e-02, 3.2643e-01, 1.6147e-01, 0.0000e+00,\n",
      "        2.8245e-01, 6.4809e-01, 1.2471e-02, 2.7968e-03, 1.4497e-01, 0.0000e+00,\n",
      "        2.8714e-02, 9.0029e-02, 1.0011e-01, 1.3770e-01, 1.5178e-01, 1.8945e-02,\n",
      "        5.7660e-02, 1.8993e-01, 2.9131e-01, 8.8730e-03, 2.4839e-02, 3.8034e-04,\n",
      "        0.0000e+00, 2.0803e-01, 3.7651e-01, 2.4608e-01, 1.4071e-01, 2.6272e-02,\n",
      "        3.1621e-02, 0.0000e+00, 0.0000e+00, 2.4580e-02, 1.4730e-01, 8.3182e-02,\n",
      "        2.1375e-01, 1.8284e-01, 8.6288e-03, 5.2352e-04, 6.8362e-02, 1.5574e-01,\n",
      "        1.5870e-01, 4.5463e-02, 3.2435e-01, 2.3021e-01, 0.0000e+00, 1.6230e-01,\n",
      "        0.0000e+00, 0.0000e+00, 6.7373e-02, 4.6644e-03, 6.6516e-02, 0.0000e+00,\n",
      "        1.1527e-01, 1.0098e-01, 3.6342e-01, 2.2588e-01, 0.0000e+00, 8.9093e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.7797e-01, 1.1494e-01, 3.5206e-03, 6.9853e-02,\n",
      "        0.0000e+00, 6.9294e-02, 6.7737e-03, 3.3966e-02, 0.0000e+00, 2.8761e-02,\n",
      "        2.4147e-01, 1.3133e-01, 1.8517e-01, 1.7204e-01, 1.6141e-04, 8.9062e-03,\n",
      "        5.5365e-02, 1.4196e-01, 0.0000e+00, 6.2781e-02, 2.8628e-02, 2.7880e-01,\n",
      "        1.6482e-03, 0.0000e+00, 1.1562e-01, 3.5212e-05, 1.3303e-03, 5.2033e-02,\n",
      "        3.5658e-01, 0.0000e+00, 5.4827e-02, 0.0000e+00, 4.8172e-05, 0.0000e+00,\n",
      "        5.2275e-01, 6.2377e-02, 6.2795e-03, 0.0000e+00, 4.0579e-01, 0.0000e+00,\n",
      "        1.7793e-01, 7.4505e-02, 8.0676e-01, 5.1530e-01, 1.9192e-02, 3.5034e-03,\n",
      "        1.3858e-02, 0.0000e+00, 5.0528e-02, 3.2497e-03, 5.1210e-02, 2.4403e-02,\n",
      "        2.5377e-01, 3.4993e-01, 8.5574e-02, 3.3712e-02, 3.2760e-02, 1.2925e-02,\n",
      "        7.2352e-02, 2.1821e-02, 3.0649e-02, 0.0000e+00, 3.3951e-04, 0.0000e+00,\n",
      "        0.0000e+00, 4.4010e-02, 2.3931e-01, 3.8403e-02, 2.1266e-02, 2.9660e-02,\n",
      "        2.6263e-01, 5.8061e-01, 2.0163e-02, 2.2812e-01, 1.1337e-02, 3.6985e-02,\n",
      "        1.2918e-01, 2.9133e-01, 1.5289e-01, 3.1886e-04, 8.5703e-02, 0.0000e+00,\n",
      "        7.2257e-02, 8.0528e-03, 7.9395e-03, 0.0000e+00, 0.0000e+00, 9.9087e-02,\n",
      "        3.1978e-01, 1.8969e-03, 1.1029e-01, 4.7661e-02, 3.5263e-02, 3.1048e-01,\n",
      "        4.7206e-01, 2.0878e-01, 4.4022e-02, 8.7068e-02, 6.2066e-03, 0.0000e+00,\n",
      "        1.8681e-02, 7.4711e-04, 1.2368e-02, 2.6336e-01, 1.9007e-01, 6.3821e-02,\n",
      "        2.0293e-01, 8.1583e-02, 1.0094e-03, 4.4240e-01, 9.4601e-02, 1.3318e-02,\n",
      "        1.7402e-01, 1.4578e-02, 4.5973e-03, 2.2027e-02, 1.1830e-02, 6.4029e-02,\n",
      "        4.1373e-02, 0.0000e+00, 1.5888e-01, 2.3051e-01, 1.1510e-01, 4.4374e-01,\n",
      "        0.0000e+00, 1.3635e-01, 1.0039e-02, 0.0000e+00, 7.5259e-02, 1.5326e-01,\n",
      "        2.0804e-01, 2.7600e-01, 0.0000e+00, 7.9630e-02, 0.0000e+00, 1.0740e-02,\n",
      "        1.3830e-02, 1.7698e-01, 2.7131e-01, 2.8492e-01, 1.0560e-01, 3.5702e-01,\n",
      "        1.3482e-01, 8.4496e-02, 1.0736e-02, 2.4471e-02, 5.0942e-05, 0.0000e+00,\n",
      "        4.7797e-02, 2.7562e-01, 1.9811e-02, 2.8773e-01, 1.7734e-01, 1.4094e-01,\n",
      "        1.1372e-03, 0.0000e+00, 0.0000e+00, 1.4582e-01, 0.0000e+00, 1.0585e-01,\n",
      "        1.2732e-02, 5.3433e-02, 2.9651e-01, 6.0066e-02, 0.0000e+00, 0.0000e+00,\n",
      "        3.5176e-02, 2.3914e-03, 0.0000e+00, 0.0000e+00, 1.3371e-03, 6.8017e-04],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0133, 0.0169, 0.0155, 0.0154, 0.0158, 0.0162, 0.0150, 0.0151, 0.0159,\n",
      "        0.0154, 0.0145, 0.0143, 0.0155, 0.0122], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0535, 0.0685, 0.0556, 0.0590, 0.0568, 0.0613, 0.0554, 0.0537, 0.0583,\n",
      "        0.0527, 0.0576, 0.0499, 0.0615, 0.0463], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.7809e-02, 2.2836e-04, 7.0299e-02, 6.4064e-02, 9.6654e-03, 1.9679e-03,\n",
      "        1.0920e-03, 9.0548e-02, 0.0000e+00, 5.2483e-02, 9.1681e-02, 1.5332e-02,\n",
      "        6.7431e-03, 1.6121e-03, 1.5877e-04, 0.0000e+00, 1.0437e-01, 3.8002e-03,\n",
      "        1.1037e-02, 8.2759e-02, 5.3839e-03, 1.3275e-02, 1.0188e-01, 4.2145e-02,\n",
      "        4.7549e-02, 1.6771e-03, 0.0000e+00, 0.0000e+00, 4.0295e-01, 4.7832e-02,\n",
      "        1.0484e-01, 3.5464e-03, 3.0145e-02, 1.3074e-02, 3.4111e-02, 1.0660e-01,\n",
      "        0.0000e+00, 6.7881e-02, 2.7598e-02, 4.1234e-02, 5.5274e-02, 8.5020e-02,\n",
      "        2.3296e-02, 4.1712e-02, 1.2686e-01, 4.8531e-02, 4.6782e-02, 5.3093e-02,\n",
      "        1.9317e-01, 4.0304e-02, 5.4259e-04, 5.1621e-02, 4.7941e-05, 0.0000e+00,\n",
      "        3.9403e-02, 1.5903e-01, 0.0000e+00, 0.0000e+00, 3.2528e-02, 1.2245e-01,\n",
      "        1.1932e-02, 2.3141e-02, 4.7116e-04, 1.1675e-01, 1.8334e-02, 5.6019e-04,\n",
      "        1.7660e-01, 3.6687e-02, 3.3301e-02, 8.4994e-02, 9.7863e-03, 2.0047e-02,\n",
      "        2.8255e-02, 3.6752e-02, 2.0489e-04, 0.0000e+00, 8.5874e-02, 0.0000e+00,\n",
      "        2.2437e-02, 7.6110e-02, 3.4233e-03, 5.9491e-03, 7.3973e-05, 7.4787e-02,\n",
      "        5.0600e-02, 7.0555e-02, 3.9282e-02, 5.0658e-02, 1.6568e-03, 1.1551e-01,\n",
      "        4.1795e-02, 4.6773e-02, 2.2170e-02, 4.2238e-03, 5.0571e-03, 7.3771e-03,\n",
      "        1.6106e-02, 1.1226e-02, 3.9517e-03, 5.5790e-02, 4.3871e-02, 2.0691e-02,\n",
      "        8.8991e-02, 6.9732e-03, 5.4185e-02, 2.1573e-04, 5.0427e-02, 5.9885e-02,\n",
      "        3.9586e-02, 9.1450e-03, 4.8411e-02, 5.5633e-02, 2.1687e-02, 4.3647e-02,\n",
      "        0.0000e+00, 1.5974e-02, 1.1639e-01, 3.7790e-02, 1.0359e-02, 2.0262e-03,\n",
      "        1.4378e-02, 4.6830e-03, 2.3495e-01, 4.5544e-02, 4.4893e-02, 7.1242e-03,\n",
      "        6.7450e-03, 9.2081e-03, 1.1570e-03, 3.3926e-03, 0.0000e+00, 4.4497e-02,\n",
      "        6.0432e-02, 3.9501e-02, 2.6376e-03, 4.1677e-05, 8.7571e-03, 1.2497e-02,\n",
      "        9.1195e-02, 7.6853e-03, 8.0769e-04, 1.4642e-03, 5.3550e-02, 2.7024e-02,\n",
      "        5.7486e-03, 8.7607e-02, 5.2917e-02, 5.9077e-02, 1.9644e-02, 1.6364e-02,\n",
      "        8.4011e-02, 6.5438e-02, 1.4778e-02, 1.3462e-01, 7.2223e-02, 5.3792e-02,\n",
      "        1.1989e-01, 1.8598e-02, 4.5856e-02, 1.2972e-03, 1.0997e-02, 1.0910e-02,\n",
      "        3.2199e-02, 6.5831e-02, 9.8046e-02, 0.0000e+00, 1.3968e-02, 9.2849e-03,\n",
      "        4.3986e-02, 1.3875e-03, 0.0000e+00, 1.9038e-01, 1.2648e-01, 1.7150e-01,\n",
      "        1.1216e-01, 0.0000e+00, 7.9166e-02, 5.0083e-02, 1.7913e-03, 0.0000e+00,\n",
      "        9.5367e-03, 1.4678e-01, 1.9191e-02, 2.4511e-02, 1.2057e-01, 5.9762e-01,\n",
      "        1.5188e-02, 0.0000e+00, 2.5520e-02, 7.8250e-02, 8.4694e-03, 0.0000e+00,\n",
      "        4.9611e-02, 3.4202e-02, 5.7766e-02, 1.1326e-02, 0.0000e+00, 7.4749e-03,\n",
      "        1.9131e-02, 2.9935e-02, 8.3465e-02, 1.5956e-02, 1.9727e-02, 1.0130e-03,\n",
      "        2.7782e-03, 8.1788e-02, 2.3184e-02, 8.0661e-05, 6.3083e-02, 2.6845e-03,\n",
      "        1.3198e-01, 1.9666e-03, 5.8882e-02, 3.6393e-02, 6.8898e-02, 8.7264e-02,\n",
      "        0.0000e+00, 2.2246e-03, 3.1823e-02, 1.1223e-01, 2.5745e-02, 0.0000e+00,\n",
      "        1.7628e-02, 6.0239e-02, 0.0000e+00, 1.7676e-02, 7.5185e-02, 5.0408e-02,\n",
      "        1.2278e-03, 7.0532e-02, 9.8849e-02, 1.9578e-03, 4.3106e-02, 1.2228e-01,\n",
      "        1.4109e-02, 9.8603e-02, 3.2151e-03, 5.2346e-03, 2.9790e-02, 1.4923e-03,\n",
      "        2.1844e-02, 7.9939e-02, 5.2453e-02, 1.6582e-01, 1.3276e-02, 1.0279e-02,\n",
      "        8.8584e-03, 0.0000e+00, 3.0868e-02, 2.3546e-02, 3.0367e-02, 1.2309e-02,\n",
      "        8.8883e-03, 5.8539e-02, 2.0553e-02, 3.3419e-04, 4.0033e-02, 6.0548e-02,\n",
      "        8.9710e-02, 2.6544e-02, 0.0000e+00, 2.0236e-03, 2.1847e-02, 3.1286e-02,\n",
      "        1.8578e-02, 5.7765e-02, 6.5280e-02, 8.4003e-02, 1.7862e-02, 1.4843e-02,\n",
      "        0.0000e+00, 8.3406e-02, 9.4554e-02, 4.3291e-02, 8.2936e-02, 4.3062e-03,\n",
      "        7.4684e-04, 3.2823e-02, 1.2919e-01, 4.1484e-02, 6.4981e-02, 7.0636e-02,\n",
      "        1.3813e-02, 2.5364e-02, 6.0765e-03, 0.0000e+00, 8.8266e-02, 1.2418e-04,\n",
      "        9.7279e-02, 2.0352e-05, 6.6425e-02, 2.2667e-02, 1.7498e-02, 2.4773e-02,\n",
      "        3.1901e-02, 1.2798e-02, 2.0304e-01, 4.9691e-02, 1.1598e-01, 2.8223e-02,\n",
      "        1.1363e-01, 3.2501e-03, 7.9869e-02, 6.4804e-02, 5.4303e-02, 9.4389e-02,\n",
      "        0.0000e+00, 6.7097e-04, 0.0000e+00, 8.6140e-02, 6.2070e-02, 2.0649e-01,\n",
      "        5.5191e-02, 3.7284e-03, 4.1508e-02, 1.9534e-02, 1.0315e-01, 2.7346e-02,\n",
      "        1.1296e-02, 4.8519e-03, 6.9884e-05, 2.5708e-03, 0.0000e+00, 1.3545e-02,\n",
      "        1.4548e-02, 4.6580e-02, 3.0194e-04, 1.2871e-03, 5.2369e-03, 4.7136e-02,\n",
      "        1.1823e-01, 2.2551e-03, 1.6987e-01, 1.6664e-02, 1.3597e-01, 4.5500e-02,\n",
      "        2.1853e-02, 1.0762e-01, 9.1896e-02, 6.1738e-02, 2.2410e-02, 2.7274e-02,\n",
      "        4.5268e-02, 8.4218e-02, 4.1350e-02, 9.1227e-03, 3.4061e-03, 3.5246e-02,\n",
      "        3.2385e-02, 6.6635e-03, 1.1760e-02, 3.9431e-02, 6.5670e-03, 2.2131e-02,\n",
      "        7.5195e-02, 0.0000e+00, 4.5312e-03, 3.2232e-02, 4.4057e-02, 1.0907e-02,\n",
      "        1.7005e-01, 6.4092e-03, 4.3930e-03, 1.3243e-02, 1.2942e-02, 9.1248e-02,\n",
      "        5.6794e-02, 1.3485e-01, 7.2986e-02, 4.2383e-02, 2.1091e-02, 4.1488e-02,\n",
      "        0.0000e+00, 8.0491e-03, 1.1988e-03, 3.8240e-02, 3.2338e-02, 1.2697e-02,\n",
      "        1.1847e-01, 2.8879e-02, 0.0000e+00, 7.5031e-02, 6.3470e-02, 2.5168e-02,\n",
      "        1.5025e-03, 6.0693e-02, 9.7382e-02, 9.9822e-02, 7.4460e-05, 2.5886e-03,\n",
      "        4.2661e-05, 0.0000e+00, 9.6299e-02, 1.2936e-01, 6.1443e-02, 3.2648e-02,\n",
      "        0.0000e+00, 1.8609e-03, 6.1221e-02, 2.2176e-02, 3.4409e-02, 3.5780e-03,\n",
      "        4.6678e-04, 3.4464e-02, 4.6692e-03, 2.3507e-01, 6.5146e-02, 6.6340e-03,\n",
      "        3.5544e-03, 4.9080e-02, 3.4320e-02, 8.7291e-02, 1.0494e-01, 1.6225e-01,\n",
      "        3.9857e-02, 0.0000e+00, 7.2403e-02, 1.0842e-02, 3.6273e-03, 2.7328e-02,\n",
      "        0.0000e+00, 2.5533e-02, 6.3217e-04, 2.4550e-02, 1.1977e-01, 2.7399e-02,\n",
      "        1.9699e-02, 2.3953e-02, 4.5078e-03, 6.8263e-03, 4.3419e-02, 1.0506e-01,\n",
      "        0.0000e+00, 7.6058e-02, 2.4794e-02, 3.1777e-02, 3.1996e-02, 0.0000e+00,\n",
      "        8.7080e-02, 1.1457e-01, 3.4355e-02, 2.1760e-01, 2.4103e-02, 4.5301e-02,\n",
      "        1.8534e-02, 2.9902e-02, 3.3083e-02, 0.0000e+00, 6.6791e-02, 2.3561e-02,\n",
      "        1.5287e-02, 1.1934e-02, 7.4850e-02, 3.5846e-02, 9.3368e-02, 0.0000e+00,\n",
      "        4.1905e-02, 1.4009e-01, 2.4972e-03, 7.5983e-02, 7.0078e-02, 3.6229e-03,\n",
      "        7.2929e-02, 0.0000e+00, 4.8558e-02, 9.1083e-02, 1.3109e-03, 1.0339e-01,\n",
      "        4.7628e-03, 5.3280e-02, 9.0081e-02, 2.6073e-03, 9.9779e-02, 4.7099e-02,\n",
      "        2.3171e-03, 6.4161e-02, 2.4590e-03, 5.0286e-03, 9.3648e-03, 8.2079e-02,\n",
      "        1.3749e-03, 2.8687e-02, 5.3161e-03, 1.6879e-02, 5.4143e-02, 6.6667e-02,\n",
      "        4.2346e-02, 4.1945e-03, 1.0163e-01, 1.8323e-03, 2.1994e-02, 0.0000e+00,\n",
      "        2.5874e-03, 3.7612e-03, 1.7352e-02, 7.0004e-02, 2.0352e-02, 4.0188e-02,\n",
      "        6.2422e-02, 9.7528e-02, 7.4811e-02, 1.1819e-03, 8.0254e-02, 2.4291e-02,\n",
      "        7.4338e-02, 5.3345e-02, 2.4412e-02, 8.0064e-02, 3.7334e-03, 2.6564e-03,\n",
      "        8.7024e-03, 7.1829e-02, 2.7429e-02, 5.7267e-02, 1.2167e-03, 1.0398e-01,\n",
      "        2.0994e-02, 2.6025e-02, 1.9866e-01, 4.1333e-02, 8.9048e-02, 1.2646e-03,\n",
      "        0.0000e+00, 9.0643e-02, 1.6102e-02, 4.8082e-03, 4.5220e-02, 1.6456e-02,\n",
      "        6.7989e-02, 1.5899e-03, 0.0000e+00, 1.0778e-02, 3.1341e-03, 3.6899e-02,\n",
      "        7.1910e-04, 4.1362e-02, 0.0000e+00, 5.2377e-03, 1.4139e-01, 6.5037e-02,\n",
      "        2.9120e-02, 6.4752e-05, 2.1105e-04, 8.6584e-02, 9.0152e-02, 2.8970e-02,\n",
      "        0.0000e+00, 3.9266e-02, 1.8744e-02, 5.2589e-02, 4.4427e-04, 4.1617e-02,\n",
      "        9.7809e-02, 1.8897e-03, 9.8436e-03, 2.0967e-02, 5.7903e-03, 2.1151e-02,\n",
      "        1.0459e-01, 1.4229e-04, 9.4145e-02, 3.6567e-02, 7.3112e-02, 4.1157e-03,\n",
      "        4.3387e-02, 1.1996e-02, 4.8574e-02, 5.0169e-02, 2.8337e-03, 1.1598e-03,\n",
      "        4.7763e-03, 1.2911e-02, 2.7641e-01, 7.0117e-02, 1.4177e-02, 1.0045e-01,\n",
      "        3.5690e-03, 1.6091e-02, 3.4451e-04, 0.0000e+00, 4.6418e-03, 3.4779e-02,\n",
      "        4.8337e-02, 3.7802e-02, 6.6973e-04, 7.2473e-02, 1.4440e-03, 1.1044e-01,\n",
      "        0.0000e+00, 1.0222e-01, 4.6983e-02, 5.1051e-02, 0.0000e+00, 8.1054e-02,\n",
      "        1.3621e-01, 8.8411e-02, 0.0000e+00, 1.2885e-02, 5.1382e-02, 6.1308e-02,\n",
      "        2.7645e-03, 2.6644e-03, 5.5333e-02, 1.8297e-02, 1.3830e-01, 1.1099e-03,\n",
      "        3.3436e-04, 2.3978e-02, 7.2426e-02, 9.1232e-02, 6.5354e-02, 6.1794e-02,\n",
      "        7.9554e-02, 0.0000e+00, 0.0000e+00, 3.1518e-02, 5.1516e-04, 7.7872e-02,\n",
      "        2.3348e-02, 2.2849e-03, 1.8386e-02, 0.0000e+00, 6.8116e-03, 1.5321e-02,\n",
      "        8.5302e-02, 4.0384e-02, 4.7430e-03, 1.2801e-04, 3.3925e-02, 0.0000e+00,\n",
      "        1.6508e-01, 2.0790e-02, 1.7392e-02, 7.7801e-02, 8.2093e-03, 1.5449e-02,\n",
      "        2.7990e-02, 1.7018e-02, 4.9587e-03, 3.3201e-02, 9.8676e-02, 2.0624e-02,\n",
      "        2.9658e-02, 8.6450e-03, 3.6150e-02, 8.7534e-02, 6.5142e-02, 5.7436e-02,\n",
      "        1.8159e-03, 5.6869e-05, 7.5300e-02, 1.2530e-01, 9.8438e-02, 0.0000e+00,\n",
      "        6.4313e-02, 1.5310e-02, 5.0328e-02, 3.7865e-02, 4.8117e-02, 7.3274e-03,\n",
      "        3.9181e-02, 0.0000e+00, 3.9125e-02, 2.3325e-02, 2.2866e-03, 4.3693e-02,\n",
      "        1.5795e-02, 5.2958e-02, 9.1955e-02, 1.5582e-02, 1.1586e-01, 2.0809e-02,\n",
      "        9.7260e-03, 1.3796e-04, 8.8139e-03, 2.6259e-02, 2.7762e-02, 2.7279e-02,\n",
      "        1.0136e-01, 4.4353e-05, 1.1226e-01, 1.2905e-01, 5.4665e-02, 7.2012e-03,\n",
      "        1.0222e-04, 0.0000e+00, 0.0000e+00, 6.4288e-02, 6.2392e-02, 3.5535e-02,\n",
      "        1.3761e-02, 1.4819e-02, 2.1231e-02, 2.9662e-03, 4.6251e-02, 2.3971e-01,\n",
      "        0.0000e+00, 8.7672e-02, 2.0501e-05, 4.7418e-02, 6.4748e-03, 3.0477e-02,\n",
      "        3.2649e-03, 1.6587e-02, 2.1197e-02, 6.5835e-02, 2.3927e-01, 1.6310e-02,\n",
      "        2.7929e-02, 1.2765e-02, 1.6898e-02, 2.5435e-03, 5.5618e-03, 1.3538e-02,\n",
      "        1.4733e-02, 4.6375e-02, 3.4984e-02, 9.0994e-05, 1.2528e-02, 5.2308e-02,\n",
      "        6.5495e-03, 2.5373e-04, 1.0582e-01, 3.3616e-02, 0.0000e+00, 1.7039e-01,\n",
      "        4.8592e-02, 1.2201e-02, 1.1060e-01, 2.7335e-03, 2.4765e-02, 0.0000e+00,\n",
      "        9.6197e-03, 1.1531e-03, 0.0000e+00, 9.6956e-02, 1.9297e-02, 3.9631e-03,\n",
      "        1.2695e-02, 1.2063e-02, 1.6414e-01, 1.2339e-03, 0.0000e+00, 3.1070e-01,\n",
      "        0.0000e+00, 1.6434e-02, 1.2582e-01, 3.5327e-03, 1.4505e-02, 6.9718e-02,\n",
      "        2.4622e-03, 4.6459e-02, 1.4674e-01, 2.2080e-02, 9.8616e-03, 2.6445e-02,\n",
      "        9.6880e-03, 4.2828e-02, 4.3473e-02, 3.5029e-02, 8.5993e-02, 1.2118e-02,\n",
      "        1.3390e-01, 9.8678e-03, 3.7153e-02, 2.5109e-02, 1.0950e-02, 1.9155e-01],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([2.4278e-04, 5.1044e-03, 3.3143e-03, 3.6523e-03, 4.9908e-03, 9.7630e-03,\n",
      "        7.5587e-03, 1.6542e-02, 4.5667e-03, 2.8923e-02, 2.8044e-04, 1.4578e-03,\n",
      "        2.4479e-04, 0.0000e+00, 7.1044e-04, 3.8785e-02, 2.9593e-04, 5.2250e-03,\n",
      "        9.9377e-03, 6.2623e-03, 2.3844e-03, 1.6565e-04, 6.6878e-03, 6.7779e-03,\n",
      "        2.0442e-03, 3.8049e-03, 1.4390e-02, 0.0000e+00, 1.6078e-02, 9.9481e-03,\n",
      "        1.4673e-02, 1.3248e-02, 4.5070e-02, 0.0000e+00, 1.5640e-03, 1.8938e-03,\n",
      "        0.0000e+00, 1.2431e-02, 0.0000e+00, 1.4103e-02, 3.9567e-05, 3.3599e-05,\n",
      "        8.5581e-02, 1.7049e-03, 2.9829e-02, 0.0000e+00, 9.7835e-04, 4.5622e-03,\n",
      "        3.9496e-05, 1.4508e-04, 1.3014e-03, 0.0000e+00, 0.0000e+00, 4.7488e-03,\n",
      "        9.5142e-04, 3.1166e-02, 1.1679e-02, 0.0000e+00, 1.1520e-03, 3.0738e-03,\n",
      "        2.1934e-03, 1.1762e-02, 4.4330e-03, 2.0977e-02, 4.5314e-03, 3.5125e-03,\n",
      "        3.2991e-04, 7.3299e-03, 0.0000e+00, 1.2792e-02, 2.9346e-03, 3.2622e-06,\n",
      "        3.6997e-03, 0.0000e+00, 8.8225e-03, 1.1080e-02, 1.3268e-02, 2.7838e-01,\n",
      "        9.5373e-03, 2.7126e-03, 5.5634e-03, 1.7990e-02, 4.9594e-03, 0.0000e+00,\n",
      "        2.0021e-03, 8.7774e-04, 3.1889e-02, 0.0000e+00, 3.9032e-03, 1.0616e-05,\n",
      "        0.0000e+00, 7.1561e-03, 1.1010e-02, 0.0000e+00, 0.0000e+00, 2.6327e-04,\n",
      "        2.5475e-02, 6.1791e-04, 0.0000e+00, 1.2030e-02, 4.7874e-03, 3.9819e-02,\n",
      "        0.0000e+00, 1.3322e-02, 1.6905e-02, 0.0000e+00, 5.0473e-02, 5.1173e-03,\n",
      "        9.4797e-03, 0.0000e+00, 5.2384e-03, 0.0000e+00, 0.0000e+00, 3.5063e-03,\n",
      "        1.4966e-01, 1.2882e-02, 9.4720e-03, 0.0000e+00, 9.2518e-03, 5.1919e-02,\n",
      "        5.6167e-03, 1.4628e-02, 7.8886e-03, 3.9339e-02, 0.0000e+00, 2.8408e-03,\n",
      "        8.3713e-04, 2.2892e-02, 2.8246e-02, 1.6707e-02, 2.6575e-02, 4.6919e-03,\n",
      "        0.0000e+00, 3.8422e-04, 2.0819e-04, 0.0000e+00, 1.5884e-02, 8.5726e-04,\n",
      "        7.7136e-03, 3.4012e-03, 2.1688e-02, 1.0418e-02, 4.8289e-03, 1.0630e-03,\n",
      "        1.5868e-03, 5.3362e-03, 3.1715e-05, 0.0000e+00, 7.3320e-04, 6.6777e-03,\n",
      "        5.2447e-04, 5.3782e-07, 8.5243e-03, 1.1528e-06, 2.2823e-02, 4.5334e-02,\n",
      "        1.1489e-02, 2.8082e-03, 1.7476e-02, 1.4813e-02, 5.1529e-03, 3.7355e-03,\n",
      "        2.8235e-03, 7.6874e-05, 7.8412e-03, 1.0566e-02, 6.2936e-03, 4.1473e-04,\n",
      "        2.1021e-02, 3.4801e-03, 4.1376e-03, 1.3684e-03, 7.6317e-02, 1.5259e-03,\n",
      "        1.5069e-02, 9.7388e-03, 1.1554e-03, 2.3930e-03, 2.3012e-05, 6.5631e-03,\n",
      "        0.0000e+00, 2.3510e-02, 1.1216e-04, 8.6390e-02, 2.6230e-02, 4.0374e-02,\n",
      "        3.7009e-04, 0.0000e+00, 1.2101e-02, 3.6417e-03, 1.3667e-02, 1.3945e-03,\n",
      "        8.2513e-03, 8.4804e-03, 1.2560e-04, 5.0493e-03, 1.1478e-02, 9.4356e-03,\n",
      "        5.2750e-03, 3.3723e-03, 4.8625e-04, 0.0000e+00, 2.2050e-02, 1.6185e-03,\n",
      "        8.2414e-03, 4.0892e-02, 4.2901e-02, 1.4023e-04, 0.0000e+00, 8.3830e-03,\n",
      "        1.3090e-02, 3.3989e-03, 0.0000e+00, 3.2532e-03, 4.1420e-03, 2.2883e-03,\n",
      "        0.0000e+00, 1.1764e-03, 7.2217e-03, 4.0045e-03, 1.5619e-03, 1.4726e-03,\n",
      "        4.9903e-03, 5.9048e-03, 1.3293e-03, 0.0000e+00, 2.4819e-02, 0.0000e+00,\n",
      "        7.4300e-03, 1.8708e-02, 4.7925e-05, 0.0000e+00, 0.0000e+00, 1.1703e-01,\n",
      "        7.6852e-03, 3.1772e-03, 6.9120e-03, 1.8492e-02, 3.6225e-02, 4.0710e-03,\n",
      "        0.0000e+00, 2.8545e-02, 3.2552e-03, 8.3530e-04, 0.0000e+00, 1.7421e-03,\n",
      "        9.1782e-03, 6.7153e-03, 7.3065e-04, 1.9536e-04, 6.0511e-03, 4.4361e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2212e-03, 5.3095e-02, 1.6680e-02,\n",
      "        0.0000e+00, 3.2336e-02, 9.4331e-02, 0.0000e+00, 0.0000e+00, 1.2620e-02,\n",
      "        3.9121e-03, 0.0000e+00, 1.2121e-02, 2.1214e-05, 4.5559e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.5129e-05, 0.0000e+00, 3.5453e-03, 6.5371e-02,\n",
      "        8.1437e-03, 5.8671e-03, 5.2592e-02, 1.6830e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.5683e-02, 2.9349e-03, 3.0014e-03, 0.0000e+00, 6.7260e-02, 1.2225e-01,\n",
      "        2.6221e-02, 3.0706e-03, 6.9473e-03, 1.7702e-03, 0.0000e+00, 7.6959e-03,\n",
      "        8.6478e-02, 7.8340e-03, 9.3918e-03, 4.7018e-03, 0.0000e+00, 7.5717e-03,\n",
      "        1.3191e-02, 7.3181e-03, 9.9033e-02, 4.9566e-03, 0.0000e+00, 0.0000e+00,\n",
      "        8.2987e-02, 1.3523e-02, 0.0000e+00, 2.5845e-02, 4.7726e-02, 1.8729e-03,\n",
      "        1.3483e-03, 3.4728e-02, 8.5692e-03, 5.0989e-03, 4.2929e-02, 2.6465e-02,\n",
      "        7.3457e-06, 3.6361e-03, 1.7697e-01, 2.9485e-03, 3.0082e-02, 3.8738e-03,\n",
      "        1.1009e-02, 2.1159e-02, 0.0000e+00, 6.5681e-04, 3.1904e-01, 4.6082e-02,\n",
      "        5.5371e-03, 4.5005e-03, 1.9667e-02, 3.1932e-01, 1.1810e-03, 4.7412e-02,\n",
      "        0.0000e+00, 4.6440e-03, 2.6095e-02, 2.6231e-02, 1.0581e-01, 0.0000e+00,\n",
      "        9.7942e-03, 7.6683e-03, 1.1068e-03, 6.3916e-04, 5.4849e-03, 0.0000e+00,\n",
      "        2.8744e-02, 0.0000e+00, 1.4259e-04, 0.0000e+00, 9.2950e-03, 1.9554e-03,\n",
      "        4.0546e-03, 0.0000e+00, 2.1225e-04, 6.2274e-03, 8.6318e-02, 0.0000e+00,\n",
      "        0.0000e+00, 4.6263e-03, 4.1468e-03, 6.2075e-04, 5.0688e-02, 5.3549e-02,\n",
      "        4.9904e-02, 6.1214e-03, 1.5224e-02, 1.9496e-03, 9.2062e-06, 9.3868e-02,\n",
      "        4.6855e-03, 8.1572e-03, 0.0000e+00, 6.2683e-03, 3.0497e-02, 0.0000e+00,\n",
      "        4.9883e-02, 0.0000e+00, 2.2970e-03, 6.2135e-04, 7.5417e-03, 3.7474e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.5983e-02, 7.5080e-04, 3.0909e-02, 2.8437e-02,\n",
      "        3.3757e-03, 1.7294e-02, 4.5295e-03, 1.5028e-03, 5.9574e-03, 1.9315e-04,\n",
      "        0.0000e+00, 1.6576e-02, 1.6405e-02, 4.1333e-03, 1.8489e-03, 1.6864e-02,\n",
      "        1.1450e-02, 9.7205e-03, 0.0000e+00, 7.5544e-05, 7.3815e-03, 0.0000e+00,\n",
      "        4.2640e-01, 2.0734e-04, 1.0446e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0992e-03, 2.1122e-02, 1.6844e-03, 1.4715e-02, 1.5803e-03, 1.3562e-03,\n",
      "        0.0000e+00, 1.7764e-03, 2.4939e-02, 2.9864e-03, 5.4563e-02, 0.0000e+00,\n",
      "        2.6414e-02, 4.1691e-02, 4.4202e-03, 2.2234e-03, 8.8392e-03, 2.7729e-03,\n",
      "        2.7733e-03, 2.8818e-02, 0.0000e+00, 1.6832e-02, 9.7898e-03, 5.7128e-02,\n",
      "        0.0000e+00, 1.1900e-02, 0.0000e+00, 2.1192e-02, 6.2120e-02, 0.0000e+00,\n",
      "        5.7548e-03, 4.8024e-02, 5.2667e-03, 7.9865e-03, 1.9016e-02, 1.6774e-04,\n",
      "        1.2918e-02, 1.3932e-02, 3.6617e-04, 0.0000e+00, 8.3164e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.2462e-03, 3.5702e-03, 4.7261e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.6326e-03, 1.4801e-03, 7.5340e-03, 1.9873e-02, 1.1641e-03, 8.7477e-02,\n",
      "        5.7734e-03, 1.7651e-03, 2.5033e-03, 1.1908e-02, 7.2080e-03, 1.2773e-02,\n",
      "        2.5740e-03, 0.0000e+00, 0.0000e+00, 1.5564e-02, 2.0229e-02, 8.9851e-03,\n",
      "        1.6587e-02, 1.5879e-02, 5.8510e-04, 1.1226e-02, 2.9143e-02, 2.0524e-02,\n",
      "        1.3262e-02, 0.0000e+00, 2.6437e-04, 1.0169e-01, 5.7651e-03, 1.0600e-02,\n",
      "        1.1902e-02, 8.3135e-04, 3.8323e-02, 1.7399e-02, 8.0217e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.1388e-02, 0.0000e+00, 1.0681e-02, 4.6153e-02, 2.2553e-04,\n",
      "        6.5413e-02, 2.0469e-02, 4.2118e-03, 8.2115e-03, 2.7153e-03, 1.5451e-04,\n",
      "        5.4711e-04, 6.1846e-03, 0.0000e+00, 5.0543e-02, 2.4058e-03, 3.6187e-03,\n",
      "        2.9387e-02, 0.0000e+00, 5.4032e-05, 1.2980e-02, 6.8929e-02, 2.7811e-05,\n",
      "        4.0419e-02, 2.1762e-02, 0.0000e+00, 1.6533e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.8922e-02, 2.9040e-03, 6.4413e-02, 3.5667e-03, 3.0119e-03, 1.1068e-03,\n",
      "        1.5706e-04, 3.3316e-03, 4.8928e-02, 8.3346e-03, 1.1873e-02, 0.0000e+00,\n",
      "        1.1479e-02, 4.2874e-02, 2.6937e-03, 5.0642e-03, 2.3866e-02, 1.7883e-03,\n",
      "        2.1339e-03, 1.2750e-04, 4.0818e-03, 4.1618e-04, 1.3778e-04, 5.0260e-03,\n",
      "        1.1281e-02, 3.1652e-03, 8.0314e-04, 5.7138e-03, 1.6757e-02, 6.1096e-03,\n",
      "        0.0000e+00, 3.1810e-03, 3.9845e-03, 1.4137e-03, 1.4881e-04, 2.0341e-03,\n",
      "        4.6564e-03, 5.0936e-03, 1.1292e-02, 1.3496e-02, 4.5071e-03, 4.9213e-05,\n",
      "        5.2711e-03, 3.2937e-02, 4.4623e-02, 0.0000e+00, 1.0925e-02, 5.8128e-02,\n",
      "        0.0000e+00, 5.8653e-03, 1.2929e-03, 3.8930e-03, 3.6961e-03, 1.7534e-02,\n",
      "        0.0000e+00, 2.1144e-03, 6.3577e-03, 4.8114e-02, 1.5837e-02, 0.0000e+00,\n",
      "        1.7047e-02, 3.5375e-02, 0.0000e+00, 6.3424e-03, 0.0000e+00, 1.5670e-02,\n",
      "        2.9854e-04, 0.0000e+00, 2.2256e-02, 0.0000e+00, 1.6216e-04, 0.0000e+00,\n",
      "        3.8624e-03, 1.2792e-02, 2.0002e-02, 7.5376e-03, 5.3974e-04, 1.6150e-02,\n",
      "        3.8876e-03, 1.2321e-04, 2.4647e-03, 3.8848e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.2994e-02, 0.0000e+00, 0.0000e+00, 3.8724e-05, 4.0559e-02, 8.4475e-04,\n",
      "        9.6931e-04, 0.0000e+00, 1.5984e-02, 0.0000e+00, 5.2222e-03, 2.4175e-03,\n",
      "        7.1591e-05, 9.8953e-03, 2.7119e-03, 5.4636e-03, 1.4134e-02, 1.4308e-03,\n",
      "        0.0000e+00, 5.5885e-04, 1.0142e-02, 2.6396e-02, 3.7138e-03, 5.6750e-04,\n",
      "        3.1366e-03, 1.1138e-02, 2.3524e-03, 8.0976e-03, 3.0903e-04, 1.8703e-03,\n",
      "        0.0000e+00, 1.5833e-02, 1.5364e-03, 1.2833e-02, 1.0055e-02, 1.8746e-02,\n",
      "        1.5080e-02, 1.8722e-03, 4.2536e-04, 3.9119e-03, 1.0810e-02, 3.4816e-03,\n",
      "        3.6567e-02, 1.3183e-02, 0.0000e+00, 0.0000e+00, 1.0503e-02, 7.4193e-04,\n",
      "        7.1408e-03, 1.1085e-02, 4.8446e-03, 1.3459e-02, 4.3721e-03, 6.7320e-03,\n",
      "        2.1486e-04, 0.0000e+00, 0.0000e+00, 4.7521e-03, 7.2077e-03, 2.5880e-03,\n",
      "        5.2960e-03, 1.1221e-01, 6.4171e-03, 4.4467e-04, 0.0000e+00, 1.2596e-03,\n",
      "        1.8876e-02, 1.0545e-02, 7.1286e-03, 2.5127e-02, 0.0000e+00, 2.4397e-03,\n",
      "        3.0102e-02, 2.3397e-03, 6.6618e-03, 3.8044e-03, 0.0000e+00, 4.8345e-03,\n",
      "        8.9462e-03, 2.8137e-02, 6.6974e-03, 4.0243e-02, 4.0903e-03, 3.7897e-02,\n",
      "        0.0000e+00, 1.0476e-02, 2.1785e-04, 1.0040e-02, 1.6332e-03, 6.1285e-05,\n",
      "        9.3941e-04, 2.5244e-02, 1.3727e-03, 3.2693e-03, 0.0000e+00, 2.5494e-04,\n",
      "        5.1664e-03, 3.8807e-03, 1.7851e-03, 4.2174e-03, 3.4660e-03, 2.7296e-03,\n",
      "        1.8040e-03, 1.8805e-02, 3.6845e-03, 6.1308e-03, 1.4358e-02, 0.0000e+00,\n",
      "        5.7121e-03, 4.9343e-04, 0.0000e+00, 9.9235e-03, 4.5949e-03, 4.5990e-02,\n",
      "        3.7583e-04, 1.3810e-02, 0.0000e+00, 0.0000e+00, 9.1023e-03, 7.0518e-03,\n",
      "        5.7912e-02, 7.2649e-05, 0.0000e+00, 1.3115e-02, 2.0280e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.9907e-02, 0.0000e+00, 2.0774e-02, 1.5939e-02, 0.0000e+00,\n",
      "        4.3494e-04, 1.8543e-03, 2.4788e-02, 0.0000e+00, 1.3067e-01, 7.6943e-03,\n",
      "        1.2078e-02, 3.8631e-03, 1.5455e-02, 2.0650e-02, 2.5496e-03, 1.1534e-02,\n",
      "        2.6192e-03, 1.0172e-02, 2.0839e-03, 4.9008e-03, 2.7261e-04, 3.7234e-04,\n",
      "        0.0000e+00, 1.9195e-02, 9.8980e-04, 9.5165e-02, 2.1461e-02, 3.7886e-02],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0019, 0.0050, 0.0027, 0.0048, 0.0033, 0.0057, 0.0019],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0181, 0.0291, 0.0235, 0.0266, 0.0256, 0.0322, 0.0187],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 5.9943e-02, 0.0000e+00, 0.0000e+00, 1.6286e-02,\n",
      "        2.3551e-02, 1.2615e-02, 2.6209e-04, 0.0000e+00, 2.5662e-02, 8.3667e-02,\n",
      "        3.9897e-02, 5.2478e-02, 1.7567e-03, 1.6009e-01, 7.7202e-02, 5.0780e-03,\n",
      "        7.1820e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4074e-05, 2.5239e-02,\n",
      "        4.3830e-02, 3.8737e-02, 8.0018e-01, 0.0000e+00, 5.7425e-01, 1.9697e-02,\n",
      "        1.0055e-02, 7.9088e-02, 3.2181e-02, 6.1297e-03, 6.5116e-03, 0.0000e+00,\n",
      "        3.1339e-02, 3.5630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1779e-02,\n",
      "        1.8597e-01, 8.4470e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.4098e-02, 5.7339e-03, 6.8445e-02, 1.7734e-02, 0.0000e+00, 4.2070e-03,\n",
      "        5.6631e-04, 1.8672e-02, 5.6263e-07, 0.0000e+00, 5.6881e-04, 1.6426e-03,\n",
      "        3.2966e-02, 2.7413e-02, 0.0000e+00, 1.5940e-02, 0.0000e+00, 8.1894e-03,\n",
      "        3.5779e-05, 0.0000e+00, 0.0000e+00, 1.6638e-02, 1.2108e-02, 1.3640e-02,\n",
      "        7.2265e-05, 5.7118e-02, 5.7784e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.7006e-03, 3.0460e-03, 2.2728e-03, 1.0511e-02, 4.2951e-02,\n",
      "        6.7418e-02, 1.0577e-01, 3.1372e-02, 7.7870e-02, 1.7138e-02, 4.1799e-02,\n",
      "        1.0787e-03, 8.3885e-04, 0.0000e+00, 0.0000e+00, 2.2275e-05, 1.8153e-02,\n",
      "        1.2316e-01, 1.5091e-01, 2.7224e-03, 1.4441e-03, 5.0080e-02, 5.5739e-02,\n",
      "        1.5611e-02, 5.4855e-02, 2.8687e-05, 1.9735e-01, 3.6872e-02, 3.6161e-03,\n",
      "        8.1065e-05, 1.0277e-01, 1.6100e-02, 7.3366e-02, 4.3457e-03, 7.8365e-03,\n",
      "        1.1247e-01, 0.0000e+00, 4.2248e-03, 1.1471e-01, 0.0000e+00, 2.4531e-03,\n",
      "        7.6433e-03, 0.0000e+00, 9.3546e-02, 0.0000e+00, 1.0666e-01, 6.4656e-03,\n",
      "        1.0315e-02, 2.2474e-02, 5.0593e-04, 1.9915e-02, 1.3778e-03, 1.4198e-02,\n",
      "        3.9503e-02, 0.0000e+00, 2.7359e-02, 4.5407e-02, 6.5793e-02, 2.8488e-03,\n",
      "        1.5244e-03, 1.9784e-02, 3.0674e-02, 4.5476e-02, 3.0981e-02, 2.3204e-02,\n",
      "        2.3101e-01, 4.1876e-03, 3.8336e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.3804e-05, 5.8011e-02, 5.5821e-03, 6.4116e-02, 1.3342e-02, 1.3130e-02,\n",
      "        1.2418e-02, 7.3459e-02, 5.0757e-02, 6.6954e-02, 0.0000e+00, 2.2526e-02,\n",
      "        0.0000e+00, 1.0357e-02, 1.8806e-03, 1.5832e-05, 1.1982e-02, 4.4165e-03,\n",
      "        7.6746e-02, 5.0241e-02, 9.7457e-02, 1.0645e-02, 9.6303e-02, 0.0000e+00,\n",
      "        3.5780e-02, 7.8977e-02, 0.0000e+00, 1.8060e-04, 4.4244e-03, 4.2546e-03,\n",
      "        3.4848e-03, 0.0000e+00, 1.4777e-02, 0.0000e+00, 9.8186e-05, 1.0167e-01,\n",
      "        9.1418e-03, 5.0914e-03, 4.0980e-02, 2.0898e-03, 8.1458e-03, 1.2382e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1858e-02, 0.0000e+00, 0.0000e+00, 7.7620e-03,\n",
      "        3.9609e-02, 1.1001e-02, 3.6325e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.5477e-02, 4.3714e-02, 4.1266e-02, 6.8925e-02, 1.0629e-02, 8.3237e-02,\n",
      "        1.0465e-02, 7.4013e-03, 9.2723e-02, 0.0000e+00, 1.0319e-02, 0.0000e+00,\n",
      "        6.8833e-02, 7.8601e-03, 3.6393e-02, 6.6940e-02, 0.0000e+00, 5.0425e-02,\n",
      "        0.0000e+00, 7.1944e-02, 2.8044e-02, 4.4815e-02, 1.4784e-02, 4.5018e-02,\n",
      "        5.1088e-02, 6.6371e-03, 3.0748e-02, 0.0000e+00, 8.0645e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 9.7447e-03, 1.0180e-01, 0.0000e+00, 9.7657e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0693e-02, 0.0000e+00,\n",
      "        4.2269e-03, 5.2464e-02, 2.6993e-03, 2.9715e-02, 1.4671e-03, 1.0924e-01,\n",
      "        1.7943e-01, 0.0000e+00, 0.0000e+00, 4.7159e-02, 6.9755e-02, 8.3962e-02,\n",
      "        0.0000e+00, 4.7372e-02, 0.0000e+00, 1.0326e-03, 8.3498e-03, 6.0103e-02,\n",
      "        1.8167e-02, 0.0000e+00, 8.7941e-03, 1.1536e-01, 8.1876e-03, 1.1448e-01,\n",
      "        8.3785e-02, 4.6515e-04, 1.4866e-02, 6.1441e-03, 1.5160e-02, 1.5703e-01,\n",
      "        2.3207e-03, 9.0622e-03, 4.6953e-02, 0.0000e+00, 0.0000e+00, 3.1039e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.5827e-02, 7.1598e-02, 7.3359e-02, 0.0000e+00,\n",
      "        2.1534e-04, 0.0000e+00, 9.0540e-03, 0.0000e+00, 3.0266e-04, 0.0000e+00,\n",
      "        4.0609e-03, 9.9626e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1933e-05,\n",
      "        7.9976e-02, 2.0701e-01, 2.7265e-03, 7.2063e-02, 8.3513e-02, 0.0000e+00,\n",
      "        0.0000e+00, 1.4926e-03, 0.0000e+00, 0.0000e+00, 4.7690e-02, 5.9247e-01,\n",
      "        4.3958e-02, 4.8789e-02, 4.8173e-02, 2.8221e-02, 1.0968e-01, 1.6009e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1038e-01, 6.2581e-03, 0.0000e+00, 6.5896e-02,\n",
      "        5.4223e-02, 0.0000e+00, 8.3299e-02, 2.8212e-02, 5.9779e-01, 0.0000e+00,\n",
      "        4.3285e-05, 0.0000e+00, 0.0000e+00, 1.2890e-01, 1.0104e-03, 1.4929e-01,\n",
      "        0.0000e+00, 0.0000e+00, 4.0761e-02, 2.8143e-03, 0.0000e+00, 0.0000e+00,\n",
      "        2.1148e-04, 0.0000e+00, 3.8980e-03, 2.5496e-03, 2.5740e-01, 8.8188e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.1052e-03, 0.0000e+00, 2.1655e-02, 0.0000e+00,\n",
      "        1.7464e-02, 1.8965e-03, 0.0000e+00, 1.7861e-02, 2.6702e-02, 6.0438e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.9852e-02, 0.0000e+00, 0.0000e+00, 7.5807e-04,\n",
      "        0.0000e+00, 6.1640e-04, 4.0067e-02, 2.4529e-02, 0.0000e+00, 6.4308e-03,\n",
      "        0.0000e+00, 2.1119e-03, 1.2802e-01, 0.0000e+00, 6.2461e-02, 1.7086e-01,\n",
      "        0.0000e+00, 2.4320e-02, 1.6803e-02, 1.0858e-02, 6.7643e-03, 9.2623e-03,\n",
      "        1.3820e-03, 4.2794e-02, 2.8081e-02, 1.7113e-02, 5.8526e-03, 4.3167e-02,\n",
      "        0.0000e+00, 2.2719e-01, 9.2247e-02, 1.1692e-04, 1.0261e-01, 2.9566e-02,\n",
      "        1.2365e-02, 0.0000e+00, 2.3237e-02, 1.7788e-02, 6.1130e-02, 8.0902e-02,\n",
      "        2.2345e-04, 5.0093e-02, 0.0000e+00, 6.8581e-02, 7.1084e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8372e-02, 0.0000e+00, 2.5466e-02,\n",
      "        2.3482e-02, 0.0000e+00, 7.6725e-03, 2.6897e-02, 0.0000e+00, 3.6913e-02,\n",
      "        8.5075e-02, 0.0000e+00, 0.0000e+00, 6.7031e-02, 6.8549e-02, 1.4984e-02,\n",
      "        8.5824e-04, 6.0790e-02, 3.8499e-03, 2.2925e-02, 3.0191e-02, 3.6790e-04,\n",
      "        2.7028e-02, 6.5319e-02, 0.0000e+00, 2.4923e-01, 6.2350e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.8623e-02, 0.0000e+00, 8.1745e-03, 1.3652e-01, 3.5094e-02,\n",
      "        1.8699e-02, 2.0652e-02, 0.0000e+00, 3.1322e-02, 4.0868e-02, 0.0000e+00,\n",
      "        0.0000e+00, 3.3946e-03, 1.8752e-01, 0.0000e+00, 1.5357e-02, 3.4038e-03,\n",
      "        0.0000e+00, 3.0598e-02, 4.3158e-02, 5.2211e-02, 0.0000e+00, 9.0517e-02,\n",
      "        6.2415e-03, 0.0000e+00, 1.2053e-02, 1.2415e-03, 0.0000e+00, 1.2414e-02,\n",
      "        0.0000e+00, 2.6608e-02, 3.3202e-01, 0.0000e+00, 0.0000e+00, 3.7025e-02,\n",
      "        1.1547e-01, 1.9563e-03, 5.5737e-02, 8.7883e-02, 9.3717e-03, 3.6051e-02,\n",
      "        7.5522e-02, 0.0000e+00, 2.1759e-04, 3.7899e-02, 3.3679e-02, 3.0900e-02,\n",
      "        5.3396e-03, 0.0000e+00, 2.6530e-02, 8.2790e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.3211e-03, 0.0000e+00, 0.0000e+00, 9.9806e-03, 1.2348e-01,\n",
      "        6.6634e-03, 2.1123e-02, 5.6950e-02, 2.4545e-03, 0.0000e+00, 3.1597e-03,\n",
      "        1.2926e-02, 3.4584e-02, 5.0209e-02, 1.0093e-01, 2.4244e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.7863e-02, 4.2965e-03, 1.8308e-02, 1.1488e-02, 9.6212e-04,\n",
      "        3.7088e-03, 1.5307e-02, 8.6630e-02, 5.3903e-03, 0.0000e+00, 0.0000e+00,\n",
      "        9.7315e-03, 2.7618e-02, 4.1141e-02, 2.5161e-02, 7.2626e-02, 0.0000e+00,\n",
      "        1.2246e-02, 8.1083e-02, 9.2837e-02, 2.3371e-04, 3.4417e-02, 2.5099e-02,\n",
      "        7.3490e-02, 4.3060e-02, 2.1955e-02, 2.3163e-03, 0.0000e+00, 2.0539e-02,\n",
      "        0.0000e+00, 0.0000e+00, 7.8203e-02, 4.6618e-02, 1.5667e-02, 4.0337e-02,\n",
      "        8.6750e-02, 3.2280e-02, 6.9234e-03, 2.9053e-03, 1.9711e-03, 0.0000e+00,\n",
      "        3.1639e-03, 5.8108e-03, 0.0000e+00, 0.0000e+00, 8.1797e-02, 3.0479e-02,\n",
      "        0.0000e+00, 2.9357e-03, 1.2628e-03, 1.7371e-02, 1.3012e-04, 8.5721e-02,\n",
      "        0.0000e+00, 1.4390e-02, 1.4412e-03, 0.0000e+00, 3.7365e-04, 0.0000e+00,\n",
      "        1.7851e-01, 3.2110e-03, 2.4949e-01, 5.0983e-02, 3.7123e-02, 0.0000e+00,\n",
      "        1.6746e-02, 3.4827e-02, 4.0365e-03, 0.0000e+00, 1.0966e-02, 4.1497e-02,\n",
      "        1.5384e-02, 1.2249e-02, 5.7169e-03, 2.9536e-02, 6.4967e-02, 2.3311e-02,\n",
      "        8.3700e-03, 6.3103e-02, 3.4438e-02, 5.1629e-03, 8.6082e-02, 0.0000e+00,\n",
      "        4.7637e-02, 3.6515e-02, 0.0000e+00, 4.7051e-02, 1.5746e-02, 0.0000e+00,\n",
      "        0.0000e+00, 1.7090e-02, 2.3064e-02, 0.0000e+00, 1.7867e-03, 2.4968e-02,\n",
      "        2.5722e-04, 1.1235e-02, 3.0817e-02, 1.7380e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.3064e-02, 1.3576e-03, 1.7146e-02, 3.1119e-02, 1.7243e-02, 1.4618e-02,\n",
      "        0.0000e+00, 4.2510e-05, 2.5834e-04, 5.1965e-04, 0.0000e+00, 1.2147e-01,\n",
      "        0.0000e+00, 4.9587e-03, 2.4134e-02, 1.0048e-01, 4.1509e-05, 1.8265e-02,\n",
      "        1.1182e-02, 0.0000e+00, 0.0000e+00, 5.4824e-03, 1.4443e-02, 8.0759e-03,\n",
      "        3.6249e-02, 2.3204e-03, 0.0000e+00, 5.8446e-02, 0.0000e+00, 2.4226e-02,\n",
      "        0.0000e+00, 7.8437e-03, 2.8008e-02, 2.5521e-01, 3.8892e-03, 3.8419e-02,\n",
      "        2.1629e-02, 1.1944e-03, 9.0501e-02, 3.6714e-02, 3.2502e-02, 1.3723e-01,\n",
      "        0.0000e+00, 0.0000e+00, 1.3162e-01, 0.0000e+00, 7.5190e-03, 1.2600e-03,\n",
      "        7.4168e-04, 0.0000e+00, 1.6863e-02, 4.7268e-02, 1.5501e-02, 0.0000e+00,\n",
      "        9.4444e-04, 6.9034e-03, 1.4126e-01, 2.9240e-02, 6.9034e-03, 1.5196e-02,\n",
      "        3.7869e-02, 1.4373e-01, 2.3230e-04, 7.4230e-04, 7.6364e-02, 3.1720e-03,\n",
      "        3.6406e-02, 6.7137e-02, 3.6066e-02, 3.4310e-03, 2.3679e-04, 2.4268e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7573e-03, 2.1680e-02, 0.0000e+00,\n",
      "        1.9899e-03, 0.0000e+00, 1.0517e-02, 0.0000e+00, 0.0000e+00, 2.8335e-04,\n",
      "        5.3403e-02, 1.6408e-02, 3.7136e-04, 1.6485e-02, 1.6714e-03, 0.0000e+00,\n",
      "        8.2176e-02, 0.0000e+00, 2.2841e-02, 1.3766e-02, 3.6215e-02, 3.9774e-04,\n",
      "        1.9314e-03, 2.5508e-03, 2.5368e-02, 2.0977e-02, 0.0000e+00, 0.0000e+00,\n",
      "        6.5108e-02, 6.7999e-02, 3.6592e-02, 0.0000e+00, 3.5041e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.6023e-04, 5.0848e-02, 0.0000e+00, 0.0000e+00, 8.1712e-02,\n",
      "        3.7267e-02, 2.1916e-03, 4.7731e-02, 1.8447e-02, 5.2180e-03, 6.4504e-02,\n",
      "        2.9042e-05, 1.6485e-03, 0.0000e+00, 1.3382e-02, 1.1106e-01, 0.0000e+00,\n",
      "        9.0855e-03, 2.0869e-03, 4.1500e-02, 0.0000e+00, 3.3022e-02, 5.1082e-02,\n",
      "        0.0000e+00, 1.5586e-03, 1.0006e-01, 3.6060e-03, 0.0000e+00, 3.9735e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1341e-03,\n",
      "        6.6574e-02, 2.5575e-02, 2.0521e-04, 3.3598e-02, 0.0000e+00, 7.3818e-02,\n",
      "        0.0000e+00, 0.0000e+00, 8.7895e-02, 0.0000e+00, 4.3592e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0014, 0.0164, 0.0017, 0.0082, 0.0019, 0.0173, 0.0018],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0178, 0.0446, 0.0219, 0.0336, 0.0225, 0.0454, 0.0188],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([1.8856e-02, 6.8049e-02, 0.0000e+00, 0.0000e+00, 2.0476e-02, 1.7816e-03,\n",
      "        5.9230e-03, 3.7255e-04, 7.0556e-02, 9.7829e-02, 9.4868e-04, 1.8745e-01,\n",
      "        1.7575e-02, 4.3309e-02, 4.4252e-03, 1.6984e-01, 0.0000e+00, 3.5434e-03,\n",
      "        0.0000e+00, 6.7484e-02, 7.0448e-02, 0.0000e+00, 1.1717e-02, 1.6988e-02,\n",
      "        2.7139e-03, 1.2062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1779e-03,\n",
      "        2.3660e-02, 0.0000e+00, 1.7891e-02, 4.2171e-02, 7.3583e-03, 1.6863e-01,\n",
      "        0.0000e+00, 1.3764e-02, 0.0000e+00, 0.0000e+00, 4.6859e-02, 2.6315e-02,\n",
      "        1.4986e-01, 6.1279e-02, 3.9956e-01, 2.7012e-02, 0.0000e+00, 0.0000e+00,\n",
      "        5.8391e-02, 0.0000e+00, 8.8342e-02, 1.1383e-02, 5.5877e-01, 3.2241e-02,\n",
      "        9.8563e-03, 9.0106e-03, 2.4318e-02, 0.0000e+00, 4.2678e-02, 2.5351e-03,\n",
      "        1.7266e-02, 0.0000e+00, 7.3493e-04, 3.5154e-02, 0.0000e+00, 2.6570e-02,\n",
      "        2.9522e-04, 1.0562e-02, 0.0000e+00, 3.7622e-03, 0.0000e+00, 6.7561e-05,\n",
      "        2.5168e-03, 9.0988e-03, 3.5714e-02, 1.5936e-01, 9.9770e-03, 0.0000e+00,\n",
      "        6.8619e-02, 7.5164e-04, 2.2681e-03, 8.9800e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.5913e-02, 4.3244e-02, 0.0000e+00, 2.3174e-03, 9.0090e-02,\n",
      "        0.0000e+00, 4.9470e-02, 0.0000e+00, 4.2606e-03, 6.2701e-03, 7.7243e-02,\n",
      "        1.3978e-01, 6.7144e-02, 9.5422e-04, 1.3670e-02, 5.5151e-03, 4.8894e-02,\n",
      "        3.2441e-02, 3.9453e-03, 0.0000e+00, 0.0000e+00, 1.2518e-03, 1.2416e-02,\n",
      "        4.8234e-03, 0.0000e+00, 3.9172e-02, 0.0000e+00, 0.0000e+00, 8.2042e-02,\n",
      "        3.6427e-02, 1.2356e-01, 1.6475e-02, 9.2305e-02, 1.1418e-01, 0.0000e+00,\n",
      "        4.9599e-03, 4.2599e-02, 1.7085e-01, 1.9862e-01, 9.7098e-02, 1.2176e-02,\n",
      "        1.7421e-02, 5.6907e-03, 0.0000e+00, 1.4681e-03, 5.6838e-03, 1.4243e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.6690e-03, 4.0214e-03, 3.9573e-02, 2.2151e-05,\n",
      "        6.5842e-03, 0.0000e+00, 2.8944e-02, 6.9978e-02, 4.3780e-02, 7.7891e-03,\n",
      "        6.3584e-05, 1.0295e-02, 0.0000e+00, 3.0635e-02, 2.3118e-03, 1.0685e-02,\n",
      "        4.7010e-03, 5.8204e-02, 3.1998e-04, 0.0000e+00, 1.3043e-02, 4.6338e-04,\n",
      "        1.2184e-02, 5.3564e-02, 6.2269e-02, 0.0000e+00, 1.2713e-01, 8.9674e-02,\n",
      "        1.8720e-02, 1.1174e-02, 7.8672e-03, 6.3747e-04, 2.9608e-02, 6.6813e-03,\n",
      "        5.8198e-02, 5.1570e-02, 5.2172e-03, 7.4541e-03, 8.7879e-02, 2.4663e-02,\n",
      "        2.4213e-02, 0.0000e+00, 6.3950e-02, 0.0000e+00, 3.4887e-03, 3.5289e-02,\n",
      "        1.1870e-02, 1.6638e-02, 6.3054e-04, 1.2287e-01, 3.0763e-02, 1.8467e-01,\n",
      "        4.5916e-03, 3.4766e-03, 5.3571e-02, 1.4339e-02, 2.9778e-02, 3.4686e-04,\n",
      "        0.0000e+00, 3.8697e-04, 0.0000e+00, 7.6711e-04, 3.7952e-02, 3.8421e-03,\n",
      "        4.0166e-03, 6.6200e-04, 0.0000e+00, 8.5362e-02, 8.4913e-02, 7.1346e-02,\n",
      "        0.0000e+00, 3.8982e-02, 0.0000e+00, 2.6286e-02, 1.5568e-02, 0.0000e+00,\n",
      "        1.0395e-03, 1.5876e-04, 0.0000e+00, 0.0000e+00, 2.4832e-03, 1.6186e-01,\n",
      "        5.3718e-02, 1.6228e-02, 1.4335e-03, 6.5232e-05, 1.3081e-01, 7.4725e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.1589e-02, 3.9701e-02, 0.0000e+00, 1.3331e-03,\n",
      "        9.8684e-03, 2.8948e-02, 6.8151e-02, 1.1853e-01, 0.0000e+00, 1.2298e-01,\n",
      "        4.3817e-02, 4.8752e-02, 2.1044e-02, 8.7395e-02, 3.1817e-02, 1.1129e-02,\n",
      "        1.4320e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.7302e-02, 4.9702e-04, 1.0968e-02, 1.6340e-03, 2.3004e-02, 1.3053e-01,\n",
      "        4.9998e-03, 9.1564e-03, 0.0000e+00, 7.6039e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.8574e-02, 8.3037e-02, 1.7172e-02, 1.4525e-02, 4.1259e-02,\n",
      "        4.9230e-02, 0.0000e+00, 7.3622e-03, 0.0000e+00, 1.4926e-02, 1.8826e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.1095e-05, 8.5414e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.2418e-02, 6.7533e-04, 8.1700e-04, 2.2639e-02, 1.9995e-01, 3.7409e-02,\n",
      "        2.6858e-02, 1.7225e-01, 3.8203e-02, 7.0534e-02, 0.0000e+00, 1.7700e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.1692e-03, 1.8837e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.2669e-02, 3.6507e-03, 0.0000e+00, 4.3384e-04, 4.8959e-03,\n",
      "        4.6774e-02, 1.8405e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.8576e-01, 8.1085e-02, 9.6545e-02, 5.4175e-03, 4.5498e-02, 7.0886e-01,\n",
      "        2.0914e-01, 1.4524e-03, 3.2899e-02, 2.3581e-02, 0.0000e+00, 2.1014e-02,\n",
      "        1.0816e-01, 0.0000e+00, 1.3466e-01, 7.5558e-04, 2.0319e-02, 3.5794e-02,\n",
      "        0.0000e+00, 6.1361e-02, 0.0000e+00, 1.4648e-03, 0.0000e+00, 3.0271e-02,\n",
      "        1.2691e-02, 7.9539e-03, 0.0000e+00, 2.4657e-01, 1.3660e-02, 9.0333e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1600e-04, 9.3181e-02, 0.0000e+00,\n",
      "        1.7765e-03, 7.7275e-02, 0.0000e+00, 1.1499e-03, 1.9656e-01, 7.9537e-02,\n",
      "        2.1216e-03, 1.6235e-01, 7.6840e-04, 1.7797e-01, 9.8664e-03, 0.0000e+00,\n",
      "        1.3076e-02, 5.5986e-02, 6.8053e-02, 1.2206e-01, 1.9686e-03, 7.5793e-02,\n",
      "        3.0566e-01, 1.3025e-01, 2.2527e-02, 0.0000e+00, 1.2718e-03, 9.7637e-03,\n",
      "        0.0000e+00, 2.3960e-02, 0.0000e+00, 0.0000e+00, 1.8235e-02, 1.9085e-02,\n",
      "        9.1370e-02, 1.2184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6074e-01,\n",
      "        5.5437e-02, 7.4676e-03, 6.9592e-02, 5.6659e-03, 0.0000e+00, 5.3552e-03,\n",
      "        0.0000e+00, 1.1240e-02, 0.0000e+00, 6.8023e-02, 2.6320e-04, 2.4104e-02,\n",
      "        7.3516e-02, 3.9484e-01, 5.2762e-02, 4.6914e-02, 0.0000e+00, 6.0037e-02,\n",
      "        1.4666e-03, 0.0000e+00, 3.3208e-03, 9.5113e-03, 0.0000e+00, 1.2561e-01,\n",
      "        9.5358e-02, 6.1873e-02, 5.4605e-04, 2.8474e-02, 2.8746e-02, 4.7839e-02,\n",
      "        3.7914e-01, 8.0460e-02, 1.6509e-04, 9.2886e-03, 5.4665e-02, 9.8555e-04,\n",
      "        2.6915e-03, 0.0000e+00, 2.1187e-02, 1.3245e-02, 3.5090e-04, 7.9288e-02,\n",
      "        0.0000e+00, 2.8665e-02, 2.9600e-02, 0.0000e+00, 7.5330e-02, 2.3163e-02,\n",
      "        1.2067e-01, 1.8233e-02, 1.3270e-02, 0.0000e+00, 0.0000e+00, 1.9888e-03,\n",
      "        9.3870e-03, 7.2769e-06, 1.4263e-02, 0.0000e+00, 2.8884e-05, 1.1490e-01,\n",
      "        0.0000e+00, 1.2777e-02, 3.5041e-02, 1.0408e-02, 1.5820e-01, 3.6547e-05,\n",
      "        1.1255e-02, 0.0000e+00, 4.7746e-02, 2.2743e-03, 0.0000e+00, 1.0974e-02,\n",
      "        5.9283e-02, 4.9719e-03, 0.0000e+00, 0.0000e+00, 8.3583e-03, 2.1484e-03,\n",
      "        0.0000e+00, 5.8690e-02, 7.8863e-02, 4.4335e-02, 0.0000e+00, 3.6801e-01,\n",
      "        0.0000e+00, 6.5851e-02, 2.6106e-03, 1.3309e-02, 1.0471e-02, 2.7515e-02,\n",
      "        2.2656e-03, 4.4894e-03, 0.0000e+00, 0.0000e+00, 3.9294e-02, 2.3758e-02,\n",
      "        0.0000e+00, 7.6152e-03, 3.2912e-02, 0.0000e+00, 6.9485e-03, 0.0000e+00,\n",
      "        7.8188e-02, 7.2355e-02, 0.0000e+00, 2.5006e-03, 1.5909e-01, 5.7272e-02,\n",
      "        5.7697e-02, 4.1426e+00, 5.9152e-02, 0.0000e+00, 0.0000e+00, 2.1557e-02,\n",
      "        0.0000e+00, 2.6557e-03, 1.4881e-01, 0.0000e+00, 1.0816e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.5204e-02, 8.1523e-04, 8.1811e-02, 2.0928e-01, 0.0000e+00,\n",
      "        7.3549e-03, 4.6818e-05, 0.0000e+00, 0.0000e+00, 1.7948e-04, 7.3495e-03,\n",
      "        2.0873e-03, 7.0197e-03, 1.9592e-03, 2.0224e-02, 0.0000e+00, 9.3225e-03,\n",
      "        7.9042e-03, 0.0000e+00, 3.2701e-02, 4.1086e-04, 0.0000e+00, 0.0000e+00,\n",
      "        2.7410e-03, 6.6049e-02, 9.6679e-03, 7.9725e-03, 2.5136e-01, 1.7286e-02,\n",
      "        0.0000e+00, 7.5205e-02, 7.8390e-02, 0.0000e+00, 0.0000e+00, 1.7890e-03,\n",
      "        7.8329e-02, 9.2353e-02, 3.6210e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.7152e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        5.0970e-02, 0.0000e+00, 1.9744e-02, 6.7501e-03, 6.6811e-03, 4.8244e-02,\n",
      "        0.0000e+00, 1.7889e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.8367e-04, 2.5222e-02, 7.1550e-03, 4.4258e-05, 0.0000e+00,\n",
      "        5.8129e-02, 1.9962e-04, 0.0000e+00, 2.3246e-02, 0.0000e+00, 7.3310e-05,\n",
      "        0.0000e+00, 0.0000e+00, 1.3686e-01, 4.4674e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.4277e-02, 2.7142e-04, 1.4597e-01, 1.1267e-03, 2.1415e-02,\n",
      "        1.7125e-02, 4.1659e-02, 3.8450e-02, 4.1900e-02, 8.0726e-02, 6.3398e-02,\n",
      "        3.1145e-02, 1.1539e-01, 1.4110e-02, 2.9522e-02, 0.0000e+00, 1.0533e-01,\n",
      "        1.9104e-03, 6.7551e-04, 0.0000e+00, 0.0000e+00, 2.1001e-02, 2.8298e-02,\n",
      "        1.6112e-02, 2.6445e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9483e-04,\n",
      "        5.6487e-03, 0.0000e+00, 5.3480e-04, 9.6919e-03, 8.8464e-03, 0.0000e+00,\n",
      "        1.0508e-02, 2.9146e-03, 2.8319e-02, 3.5206e-02, 1.3664e-03, 0.0000e+00,\n",
      "        4.7376e-02, 3.8703e-02, 8.4929e-04, 5.8882e-02, 0.0000e+00, 2.6645e-01,\n",
      "        9.4148e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3904e-02, 3.5755e-03,\n",
      "        0.0000e+00, 5.7055e-02, 9.5513e-02, 5.9988e-03, 5.8256e-03, 2.4508e-04,\n",
      "        0.0000e+00, 1.0678e-03, 3.7473e-02, 6.9391e-02, 0.0000e+00, 1.8564e-02,\n",
      "        0.0000e+00, 1.9100e-02, 0.0000e+00, 6.3514e-01, 0.0000e+00, 0.0000e+00,\n",
      "        1.9046e-02, 1.1204e-02, 0.0000e+00, 5.9437e-02, 4.7983e-02, 1.4648e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2869e-01, 1.0489e-01, 1.8663e-02,\n",
      "        2.9177e-03, 9.1538e-02, 2.8024e-02, 1.7241e-03, 7.5718e-03, 0.0000e+00,\n",
      "        2.0638e-04, 3.2593e-02, 0.0000e+00, 0.0000e+00, 4.8200e-02, 2.2022e-04,\n",
      "        4.1300e-04, 1.5607e-03, 7.0045e-03, 8.6415e-04, 1.3914e-01, 9.5273e-03,\n",
      "        2.3637e-02, 4.3219e-02, 3.8082e-03, 2.4686e-02, 0.0000e+00, 8.5043e-02,\n",
      "        3.7161e-03, 8.9510e-02, 1.9015e-01, 0.0000e+00, 5.8785e-03, 7.2330e-02,\n",
      "        1.3066e-03, 3.8819e-02, 1.1140e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0114e-02, 1.0452e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7732e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3891e-03, 0.0000e+00, 1.5012e-03,\n",
      "        8.1950e-02, 3.4401e-03, 1.4870e-03, 0.0000e+00, 0.0000e+00, 5.0956e-05,\n",
      "        8.0866e-02, 0.0000e+00, 0.0000e+00, 6.7076e-02, 4.6576e-03, 5.9930e-02,\n",
      "        0.0000e+00, 4.8452e-02, 6.2841e-06, 4.0155e-02, 5.9374e-03, 2.2678e-02,\n",
      "        0.0000e+00, 1.2831e-02, 1.2954e-02, 4.7025e-02, 2.4259e-03, 0.0000e+00,\n",
      "        1.6385e-02, 0.0000e+00, 3.9955e-03, 2.0784e-02, 9.1169e-02, 8.0446e-02,\n",
      "        4.7175e-04, 8.1356e-04, 9.4545e-02, 0.0000e+00, 1.6094e-02, 1.0382e-01,\n",
      "        2.9890e-04, 0.0000e+00, 1.0230e-01, 1.2274e-02, 0.0000e+00, 1.1495e-02,\n",
      "        3.9553e-03, 4.9165e-03, 2.0706e-01, 3.4394e-03, 1.1448e-01, 6.3313e-04,\n",
      "        0.0000e+00, 2.9415e-05, 0.0000e+00, 8.5533e-02, 5.2927e-02, 8.7695e-02,\n",
      "        6.3140e-03, 0.0000e+00, 4.5193e-02, 1.2357e-04, 8.8427e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0003, 0.0328, 0.0015, 0.0085, 0.0014, 0.0369, 0.0004],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0121, 0.0476, 0.0156, 0.0317, 0.0159, 0.0511, 0.0128],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0000, 0.0000, 0.1705, 0.3687, 0.9242, 0.0000, 0.0000, 0.5029, 0.0000,\n",
      "        0.0000], device='cuda:0') torch.Size([10])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 7.9517e-01, 0.0000e+00, 4.1610e-01, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 8.0445e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.3357e+00, 9.4621e-02, 0.0000e+00, 0.0000e+00, 2.5304e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.3615e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.4487e+00, 2.3436e-02, 1.3762e-01, 2.2767e-01, 2.7563e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.3441e-03, 2.6298e-02, 0.0000e+00, 1.1334e-02,\n",
      "        0.0000e+00, 5.1408e-02, 1.3963e-01, 8.8616e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.9974e-02, 0.0000e+00, 1.5570e+00, 0.0000e+00, 3.9853e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 6.7071e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.4512e-02, 3.2202e+00, 5.1580e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.3391e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 7.0213e-02, 0.0000e+00, 4.9442e-02,\n",
      "        0.0000e+00, 2.8809e-01, 0.0000e+00, 4.6919e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.4448e+00, 3.7264e-02, 0.0000e+00, 6.3292e-02, 1.9096e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([2.8526e-04, 1.4992e-04, 1.7503e-04, 2.4435e-04, 0.0000e+00, 7.6294e-04,\n",
      "        1.1145e-06, 5.8160e-04, 1.0649e-03, 0.0000e+00, 1.0513e-03, 4.7384e-04,\n",
      "        1.1443e-03, 1.2935e-04, 3.7553e-04, 5.1945e-04, 4.7589e-04, 8.6432e-05,\n",
      "        1.4067e-03, 3.8259e-04, 9.8869e-04, 2.1447e-05, 1.6764e-03, 2.3208e-06,\n",
      "        0.0000e+00, 2.7059e-04, 2.4191e-04, 1.7017e-05, 0.0000e+00, 2.1669e-04,\n",
      "        0.0000e+00, 1.0810e-03, 3.9838e-04, 7.6560e-04, 2.0000e-05, 1.9892e-04,\n",
      "        1.0981e-04, 2.6322e-04, 9.5027e-06, 1.7725e-04, 5.2351e-04, 2.8601e-04,\n",
      "        1.2928e-04, 2.5381e-04, 0.0000e+00, 3.2197e-04, 0.0000e+00, 3.0163e-04,\n",
      "        1.5093e-04, 1.5103e-04, 1.2703e-04, 6.4519e-04, 1.0550e-03, 5.2482e-04,\n",
      "        1.0745e-05, 1.0147e-03, 8.7828e-04, 0.0000e+00, 9.7995e-05, 1.1404e-02,\n",
      "        3.8912e-03, 0.0000e+00, 0.0000e+00, 1.6403e-04, 3.0533e-04, 1.2810e-04,\n",
      "        1.5122e-04, 0.0000e+00, 2.8581e-04, 8.7618e-03, 1.4532e-05, 0.0000e+00,\n",
      "        1.0740e-04, 3.2265e-04, 3.9301e-04, 1.8301e-04, 1.2370e-04, 0.0000e+00,\n",
      "        4.5634e-04, 1.4651e-05, 1.3540e-03, 7.2938e-04, 2.0420e-04, 1.3439e-03,\n",
      "        8.8494e-05, 0.0000e+00, 3.3476e-04, 7.8932e-06, 2.2645e-04, 1.0975e-04,\n",
      "        3.8917e-04, 1.3969e-04, 4.5168e-04, 4.9690e-04, 3.4995e-04, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0929, 0.0576, 0.0550, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522,\n",
      "        0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0522, 0.0551,\n",
      "        0.0581, 0.2175], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0632, 0.0578, 0.0586, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597,\n",
      "        0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0597, 0.0587,\n",
      "        0.0580, 0.0595], device='cuda:0') torch.Size([56])\n",
      "score tensor([6.6442e-04, 4.2174e-03, 6.8088e-03, 2.0169e-03, 1.3097e-02, 0.0000e+00,\n",
      "        1.6589e-04, 1.5179e-02, 1.7192e-03, 1.2147e-03, 0.0000e+00, 3.2143e-04,\n",
      "        2.4660e-03, 3.0125e-03, 4.2531e-03, 2.5678e-03, 2.3176e-08, 5.7961e-03,\n",
      "        1.7439e-03, 2.8081e-03, 7.0426e-05, 4.3377e-03, 3.5505e-03, 7.5497e-04,\n",
      "        2.5946e-03, 5.3912e-03, 2.3709e-03, 3.5204e-03, 2.1720e-03, 1.3273e-04,\n",
      "        6.7543e-03, 8.9609e-04, 2.6822e-03, 3.7706e-03, 3.0913e-03, 2.5290e-03,\n",
      "        2.6934e-03, 6.5049e-05, 3.4688e-03, 2.1489e-03, 4.8021e-03, 3.8761e-03,\n",
      "        4.6023e-05, 7.1323e-03, 7.4810e-03, 3.3002e-03, 3.5134e-03, 2.1284e-03,\n",
      "        3.4215e-03, 1.8869e-03, 4.6760e-03, 4.4040e-03, 3.3801e-02, 9.6786e-04,\n",
      "        1.0512e-03, 2.0367e-03, 2.8824e-03, 4.7415e-03, 0.0000e+00, 2.6054e-03,\n",
      "        3.1633e-04, 1.0997e-04, 2.5863e-03, 2.9005e-03, 1.2714e-03, 3.7026e-03,\n",
      "        3.9761e-03, 8.7920e-03, 1.7449e-03, 4.9377e-03, 4.6834e-03, 7.0173e-08,\n",
      "        7.3836e-04, 1.2476e-03, 1.8648e-03, 1.8448e-03, 1.6835e-03, 9.6715e-05,\n",
      "        4.0757e-03, 3.1098e-03, 9.5503e-03, 3.0235e-03, 3.4673e-04, 6.0244e-03,\n",
      "        2.0152e-03, 3.1148e-03, 1.4750e-03, 1.5805e-03, 1.6484e-03, 2.3807e-03,\n",
      "        2.2999e-03, 1.2437e-02, 2.4851e-03, 1.1322e-03, 2.1013e-04, 3.2665e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0260, 0.0228, 0.0168, 0.0168, 0.0154, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0152,\n",
      "        0.0152, 0.0152, 0.0152, 0.0152, 0.0152, 0.0153, 0.0154, 0.0174, 0.0167,\n",
      "        0.0243, 0.0369], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0373, 0.0385, 0.0360, 0.0359, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370,\n",
      "        0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0370, 0.0362, 0.0371,\n",
      "        0.0408, 0.0424], device='cuda:0') torch.Size([56])\n",
      "score tensor([1.8201e-03, 1.1953e-02, 1.6332e-02, 1.0135e-03, 1.2222e-03, 0.0000e+00,\n",
      "        9.3536e-03, 4.4624e-02, 1.0057e-02, 1.1856e-02, 0.0000e+00, 2.1293e-02,\n",
      "        1.6234e-05, 9.6559e-03, 1.2067e-02, 2.5830e-02, 6.8715e-04, 3.5942e-04,\n",
      "        7.6328e-03, 7.1265e-03, 1.7196e-02, 5.2343e-03, 1.7601e-02, 1.2012e-03,\n",
      "        1.5630e-02, 1.2315e-02, 5.6379e-04, 1.5887e-02, 2.0259e-02, 2.2281e-02,\n",
      "        1.1063e-02, 1.1138e-02, 9.1796e-03, 5.5287e-03, 1.7371e-02, 2.5715e-02,\n",
      "        7.0968e-02, 2.0869e-03, 4.2323e-02, 7.2269e-03, 1.8224e-02, 4.2371e-03,\n",
      "        6.2002e-03, 2.2582e-02, 2.1482e-02, 3.3565e-02, 2.1233e-02, 1.0036e-02,\n",
      "        1.2726e-02, 0.0000e+00, 4.7546e-03, 2.0495e-02, 2.8849e-03, 5.8231e-04,\n",
      "        1.0670e-02, 1.2585e-02, 9.1994e-03, 4.1080e-03, 7.7554e-02, 8.7774e-02,\n",
      "        4.1278e-03, 1.0450e-02, 8.5825e-03, 7.4389e-03, 3.4659e-02, 0.0000e+00,\n",
      "        1.4106e-02, 6.1953e-03, 1.9497e-02, 1.5249e-02, 4.2964e-03, 0.0000e+00,\n",
      "        1.6211e-02, 4.8179e-02, 0.0000e+00, 6.7259e-03, 1.0320e-02, 2.5877e-02,\n",
      "        8.0800e-03, 7.1173e-03, 3.5631e-02, 8.8223e-04, 3.0127e-02, 1.1762e-02,\n",
      "        1.0051e-02, 8.7778e-03, 6.4477e-03, 1.3240e-02, 1.3787e-02, 6.8265e-03,\n",
      "        1.5901e-02, 2.3535e-02, 1.2305e-03, 5.9870e-03, 3.0122e-04, 1.5314e-03],\n",
      "       device='cuda:0') torch.Size([96])\n",
      "score tensor([0.0677, 0.0524, 0.0383, 0.0329, 0.0351, 0.0348, 0.0341, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342, 0.0342,\n",
      "        0.0342, 0.0342, 0.0342, 0.0342, 0.0341, 0.0341, 0.0332, 0.0296, 0.0292,\n",
      "        0.0287, 0.0377], device='cuda:0') torch.Size([56])\n",
      "score tensor([0.0350, 0.0373, 0.0356, 0.0358, 0.0390, 0.0388, 0.0385, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387, 0.0387,\n",
      "        0.0387, 0.0387, 0.0387, 0.0387, 0.0386, 0.0389, 0.0391, 0.0364, 0.0371,\n",
      "        0.0352, 0.0413], device='cuda:0') torch.Size([56])\n",
      "score tensor([2.1250e-03, 3.1641e-06, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.3549e-03,\n",
      "        1.4051e-02, 6.6495e-02, 1.5951e-01, 0.0000e+00, 2.9916e-02, 8.9347e-02,\n",
      "        1.1387e-01, 7.3310e-02, 9.6059e-02, 1.8380e-04, 6.8377e-04, 7.5983e-04,\n",
      "        4.1027e-04, 5.2199e-02, 5.3224e-07, 1.4187e-01, 0.0000e+00, 4.8534e-03,\n",
      "        0.0000e+00, 1.0056e-01, 1.7630e-02, 1.3116e-01, 1.0220e-05, 0.0000e+00,\n",
      "        2.4030e-02, 9.4485e-05, 2.8883e-02, 2.2338e-05, 5.1729e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 2.8656e-05, 1.2600e-03, 4.4448e-03, 8.4249e-02,\n",
      "        1.2208e-02, 1.0365e-01, 0.0000e+00, 1.6119e-01, 6.2706e-04, 0.0000e+00,\n",
      "        1.6805e-03, 3.7975e-02, 0.0000e+00, 3.0407e-05, 0.0000e+00, 1.5388e-03,\n",
      "        1.0652e-02, 7.8128e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.7612e-02,\n",
      "        9.1774e-06, 0.0000e+00, 1.3563e-01, 0.0000e+00, 4.5076e-02, 1.5460e-02,\n",
      "        3.7007e-02, 0.0000e+00, 3.8308e-02, 0.0000e+00, 0.0000e+00, 2.3529e-02,\n",
      "        1.0126e-01, 7.4645e-05, 0.0000e+00, 0.0000e+00, 3.0436e-01, 5.1260e-01,\n",
      "        5.2831e-04, 1.2802e-01, 0.0000e+00, 4.3526e-03, 0.0000e+00, 0.0000e+00,\n",
      "        5.5922e-03, 7.0205e-02, 1.3235e-01, 0.0000e+00, 8.1418e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.6592e-03, 2.2746e+00, 1.0241e-01, 8.0940e-02, 0.0000e+00,\n",
      "        1.1053e-01, 3.6541e-02, 7.6549e-06, 1.1757e-03, 1.3681e-01, 8.1139e-02,\n",
      "        2.7346e-04, 1.5179e-01, 0.0000e+00, 1.5594e-01, 3.3839e-02, 1.2029e-02,\n",
      "        2.9469e-01, 0.0000e+00, 1.7261e-05, 0.0000e+00, 3.0063e-05, 0.0000e+00,\n",
      "        5.3294e-02, 8.4536e-02, 9.3722e-04, 1.2829e-02, 0.0000e+00, 9.6902e-04,\n",
      "        1.0758e-05, 9.3815e-04, 0.0000e+00, 4.8115e-04, 4.2528e-03, 2.5944e-05,\n",
      "        1.2047e-01, 0.0000e+00, 2.5061e-02, 8.9163e-05, 3.1186e-03, 3.2195e-01,\n",
      "        2.5566e-01, 5.8715e-03, 0.0000e+00, 2.8526e-02, 3.6987e-03, 3.2692e-06,\n",
      "        2.7234e-04, 2.4497e-02, 1.9821e-04, 1.4833e-01, 9.1543e-02, 0.0000e+00,\n",
      "        2.0457e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0787e-03, 3.4822e-04,\n",
      "        1.1057e-01, 6.0902e-04, 6.6985e-02, 2.2191e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.1348e-01, 1.9196e-03, 0.0000e+00, 1.4901e-01, 1.6753e-05,\n",
      "        3.5947e-02, 1.4364e-01, 2.7948e-01, 0.0000e+00, 1.3598e-03, 0.0000e+00,\n",
      "        0.0000e+00, 3.5900e-03, 0.0000e+00, 1.0359e-03, 2.2143e-02, 5.8714e-04,\n",
      "        1.1901e-02, 0.0000e+00, 2.6048e-03, 2.4130e-02, 1.1394e-03, 0.0000e+00,\n",
      "        6.3744e-03, 0.0000e+00, 3.4061e-03, 1.1123e-03, 1.4930e-01, 4.3058e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.8804e-04, 4.5933e-02, 3.1749e-02, 3.2862e-05],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([1.1398e-04, 4.7708e-03, 1.2853e-02, 5.2054e-04, 0.0000e+00, 1.0851e-03,\n",
      "        1.4297e-04, 8.1036e-04, 1.1764e-03, 4.2036e-06, 3.5694e-03, 0.0000e+00,\n",
      "        4.9244e-03, 2.2074e-05, 5.3207e-06, 1.4056e-04, 6.0984e-04, 7.5830e-04,\n",
      "        6.1275e-03, 1.3493e-04, 9.7206e-03, 4.2004e-05, 4.1519e-03, 4.8450e-03,\n",
      "        2.7574e-03, 8.6861e-05, 1.1847e-04, 0.0000e+00, 1.0745e-04, 9.9571e-04,\n",
      "        4.6017e-04, 2.4858e-02, 1.5393e-05, 1.6569e-03, 6.4316e-04, 2.9642e-03,\n",
      "        9.4376e-04, 1.4952e-02, 1.2886e-04, 4.5493e-07, 1.3504e-04, 4.8785e-03,\n",
      "        6.9863e-04, 1.2067e-03, 1.5495e-04, 3.2480e-03, 6.0674e-06, 3.2526e-02,\n",
      "        8.9191e-03, 5.2787e-05, 6.1864e-04, 3.8029e-04, 1.4021e-03, 2.0067e-04,\n",
      "        7.7498e-04, 3.4461e-03, 1.7967e-03, 2.7483e-04, 1.5815e-04, 3.2127e-02,\n",
      "        3.2051e-04, 3.7298e-03, 6.7843e-03, 2.6266e-04, 3.8136e-04, 2.0562e-03,\n",
      "        3.6438e-04, 2.2635e-03, 0.0000e+00, 1.8645e-02, 0.0000e+00, 2.3223e-05,\n",
      "        1.5041e-05, 9.5529e-05, 0.0000e+00, 1.1022e-03, 2.0979e-03, 4.7658e-03,\n",
      "        6.5896e-05, 7.9812e-04, 5.3670e-05, 2.3269e-02, 3.1270e-04, 6.1543e-04,\n",
      "        0.0000e+00, 2.9472e-04, 1.1604e-03, 2.8044e-03, 4.7813e-05, 4.0630e-03,\n",
      "        1.7346e-03, 1.4615e-02, 1.2362e-02, 1.6982e-03, 1.6581e-02, 0.0000e+00,\n",
      "        0.0000e+00, 5.3713e-03, 8.1687e-04, 0.0000e+00, 1.0709e-03, 0.0000e+00,\n",
      "        1.4239e-04, 3.3438e-02, 1.2497e-03, 1.0786e-04, 2.0330e-02, 1.1047e-03,\n",
      "        4.3298e-03, 2.2247e-03, 0.0000e+00, 0.0000e+00, 8.2172e-03, 1.2658e-04,\n",
      "        5.4252e-04, 1.2356e-03, 1.1873e-03, 1.1370e-06, 5.0737e-03, 4.0171e-03,\n",
      "        3.9690e-05, 2.3254e-04, 5.0354e-03, 0.0000e+00, 3.8263e-04, 1.3243e-04,\n",
      "        3.3230e-02, 2.3676e-03, 8.8254e-03, 1.6509e-02, 9.6839e-03, 1.1573e-03,\n",
      "        1.2999e-03, 7.4647e-04, 4.9026e-03, 4.7943e-04, 2.8784e-04, 8.1321e-04,\n",
      "        1.4185e-02, 1.1939e-02, 2.2381e-05, 4.6478e-04, 2.8349e-04, 8.0140e-05,\n",
      "        1.1773e-03, 1.4378e-02, 1.2813e-04, 1.1124e-03, 5.8977e-04, 4.7173e-03,\n",
      "        4.6463e-07, 3.0078e-03, 3.2807e-04, 4.8494e-03, 3.5239e-03, 0.0000e+00,\n",
      "        8.8148e-03, 1.8530e-03, 7.6473e-03, 1.9041e-04, 6.8844e-04, 1.3382e-04,\n",
      "        5.1625e-03, 1.2200e-03, 1.5350e-03, 0.0000e+00, 4.9860e-03, 2.4760e-02,\n",
      "        5.6660e-03, 5.9850e-06, 1.9886e-03, 1.0606e-03, 6.0488e-03, 2.1275e-03,\n",
      "        9.4599e-05, 3.1348e-04, 1.8316e-04, 3.4494e-03, 0.0000e+00, 2.5743e-04,\n",
      "        3.6949e-03, 7.7493e-06, 1.3794e-04, 2.1395e-03, 1.5456e-03, 7.7880e-04,\n",
      "        1.0849e-05, 1.7391e-05, 1.3524e-07, 4.1007e-03, 7.2610e-06, 4.1321e-03],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0170, 0.0141, 0.0117, 0.0112, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108,\n",
      "        0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0108, 0.0112, 0.0122, 0.0171,\n",
      "        0.0190], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0300, 0.0309, 0.0297, 0.0294, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292,\n",
      "        0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0292,\n",
      "        0.0292, 0.0292, 0.0292, 0.0292, 0.0292, 0.0291, 0.0292, 0.0303, 0.0338,\n",
      "        0.0323], device='cuda:0') torch.Size([28])\n",
      "score tensor([1.2822e-02, 1.5388e-04, 1.7542e-01, 0.0000e+00, 8.1747e-05, 1.1079e-03,\n",
      "        2.1358e-05, 2.7842e-06, 0.0000e+00, 4.2787e-02, 5.9599e-03, 0.0000e+00,\n",
      "        0.0000e+00, 9.8163e-03, 7.2272e-04, 5.2414e-04, 0.0000e+00, 2.0504e-03,\n",
      "        0.0000e+00, 2.5707e-04, 2.2552e-04, 7.9327e-05, 9.7219e-02, 7.4776e-04,\n",
      "        3.7142e-03, 0.0000e+00, 7.2798e-04, 0.0000e+00, 1.0853e-04, 7.4608e-04,\n",
      "        2.2975e-02, 1.0940e-04, 0.0000e+00, 2.7693e-02, 0.0000e+00, 1.3142e-02,\n",
      "        0.0000e+00, 3.8636e-02, 6.8152e-04, 8.9760e-03, 6.4065e-04, 1.7096e-03,\n",
      "        4.6669e-07, 0.0000e+00, 7.9368e-03, 0.0000e+00, 5.0859e-03, 3.2397e-02,\n",
      "        0.0000e+00, 2.9600e-03, 2.4231e-03, 1.3762e-02, 0.0000e+00, 1.0094e-04,\n",
      "        0.0000e+00, 3.2297e-02, 4.5528e-03, 3.2010e-02, 0.0000e+00, 1.2798e-03,\n",
      "        0.0000e+00, 8.3866e-06, 1.0675e-04, 0.0000e+00, 2.2208e-02, 5.5800e-06,\n",
      "        7.6584e-03, 0.0000e+00, 3.1666e-02, 4.7974e-05, 7.5318e-02, 8.7454e-05,\n",
      "        1.1764e-03, 0.0000e+00, 6.7835e-03, 0.0000e+00, 6.9392e-03, 3.0259e-04,\n",
      "        2.6940e-05, 1.0261e-04, 6.8576e-03, 0.0000e+00, 4.4101e-02, 1.9438e-03,\n",
      "        2.3622e-02, 1.6609e-04, 0.0000e+00, 0.0000e+00, 7.0736e-04, 3.3841e-04,\n",
      "        3.0459e-04, 1.0267e-03, 2.8238e-02, 1.5958e-04, 1.7340e-06, 1.2577e-02,\n",
      "        7.3481e-03, 9.4268e-05, 1.7361e-04, 0.0000e+00, 4.2074e-03, 3.8741e-04,\n",
      "        3.5795e-04, 2.2044e-06, 4.8092e-03, 1.3364e-02, 4.0164e-03, 3.3110e-03,\n",
      "        6.5631e-02, 4.5335e-04, 7.0436e-03, 9.0593e-03, 2.5654e-02, 0.0000e+00,\n",
      "        1.2611e-03, 1.1948e-02, 1.7847e-04, 3.3939e-04, 3.0702e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.8848e-02, 0.0000e+00, 0.0000e+00, 1.3224e-04, 5.8075e-03,\n",
      "        0.0000e+00, 3.7460e-04, 1.0521e-01, 3.8152e-04, 2.2624e-02, 4.7928e-04,\n",
      "        1.4597e-03, 1.9866e-02, 0.0000e+00, 4.8555e-02, 2.4622e-04, 5.5955e-04,\n",
      "        0.0000e+00, 0.0000e+00, 7.4639e-03, 1.5312e-03, 1.9397e-03, 2.0711e-03,\n",
      "        4.9414e-03, 0.0000e+00, 4.5460e-03, 0.0000e+00, 0.0000e+00, 1.4746e-03,\n",
      "        0.0000e+00, 2.3630e-05, 1.4651e-02, 1.9066e-03, 2.2127e-06, 0.0000e+00,\n",
      "        3.6122e-02, 1.3878e-02, 0.0000e+00, 2.4852e-03, 1.8051e-02, 0.0000e+00,\n",
      "        1.4990e-03, 1.6129e-03, 2.1192e-03, 1.9821e-03, 8.1403e-04, 0.0000e+00,\n",
      "        4.7232e-02, 9.8164e-07, 0.0000e+00, 3.8782e-02, 1.0382e-04, 2.3042e-02,\n",
      "        0.0000e+00, 1.7700e-06, 6.3670e-05, 0.0000e+00, 3.2516e-04, 0.0000e+00,\n",
      "        5.3431e-04, 9.0467e-03, 1.4388e-03, 0.0000e+00, 2.1793e-03, 0.0000e+00,\n",
      "        4.7829e-02, 4.1291e-02, 2.7325e-06, 2.4147e-06, 1.7621e-03, 5.2388e-02],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0552, 0.0377, 0.0333, 0.0326, 0.0330, 0.0335, 0.0337, 0.0338, 0.0338,\n",
      "        0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338, 0.0338,\n",
      "        0.0338, 0.0338, 0.0338, 0.0337, 0.0335, 0.0328, 0.0319, 0.0321, 0.0330,\n",
      "        0.0482], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0726, 0.0601, 0.0559, 0.0584, 0.0587, 0.0600, 0.0605, 0.0607, 0.0607,\n",
      "        0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607, 0.0607,\n",
      "        0.0607, 0.0607, 0.0607, 0.0606, 0.0601, 0.0587, 0.0581, 0.0566, 0.0553,\n",
      "        0.0664], device='cuda:0') torch.Size([28])\n",
      "score tensor([5.5413e-04, 6.8330e-03, 2.0432e-05, 5.0336e-04, 1.5844e-02, 3.9921e-04,\n",
      "        3.4608e-04, 0.0000e+00, 3.0729e-04, 8.2974e-03, 6.5116e-03, 2.6519e-03,\n",
      "        3.0610e-02, 4.3852e-02, 1.0570e-02, 3.3981e-04, 6.1594e-03, 3.4320e-04,\n",
      "        4.3444e-04, 1.6094e-06, 9.0837e-04, 1.5457e-03, 4.0368e-02, 6.6796e-05,\n",
      "        1.6516e-02, 1.2750e-04, 1.0239e-03, 6.5637e-03, 7.5800e-03, 4.2697e-03,\n",
      "        1.0639e-04, 0.0000e+00, 1.0236e-03, 3.8928e-04, 5.2788e-04, 7.4852e-03,\n",
      "        0.0000e+00, 9.4600e-02, 6.0816e-04, 5.9468e-03, 1.1103e-04, 3.5347e-03,\n",
      "        1.3342e-02, 0.0000e+00, 1.0830e-03, 2.0382e-05, 6.1601e-02, 2.5056e-05,\n",
      "        9.6671e-03, 7.9740e-03, 8.1990e-05, 6.5808e-05, 1.0823e-03, 1.6365e-03,\n",
      "        1.4503e-02, 2.0038e-03, 3.1397e-03, 3.9409e-03, 1.2166e-02, 7.6018e-03,\n",
      "        2.0354e-03, 4.0363e-02, 5.0881e-05, 1.1206e-04, 0.0000e+00, 0.0000e+00,\n",
      "        2.8651e-05, 4.6968e-03, 3.4266e-03, 9.1793e-04, 2.1662e-03, 1.1928e-02,\n",
      "        2.1372e-03, 3.2016e-02, 0.0000e+00, 1.3422e-03, 1.1529e-03, 2.1344e-03,\n",
      "        4.0395e-04, 0.0000e+00, 1.4230e-02, 1.0560e-04, 2.4957e-03, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 6.9636e-03, 2.6980e-04, 0.0000e+00,\n",
      "        0.0000e+00, 4.3649e-02, 2.8041e-03, 4.9503e-05, 0.0000e+00, 0.0000e+00,\n",
      "        5.5329e-04, 0.0000e+00, 4.8413e-02, 1.8805e-05, 7.8960e-04, 1.4648e-03,\n",
      "        1.4919e-02, 1.0736e-02, 0.0000e+00, 1.5621e-03, 1.4369e-03, 7.1651e-04,\n",
      "        4.2166e-07, 1.2695e-02, 3.6258e-03, 1.6923e-04, 1.9858e-03, 4.2114e-02,\n",
      "        4.1617e-04, 1.6579e-03, 0.0000e+00, 2.1062e-03, 0.0000e+00, 9.8010e-03,\n",
      "        7.5761e-05, 6.7155e-06, 0.0000e+00, 6.1723e-03, 1.0694e-03, 1.6106e-02,\n",
      "        1.1187e-02, 8.9274e-03, 7.0994e-04, 1.1703e-03, 1.3672e-03, 1.8904e-04,\n",
      "        2.3841e-03, 3.2589e-06, 1.5965e-03, 0.0000e+00, 1.5458e-03, 9.3663e-04,\n",
      "        4.1003e-03, 1.8531e-04, 4.2283e-02, 4.5336e-03, 4.2899e-05, 0.0000e+00,\n",
      "        5.9865e-05, 6.4761e-03, 4.0760e-02, 1.4530e-02, 4.3186e-04, 0.0000e+00,\n",
      "        8.9921e-04, 3.2293e-04, 2.6279e-04, 6.4053e-03, 1.0055e-06, 2.1881e-03,\n",
      "        1.1002e-02, 2.6266e-03, 1.3236e-03, 3.2389e-03, 6.9216e-06, 2.3727e-02,\n",
      "        9.0596e-04, 1.4073e-03, 5.6701e-05, 5.0390e-06, 4.9078e-04, 0.0000e+00,\n",
      "        0.0000e+00, 3.3891e-02, 4.0206e-04, 1.8996e-02, 1.4516e-02, 0.0000e+00,\n",
      "        8.8666e-03, 6.0496e-05, 0.0000e+00, 9.5113e-04, 5.2393e-03, 0.0000e+00,\n",
      "        1.1837e-03, 2.7810e-03, 0.0000e+00, 4.6149e-04, 2.3168e-04, 2.0603e-03,\n",
      "        0.0000e+00, 9.2794e-04, 8.3138e-03, 3.2302e-05, 2.3485e-05, 1.4717e-03],\n",
      "       device='cuda:0') torch.Size([192])\n",
      "score tensor([0.0187, 0.0237, 0.0192, 0.0179, 0.0193, 0.0188, 0.0190, 0.0192, 0.0194,\n",
      "        0.0194, 0.0194, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195, 0.0195,\n",
      "        0.0194, 0.0194, 0.0194, 0.0194, 0.0199, 0.0237, 0.0211, 0.0284, 0.0268,\n",
      "        0.0259], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0489, 0.0685, 0.0664, 0.0732, 0.0728, 0.0738, 0.0746, 0.0750, 0.0752,\n",
      "        0.0753, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754, 0.0754,\n",
      "        0.0754, 0.0754, 0.0753, 0.0750, 0.0748, 0.0749, 0.0721, 0.0751, 0.0575,\n",
      "        0.0532], device='cuda:0') torch.Size([28])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 5.9939e-02, 1.4309e-03, 1.0027e-01, 4.8641e-02,\n",
      "        6.5916e-03, 0.0000e+00, 1.2390e+00, 6.2512e-02, 4.3132e-02, 1.2420e-01,\n",
      "        1.7758e-02, 3.0780e-04, 0.0000e+00, 3.4033e-02, 0.0000e+00, 5.0831e-03,\n",
      "        0.0000e+00, 1.2698e-02, 4.0941e-04, 8.1152e-04, 1.2890e-03, 3.6835e-01,\n",
      "        1.0736e-01, 0.0000e+00, 6.9568e-02, 2.4073e-03, 4.1617e-02, 4.0763e-02,\n",
      "        2.7098e-02, 1.2543e-02, 1.6956e-03, 7.5609e-02, 5.1857e-02, 3.0407e-03,\n",
      "        1.3258e-01, 2.1829e-03, 6.6288e-03, 1.5926e-02, 7.1224e-02, 0.0000e+00,\n",
      "        3.3037e-02, 3.3585e-02, 0.0000e+00, 2.4734e-03, 7.1781e-05, 4.1354e-03,\n",
      "        2.1474e-04, 5.3668e-01, 1.5307e-02, 3.3986e-02, 1.5004e-02, 3.7625e-02,\n",
      "        4.7761e-04, 4.4108e-02, 0.0000e+00, 2.9319e-05, 5.4076e-01, 0.0000e+00,\n",
      "        7.3015e-02, 1.0927e-02, 1.2747e-01, 3.7130e-02, 2.8096e-02, 0.0000e+00,\n",
      "        0.0000e+00, 7.2544e-03, 2.4315e-02, 4.1096e-02, 2.5836e-02, 4.2162e-02,\n",
      "        0.0000e+00, 1.3818e-02, 6.4579e-03, 7.7382e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.5399e-05, 0.0000e+00, 1.6720e-02, 4.0701e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.9635e-02, 6.5796e-03, 4.2719e-02, 8.9107e-02, 3.0547e-06,\n",
      "        2.7840e-02, 1.2318e-01, 0.0000e+00, 2.3794e-02, 5.4032e-03, 1.2424e-02,\n",
      "        1.1559e-03, 4.6927e-04, 0.0000e+00, 0.0000e+00, 5.7728e-02, 9.9951e-06,\n",
      "        0.0000e+00, 0.0000e+00, 1.2745e-01, 0.0000e+00, 0.0000e+00, 1.6641e-02,\n",
      "        8.2857e-03, 4.0786e-02, 4.6745e-02, 7.7926e-03, 1.7212e-02, 0.0000e+00,\n",
      "        1.7010e-01, 2.9829e-02, 1.8263e-01, 4.6542e-02, 1.4895e-02, 3.2480e-02,\n",
      "        0.0000e+00, 7.3839e-03, 5.1982e-04, 3.5019e-02, 2.9117e-04, 0.0000e+00,\n",
      "        9.3821e-03, 5.9954e-03, 6.6747e-02, 2.8804e-03, 8.5007e-03, 0.0000e+00,\n",
      "        6.7314e-03, 1.5924e-02, 2.5119e-02, 1.1197e-01, 2.3941e-02, 1.3398e-02,\n",
      "        9.8055e-02, 0.0000e+00, 3.4514e-02, 0.0000e+00, 1.1831e-03, 0.0000e+00,\n",
      "        9.5380e-03, 5.4282e-04, 3.1455e-03, 0.0000e+00, 1.3040e-02, 2.0323e-03,\n",
      "        0.0000e+00, 1.0756e-03, 0.0000e+00, 8.7447e-02, 6.3563e-03, 0.0000e+00,\n",
      "        2.2283e-01, 2.5711e-04, 8.5837e-04, 0.0000e+00, 5.5984e-03, 2.5180e-03,\n",
      "        5.0748e-03, 0.0000e+00, 6.9174e-02, 5.5268e-03, 0.0000e+00, 0.0000e+00,\n",
      "        1.7101e-03, 0.0000e+00, 3.8029e-04, 3.4988e-02, 5.6030e-05, 6.8634e-03,\n",
      "        1.1994e-04, 5.2013e-02, 7.2985e-03, 4.8626e-03, 0.0000e+00, 1.0617e-03,\n",
      "        0.0000e+00, 8.0935e-05, 1.8486e-02, 5.4259e-02, 6.8909e-02, 1.4231e-03,\n",
      "        0.0000e+00, 8.9129e-04, 0.0000e+00, 2.4443e-03, 4.4216e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.9199e-03, 2.4851e-02, 2.2650e-02, 9.6908e-03, 6.6064e-02,\n",
      "        2.7041e-02, 3.1352e-01, 8.5635e-02, 1.9966e-02, 1.3417e-02, 3.0733e-02,\n",
      "        2.8351e-02, 5.6757e-02, 1.9236e-03, 0.0000e+00, 6.9152e-02, 0.0000e+00,\n",
      "        1.5910e-02, 1.1006e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.6106e-02,\n",
      "        5.2779e-03, 3.5424e-02, 0.0000e+00, 8.8567e-03, 1.1576e-02, 6.9350e-02,\n",
      "        3.1475e-03, 0.0000e+00, 5.0239e-02, 2.3555e-02, 4.2826e-03, 1.9418e-02,\n",
      "        3.6116e-03, 5.8238e-02, 2.2729e-04, 3.6831e-02, 1.5128e-03, 5.4066e-03,\n",
      "        1.0019e-02, 3.7981e-02, 2.2184e+00, 6.8897e-02, 0.0000e+00, 3.3698e-01,\n",
      "        5.2541e-03, 0.0000e+00, 2.5828e-06, 0.0000e+00, 9.8688e-06, 3.1989e-01,\n",
      "        2.3165e-02, 2.8681e-02, 9.0928e-03, 2.0590e-02, 1.2818e-03, 7.3104e-02,\n",
      "        1.1438e-01, 0.0000e+00, 5.2542e-02, 4.2370e-01, 0.0000e+00, 0.0000e+00,\n",
      "        2.0401e-02, 2.5091e-01, 0.0000e+00, 1.0394e-02, 0.0000e+00, 3.4031e-02,\n",
      "        2.2529e-02, 4.6920e-02, 8.3188e-02, 5.1544e-02, 1.7570e-02, 4.0793e-04,\n",
      "        0.0000e+00, 1.1200e-01, 2.4691e-02, 1.1567e-03, 1.4999e-03, 2.3040e-02,\n",
      "        3.2260e-02, 2.7740e-04, 1.0932e-03, 1.0773e-03, 1.3356e-04, 1.8627e-02,\n",
      "        5.4099e-03, 0.0000e+00, 9.2388e-02, 6.2580e-04, 2.4447e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.4963e-03, 0.0000e+00, 6.1041e-02, 0.0000e+00,\n",
      "        1.3946e-02, 8.2258e-05, 1.4412e-02, 0.0000e+00, 5.0635e-02, 2.2284e-01,\n",
      "        6.1962e-03, 8.1627e-02, 6.5597e-03, 0.0000e+00, 4.0545e-02, 4.8748e-03,\n",
      "        5.5871e-02, 2.9698e-02, 0.0000e+00, 5.3374e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 1.9877e-03, 7.9872e-02, 3.9953e-02, 1.8329e-05, 5.3370e-03,\n",
      "        3.4343e-03, 8.0117e-03, 0.0000e+00, 3.0698e-02, 1.8670e-04, 0.0000e+00,\n",
      "        4.0309e-02, 5.5036e-02, 1.1180e-02, 3.5491e-02, 0.0000e+00, 5.1335e-02,\n",
      "        9.6536e-02, 0.0000e+00, 6.5535e-02, 0.0000e+00, 2.6232e-06, 0.0000e+00,\n",
      "        0.0000e+00, 1.0001e-02, 6.9291e-02, 2.2234e-03, 1.6376e-01, 7.7700e-04,\n",
      "        4.0994e-02, 8.8364e-02, 3.3583e-03, 0.0000e+00, 2.6016e-02, 2.2681e-02,\n",
      "        4.9233e-02, 0.0000e+00, 3.9178e-02, 9.3144e-03, 0.0000e+00, 3.5825e-03,\n",
      "        5.4976e-03, 0.0000e+00, 7.8567e-03, 1.6480e-02, 8.9949e-03, 4.1107e-05,\n",
      "        4.3018e-02, 2.9189e-04, 5.5808e-03, 0.0000e+00, 1.6812e-03, 7.2220e-03,\n",
      "        9.7682e-03, 9.0559e-02, 1.4006e-03, 1.5341e-03, 2.2336e-04, 3.6217e-04,\n",
      "        1.1276e-02, 6.2781e-02, 0.0000e+00, 3.1922e-02, 3.5792e-02, 0.0000e+00,\n",
      "        0.0000e+00, 7.1726e-06, 8.1727e-02, 0.0000e+00, 2.0042e-03, 1.3470e-05],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([5.7125e-03, 1.2607e-03, 9.1151e-05, 0.0000e+00, 2.0622e-02, 1.0712e-03,\n",
      "        0.0000e+00, 9.6046e-05, 4.9116e-02, 4.8091e-04, 0.0000e+00, 1.5276e-03,\n",
      "        1.1440e-02, 0.0000e+00, 0.0000e+00, 1.9492e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.4408e-03, 1.2114e-04, 2.5482e-03, 8.8223e-03, 2.4755e-03, 1.6903e-02,\n",
      "        4.3950e-02, 3.9545e-05, 5.0666e-02, 1.4132e-02, 4.4898e-06, 7.5141e-03,\n",
      "        3.1656e-03, 1.9736e-03, 3.1743e-03, 1.9808e-03, 3.3505e-03, 1.7040e-04,\n",
      "        1.2176e-02, 0.0000e+00, 0.0000e+00, 4.3202e-03, 1.2111e-05, 3.0712e-04,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.5313e-06, 3.5532e-03, 2.7679e-05,\n",
      "        6.3935e-04, 2.4570e-04, 0.0000e+00, 5.0473e-04, 5.4964e-04, 5.6284e-03,\n",
      "        1.3735e-01, 0.0000e+00, 3.6311e-03, 2.0056e-04, 1.2449e-02, 0.0000e+00,\n",
      "        1.0162e-02, 0.0000e+00, 1.0325e-02, 1.0350e-02, 3.2303e-05, 1.0274e-02,\n",
      "        1.4586e-04, 1.4728e-03, 0.0000e+00, 1.3837e-03, 0.0000e+00, 0.0000e+00,\n",
      "        6.3964e-03, 0.0000e+00, 6.1285e-04, 0.0000e+00, 1.1992e-04, 0.0000e+00,\n",
      "        1.1274e-02, 7.1528e-04, 1.7521e-02, 3.7453e-05, 2.9709e-02, 3.4007e-05,\n",
      "        0.0000e+00, 2.7425e-04, 1.7770e-02, 1.3054e-02, 0.0000e+00, 3.5212e-02,\n",
      "        0.0000e+00, 8.2884e-03, 2.0899e-02, 5.1334e-03, 8.9995e-04, 0.0000e+00,\n",
      "        7.3090e-05, 0.0000e+00, 1.7742e-03, 2.5929e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.8768e-03, 0.0000e+00, 1.1170e-03, 1.9680e-02, 8.3362e-05, 0.0000e+00,\n",
      "        4.0408e-03, 8.5923e-04, 0.0000e+00, 2.8903e-03, 4.6467e-03, 5.9679e-04,\n",
      "        6.7584e-03, 0.0000e+00, 1.1843e-02, 4.9982e-04, 6.9943e-04, 1.1160e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.8320e-03, 8.0298e-05, 4.0204e-03,\n",
      "        5.3676e-03, 3.9472e-03, 7.8494e-03, 0.0000e+00, 0.0000e+00, 6.9861e-03,\n",
      "        0.0000e+00, 2.5432e-02, 0.0000e+00, 5.0532e-03, 2.1005e-03, 8.7459e-05,\n",
      "        0.0000e+00, 8.7627e-04, 0.0000e+00, 1.3555e-03, 0.0000e+00, 2.4638e-04,\n",
      "        9.8443e-04, 2.5472e-03, 9.4158e-06, 0.0000e+00, 1.7542e-02, 3.2168e-03,\n",
      "        1.9522e-02, 0.0000e+00, 1.3986e-03, 6.3272e-03, 2.9292e-03, 2.4728e-03,\n",
      "        6.5725e-03, 6.6802e-03, 7.0889e-05, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 3.7189e-02, 1.4569e-04, 0.0000e+00, 1.7224e-03, 5.0027e-03,\n",
      "        3.6220e-03, 0.0000e+00, 3.6017e-03, 1.8512e-04, 7.6791e-04, 1.0622e-02,\n",
      "        0.0000e+00, 2.3025e-03, 2.6488e-03, 3.6256e-05, 9.1798e-06, 0.0000e+00,\n",
      "        4.8312e-03, 2.2637e-02, 2.0247e-04, 0.0000e+00, 4.7766e-05, 1.7106e-02,\n",
      "        1.0155e-02, 6.9611e-04, 2.5413e-03, 1.0183e-03, 1.3670e-06, 0.0000e+00,\n",
      "        1.5863e-04, 7.5562e-03, 7.0913e-04, 0.0000e+00, 7.9979e-04, 1.0720e-03,\n",
      "        0.0000e+00, 0.0000e+00, 4.2877e-05, 1.9825e-02, 8.0252e-07, 1.5024e-05,\n",
      "        4.8428e-04, 0.0000e+00, 9.3134e-04, 8.5038e-06, 1.0228e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.5693e-04, 1.7827e-03, 8.5351e-03, 0.0000e+00, 1.4165e-05,\n",
      "        0.0000e+00, 1.5932e-05, 0.0000e+00, 0.0000e+00, 6.4898e-04, 9.2327e-03,\n",
      "        8.3661e-03, 2.3608e-04, 2.4220e-03, 3.7757e-06, 1.9317e-02, 3.4314e-03,\n",
      "        7.6608e-04, 1.1936e-04, 0.0000e+00, 1.1551e-02, 0.0000e+00, 7.4790e-03,\n",
      "        6.1151e-04, 1.0678e-03, 1.5910e-02, 8.1428e-05, 1.7744e-02, 2.2216e-03,\n",
      "        4.9887e-03, 0.0000e+00, 0.0000e+00, 1.6743e-05, 0.0000e+00, 6.7831e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.9671e-05, 5.3237e-03,\n",
      "        3.7971e-04, 2.4400e-02, 1.0646e-02, 3.1288e-03, 1.2967e-02, 2.3432e-02,\n",
      "        0.0000e+00, 1.0958e-02, 0.0000e+00, 1.0543e-03, 1.1333e-05, 0.0000e+00,\n",
      "        1.5402e-03, 8.3685e-04, 1.8014e-03, 0.0000e+00, 1.1920e-02, 2.0972e-03,\n",
      "        2.0185e-03, 1.2611e-02, 0.0000e+00, 2.6110e-05, 6.5749e-04, 3.1599e-03,\n",
      "        1.5204e-03, 1.5995e-03, 5.5611e-05, 1.0559e-03, 8.4016e-04, 8.6758e-05,\n",
      "        0.0000e+00, 0.0000e+00, 8.7813e-04, 0.0000e+00, 0.0000e+00, 2.3144e-03,\n",
      "        8.4532e-05, 2.3728e-03, 0.0000e+00, 6.9395e-05, 1.6949e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.2852e-03, 3.7883e-03, 1.9843e-02, 0.0000e+00, 7.0955e-03,\n",
      "        1.6243e-05, 1.0345e-02, 5.6562e-04, 4.1200e-04, 1.7934e-04, 1.8261e-04,\n",
      "        4.4127e-03, 0.0000e+00, 1.4013e-02, 0.0000e+00, 3.8851e-03, 0.0000e+00,\n",
      "        2.2591e-03, 2.5168e-02, 1.3308e-02, 1.7781e-03, 6.0263e-03, 0.0000e+00,\n",
      "        0.0000e+00, 3.2102e-04, 5.6538e-04, 1.7701e-04, 2.4468e-03, 3.6925e-04,\n",
      "        0.0000e+00, 2.7930e-03, 0.0000e+00, 3.4614e-04, 1.2609e-03, 4.0343e-04,\n",
      "        1.8535e-04, 1.8462e-03, 0.0000e+00, 6.5062e-03, 1.0207e-03, 1.4370e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.2308e-04, 1.3802e-03, 1.8356e-02, 0.0000e+00,\n",
      "        4.4950e-04, 8.3973e-06, 0.0000e+00, 7.1917e-04, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.4936e-03, 9.6255e-04, 3.1658e-04, 1.4495e-02, 1.5322e-03,\n",
      "        6.4198e-05, 5.6230e-04, 4.4231e-05, 6.0349e-04, 2.6837e-04, 4.9510e-04,\n",
      "        0.0000e+00, 0.0000e+00, 7.1808e-04, 0.0000e+00, 1.0748e-02, 3.0739e-05,\n",
      "        0.0000e+00, 0.0000e+00, 1.2292e-04, 0.0000e+00, 5.3514e-03, 3.4958e-02,\n",
      "        2.9561e-03, 1.1885e-03, 1.3908e-03, 2.0835e-04, 1.0890e-02, 2.0770e-02,\n",
      "        7.2944e-03, 0.0000e+00, 2.2378e-03, 2.7448e-03, 1.0027e-03, 2.2551e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0285, 0.0268, 0.0250, 0.0274, 0.0274, 0.0275, 0.0276, 0.0276, 0.0276,\n",
      "        0.0280, 0.0289, 0.0280, 0.0304, 0.0318], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0513, 0.0479, 0.0443, 0.0472, 0.0462, 0.0459, 0.0459, 0.0458, 0.0457,\n",
      "        0.0459, 0.0475, 0.0457, 0.0481, 0.0524], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 4.6745e-03, 2.6597e-04, 2.6717e-05, 0.0000e+00, 2.0946e-02,\n",
      "        0.0000e+00, 1.0664e-03, 3.2328e-02, 0.0000e+00, 0.0000e+00, 1.3169e-03,\n",
      "        2.8878e-02, 1.9358e-03, 0.0000e+00, 7.9156e-03, 1.9341e-02, 8.0617e-03,\n",
      "        4.8927e-05, 0.0000e+00, 4.1716e-03, 2.4092e-04, 6.2555e-03, 2.0531e-03,\n",
      "        3.4284e-03, 0.0000e+00, 2.7117e-02, 4.7614e-03, 4.6149e-04, 9.4217e-03,\n",
      "        1.7789e-02, 0.0000e+00, 0.0000e+00, 3.1835e-03, 1.6255e-04, 1.9513e-03,\n",
      "        1.9506e-03, 0.0000e+00, 2.2338e-02, 5.9406e-03, 3.3988e-03, 6.1774e-04,\n",
      "        4.0845e-04, 1.1829e-04, 3.8214e-05, 0.0000e+00, 1.4485e-05, 2.1258e-02,\n",
      "        0.0000e+00, 4.4967e-03, 2.1662e-03, 1.1694e-03, 4.0650e-03, 1.1209e-04,\n",
      "        3.7110e-03, 2.2200e-05, 1.0801e-03, 1.1807e-02, 6.1359e-02, 2.7224e-03,\n",
      "        2.7524e-02, 2.8121e-03, 1.1144e-02, 1.8534e-02, 8.2834e-05, 2.0431e-02,\n",
      "        1.1177e-03, 5.6134e-03, 0.0000e+00, 4.1671e-03, 1.0375e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 3.1840e-03, 0.0000e+00, 0.0000e+00, 2.5912e-03,\n",
      "        7.3365e-03, 3.4423e-04, 0.0000e+00, 1.1456e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.0217e-02, 6.4206e-03, 7.0376e-03, 0.0000e+00, 2.8415e-04, 1.1130e-04,\n",
      "        4.6423e-03, 8.1524e-03, 2.3881e-02, 7.2211e-05, 0.0000e+00, 1.5159e-02,\n",
      "        3.0108e-04, 1.0430e-05, 1.3174e-02, 1.3304e-02, 1.3476e-04, 0.0000e+00,\n",
      "        6.1122e-07, 3.6134e-02, 2.2869e-03, 1.3793e-02, 5.0233e-03, 0.0000e+00,\n",
      "        4.4869e-03, 3.1570e-02, 1.4572e-02, 1.3085e-03, 7.2458e-04, 6.4862e-03,\n",
      "        2.6861e-02, 1.1852e-02, 2.0519e-02, 5.9833e-04, 1.4038e-02, 3.2950e-03,\n",
      "        1.2249e-02, 2.7036e-03, 1.0181e-02, 3.8134e-04, 2.4904e-03, 3.1029e-03,\n",
      "        7.3449e-04, 2.6685e-03, 0.0000e+00, 4.3607e-04, 0.0000e+00, 8.9997e-04,\n",
      "        2.6799e-04, 1.3063e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.1068e-04,\n",
      "        2.5750e-02, 2.2846e-06, 3.3831e-04, 0.0000e+00, 6.7338e-04, 2.1899e-02,\n",
      "        8.6071e-04, 1.5713e-02, 3.9733e-04, 1.0045e-02, 6.6497e-05, 1.4681e-02,\n",
      "        0.0000e+00, 1.7921e-03, 6.3228e-03, 3.8396e-03, 3.4047e-03, 1.8055e-03,\n",
      "        1.9728e-02, 0.0000e+00, 1.7048e-03, 1.3336e-02, 4.7503e-05, 6.9176e-05,\n",
      "        8.0599e-04, 8.6580e-03, 1.1714e-03, 3.6999e-05, 3.0691e-02, 1.9296e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.3476e-02, 1.4999e-02, 1.7978e-05, 0.0000e+00,\n",
      "        1.4901e-03, 3.4628e-06, 5.9802e-04, 8.1351e-07, 3.1071e-04, 0.0000e+00,\n",
      "        5.5287e-04, 3.0620e-03, 3.6025e-05, 7.1813e-04, 5.8363e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 4.3087e-03, 7.2932e-03, 1.6007e-02, 7.3673e-03,\n",
      "        5.6059e-03, 2.6953e-02, 2.1821e-03, 4.3543e-02, 0.0000e+00, 2.5933e-03,\n",
      "        1.3671e-02, 1.2803e-02, 8.1155e-03, 3.3397e-03, 0.0000e+00, 3.2248e-04,\n",
      "        1.0330e-07, 2.0373e-02, 2.7790e-03, 2.6782e-02, 7.8897e-02, 2.4596e-02,\n",
      "        2.4166e-02, 8.2353e-03, 1.1187e-03, 4.4246e-03, 7.2238e-03, 6.2135e-03,\n",
      "        2.1861e-04, 5.7809e-04, 2.6853e-04, 1.2292e-02, 2.7085e-04, 1.0133e-02,\n",
      "        2.3530e-04, 1.1033e-03, 3.7287e-03, 4.6723e-04, 5.8914e-04, 1.7463e-03,\n",
      "        1.8697e-03, 6.6236e-05, 0.0000e+00, 0.0000e+00, 8.8786e-05, 8.6022e-05,\n",
      "        6.2103e-04, 1.8165e-03, 8.0932e-02, 9.5162e-04, 9.2355e-03, 5.0575e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9287e-06, 1.3486e-03, 0.0000e+00, 7.0314e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.5304e-02, 3.2588e-03, 2.2743e-04, 2.7346e-03,\n",
      "        1.9287e-03, 2.4664e-02, 1.1320e-03, 1.4079e-02, 3.0632e-03, 0.0000e+00,\n",
      "        3.1815e-03, 1.6891e-04, 7.5444e-05, 5.7147e-03, 5.1613e-03, 2.0813e-03,\n",
      "        1.2746e-02, 0.0000e+00, 0.0000e+00, 3.0653e-02, 4.1010e-03, 0.0000e+00,\n",
      "        2.0897e-04, 1.5309e-02, 2.7911e-03, 2.8494e-04, 4.0578e-03, 0.0000e+00,\n",
      "        7.1999e-03, 6.4295e-05, 6.1889e-02, 6.5530e-04, 9.7356e-03, 5.7994e-03,\n",
      "        0.0000e+00, 2.4270e-02, 3.5449e-04, 2.5063e-05, 0.0000e+00, 0.0000e+00,\n",
      "        8.7292e-06, 3.5487e-03, 1.0471e-02, 7.9731e-03, 1.2049e-02, 6.4458e-04,\n",
      "        6.8623e-03, 4.2847e-03, 4.6301e-05, 2.6903e-02, 3.9952e-03, 4.9840e-03,\n",
      "        3.1645e-05, 7.8987e-03, 3.0482e-03, 4.3564e-03, 0.0000e+00, 2.5203e-04,\n",
      "        6.4148e-03, 3.3204e-02, 2.1345e-05, 2.8447e-03, 0.0000e+00, 6.2561e-03,\n",
      "        2.9820e-03, 3.7249e-05, 6.3659e-04, 8.0041e-03, 3.9439e-04, 4.4365e-03,\n",
      "        4.4582e-03, 7.6291e-05, 1.3007e-02, 1.0691e-03, 1.6678e-03, 1.7513e-03,\n",
      "        1.0440e-02, 1.5539e-02, 1.0992e-02, 0.0000e+00, 0.0000e+00, 1.6875e-02,\n",
      "        9.2300e-03, 8.8064e-05, 1.0245e-03, 0.0000e+00, 1.2908e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.3878e-03, 3.6739e-05, 2.9997e-03, 7.2364e-03, 0.0000e+00,\n",
      "        1.6247e-03, 1.6531e-02, 1.5070e-03, 2.7541e-05, 6.4449e-05, 4.6371e-03,\n",
      "        0.0000e+00, 9.0442e-03, 1.0567e-03, 0.0000e+00, 8.0521e-03, 3.4868e-05,\n",
      "        1.3697e-03, 6.6510e-03, 5.8345e-04, 0.0000e+00, 5.8541e-03, 1.6770e-04,\n",
      "        1.8458e-04, 1.4252e-02, 2.7422e-03, 8.1324e-04, 7.4996e-04, 1.0527e-03,\n",
      "        5.4143e-04, 7.7863e-06, 0.0000e+00, 1.0961e-04, 2.2530e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.1457e-03, 8.0208e-05, 6.7151e-05, 0.0000e+00, 4.3559e-03,\n",
      "        0.0000e+00, 1.3253e-02, 2.7569e-02, 8.8086e-03, 8.4187e-03, 6.3316e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0211, 0.0143, 0.0141, 0.0131, 0.0148, 0.0144, 0.0156, 0.0154, 0.0140,\n",
      "        0.0136, 0.0132, 0.0139, 0.0165, 0.0174], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0494, 0.0368, 0.0362, 0.0354, 0.0356, 0.0354, 0.0367, 0.0363, 0.0350,\n",
      "        0.0347, 0.0342, 0.0362, 0.0388, 0.0498], device='cuda:0') torch.Size([14])\n",
      "score tensor([4.4557e-03, 5.4947e-03, 5.5124e-03, 1.4664e-03, 5.0942e-03, 2.2741e-03,\n",
      "        9.9161e-04, 8.4766e-03, 3.9167e-02, 2.3999e-03, 8.6893e-03, 7.3236e-03,\n",
      "        5.3546e-03, 4.6143e-04, 3.1448e-03, 7.6715e-03, 2.9346e-03, 1.9472e-03,\n",
      "        8.1154e-02, 2.9176e-03, 1.6562e-03, 5.5000e-03, 1.3538e-03, 1.4821e-03,\n",
      "        5.0774e-03, 2.8379e-03, 3.9478e-03, 5.1609e-03, 1.2222e-02, 1.5644e-03,\n",
      "        8.5693e-06, 2.3580e-03, 1.1008e-02, 1.9227e-02, 3.3948e-02, 3.3086e-03,\n",
      "        3.1721e-03, 3.1059e-03, 7.0120e-03, 5.3150e-03, 2.9119e-03, 1.1136e-03,\n",
      "        4.2727e-03, 2.6573e-03, 2.9058e-03, 1.9495e-03, 4.7448e-03, 5.7283e-03,\n",
      "        4.3896e-03, 7.5025e-02, 2.3113e-03, 5.3954e-03, 4.4692e-03, 6.3506e-03,\n",
      "        3.0917e-02, 4.8740e-03, 8.7453e-03, 3.7310e-03, 0.0000e+00, 3.7457e-03,\n",
      "        7.4415e-03, 7.6675e-04, 5.6517e-03, 5.4661e-03, 8.6256e-04, 4.9694e-03,\n",
      "        4.2654e-03, 1.6886e-03, 4.8779e-03, 6.3019e-02, 1.6855e-03, 6.3362e-03,\n",
      "        1.0148e-04, 2.5674e-03, 4.1521e-03, 6.8664e-03, 6.6675e-03, 1.5161e-02,\n",
      "        3.3973e-04, 4.2321e-03, 0.0000e+00, 5.3253e-03, 3.3636e-03, 7.6979e-03,\n",
      "        1.0069e-02, 0.0000e+00, 4.0879e-02, 1.9284e-03, 8.9011e-03, 3.0536e-03,\n",
      "        4.8379e-03, 7.3128e-02, 0.0000e+00, 1.4199e-03, 6.6803e-04, 2.6927e-03,\n",
      "        5.1197e-03, 0.0000e+00, 5.3841e-03, 3.0998e-03, 5.6694e-03, 1.5687e-02,\n",
      "        5.2377e-03, 3.4630e-02, 5.7868e-03, 2.4535e-03, 5.4920e-03, 1.7476e-05,\n",
      "        1.5788e-03, 7.8130e-03, 8.8914e-02, 1.0430e-02, 6.7769e-05, 3.4713e-03,\n",
      "        0.0000e+00, 2.8634e-03, 1.0292e-02, 1.2277e-03, 6.8624e-04, 2.6932e-03,\n",
      "        5.3409e-03, 0.0000e+00, 1.0143e-03, 8.1865e-03, 5.6125e-03, 6.2648e-03,\n",
      "        5.3250e-03, 5.1486e-03, 0.0000e+00, 1.7400e-03, 6.7085e-03, 1.2627e-02,\n",
      "        5.0952e-03, 5.9216e-04, 1.9703e-03, 5.4687e-03, 5.5371e-03, 4.8949e-03,\n",
      "        7.5712e-03, 7.2030e-03, 2.8801e-03, 7.2323e-03, 2.7032e-03, 5.6510e-03,\n",
      "        3.3768e-03, 4.3548e-03, 4.3028e-03, 6.2069e-03, 3.5787e-03, 4.9272e-02,\n",
      "        6.7589e-02, 2.0905e-03, 8.1806e-03, 0.0000e+00, 4.6824e-03, 6.1190e-03,\n",
      "        0.0000e+00, 4.0100e-03, 2.5969e-02, 0.0000e+00, 5.6219e-03, 5.5368e-03,\n",
      "        2.0169e-03, 5.0771e-03, 1.4772e-03, 8.0760e-03, 2.5446e-03, 2.6974e-03,\n",
      "        1.1790e-03, 2.2984e-03, 8.5244e-04, 2.1158e-03, 5.3251e-04, 5.0297e-03,\n",
      "        3.2858e-03, 2.9728e-03, 2.0506e-03, 4.2531e-03, 6.1230e-03, 4.3518e-03,\n",
      "        2.1743e-03, 7.7757e-02, 7.2028e-03, 2.5072e-03, 2.5733e-03, 4.1414e-03,\n",
      "        6.8577e-03, 4.4448e-03, 4.1760e-03, 2.9233e-03, 6.4134e-03, 4.9301e-03,\n",
      "        8.6453e-03, 1.1907e-02, 1.3578e-03, 7.6980e-03, 3.6179e-03, 1.1474e-03,\n",
      "        3.4168e-03, 0.0000e+00, 3.0775e-04, 3.9459e-02, 2.5067e-04, 3.7831e-03,\n",
      "        1.4480e-03, 3.6651e-04, 6.8080e-03, 1.6154e-02, 1.9773e-02, 2.2155e-03,\n",
      "        3.0109e-03, 7.4544e-03, 2.1323e-02, 3.2288e-03, 1.2542e-02, 0.0000e+00,\n",
      "        1.2562e-03, 3.2509e-03, 2.4992e-03, 2.7707e-03, 2.4566e-04, 2.0630e-02,\n",
      "        5.5301e-04, 6.6474e-03, 1.7403e-03, 4.8011e-03, 1.1987e-03, 2.4143e-04,\n",
      "        2.1748e-03, 1.1981e-03, 1.2598e-03, 3.8612e-03, 2.3702e-03, 2.6128e-03,\n",
      "        3.3157e-03, 8.4045e-03, 3.2781e-02, 0.0000e+00, 5.4057e-04, 3.8763e-02,\n",
      "        6.4455e-04, 1.0948e-02, 1.6593e-03, 5.6094e-03, 4.4996e-04, 0.0000e+00,\n",
      "        0.0000e+00, 1.7265e-03, 1.7207e-03, 4.1648e-03, 6.5666e-03, 4.1382e-03,\n",
      "        3.0134e-03, 6.4426e-03, 1.5090e-03, 1.2966e-02, 4.1092e-03, 0.0000e+00,\n",
      "        2.8643e-03, 0.0000e+00, 2.8252e-03, 4.4207e-03, 4.9882e-03, 3.3149e-03,\n",
      "        1.6640e-02, 8.3129e-03, 4.6418e-02, 3.8658e-03, 0.0000e+00, 2.8503e-03,\n",
      "        5.4100e-03, 6.4783e-03, 3.8287e-03, 2.4342e-03, 5.0570e-03, 1.9990e-03,\n",
      "        3.4901e-03, 1.0138e-03, 0.0000e+00, 9.6978e-04, 8.7815e-03, 2.4300e-03,\n",
      "        3.9000e-03, 5.5206e-02, 5.2052e-03, 0.0000e+00, 5.2654e-03, 2.4026e-03,\n",
      "        4.5757e-03, 2.3685e-02, 2.4603e-02, 2.9497e-03, 9.9581e-03, 5.2037e-03,\n",
      "        1.6026e-03, 1.6334e-02, 1.6030e-03, 1.9452e-02, 1.0067e-02, 5.3757e-03,\n",
      "        1.1749e-04, 1.6475e-03, 6.5999e-03, 0.0000e+00, 0.0000e+00, 1.4585e-02,\n",
      "        1.0489e-02, 7.0810e-03, 1.8975e-03, 1.2927e-03, 3.3233e-03, 3.8138e-03,\n",
      "        5.9912e-03, 4.2486e-03, 9.0713e-03, 1.6758e-03, 1.0004e-03, 1.6475e-02,\n",
      "        9.5293e-04, 3.2775e-03, 0.0000e+00, 1.4551e-02, 1.4081e-03, 1.7764e-03,\n",
      "        4.6463e-06, 4.2015e-03, 2.9649e-03, 1.5799e-03, 2.8096e-03, 6.1725e-02,\n",
      "        1.4404e-02, 4.3846e-03, 1.0490e-03, 2.4966e-03, 3.0498e-03, 8.3430e-04,\n",
      "        1.0693e-02, 1.8782e-03, 5.7117e-04, 3.0295e-03, 1.0537e-02, 7.2160e-04,\n",
      "        1.7039e-03, 7.1719e-04, 1.7242e-03, 2.6511e-03, 6.9537e-03, 4.2655e-03,\n",
      "        3.8905e-03, 1.9634e-02, 6.9369e-03, 2.1338e-03, 3.0847e-02, 3.1493e-03,\n",
      "        1.2812e-03, 3.6454e-03, 1.5766e-03, 1.8116e-03, 4.6335e-03, 9.2601e-04,\n",
      "        5.6415e-03, 3.6132e-03, 8.7068e-04, 1.4302e-03, 1.4936e-04, 3.6785e-03,\n",
      "        9.2214e-04, 4.7115e-03, 2.2817e-02, 8.7129e-03, 3.4223e-03, 1.0440e-03,\n",
      "        5.0372e-03, 7.0065e-03, 1.9830e-03, 3.6822e-03, 6.5570e-03, 7.4150e-03,\n",
      "        6.5066e-03, 5.2277e-03, 8.6263e-03, 1.7035e-03, 5.2685e-04, 8.0637e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0112, 0.0103, 0.0108, 0.0123, 0.0122, 0.0126, 0.0127, 0.0128, 0.0130,\n",
      "        0.0125, 0.0122, 0.0111, 0.0103, 0.0103], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0386, 0.0338, 0.0336, 0.0352, 0.0348, 0.0347, 0.0353, 0.0355, 0.0354,\n",
      "        0.0354, 0.0354, 0.0343, 0.0345, 0.0398], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 2.6689e-03, 2.5336e-02, 8.3615e-04, 1.9458e-02, 7.4745e-04,\n",
      "        1.7481e-02, 4.2833e-02, 4.6842e-02, 1.8717e-04, 1.0158e-01, 4.2858e-03,\n",
      "        4.8560e-04, 4.9385e-03, 1.8597e-03, 2.2003e-02, 5.4729e-03, 1.9183e-03,\n",
      "        7.4352e-03, 7.9635e-03, 1.2384e-02, 8.4327e-02, 5.3830e-02, 0.0000e+00,\n",
      "        1.1848e-02, 0.0000e+00, 0.0000e+00, 1.3931e-02, 8.2363e-02, 1.9356e-03,\n",
      "        1.5403e-04, 1.6508e-02, 1.2750e-03, 4.9081e-02, 1.2092e-03, 2.4771e-02,\n",
      "        6.2458e-02, 2.8474e-02, 2.4604e-02, 0.0000e+00, 4.5405e-03, 1.1369e-02,\n",
      "        9.3954e-04, 1.8424e-03, 6.5185e-03, 6.2110e-04, 5.8982e-03, 1.0174e-01,\n",
      "        1.6863e-02, 1.0556e-02, 0.0000e+00, 1.2181e-02, 1.6299e-04, 9.5049e-03,\n",
      "        2.1542e-02, 3.0415e-02, 1.6511e-01, 1.0471e-04, 2.5972e-02, 4.2119e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.8260e-02, 1.3484e-02, 6.8043e-02, 3.7766e-04,\n",
      "        2.6542e-03, 7.9632e-03, 2.7912e-02, 4.2929e-02, 0.0000e+00, 3.9534e-02,\n",
      "        1.1538e-02, 1.3426e-02, 2.9524e-03, 0.0000e+00, 3.7379e-02, 3.2841e-02,\n",
      "        0.0000e+00, 4.6464e-02, 2.0827e-01, 3.4753e-02, 0.0000e+00, 1.4731e-03,\n",
      "        1.6923e-03, 9.3103e-03, 5.4403e-04, 2.9668e-02, 9.4968e-03, 1.2867e-02,\n",
      "        0.0000e+00, 1.7300e-02, 2.2010e-02, 1.3531e-02, 3.1216e-02, 2.9723e-03,\n",
      "        0.0000e+00, 1.2760e-02, 2.5466e-02, 7.7356e-03, 1.2493e-02, 2.5327e-02,\n",
      "        0.0000e+00, 0.0000e+00, 6.9203e-02, 6.3480e-03, 3.9787e-03, 3.3802e-02,\n",
      "        8.5286e-02, 3.7372e-02, 1.4002e-02, 3.6718e-02, 2.1643e-02, 3.9246e-02,\n",
      "        5.0768e-02, 3.0069e-02, 2.2603e-02, 1.3187e-01, 2.8959e-02, 5.8008e-02,\n",
      "        1.4267e-02, 1.4711e-02, 3.1737e-04, 1.3629e-03, 2.5704e-02, 3.6547e-02,\n",
      "        7.9408e-04, 4.4466e-03, 0.0000e+00, 5.1627e-04, 1.3215e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.3806e-04, 0.0000e+00, 4.6132e-02, 2.4613e-02, 8.2743e-03,\n",
      "        0.0000e+00, 3.8323e-02, 5.1955e-04, 2.0915e-02, 4.3322e-04, 0.0000e+00,\n",
      "        8.6459e-03, 1.5365e-02, 2.7464e-02, 0.0000e+00, 1.5052e-02, 2.3854e-02,\n",
      "        1.2147e-01, 5.1010e-04, 5.0755e-03, 6.6018e-02, 8.4173e-03, 2.7793e-02,\n",
      "        0.0000e+00, 1.1236e-01, 7.1203e-03, 3.4227e-01, 4.9300e-02, 5.2812e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.6944e-02, 4.2151e-02, 4.9672e-02, 3.2431e-02,\n",
      "        1.1574e-02, 1.1197e-02, 5.8115e-03, 0.0000e+00, 2.5398e-02, 2.5671e-04,\n",
      "        1.0572e-04, 2.7758e-02, 2.5662e-03, 1.2152e-02, 2.1727e-02, 9.2462e-02,\n",
      "        2.5600e-04, 1.6209e-02, 5.7773e-03, 3.2391e-02, 1.3195e-02, 0.0000e+00,\n",
      "        2.4131e-02, 4.4236e-02, 1.4625e-02, 0.0000e+00, 0.0000e+00, 3.8061e-04,\n",
      "        0.0000e+00, 1.8903e-01, 0.0000e+00, 4.0356e-02, 2.4001e-02, 1.2609e-02,\n",
      "        1.2749e-02, 2.7808e-02, 1.5095e-02, 6.4214e-04, 1.3059e-03, 2.5149e-02,\n",
      "        2.0559e-02, 2.8884e-02, 4.0045e-02, 0.0000e+00, 4.6177e-02, 1.2497e-02,\n",
      "        2.9941e-02, 0.0000e+00, 8.2987e-02, 5.0506e-03, 4.4823e-02, 0.0000e+00,\n",
      "        2.4865e-02, 5.0060e-02, 4.9062e-02, 1.2662e-03, 6.2416e-02, 1.9856e-03,\n",
      "        2.6742e-02, 7.6265e-03, 0.0000e+00, 6.0419e-02, 3.5644e-04, 4.5404e-03,\n",
      "        3.5126e-02, 0.0000e+00, 1.5517e-03, 2.8533e-02, 2.2139e-03, 1.2890e-03,\n",
      "        2.6526e-02, 2.8783e-02, 1.5379e-02, 2.5924e-05, 4.3656e-03, 0.0000e+00,\n",
      "        3.1559e-03, 1.8942e-02, 1.7868e-02, 8.3266e-03, 0.0000e+00, 6.4803e-02,\n",
      "        9.5841e-03, 2.9461e-02, 1.5694e-02, 6.2291e-03, 0.0000e+00, 1.3331e-02,\n",
      "        9.2468e-02, 0.0000e+00, 1.0965e-02, 5.9389e-03, 0.0000e+00, 6.7797e-02,\n",
      "        2.3708e-02, 1.5262e-01, 0.0000e+00, 1.9873e-02, 1.2909e-06, 4.4037e-02,\n",
      "        1.7762e-02, 0.0000e+00, 2.8740e-02, 3.8076e-02, 2.1083e-03, 1.8048e-04,\n",
      "        3.2053e-04, 7.3038e-02, 0.0000e+00, 2.6590e-03, 1.0868e-02, 1.5882e-02,\n",
      "        1.0233e-02, 3.6876e-05, 0.0000e+00, 9.5398e-03, 0.0000e+00, 0.0000e+00,\n",
      "        5.2205e-05, 0.0000e+00, 6.2993e-03, 3.0867e-02, 5.0105e-03, 9.5083e-02,\n",
      "        1.1607e-03, 9.2571e-02, 4.8152e-03, 1.0181e-02, 0.0000e+00, 3.4635e-02,\n",
      "        2.4883e-03, 5.7265e-02, 8.4603e-03, 8.8665e-04, 9.4024e-02, 3.9247e-02,\n",
      "        2.5660e-02, 3.0419e-02, 4.7998e-03, 9.0142e-02, 0.0000e+00, 8.0658e-03,\n",
      "        9.8969e-02, 3.1879e-02, 4.7361e-02, 1.9952e-02, 0.0000e+00, 4.1888e-04,\n",
      "        1.7475e-05, 3.2284e-04, 1.5510e-02, 8.1034e-03, 1.1179e-03, 8.2994e-05,\n",
      "        5.7973e-02, 4.1771e-03, 3.8456e-02, 0.0000e+00, 2.1142e-02, 2.1451e-03,\n",
      "        1.5174e-02, 1.2404e-02, 0.0000e+00, 0.0000e+00, 3.5776e-04, 0.0000e+00,\n",
      "        5.7078e-02, 5.6767e-03, 2.3517e-02, 5.9321e-02, 3.6584e-02, 4.5578e-02,\n",
      "        2.7149e-03, 7.1914e-05, 1.2363e-02, 2.8732e-03, 0.0000e+00, 3.8089e-02,\n",
      "        2.3903e-02, 2.7742e-02, 0.0000e+00, 3.8504e-03, 2.6159e-02, 1.6124e-02,\n",
      "        5.8100e-03, 0.0000e+00, 1.9921e-02, 6.8734e-02, 2.7792e-02, 1.1021e-04,\n",
      "        0.0000e+00, 0.0000e+00, 1.0046e-02, 2.5809e-03, 0.0000e+00, 1.9423e-02,\n",
      "        2.3542e-02, 0.0000e+00, 4.9490e-03, 3.2016e-03, 6.4935e-03, 2.1264e-02,\n",
      "        9.3415e-02, 4.9732e-04, 6.4118e-03, 1.2864e-04, 6.5626e-02, 1.4158e-02,\n",
      "        5.8824e-03, 5.8854e-03, 0.0000e+00, 3.4105e-02, 1.6355e-03, 1.0190e-02,\n",
      "        6.8399e-04, 3.5320e-05, 2.9544e-02, 1.5293e-02, 2.9226e-02, 1.2577e-01],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0191, 0.0192, 0.0226, 0.0256, 0.0263, 0.0268, 0.0264, 0.0265, 0.0268,\n",
      "        0.0266, 0.0252, 0.0222, 0.0200, 0.0179], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0389, 0.0375, 0.0382, 0.0408, 0.0395, 0.0405, 0.0403, 0.0409, 0.0416,\n",
      "        0.0408, 0.0424, 0.0401, 0.0410, 0.0423], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 1.2695e-02, 4.1139e-03, 4.0144e-03, 5.0402e-02, 3.0981e-02,\n",
      "        1.3109e-02, 1.4703e-02, 6.3367e-02, 4.6618e-03, 1.1496e-03, 1.6106e-02,\n",
      "        8.3149e-03, 3.9773e-03, 6.6425e-03, 6.3571e-03, 0.0000e+00, 4.3011e-04,\n",
      "        2.6972e-02, 6.9600e-04, 2.4752e-03, 2.2531e-03, 2.8793e-02, 3.3077e-02,\n",
      "        1.1936e-02, 1.3995e-03, 1.6271e-02, 1.5300e-02, 1.4273e-02, 4.1360e-06,\n",
      "        2.9705e-03, 1.4091e-02, 3.3365e-02, 1.4812e-05, 2.9477e-03, 1.2447e-02,\n",
      "        2.1707e-02, 1.8362e-02, 4.7117e-03, 1.1928e-02, 8.0865e-03, 2.2891e-02,\n",
      "        3.6897e-03, 5.3855e-03, 5.4203e-03, 0.0000e+00, 4.3925e-03, 0.0000e+00,\n",
      "        1.0600e-03, 1.6817e-02, 1.1089e-03, 8.5972e-05, 1.7863e-03, 8.9439e-02,\n",
      "        3.3413e-03, 9.6029e-07, 0.0000e+00, 3.8683e-03, 1.2463e-02, 3.1487e-02,\n",
      "        1.1270e-02, 0.0000e+00, 4.8812e-02, 1.8501e-02, 4.9424e-03, 2.4499e-02,\n",
      "        2.6720e-02, 1.1121e-04, 8.8108e-03, 0.0000e+00, 1.4452e-02, 5.6405e-06,\n",
      "        1.1827e-03, 1.4418e-03, 3.0254e-03, 5.1742e-03, 4.3004e-03, 0.0000e+00,\n",
      "        2.2609e-02, 3.1814e-02, 1.1832e-01, 2.5572e-02, 6.3627e-04, 1.6753e-03,\n",
      "        1.0000e-02, 4.1955e-03, 1.9317e-02, 1.6068e-02, 7.4428e-03, 2.5641e-03,\n",
      "        2.8307e-03, 2.3880e-03, 6.5279e-04, 2.5148e-02, 5.0386e-03, 1.2288e-02,\n",
      "        1.1265e-02, 1.0064e-02, 8.1882e-03, 1.9966e-02, 8.9576e-03, 1.3042e-02,\n",
      "        1.8801e-02, 6.8769e-02, 3.1709e-03, 7.8435e-05, 1.8202e-02, 7.3866e-03,\n",
      "        0.0000e+00, 1.5129e-03, 4.4290e-02, 1.5716e-02, 3.4370e-03, 7.4198e-03,\n",
      "        0.0000e+00, 6.4591e-03, 7.3562e-03, 0.0000e+00, 8.9977e-06, 1.2574e-02,\n",
      "        3.1512e-03, 5.2059e-02, 1.8774e-02, 1.8796e-03, 1.1619e-02, 1.3611e-02,\n",
      "        5.0782e-03, 0.0000e+00, 3.8976e-02, 8.2799e-03, 3.8926e-02, 0.0000e+00,\n",
      "        2.1586e-03, 1.2355e-03, 1.5916e-03, 7.3722e-03, 7.3137e-03, 3.0095e-03,\n",
      "        3.6389e-02, 9.1647e-03, 1.2614e-02, 3.5059e-02, 7.7256e-04, 0.0000e+00,\n",
      "        2.2386e-05, 1.0209e-02, 3.4149e-03, 1.6169e-02, 2.0306e-03, 1.1170e-01,\n",
      "        1.0835e-01, 1.5316e-02, 9.6715e-04, 5.4319e-02, 4.1469e-03, 0.0000e+00,\n",
      "        1.7470e-01, 7.4674e-03, 4.2666e-02, 0.0000e+00, 6.4821e-03, 2.0465e-03,\n",
      "        8.0424e-03, 6.7837e-03, 2.6360e-02, 2.0322e-02, 7.4731e-02, 6.3980e-03,\n",
      "        8.3565e-03, 6.2985e-03, 3.1391e-02, 8.7906e-03, 2.0054e-02, 1.9024e-02,\n",
      "        1.3835e-02, 4.7903e-03, 2.3065e-03, 6.9792e-02, 6.1961e-03, 2.5716e-02,\n",
      "        1.9199e-02, 2.1838e-01, 1.8540e-04, 1.0993e-02, 9.1722e-03, 4.2045e-02,\n",
      "        7.0196e-03, 5.1490e-04, 9.7048e-03, 3.2843e-03, 2.6795e-04, 1.0798e-04,\n",
      "        1.8088e-03, 4.6878e-03, 1.9719e-03, 7.3589e-03, 1.7731e-03, 1.3199e-02,\n",
      "        1.3919e-03, 8.4436e-03, 7.4861e-03, 0.0000e+00, 1.4666e-02, 5.9419e-02,\n",
      "        2.8433e-02, 1.4729e-02, 4.4781e-02, 1.0143e-02, 1.2111e-02, 5.9383e-04,\n",
      "        2.7357e-02, 7.7654e-03, 1.4602e-02, 7.3993e-04, 8.6573e-03, 0.0000e+00,\n",
      "        2.9925e-03, 3.2404e-03, 3.6181e-03, 1.9120e-03, 2.4033e-03, 4.1378e-03,\n",
      "        2.4799e-02, 1.4504e-02, 1.8542e-03, 2.7143e-03, 2.2463e-03, 7.9697e-05,\n",
      "        2.8861e-03, 9.0622e-05, 1.3740e-02, 4.2739e-04, 4.0719e-02, 1.8270e-02,\n",
      "        4.2642e-03, 4.2287e-03, 3.5060e-02, 2.3069e-03, 4.4722e-03, 8.5825e-02,\n",
      "        1.4522e-02, 3.4565e-03, 2.3008e-03, 3.9654e-03, 1.1229e-02, 2.9097e-03,\n",
      "        1.6356e-03, 6.9016e-03, 1.4522e-02, 1.2452e-02, 3.1259e-03, 1.1678e-02,\n",
      "        1.0593e-02, 1.6796e-02, 0.0000e+00, 3.0116e-02, 0.0000e+00, 6.4266e-02,\n",
      "        1.4925e-02, 6.9147e-03, 0.0000e+00, 2.0571e-02, 2.3369e-02, 1.1872e-02,\n",
      "        6.6482e-03, 0.0000e+00, 1.5742e-03, 2.2726e-02, 1.2744e-02, 5.3909e-03,\n",
      "        2.6558e-05, 1.3029e-02, 1.7243e-04, 2.0402e-03, 1.3160e-02, 1.5979e-02,\n",
      "        4.5040e-03, 1.8994e-03, 8.4964e-02, 3.0887e-03, 6.5624e-03, 5.8101e-06,\n",
      "        8.4040e-03, 0.0000e+00, 8.5111e-03, 2.0816e-04, 1.7814e-02, 1.3797e-02,\n",
      "        1.1949e-02, 5.0685e-02, 2.8712e-02, 3.0055e-03, 0.0000e+00, 1.4062e-02,\n",
      "        0.0000e+00, 3.5563e-03, 1.7636e-03, 3.4471e-03, 2.1095e-02, 3.6360e-02,\n",
      "        1.4937e-01, 2.3007e-02, 1.9527e-02, 1.9320e-02, 7.2969e-03, 7.0246e-05,\n",
      "        0.0000e+00, 1.3744e-03, 7.2300e-02, 7.2144e-04, 9.0210e-04, 5.6310e-03,\n",
      "        3.6472e-03, 7.9892e-03, 1.7538e-02, 2.6349e-05, 0.0000e+00, 2.7893e-03,\n",
      "        1.8665e-02, 9.7350e-03, 2.1447e-03, 4.5728e-03, 1.0924e-03, 1.7814e-03,\n",
      "        9.3441e-03, 5.7397e-03, 6.3655e-03, 4.1043e-04, 1.4970e-03, 1.4414e-03,\n",
      "        8.8257e-03, 7.6797e-03, 2.7627e-02, 2.3399e-03, 6.2111e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.0961e-02, 1.1999e-03, 1.9054e-02, 8.9930e-03, 3.8041e-02,\n",
      "        2.5908e-02, 0.0000e+00, 3.0360e-05, 5.7382e-05, 1.3175e-02, 7.7407e-03,\n",
      "        3.6949e-05, 2.0463e-02, 1.9305e-02, 1.1158e-03, 1.1872e-02, 0.0000e+00,\n",
      "        1.5616e-02, 3.8053e-03, 2.2219e-03, 2.3015e-03, 3.0887e-03, 3.7790e-03,\n",
      "        1.3097e-02, 2.0239e-02, 1.0540e-02, 8.6964e-03, 2.7380e-03, 1.2184e-02,\n",
      "        4.4963e-02, 5.0731e-04, 1.8701e-02, 1.1420e-02, 1.1048e-04, 2.3165e-02,\n",
      "        1.2613e-02, 2.3249e-04, 1.7205e-02, 1.1847e-02, 1.3675e-02, 2.0138e-02,\n",
      "        4.3044e-02, 1.2207e-02, 1.2142e-02, 3.5063e-02, 3.2856e-03, 5.0405e-03],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0044, 0.0049, 0.0063, 0.0091, 0.0089, 0.0110, 0.0090, 0.0107, 0.0093,\n",
      "        0.0100, 0.0068, 0.0088, 0.0061, 0.0053], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0293, 0.0315, 0.0307, 0.0318, 0.0321, 0.0328, 0.0316, 0.0309, 0.0308,\n",
      "        0.0298, 0.0309, 0.0305, 0.0316, 0.0300], device='cuda:0') torch.Size([14])\n",
      "score tensor([3.3324e-02, 6.8126e-03, 5.2239e-03, 3.5220e-03, 1.7367e-01, 3.2148e-03,\n",
      "        6.4482e-04, 9.2635e-05, 2.5804e-02, 3.4904e-03, 7.4063e-02, 9.1362e-04,\n",
      "        1.7444e-02, 7.0046e-02, 1.2288e-02, 1.8418e-02, 3.3933e-04, 5.3747e-04,\n",
      "        4.2587e-02, 1.0948e-02, 2.3407e-03, 2.9490e-02, 8.2055e-03, 2.7085e-03,\n",
      "        3.2274e-03, 2.7077e-02, 3.5460e-02, 5.1597e-03, 3.2357e-02, 4.7361e-04,\n",
      "        7.0468e-02, 2.6870e-02, 4.3720e-03, 3.3042e-02, 4.3948e-02, 1.1550e-05,\n",
      "        2.1404e-02, 2.4334e-02, 8.2348e-02, 2.8163e-04, 3.2684e-03, 2.1595e-02,\n",
      "        7.1875e-03, 4.0543e-03, 6.7028e-03, 1.1059e-04, 3.6415e-03, 1.5004e-02,\n",
      "        6.0382e-04, 7.5865e-03, 4.0285e-03, 1.5187e-02, 4.1997e-03, 1.6719e-01,\n",
      "        2.1783e-02, 2.7922e-03, 1.3957e-01, 2.1356e-02, 9.2109e-03, 1.4264e-03,\n",
      "        2.7555e-02, 5.3310e-02, 4.9753e-02, 4.6133e-02, 0.0000e+00, 2.4946e-04,\n",
      "        9.9907e-03, 1.5879e-03, 7.5878e-05, 1.7093e-01, 1.9827e-02, 2.0630e-04,\n",
      "        0.0000e+00, 8.9429e-05, 2.8181e-03, 1.1375e-02, 8.5491e-03, 1.1454e-02,\n",
      "        4.4218e-02, 0.0000e+00, 1.5847e-01, 1.9270e-02, 6.2671e-02, 2.5841e-03,\n",
      "        1.6530e-03, 4.1415e-02, 0.0000e+00, 2.5649e-02, 1.1880e-02, 6.1112e-03,\n",
      "        3.0144e-02, 1.6522e-03, 2.2313e-04, 2.8625e-03, 4.3958e-03, 3.4780e-02,\n",
      "        1.6904e-02, 1.0663e-02, 8.5633e-04, 1.1782e-02, 1.3709e-02, 3.3392e-03,\n",
      "        2.1525e-02, 5.2474e-04, 0.0000e+00, 3.8057e-05, 1.6925e-05, 8.5892e-02,\n",
      "        0.0000e+00, 9.6851e-03, 2.3571e-03, 1.2847e-02, 1.7748e-02, 7.4114e-03,\n",
      "        5.2512e-02, 1.0755e-02, 1.7426e-02, 7.9346e-04, 0.0000e+00, 3.8129e-02,\n",
      "        1.8849e-02, 0.0000e+00, 2.6922e-02, 3.8645e-03, 1.5270e-03, 0.0000e+00,\n",
      "        1.8995e-02, 0.0000e+00, 2.0362e-01, 1.5732e-05, 2.3907e-05, 1.4139e-01,\n",
      "        3.2550e-04, 2.0918e-03, 0.0000e+00, 2.1274e-02, 5.8136e-05, 2.5788e-02,\n",
      "        0.0000e+00, 8.2425e-03, 0.0000e+00, 7.0439e-03, 1.1465e-04, 2.1039e-04,\n",
      "        0.0000e+00, 1.0064e-02, 1.1957e-02, 8.4846e-03, 2.2196e-02, 2.6935e-02,\n",
      "        1.2647e-01, 5.7092e-03, 1.8948e-02, 3.8131e-02, 1.7149e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.5714e-02, 1.8920e-02, 0.0000e+00, 4.9768e-03, 6.0657e-02,\n",
      "        2.4904e-04, 1.4156e-02, 5.0674e-03, 3.5141e-02, 0.0000e+00, 8.4283e-03,\n",
      "        7.1997e-03, 1.0180e-03, 2.9863e-03, 1.1004e-03, 3.3665e-03, 9.9392e-04,\n",
      "        1.9200e-02, 7.8673e-03, 2.7280e-03, 0.0000e+00, 5.9487e-03, 1.7279e-02,\n",
      "        2.0314e-03, 0.0000e+00, 4.7225e-03, 1.2447e-02, 1.4969e-02, 1.0659e-04,\n",
      "        8.3514e-03, 1.1234e-03, 1.1020e-02, 2.0255e-02, 7.6465e-03, 1.6223e-02,\n",
      "        9.5935e-02, 3.7742e-02, 1.6267e-03, 5.2813e-04, 0.0000e+00, 1.4515e-03,\n",
      "        2.1612e-03, 4.1085e-02, 6.2907e-02, 3.8673e-02, 1.1074e-04, 0.0000e+00,\n",
      "        2.6083e-03, 6.4781e-04, 2.1281e-02, 5.2451e-02, 2.1688e-04, 1.4585e-05,\n",
      "        2.2731e-02, 3.6715e-02, 0.0000e+00, 1.3026e-02, 4.4775e-04, 1.2975e-01,\n",
      "        9.7493e-03, 1.5385e-03, 6.6796e-03, 1.2223e-02, 9.1296e-04, 1.3741e-02,\n",
      "        3.7478e-05, 1.1803e-02, 2.3570e-04, 2.6642e-02, 2.9846e-03, 9.3374e-04,\n",
      "        2.9748e-03, 2.7460e-04, 2.5426e-02, 2.6172e-03, 7.1453e-05, 1.0839e-02,\n",
      "        7.6412e-03, 2.3416e-02, 1.9068e-01, 9.5803e-03, 1.4107e-02, 1.0264e-03,\n",
      "        3.4755e-05, 5.7192e-02, 1.9244e-03, 2.7072e-02, 0.0000e+00, 1.5618e-01,\n",
      "        1.2882e-02, 1.1886e-02, 1.7232e-03, 2.5303e-02, 2.8262e-02, 8.1482e-03,\n",
      "        6.9595e-02, 6.0319e-04, 0.0000e+00, 1.0533e-02, 0.0000e+00, 6.9479e-02,\n",
      "        4.0068e-03, 3.7610e-03, 0.0000e+00, 2.8270e-06, 7.7607e-03, 3.2818e-02,\n",
      "        2.7700e-02, 0.0000e+00, 4.0634e-04, 1.6046e-03, 4.0983e-03, 7.6447e-04,\n",
      "        1.8712e-02, 7.7591e-03, 2.7574e-05, 2.6241e-03, 2.6550e-02, 6.0214e-03,\n",
      "        1.5246e-03, 9.2630e-03, 0.0000e+00, 1.3700e-02, 3.4090e-02, 2.7377e-02,\n",
      "        2.3123e-02, 1.3132e-01, 1.1707e-02, 2.3758e-02, 2.2481e-04, 8.3240e-03,\n",
      "        1.6872e-02, 0.0000e+00, 2.8344e-02, 6.2066e-03, 3.0471e-03, 2.5937e-03,\n",
      "        1.7645e-02, 2.2804e-02, 1.3605e-04, 3.4213e-03, 0.0000e+00, 9.6286e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.2601e-02, 1.2398e-02, 2.3888e-02, 2.6650e-02,\n",
      "        0.0000e+00, 1.1935e-02, 0.0000e+00, 1.3371e-02, 7.4474e-02, 2.3322e-04,\n",
      "        7.0888e-03, 9.6852e-03, 7.8987e-03, 0.0000e+00, 9.1749e-04, 1.1031e-02,\n",
      "        1.6898e-02, 3.1865e-02, 2.7402e-03, 0.0000e+00, 1.7288e-02, 1.8810e-03,\n",
      "        9.1943e-03, 1.3557e-02, 0.0000e+00, 2.3482e-02, 7.2978e-04, 1.0286e-02,\n",
      "        6.1511e-04, 1.9700e-01, 0.0000e+00, 1.9752e-02, 1.2399e-02, 4.4470e-06,\n",
      "        0.0000e+00, 1.3737e-02, 8.6720e-03, 3.0686e-02, 6.6730e-05, 0.0000e+00,\n",
      "        1.4409e-02, 1.3415e-05, 2.3762e-02, 3.5344e-03, 2.7937e-02, 5.3942e-02,\n",
      "        1.3529e-02, 3.2980e-02, 6.2986e-02, 6.2284e-02, 8.4154e-03, 8.3450e-02,\n",
      "        5.8253e-04, 1.8635e-02, 4.5916e-03, 2.8729e-03, 1.2910e-03, 3.8816e-04,\n",
      "        6.8306e-03, 0.0000e+00, 4.1070e-04, 1.2870e-03, 1.5488e-02, 5.4794e-03,\n",
      "        0.0000e+00, 8.6242e-03, 2.5362e-02, 2.7842e-03, 7.3923e-02, 5.7004e-04,\n",
      "        1.3522e-02, 7.6246e-04, 6.8921e-03, 4.1025e-02, 2.9295e-02, 3.4918e-03,\n",
      "        7.5244e-02, 1.3239e-02, 4.4719e-03, 4.3975e-04, 6.2531e-03, 5.8747e-02],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0087, 0.0077, 0.0103, 0.0101, 0.0108, 0.0108, 0.0108, 0.0111, 0.0105,\n",
      "        0.0107, 0.0087, 0.0088, 0.0076, 0.0065], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0240, 0.0221, 0.0237, 0.0233, 0.0230, 0.0241, 0.0237, 0.0256, 0.0241,\n",
      "        0.0263, 0.0224, 0.0249, 0.0216, 0.0205], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.3465e-01, 1.6568e-02, 1.0338e-03, 3.6575e-02, 0.0000e+00, 1.2237e-02,\n",
      "        1.2954e-03, 1.2392e-03, 1.4076e-03, 9.8839e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.5837e-01, 1.0329e-02, 0.0000e+00, 4.5475e-02, 2.7309e-04, 3.4738e-03,\n",
      "        0.0000e+00, 4.2199e-05, 4.0801e-02, 3.0496e-03, 2.7777e-02, 0.0000e+00,\n",
      "        3.0199e-02, 0.0000e+00, 0.0000e+00, 4.4045e-02, 6.0588e-05, 0.0000e+00,\n",
      "        0.0000e+00, 4.2602e-03, 0.0000e+00, 6.8118e-02, 1.5294e-01, 7.2322e-02,\n",
      "        2.6584e-01, 1.5200e-01, 0.0000e+00, 1.4985e-01, 1.9541e-02, 6.4256e-04,\n",
      "        4.5762e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.9284e-03, 3.4436e-03, 0.0000e+00, 0.0000e+00, 2.7895e-04, 2.6271e-01,\n",
      "        1.0577e-01, 0.0000e+00, 0.0000e+00, 9.9632e-02, 9.9674e-04, 2.4579e-01,\n",
      "        8.5257e-02, 2.6767e-01, 1.8400e-01, 2.5393e-01, 3.2788e-02, 2.4143e-01,\n",
      "        4.2973e-02, 6.6226e-02, 1.5880e-03, 0.0000e+00, 0.0000e+00, 1.5162e-01,\n",
      "        1.2661e-03, 3.9626e-02, 8.2094e-02, 6.3620e-05, 0.0000e+00, 8.6146e-03,\n",
      "        0.0000e+00, 3.6562e-04, 2.7813e-01, 3.1138e-02, 0.0000e+00, 1.9312e-01,\n",
      "        7.7148e-02, 6.9765e-02, 1.6878e-01, 0.0000e+00, 1.4523e-02, 7.5658e-02,\n",
      "        0.0000e+00, 1.8383e-02, 4.9740e-02, 3.0853e-01, 0.0000e+00, 0.0000e+00,\n",
      "        3.0451e-01, 1.5587e-01, 0.0000e+00, 4.7468e-02, 2.4270e-03, 6.4941e-02,\n",
      "        6.2361e-02, 1.6384e-03, 0.0000e+00, 1.6001e-03, 6.9777e-02, 8.3293e-03,\n",
      "        0.0000e+00, 4.1927e-02, 4.1351e-02, 1.5834e-01, 0.0000e+00, 2.8790e-02,\n",
      "        1.1480e-01, 1.5310e-04, 0.0000e+00, 2.5362e-01, 4.7630e-02, 1.6698e-02,\n",
      "        4.0719e-03, 4.6743e-02, 0.0000e+00, 1.0335e-02, 2.1969e-02, 0.0000e+00,\n",
      "        4.7368e-02, 4.8346e-03, 0.0000e+00, 9.6225e-02, 5.5122e-02, 0.0000e+00,\n",
      "        6.7836e-03, 1.8834e-02, 0.0000e+00, 7.5038e-02, 1.8671e-03, 1.4017e-01,\n",
      "        0.0000e+00, 9.3177e-03, 4.0843e-02, 4.3713e-03, 9.6623e-02, 2.9699e-01,\n",
      "        3.2215e-05, 4.0915e-03, 2.2249e-02, 4.1583e-02, 3.3215e-04, 6.3620e-01,\n",
      "        0.0000e+00, 2.8466e-02, 2.0213e-02, 2.0560e-01, 1.7667e-04, 1.9874e-01,\n",
      "        2.1839e-01, 5.8994e-02, 2.4357e-02, 1.4713e-02, 9.7682e-03, 0.0000e+00,\n",
      "        1.3588e-01, 0.0000e+00, 0.0000e+00, 7.3588e-02, 3.0108e-02, 2.5203e-02,\n",
      "        3.3224e-02, 1.5977e-02, 0.0000e+00, 3.7573e-02, 0.0000e+00, 1.8753e-04,\n",
      "        1.4836e-01, 0.0000e+00, 0.0000e+00, 1.2357e-01, 1.6030e-01, 0.0000e+00,\n",
      "        6.1669e-02, 0.0000e+00, 0.0000e+00, 5.4745e-02, 2.3585e-02, 6.5624e-02,\n",
      "        0.0000e+00, 1.1694e-01, 1.1759e-01, 1.4988e-02, 0.0000e+00, 5.5965e-02,\n",
      "        1.0565e+00, 6.4331e-02, 0.0000e+00, 0.0000e+00, 7.0051e-02, 3.3810e-04,\n",
      "        5.9556e-02, 3.8427e-02, 4.9827e-02, 8.8555e-02, 3.6299e-02, 0.0000e+00,\n",
      "        9.3225e-02, 5.9792e-06, 2.3066e-01, 2.2727e-01, 0.0000e+00, 8.2415e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0227e-01, 8.5063e-02, 1.7908e-01,\n",
      "        4.3308e-03, 3.4049e-02, 4.2643e-02, 4.1548e-03, 8.8921e-03, 2.4988e-03,\n",
      "        0.0000e+00, 4.0702e-02, 0.0000e+00, 6.3499e-05, 1.2909e-01, 3.5941e-03,\n",
      "        0.0000e+00, 3.3365e-03, 5.1371e-02, 6.1530e-03, 0.0000e+00, 0.0000e+00,\n",
      "        4.7577e-03, 0.0000e+00, 4.9901e-02, 4.3761e-03, 2.0306e-05, 6.4977e-03,\n",
      "        3.5430e-01, 2.5868e-02, 3.1041e-03, 1.5061e-01, 4.6751e-01, 0.0000e+00,\n",
      "        1.2888e-01, 2.4079e-02, 7.7512e-03, 0.0000e+00, 0.0000e+00, 1.7331e-02,\n",
      "        4.5670e-02, 9.1728e-02, 4.1038e-02, 2.8805e-01, 2.6272e-01, 1.4482e-01,\n",
      "        6.6691e-02, 0.0000e+00, 5.4272e-02, 5.6171e-02, 1.5554e-02, 3.2385e-02,\n",
      "        1.4853e-01, 0.0000e+00, 1.1655e-01, 1.3684e-01, 2.1116e-01, 7.7517e-04,\n",
      "        2.6422e-03, 7.9858e-02, 0.0000e+00, 1.0332e-01, 2.3018e-03, 0.0000e+00,\n",
      "        6.8876e-02, 4.0369e-04, 4.1411e-01, 1.6079e-02, 5.3138e-02, 0.0000e+00,\n",
      "        4.6817e-02, 4.7394e-01, 6.5133e-02, 0.0000e+00, 1.2349e-01, 6.8775e-02,\n",
      "        2.4564e-02, 4.0765e-02, 1.9886e-02, 6.9182e-03, 2.4011e-02, 1.8738e-02,\n",
      "        1.7895e-02, 1.7996e-02, 2.9494e-02, 3.3333e-01, 0.0000e+00, 1.3249e-02,\n",
      "        3.5332e-01, 2.2861e-01, 8.1477e-02, 1.5508e-01, 6.6553e-03, 4.9125e-05,\n",
      "        4.4504e-01, 3.3485e-03, 0.0000e+00, 9.9612e-03, 2.6382e-02, 5.2087e-02,\n",
      "        2.0584e-02, 6.3441e-02, 1.0944e-02, 0.0000e+00, 3.7867e-02, 5.5961e-06,\n",
      "        2.2434e-01, 2.2627e-02, 7.6459e-02, 3.1366e-01, 0.0000e+00, 1.4948e-01,\n",
      "        0.0000e+00, 9.5770e-02, 1.2813e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        9.1032e-02, 5.6811e-01, 0.0000e+00, 8.3634e-03, 2.4729e-02, 2.5431e-01,\n",
      "        2.7989e-01, 0.0000e+00, 8.5586e-03, 1.8380e-02, 1.1236e-01, 1.0115e-01,\n",
      "        6.7305e-03, 0.0000e+00, 3.1267e-01, 3.5159e-03, 0.0000e+00, 3.4208e-02,\n",
      "        3.4146e-02, 1.8499e-01, 6.1924e-02, 0.0000e+00, 2.0915e-02, 1.2002e-03,\n",
      "        1.4219e-01, 5.7664e-02, 1.8451e-02, 0.0000e+00, 6.2333e-02, 7.4260e-02,\n",
      "        5.1527e-02, 1.0502e-01, 4.4507e-04, 2.3705e-02, 0.0000e+00, 3.9820e-02,\n",
      "        9.6006e-02, 5.0882e-02, 3.2485e-02, 2.0779e-02, 2.4816e-01, 4.8979e-03,\n",
      "        1.4488e-01, 2.8293e-02, 1.1210e-03, 6.6210e-02, 0.0000e+00, 1.2973e-01,\n",
      "        1.2650e-01, 1.9964e-03, 1.6415e-03, 2.4257e-02, 5.3329e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0108, 0.0131, 0.0142, 0.0160, 0.0141, 0.0145, 0.0143, 0.0146, 0.0145,\n",
      "        0.0143, 0.0156, 0.0136, 0.0130, 0.0103], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0368, 0.0316, 0.0319, 0.0324, 0.0320, 0.0324, 0.0327, 0.0328, 0.0334,\n",
      "        0.0329, 0.0333, 0.0324, 0.0334, 0.0362], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.7048e-02, 1.8785e-02, 2.7665e-02, 1.1318e-02, 3.8623e-01, 1.2910e-01,\n",
      "        2.2277e-03, 0.0000e+00, 0.0000e+00, 3.5444e-02, 1.6433e-01, 0.0000e+00,\n",
      "        0.0000e+00, 3.5881e-02, 3.8419e-03, 2.2856e-03, 5.1910e-02, 1.2427e-01,\n",
      "        1.4074e-01, 3.0595e-04, 4.7437e-03, 2.4286e-02, 4.5902e-01, 0.0000e+00,\n",
      "        3.1246e-02, 9.6340e-03, 8.0691e-02, 3.0272e-04, 2.7081e-02, 1.9545e-03,\n",
      "        9.8708e-02, 3.4667e-04, 1.3837e-03, 6.9724e-02, 0.0000e+00, 1.7901e-02,\n",
      "        0.0000e+00, 6.2407e-02, 0.0000e+00, 1.9316e-02, 3.6550e-02, 6.0780e-03,\n",
      "        0.0000e+00, 0.0000e+00, 1.4015e-02, 0.0000e+00, 1.0588e-03, 5.3217e-03,\n",
      "        8.3038e-02, 3.0742e-02, 1.1905e-01, 4.0193e-03, 6.3805e-03, 3.3470e-01,\n",
      "        8.1757e-02, 3.4473e-02, 2.2937e-01, 5.6816e-02, 1.0641e-02, 1.1917e-01,\n",
      "        0.0000e+00, 1.6116e-01, 0.0000e+00, 1.2544e-01, 3.5744e-03, 0.0000e+00,\n",
      "        3.8078e-02, 8.8628e-04, 4.9854e-02, 0.0000e+00, 8.1176e-02, 1.9214e-02,\n",
      "        6.3633e-02, 4.5962e-03, 2.3225e-02, 5.0210e-04, 3.3532e-02, 3.0156e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.9295e-01, 0.0000e+00, 7.2902e-06, 7.2273e-02,\n",
      "        0.0000e+00, 1.1471e-01, 0.0000e+00, 5.4099e-02, 3.8753e-02, 3.6548e-02,\n",
      "        6.3444e-02, 3.5751e-02, 3.8812e-04, 3.0087e-02, 3.8214e-02, 1.5871e-03,\n",
      "        0.0000e+00, 4.5740e-02, 4.7011e-02, 4.5984e-03, 2.1087e-03, 3.4801e-02,\n",
      "        8.8147e-06, 2.5149e-02, 0.0000e+00, 1.7272e-02, 1.6529e-01, 4.1149e-02,\n",
      "        0.0000e+00, 3.8212e-03, 7.1445e-02, 8.6406e-03, 6.2135e-02, 4.9596e-03,\n",
      "        8.1470e-04, 7.0935e-02, 0.0000e+00, 6.3008e-04, 4.4365e-02, 7.6496e-05,\n",
      "        1.0113e-03, 1.4397e-02, 0.0000e+00, 6.7813e-04, 8.8482e-02, 6.7423e-02,\n",
      "        8.6641e-02, 2.5592e-02, 0.0000e+00, 0.0000e+00, 5.6565e-02, 1.2950e-01,\n",
      "        6.7493e-05, 7.5650e-02, 0.0000e+00, 1.1134e-03, 7.4377e-03, 8.6017e-02,\n",
      "        0.0000e+00, 7.7230e-02, 3.3514e-05, 1.2596e-02, 1.9490e-02, 8.4402e-02,\n",
      "        3.7338e-03, 5.8981e-03, 2.0303e-02, 6.8169e-02, 2.0358e-01, 0.0000e+00,\n",
      "        0.0000e+00, 8.9788e-02, 5.1393e-02, 0.0000e+00, 1.0814e-03, 3.7009e-05,\n",
      "        2.7770e-01, 0.0000e+00, 8.1650e-02, 0.0000e+00, 9.7992e-03, 1.1454e-02,\n",
      "        3.8849e-03, 1.1976e-02, 7.6466e-02, 1.0349e-03, 8.2537e-02, 3.4902e-02,\n",
      "        5.3694e-02, 3.8978e-03, 1.0480e-01, 2.9784e-02, 1.6125e-02, 4.4775e-02,\n",
      "        4.9772e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5786e-03,\n",
      "        3.4827e-03, 5.6369e-01, 0.0000e+00, 6.4055e-03, 1.5614e-02, 6.7906e-02,\n",
      "        1.9772e-02, 8.8253e-02, 3.1324e-02, 9.7846e-03, 0.0000e+00, 2.9332e-02,\n",
      "        2.5312e-01, 2.3092e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.5343e-02,\n",
      "        1.9519e-02, 1.4288e-02, 5.1669e-02, 4.8448e-02, 3.2059e-04, 0.0000e+00,\n",
      "        7.1143e-02, 4.0267e-02, 1.8087e-03, 0.0000e+00, 1.3847e-02, 5.7318e-03,\n",
      "        0.0000e+00, 7.2871e-02, 1.4708e-01, 4.1283e-02, 1.5174e-03, 9.4019e-03,\n",
      "        0.0000e+00, 3.1344e-02, 1.0943e-02, 1.3251e-02, 2.1553e-01, 2.0537e-02,\n",
      "        0.0000e+00, 8.3576e-03, 4.4156e-04, 0.0000e+00, 2.5893e-02, 3.6936e-02,\n",
      "        1.6446e-02, 1.9882e-02, 3.4049e-02, 2.8917e-02, 1.6611e-02, 0.0000e+00,\n",
      "        8.3673e-03, 2.8487e-02, 8.7212e-02, 2.7364e-02, 4.4652e-02, 4.2044e-03,\n",
      "        2.7112e-01, 0.0000e+00, 8.1542e-03, 6.1982e-02, 1.5458e-01, 3.1608e-01,\n",
      "        4.2312e-01, 2.3086e-02, 2.4148e-02, 1.2809e-01, 0.0000e+00, 4.1898e-03,\n",
      "        1.2633e-01, 3.7604e-02, 0.0000e+00, 1.9517e-02, 0.0000e+00, 3.6381e-02,\n",
      "        4.1828e-03, 2.7459e-02, 9.2722e-02, 4.3920e-06, 4.2615e-02, 4.2553e-03,\n",
      "        2.1998e-02, 1.0238e-01, 2.8781e-02, 5.9323e-03, 4.1294e-03, 1.3097e-03,\n",
      "        2.3099e-03, 4.4549e-02, 0.0000e+00, 1.3203e-01, 3.7900e-05, 0.0000e+00,\n",
      "        4.4226e-02, 8.2845e-04, 1.3980e-01, 1.4209e-02, 3.0857e-05, 4.0815e-02,\n",
      "        4.8960e-02, 4.1560e-01, 2.1295e-02, 1.0150e-01, 3.6373e-03, 2.3901e-02,\n",
      "        5.1163e-03, 4.2300e-01, 3.9892e-02, 9.3946e-03, 6.1344e-02, 7.9082e-03,\n",
      "        9.9964e-03, 1.2329e-02, 1.4553e-02, 0.0000e+00, 3.0513e-01, 1.6358e-01,\n",
      "        2.9000e-01, 1.9193e-02, 1.0505e-03, 0.0000e+00, 4.4625e-02, 1.6645e-01,\n",
      "        0.0000e+00, 7.4191e-02, 0.0000e+00, 2.5385e-02, 0.0000e+00, 3.4047e-02,\n",
      "        2.1538e-02, 1.0320e-02, 1.4807e-02, 1.3877e-04, 9.2735e-03, 2.7729e-02,\n",
      "        0.0000e+00, 2.5529e-02, 8.3813e-03, 0.0000e+00, 8.4297e-02, 2.3296e-02,\n",
      "        1.4327e-02, 2.0587e-02, 5.0994e-03, 1.6513e-02, 1.4448e-03, 7.3321e-02,\n",
      "        4.0629e-03, 4.0363e-01, 1.4458e-01, 1.4784e-03, 5.9046e-03, 1.2997e-01,\n",
      "        4.6922e-02, 3.8500e-02, 1.0423e-02, 0.0000e+00, 4.6521e-02, 2.0887e-02,\n",
      "        4.5741e-02, 0.0000e+00, 0.0000e+00, 1.0620e-02, 8.4871e-02, 4.5812e-02,\n",
      "        3.7779e-02, 1.3640e-02, 7.5452e-02, 1.5774e-01, 3.3268e-03, 5.4691e-02,\n",
      "        1.5575e-03, 2.5863e-04, 7.4741e-03, 6.0682e-02, 8.0132e-04, 2.9925e-04,\n",
      "        1.2468e-02, 6.0845e-02, 7.9913e-04, 1.1753e-01, 1.8908e-01, 1.5074e-02,\n",
      "        8.4336e-03, 1.2249e-06, 5.3688e-02, 0.0000e+00, 1.9769e-01, 1.3801e-02,\n",
      "        0.0000e+00, 5.4673e-03, 5.5612e-02, 7.5322e-03, 0.0000e+00, 0.0000e+00,\n",
      "        1.1017e-03, 1.6631e-03, 4.6131e-02, 1.7582e-02, 4.2941e-02, 6.5812e-02],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0073, 0.0103, 0.0126, 0.0110, 0.0104, 0.0101, 0.0107, 0.0111, 0.0105,\n",
      "        0.0115, 0.0103, 0.0129, 0.0095, 0.0072], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0372, 0.0412, 0.0403, 0.0393, 0.0404, 0.0404, 0.0399, 0.0397, 0.0402,\n",
      "        0.0400, 0.0376, 0.0392, 0.0382, 0.0334], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0000e+00, 3.0989e-02, 2.0407e-03, 0.0000e+00, 6.3836e-01, 2.3158e-02,\n",
      "        1.1003e-02, 0.0000e+00, 0.0000e+00, 8.4548e-02, 2.3230e-01, 3.3102e-03,\n",
      "        0.0000e+00, 3.3687e-01, 4.3942e-02, 3.9098e-02, 3.2153e-02, 3.0337e-01,\n",
      "        0.0000e+00, 0.0000e+00, 5.2413e-02, 9.7694e-02, 8.7143e-03, 7.7113e-01,\n",
      "        3.2357e-02, 3.2413e-02, 1.8637e-01, 1.2489e-02, 2.1831e-02, 0.0000e+00,\n",
      "        6.5921e-02, 9.1672e-03, 4.3294e-03, 6.1975e-02, 2.0247e-02, 5.4838e-02,\n",
      "        1.9771e-01, 5.4234e-01, 3.4021e-01, 3.7835e-02, 3.5411e-02, 1.9630e-01,\n",
      "        0.0000e+00, 1.0800e-01, 0.0000e+00, 0.0000e+00, 4.7166e-03, 1.9439e-01,\n",
      "        1.0453e-01, 6.9322e-02, 2.0814e-02, 3.0106e-02, 3.8711e-02, 1.2020e-04,\n",
      "        8.0378e-01, 1.3481e-01, 5.1876e-01, 1.6719e-02, 0.0000e+00, 0.0000e+00,\n",
      "        8.3521e-02, 7.6305e-02, 5.9881e-01, 0.0000e+00, 4.4678e-03, 0.0000e+00,\n",
      "        2.0578e-01, 4.7130e-02, 1.5575e-02, 3.2440e-03, 4.6817e-02, 5.1611e-03,\n",
      "        7.9265e-02, 4.4990e-02, 0.0000e+00, 8.4287e-02, 1.1114e-02, 3.0422e-01,\n",
      "        0.0000e+00, 2.4333e-01, 0.0000e+00, 0.0000e+00, 3.4092e-01, 2.4346e-01,\n",
      "        5.7604e-04, 2.2269e-01, 4.2840e-02, 0.0000e+00, 1.4733e-01, 0.0000e+00,\n",
      "        0.0000e+00, 3.8578e-02, 8.3714e-02, 2.7716e-02, 0.0000e+00, 0.0000e+00,\n",
      "        3.0074e-01, 3.3924e-02, 1.5281e-01, 5.4232e-02, 2.5266e-02, 1.6492e-02,\n",
      "        1.0540e-01, 0.0000e+00, 3.4348e-01, 2.4113e-02, 1.7678e-01, 2.7367e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.2488e-02, 2.8082e-01, 1.3714e-04, 0.0000e+00,\n",
      "        7.9381e-02, 0.0000e+00, 0.0000e+00, 2.8166e-01, 0.0000e+00, 1.2021e-01,\n",
      "        3.2565e-02, 0.0000e+00, 2.6303e-01, 2.5187e-02, 2.8019e-01, 2.0413e-01,\n",
      "        1.7000e-01, 4.0631e-02, 0.0000e+00, 2.8180e-01, 5.1326e-02, 4.1020e-02,\n",
      "        2.5754e-02, 2.0346e-01, 2.9305e-01, 7.2781e-03, 1.1004e-01, 1.0455e-04,\n",
      "        0.0000e+00, 0.0000e+00, 2.4382e-01, 1.0595e-01, 7.7716e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.3143e-02, 7.1072e-02, 3.1073e-01, 0.0000e+00, 6.7579e-01,\n",
      "        1.6173e-01, 1.4309e-03, 1.8743e-02, 3.2643e-01, 1.6147e-01, 0.0000e+00,\n",
      "        2.8245e-01, 6.4809e-01, 1.2471e-02, 2.7968e-03, 1.4497e-01, 0.0000e+00,\n",
      "        2.8714e-02, 9.0029e-02, 1.0011e-01, 1.3770e-01, 1.5178e-01, 1.8945e-02,\n",
      "        5.7660e-02, 1.8993e-01, 2.9131e-01, 8.8730e-03, 2.4839e-02, 3.8034e-04,\n",
      "        0.0000e+00, 2.0803e-01, 3.7651e-01, 2.4608e-01, 1.4071e-01, 2.6272e-02,\n",
      "        3.1621e-02, 0.0000e+00, 0.0000e+00, 2.4580e-02, 1.4730e-01, 8.3182e-02,\n",
      "        2.1375e-01, 1.8284e-01, 8.6288e-03, 5.2352e-04, 6.8362e-02, 1.5574e-01,\n",
      "        1.5870e-01, 4.5463e-02, 3.2435e-01, 2.3021e-01, 0.0000e+00, 1.6230e-01,\n",
      "        0.0000e+00, 0.0000e+00, 6.7373e-02, 4.6644e-03, 6.6516e-02, 0.0000e+00,\n",
      "        1.1527e-01, 1.0098e-01, 3.6342e-01, 2.2588e-01, 0.0000e+00, 8.9093e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.7797e-01, 1.1494e-01, 3.5206e-03, 6.9853e-02,\n",
      "        0.0000e+00, 6.9294e-02, 6.7737e-03, 3.3966e-02, 0.0000e+00, 2.8761e-02,\n",
      "        2.4147e-01, 1.3133e-01, 1.8517e-01, 1.7204e-01, 1.6141e-04, 8.9062e-03,\n",
      "        5.5365e-02, 1.4196e-01, 0.0000e+00, 6.2781e-02, 2.8628e-02, 2.7880e-01,\n",
      "        1.6482e-03, 0.0000e+00, 1.1562e-01, 3.5212e-05, 1.3303e-03, 5.2033e-02,\n",
      "        3.5658e-01, 0.0000e+00, 5.4827e-02, 0.0000e+00, 4.8172e-05, 0.0000e+00,\n",
      "        5.2275e-01, 6.2377e-02, 6.2795e-03, 0.0000e+00, 4.0579e-01, 0.0000e+00,\n",
      "        1.7793e-01, 7.4505e-02, 8.0676e-01, 5.1530e-01, 1.9192e-02, 3.5034e-03,\n",
      "        1.3858e-02, 0.0000e+00, 5.0528e-02, 3.2497e-03, 5.1210e-02, 2.4403e-02,\n",
      "        2.5377e-01, 3.4993e-01, 8.5574e-02, 3.3712e-02, 3.2760e-02, 1.2925e-02,\n",
      "        7.2352e-02, 2.1821e-02, 3.0649e-02, 0.0000e+00, 3.3951e-04, 0.0000e+00,\n",
      "        0.0000e+00, 4.4010e-02, 2.3931e-01, 3.8403e-02, 2.1266e-02, 2.9660e-02,\n",
      "        2.6263e-01, 5.8061e-01, 2.0163e-02, 2.2812e-01, 1.1337e-02, 3.6985e-02,\n",
      "        1.2918e-01, 2.9133e-01, 1.5289e-01, 3.1886e-04, 8.5703e-02, 0.0000e+00,\n",
      "        7.2257e-02, 8.0528e-03, 7.9395e-03, 0.0000e+00, 0.0000e+00, 9.9087e-02,\n",
      "        3.1978e-01, 1.8969e-03, 1.1029e-01, 4.7661e-02, 3.5263e-02, 3.1048e-01,\n",
      "        4.7206e-01, 2.0878e-01, 4.4022e-02, 8.7068e-02, 6.2066e-03, 0.0000e+00,\n",
      "        1.8681e-02, 7.4711e-04, 1.2368e-02, 2.6336e-01, 1.9007e-01, 6.3821e-02,\n",
      "        2.0293e-01, 8.1583e-02, 1.0094e-03, 4.4240e-01, 9.4601e-02, 1.3318e-02,\n",
      "        1.7402e-01, 1.4578e-02, 4.5973e-03, 2.2027e-02, 1.1830e-02, 6.4029e-02,\n",
      "        4.1373e-02, 0.0000e+00, 1.5888e-01, 2.3051e-01, 1.1510e-01, 4.4374e-01,\n",
      "        0.0000e+00, 1.3635e-01, 1.0039e-02, 0.0000e+00, 7.5259e-02, 1.5326e-01,\n",
      "        2.0804e-01, 2.7600e-01, 0.0000e+00, 7.9630e-02, 0.0000e+00, 1.0740e-02,\n",
      "        1.3830e-02, 1.7698e-01, 2.7131e-01, 2.8492e-01, 1.0560e-01, 3.5702e-01,\n",
      "        1.3482e-01, 8.4496e-02, 1.0736e-02, 2.4471e-02, 5.0942e-05, 0.0000e+00,\n",
      "        4.7797e-02, 2.7562e-01, 1.9811e-02, 2.8773e-01, 1.7734e-01, 1.4094e-01,\n",
      "        1.1372e-03, 0.0000e+00, 0.0000e+00, 1.4582e-01, 0.0000e+00, 1.0585e-01,\n",
      "        1.2732e-02, 5.3433e-02, 2.9651e-01, 6.0066e-02, 0.0000e+00, 0.0000e+00,\n",
      "        3.5176e-02, 2.3914e-03, 0.0000e+00, 0.0000e+00, 1.3371e-03, 6.8017e-04],\n",
      "       device='cuda:0') torch.Size([384])\n",
      "score tensor([0.0133, 0.0169, 0.0155, 0.0154, 0.0158, 0.0162, 0.0150, 0.0151, 0.0159,\n",
      "        0.0154, 0.0145, 0.0143, 0.0155, 0.0122], device='cuda:0') torch.Size([14])\n",
      "score tensor([0.0535, 0.0685, 0.0556, 0.0590, 0.0568, 0.0613, 0.0554, 0.0537, 0.0583,\n",
      "        0.0527, 0.0576, 0.0499, 0.0615, 0.0463], device='cuda:0') torch.Size([14])\n",
      "score tensor([1.7809e-02, 2.2836e-04, 7.0299e-02, 6.4064e-02, 9.6654e-03, 1.9679e-03,\n",
      "        1.0920e-03, 9.0548e-02, 0.0000e+00, 5.2483e-02, 9.1681e-02, 1.5332e-02,\n",
      "        6.7431e-03, 1.6121e-03, 1.5877e-04, 0.0000e+00, 1.0437e-01, 3.8002e-03,\n",
      "        1.1037e-02, 8.2759e-02, 5.3839e-03, 1.3275e-02, 1.0188e-01, 4.2145e-02,\n",
      "        4.7549e-02, 1.6771e-03, 0.0000e+00, 0.0000e+00, 4.0295e-01, 4.7832e-02,\n",
      "        1.0484e-01, 3.5464e-03, 3.0145e-02, 1.3074e-02, 3.4111e-02, 1.0660e-01,\n",
      "        0.0000e+00, 6.7881e-02, 2.7598e-02, 4.1234e-02, 5.5274e-02, 8.5020e-02,\n",
      "        2.3296e-02, 4.1712e-02, 1.2686e-01, 4.8531e-02, 4.6782e-02, 5.3093e-02,\n",
      "        1.9317e-01, 4.0304e-02, 5.4259e-04, 5.1621e-02, 4.7941e-05, 0.0000e+00,\n",
      "        3.9403e-02, 1.5903e-01, 0.0000e+00, 0.0000e+00, 3.2528e-02, 1.2245e-01,\n",
      "        1.1932e-02, 2.3141e-02, 4.7116e-04, 1.1675e-01, 1.8334e-02, 5.6019e-04,\n",
      "        1.7660e-01, 3.6687e-02, 3.3301e-02, 8.4994e-02, 9.7863e-03, 2.0047e-02,\n",
      "        2.8255e-02, 3.6752e-02, 2.0489e-04, 0.0000e+00, 8.5874e-02, 0.0000e+00,\n",
      "        2.2437e-02, 7.6110e-02, 3.4233e-03, 5.9491e-03, 7.3973e-05, 7.4787e-02,\n",
      "        5.0600e-02, 7.0555e-02, 3.9282e-02, 5.0658e-02, 1.6568e-03, 1.1551e-01,\n",
      "        4.1795e-02, 4.6773e-02, 2.2170e-02, 4.2238e-03, 5.0571e-03, 7.3771e-03,\n",
      "        1.6106e-02, 1.1226e-02, 3.9517e-03, 5.5790e-02, 4.3871e-02, 2.0691e-02,\n",
      "        8.8991e-02, 6.9732e-03, 5.4185e-02, 2.1573e-04, 5.0427e-02, 5.9885e-02,\n",
      "        3.9586e-02, 9.1450e-03, 4.8411e-02, 5.5633e-02, 2.1687e-02, 4.3647e-02,\n",
      "        0.0000e+00, 1.5974e-02, 1.1639e-01, 3.7790e-02, 1.0359e-02, 2.0262e-03,\n",
      "        1.4378e-02, 4.6830e-03, 2.3495e-01, 4.5544e-02, 4.4893e-02, 7.1242e-03,\n",
      "        6.7450e-03, 9.2081e-03, 1.1570e-03, 3.3926e-03, 0.0000e+00, 4.4497e-02,\n",
      "        6.0432e-02, 3.9501e-02, 2.6376e-03, 4.1677e-05, 8.7571e-03, 1.2497e-02,\n",
      "        9.1195e-02, 7.6853e-03, 8.0769e-04, 1.4642e-03, 5.3550e-02, 2.7024e-02,\n",
      "        5.7486e-03, 8.7607e-02, 5.2917e-02, 5.9077e-02, 1.9644e-02, 1.6364e-02,\n",
      "        8.4011e-02, 6.5438e-02, 1.4778e-02, 1.3462e-01, 7.2223e-02, 5.3792e-02,\n",
      "        1.1989e-01, 1.8598e-02, 4.5856e-02, 1.2972e-03, 1.0997e-02, 1.0910e-02,\n",
      "        3.2199e-02, 6.5831e-02, 9.8046e-02, 0.0000e+00, 1.3968e-02, 9.2849e-03,\n",
      "        4.3986e-02, 1.3875e-03, 0.0000e+00, 1.9038e-01, 1.2648e-01, 1.7150e-01,\n",
      "        1.1216e-01, 0.0000e+00, 7.9166e-02, 5.0083e-02, 1.7913e-03, 0.0000e+00,\n",
      "        9.5367e-03, 1.4678e-01, 1.9191e-02, 2.4511e-02, 1.2057e-01, 5.9762e-01,\n",
      "        1.5188e-02, 0.0000e+00, 2.5520e-02, 7.8250e-02, 8.4694e-03, 0.0000e+00,\n",
      "        4.9611e-02, 3.4202e-02, 5.7766e-02, 1.1326e-02, 0.0000e+00, 7.4749e-03,\n",
      "        1.9131e-02, 2.9935e-02, 8.3465e-02, 1.5956e-02, 1.9727e-02, 1.0130e-03,\n",
      "        2.7782e-03, 8.1788e-02, 2.3184e-02, 8.0661e-05, 6.3083e-02, 2.6845e-03,\n",
      "        1.3198e-01, 1.9666e-03, 5.8882e-02, 3.6393e-02, 6.8898e-02, 8.7264e-02,\n",
      "        0.0000e+00, 2.2246e-03, 3.1823e-02, 1.1223e-01, 2.5745e-02, 0.0000e+00,\n",
      "        1.7628e-02, 6.0239e-02, 0.0000e+00, 1.7676e-02, 7.5185e-02, 5.0408e-02,\n",
      "        1.2278e-03, 7.0532e-02, 9.8849e-02, 1.9578e-03, 4.3106e-02, 1.2228e-01,\n",
      "        1.4109e-02, 9.8603e-02, 3.2151e-03, 5.2346e-03, 2.9790e-02, 1.4923e-03,\n",
      "        2.1844e-02, 7.9939e-02, 5.2453e-02, 1.6582e-01, 1.3276e-02, 1.0279e-02,\n",
      "        8.8584e-03, 0.0000e+00, 3.0868e-02, 2.3546e-02, 3.0367e-02, 1.2309e-02,\n",
      "        8.8883e-03, 5.8539e-02, 2.0553e-02, 3.3419e-04, 4.0033e-02, 6.0548e-02,\n",
      "        8.9710e-02, 2.6544e-02, 0.0000e+00, 2.0236e-03, 2.1847e-02, 3.1286e-02,\n",
      "        1.8578e-02, 5.7765e-02, 6.5280e-02, 8.4003e-02, 1.7862e-02, 1.4843e-02,\n",
      "        0.0000e+00, 8.3406e-02, 9.4554e-02, 4.3291e-02, 8.2936e-02, 4.3062e-03,\n",
      "        7.4684e-04, 3.2823e-02, 1.2919e-01, 4.1484e-02, 6.4981e-02, 7.0636e-02,\n",
      "        1.3813e-02, 2.5364e-02, 6.0765e-03, 0.0000e+00, 8.8266e-02, 1.2418e-04,\n",
      "        9.7279e-02, 2.0352e-05, 6.6425e-02, 2.2667e-02, 1.7498e-02, 2.4773e-02,\n",
      "        3.1901e-02, 1.2798e-02, 2.0304e-01, 4.9691e-02, 1.1598e-01, 2.8223e-02,\n",
      "        1.1363e-01, 3.2501e-03, 7.9869e-02, 6.4804e-02, 5.4303e-02, 9.4389e-02,\n",
      "        0.0000e+00, 6.7097e-04, 0.0000e+00, 8.6140e-02, 6.2070e-02, 2.0649e-01,\n",
      "        5.5191e-02, 3.7284e-03, 4.1508e-02, 1.9534e-02, 1.0315e-01, 2.7346e-02,\n",
      "        1.1296e-02, 4.8519e-03, 6.9884e-05, 2.5708e-03, 0.0000e+00, 1.3545e-02,\n",
      "        1.4548e-02, 4.6580e-02, 3.0194e-04, 1.2871e-03, 5.2369e-03, 4.7136e-02,\n",
      "        1.1823e-01, 2.2551e-03, 1.6987e-01, 1.6664e-02, 1.3597e-01, 4.5500e-02,\n",
      "        2.1853e-02, 1.0762e-01, 9.1896e-02, 6.1738e-02, 2.2410e-02, 2.7274e-02,\n",
      "        4.5268e-02, 8.4218e-02, 4.1350e-02, 9.1227e-03, 3.4061e-03, 3.5246e-02,\n",
      "        3.2385e-02, 6.6635e-03, 1.1760e-02, 3.9431e-02, 6.5670e-03, 2.2131e-02,\n",
      "        7.5195e-02, 0.0000e+00, 4.5312e-03, 3.2232e-02, 4.4057e-02, 1.0907e-02,\n",
      "        1.7005e-01, 6.4092e-03, 4.3930e-03, 1.3243e-02, 1.2942e-02, 9.1248e-02,\n",
      "        5.6794e-02, 1.3485e-01, 7.2986e-02, 4.2383e-02, 2.1091e-02, 4.1488e-02,\n",
      "        0.0000e+00, 8.0491e-03, 1.1988e-03, 3.8240e-02, 3.2338e-02, 1.2697e-02,\n",
      "        1.1847e-01, 2.8879e-02, 0.0000e+00, 7.5031e-02, 6.3470e-02, 2.5168e-02,\n",
      "        1.5025e-03, 6.0693e-02, 9.7382e-02, 9.9822e-02, 7.4460e-05, 2.5886e-03,\n",
      "        4.2661e-05, 0.0000e+00, 9.6299e-02, 1.2936e-01, 6.1443e-02, 3.2648e-02,\n",
      "        0.0000e+00, 1.8609e-03, 6.1221e-02, 2.2176e-02, 3.4409e-02, 3.5780e-03,\n",
      "        4.6678e-04, 3.4464e-02, 4.6692e-03, 2.3507e-01, 6.5146e-02, 6.6340e-03,\n",
      "        3.5544e-03, 4.9080e-02, 3.4320e-02, 8.7291e-02, 1.0494e-01, 1.6225e-01,\n",
      "        3.9857e-02, 0.0000e+00, 7.2403e-02, 1.0842e-02, 3.6273e-03, 2.7328e-02,\n",
      "        0.0000e+00, 2.5533e-02, 6.3217e-04, 2.4550e-02, 1.1977e-01, 2.7399e-02,\n",
      "        1.9699e-02, 2.3953e-02, 4.5078e-03, 6.8263e-03, 4.3419e-02, 1.0506e-01,\n",
      "        0.0000e+00, 7.6058e-02, 2.4794e-02, 3.1777e-02, 3.1996e-02, 0.0000e+00,\n",
      "        8.7080e-02, 1.1457e-01, 3.4355e-02, 2.1760e-01, 2.4103e-02, 4.5301e-02,\n",
      "        1.8534e-02, 2.9902e-02, 3.3083e-02, 0.0000e+00, 6.6791e-02, 2.3561e-02,\n",
      "        1.5287e-02, 1.1934e-02, 7.4850e-02, 3.5846e-02, 9.3368e-02, 0.0000e+00,\n",
      "        4.1905e-02, 1.4009e-01, 2.4972e-03, 7.5983e-02, 7.0078e-02, 3.6229e-03,\n",
      "        7.2929e-02, 0.0000e+00, 4.8558e-02, 9.1083e-02, 1.3109e-03, 1.0339e-01,\n",
      "        4.7628e-03, 5.3280e-02, 9.0081e-02, 2.6073e-03, 9.9779e-02, 4.7099e-02,\n",
      "        2.3171e-03, 6.4161e-02, 2.4590e-03, 5.0286e-03, 9.3648e-03, 8.2079e-02,\n",
      "        1.3749e-03, 2.8687e-02, 5.3161e-03, 1.6879e-02, 5.4143e-02, 6.6667e-02,\n",
      "        4.2346e-02, 4.1945e-03, 1.0163e-01, 1.8323e-03, 2.1994e-02, 0.0000e+00,\n",
      "        2.5874e-03, 3.7612e-03, 1.7352e-02, 7.0004e-02, 2.0352e-02, 4.0188e-02,\n",
      "        6.2422e-02, 9.7528e-02, 7.4811e-02, 1.1819e-03, 8.0254e-02, 2.4291e-02,\n",
      "        7.4338e-02, 5.3345e-02, 2.4412e-02, 8.0064e-02, 3.7334e-03, 2.6564e-03,\n",
      "        8.7024e-03, 7.1829e-02, 2.7429e-02, 5.7267e-02, 1.2167e-03, 1.0398e-01,\n",
      "        2.0994e-02, 2.6025e-02, 1.9866e-01, 4.1333e-02, 8.9048e-02, 1.2646e-03,\n",
      "        0.0000e+00, 9.0643e-02, 1.6102e-02, 4.8082e-03, 4.5220e-02, 1.6456e-02,\n",
      "        6.7989e-02, 1.5899e-03, 0.0000e+00, 1.0778e-02, 3.1341e-03, 3.6899e-02,\n",
      "        7.1910e-04, 4.1362e-02, 0.0000e+00, 5.2377e-03, 1.4139e-01, 6.5037e-02,\n",
      "        2.9120e-02, 6.4752e-05, 2.1105e-04, 8.6584e-02, 9.0152e-02, 2.8970e-02,\n",
      "        0.0000e+00, 3.9266e-02, 1.8744e-02, 5.2589e-02, 4.4427e-04, 4.1617e-02,\n",
      "        9.7809e-02, 1.8897e-03, 9.8436e-03, 2.0967e-02, 5.7903e-03, 2.1151e-02,\n",
      "        1.0459e-01, 1.4229e-04, 9.4145e-02, 3.6567e-02, 7.3112e-02, 4.1157e-03,\n",
      "        4.3387e-02, 1.1996e-02, 4.8574e-02, 5.0169e-02, 2.8337e-03, 1.1598e-03,\n",
      "        4.7763e-03, 1.2911e-02, 2.7641e-01, 7.0117e-02, 1.4177e-02, 1.0045e-01,\n",
      "        3.5690e-03, 1.6091e-02, 3.4451e-04, 0.0000e+00, 4.6418e-03, 3.4779e-02,\n",
      "        4.8337e-02, 3.7802e-02, 6.6973e-04, 7.2473e-02, 1.4440e-03, 1.1044e-01,\n",
      "        0.0000e+00, 1.0222e-01, 4.6983e-02, 5.1051e-02, 0.0000e+00, 8.1054e-02,\n",
      "        1.3621e-01, 8.8411e-02, 0.0000e+00, 1.2885e-02, 5.1382e-02, 6.1308e-02,\n",
      "        2.7645e-03, 2.6644e-03, 5.5333e-02, 1.8297e-02, 1.3830e-01, 1.1099e-03,\n",
      "        3.3436e-04, 2.3978e-02, 7.2426e-02, 9.1232e-02, 6.5354e-02, 6.1794e-02,\n",
      "        7.9554e-02, 0.0000e+00, 0.0000e+00, 3.1518e-02, 5.1516e-04, 7.7872e-02,\n",
      "        2.3348e-02, 2.2849e-03, 1.8386e-02, 0.0000e+00, 6.8116e-03, 1.5321e-02,\n",
      "        8.5302e-02, 4.0384e-02, 4.7430e-03, 1.2801e-04, 3.3925e-02, 0.0000e+00,\n",
      "        1.6508e-01, 2.0790e-02, 1.7392e-02, 7.7801e-02, 8.2093e-03, 1.5449e-02,\n",
      "        2.7990e-02, 1.7018e-02, 4.9587e-03, 3.3201e-02, 9.8676e-02, 2.0624e-02,\n",
      "        2.9658e-02, 8.6450e-03, 3.6150e-02, 8.7534e-02, 6.5142e-02, 5.7436e-02,\n",
      "        1.8159e-03, 5.6869e-05, 7.5300e-02, 1.2530e-01, 9.8438e-02, 0.0000e+00,\n",
      "        6.4313e-02, 1.5310e-02, 5.0328e-02, 3.7865e-02, 4.8117e-02, 7.3274e-03,\n",
      "        3.9181e-02, 0.0000e+00, 3.9125e-02, 2.3325e-02, 2.2866e-03, 4.3693e-02,\n",
      "        1.5795e-02, 5.2958e-02, 9.1955e-02, 1.5582e-02, 1.1586e-01, 2.0809e-02,\n",
      "        9.7260e-03, 1.3796e-04, 8.8139e-03, 2.6259e-02, 2.7762e-02, 2.7279e-02,\n",
      "        1.0136e-01, 4.4353e-05, 1.1226e-01, 1.2905e-01, 5.4665e-02, 7.2012e-03,\n",
      "        1.0222e-04, 0.0000e+00, 0.0000e+00, 6.4288e-02, 6.2392e-02, 3.5535e-02,\n",
      "        1.3761e-02, 1.4819e-02, 2.1231e-02, 2.9662e-03, 4.6251e-02, 2.3971e-01,\n",
      "        0.0000e+00, 8.7672e-02, 2.0501e-05, 4.7418e-02, 6.4748e-03, 3.0477e-02,\n",
      "        3.2649e-03, 1.6587e-02, 2.1197e-02, 6.5835e-02, 2.3927e-01, 1.6310e-02,\n",
      "        2.7929e-02, 1.2765e-02, 1.6898e-02, 2.5435e-03, 5.5618e-03, 1.3538e-02,\n",
      "        1.4733e-02, 4.6375e-02, 3.4984e-02, 9.0994e-05, 1.2528e-02, 5.2308e-02,\n",
      "        6.5495e-03, 2.5373e-04, 1.0582e-01, 3.3616e-02, 0.0000e+00, 1.7039e-01,\n",
      "        4.8592e-02, 1.2201e-02, 1.1060e-01, 2.7335e-03, 2.4765e-02, 0.0000e+00,\n",
      "        9.6197e-03, 1.1531e-03, 0.0000e+00, 9.6956e-02, 1.9297e-02, 3.9631e-03,\n",
      "        1.2695e-02, 1.2063e-02, 1.6414e-01, 1.2339e-03, 0.0000e+00, 3.1070e-01,\n",
      "        0.0000e+00, 1.6434e-02, 1.2582e-01, 3.5327e-03, 1.4505e-02, 6.9718e-02,\n",
      "        2.4622e-03, 4.6459e-02, 1.4674e-01, 2.2080e-02, 9.8616e-03, 2.6445e-02,\n",
      "        9.6880e-03, 4.2828e-02, 4.3473e-02, 3.5029e-02, 8.5993e-02, 1.2118e-02,\n",
      "        1.3390e-01, 9.8678e-03, 3.7153e-02, 2.5109e-02, 1.0950e-02, 1.9155e-01],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([2.4278e-04, 5.1044e-03, 3.3143e-03, 3.6523e-03, 4.9908e-03, 9.7630e-03,\n",
      "        7.5587e-03, 1.6542e-02, 4.5667e-03, 2.8923e-02, 2.8044e-04, 1.4578e-03,\n",
      "        2.4479e-04, 0.0000e+00, 7.1044e-04, 3.8785e-02, 2.9593e-04, 5.2250e-03,\n",
      "        9.9377e-03, 6.2623e-03, 2.3844e-03, 1.6565e-04, 6.6878e-03, 6.7779e-03,\n",
      "        2.0442e-03, 3.8049e-03, 1.4390e-02, 0.0000e+00, 1.6078e-02, 9.9481e-03,\n",
      "        1.4673e-02, 1.3248e-02, 4.5070e-02, 0.0000e+00, 1.5640e-03, 1.8938e-03,\n",
      "        0.0000e+00, 1.2431e-02, 0.0000e+00, 1.4103e-02, 3.9567e-05, 3.3599e-05,\n",
      "        8.5581e-02, 1.7049e-03, 2.9829e-02, 0.0000e+00, 9.7835e-04, 4.5622e-03,\n",
      "        3.9496e-05, 1.4508e-04, 1.3014e-03, 0.0000e+00, 0.0000e+00, 4.7488e-03,\n",
      "        9.5142e-04, 3.1166e-02, 1.1679e-02, 0.0000e+00, 1.1520e-03, 3.0738e-03,\n",
      "        2.1934e-03, 1.1762e-02, 4.4330e-03, 2.0977e-02, 4.5314e-03, 3.5125e-03,\n",
      "        3.2991e-04, 7.3299e-03, 0.0000e+00, 1.2792e-02, 2.9346e-03, 3.2622e-06,\n",
      "        3.6997e-03, 0.0000e+00, 8.8225e-03, 1.1080e-02, 1.3268e-02, 2.7838e-01,\n",
      "        9.5373e-03, 2.7126e-03, 5.5634e-03, 1.7990e-02, 4.9594e-03, 0.0000e+00,\n",
      "        2.0021e-03, 8.7774e-04, 3.1889e-02, 0.0000e+00, 3.9032e-03, 1.0616e-05,\n",
      "        0.0000e+00, 7.1561e-03, 1.1010e-02, 0.0000e+00, 0.0000e+00, 2.6327e-04,\n",
      "        2.5475e-02, 6.1791e-04, 0.0000e+00, 1.2030e-02, 4.7874e-03, 3.9819e-02,\n",
      "        0.0000e+00, 1.3322e-02, 1.6905e-02, 0.0000e+00, 5.0473e-02, 5.1173e-03,\n",
      "        9.4797e-03, 0.0000e+00, 5.2384e-03, 0.0000e+00, 0.0000e+00, 3.5063e-03,\n",
      "        1.4966e-01, 1.2882e-02, 9.4720e-03, 0.0000e+00, 9.2518e-03, 5.1919e-02,\n",
      "        5.6167e-03, 1.4628e-02, 7.8886e-03, 3.9339e-02, 0.0000e+00, 2.8408e-03,\n",
      "        8.3713e-04, 2.2892e-02, 2.8246e-02, 1.6707e-02, 2.6575e-02, 4.6919e-03,\n",
      "        0.0000e+00, 3.8422e-04, 2.0819e-04, 0.0000e+00, 1.5884e-02, 8.5726e-04,\n",
      "        7.7136e-03, 3.4012e-03, 2.1688e-02, 1.0418e-02, 4.8289e-03, 1.0630e-03,\n",
      "        1.5868e-03, 5.3362e-03, 3.1715e-05, 0.0000e+00, 7.3320e-04, 6.6777e-03,\n",
      "        5.2447e-04, 5.3782e-07, 8.5243e-03, 1.1528e-06, 2.2823e-02, 4.5334e-02,\n",
      "        1.1489e-02, 2.8082e-03, 1.7476e-02, 1.4813e-02, 5.1529e-03, 3.7355e-03,\n",
      "        2.8235e-03, 7.6874e-05, 7.8412e-03, 1.0566e-02, 6.2936e-03, 4.1473e-04,\n",
      "        2.1021e-02, 3.4801e-03, 4.1376e-03, 1.3684e-03, 7.6317e-02, 1.5259e-03,\n",
      "        1.5069e-02, 9.7388e-03, 1.1554e-03, 2.3930e-03, 2.3012e-05, 6.5631e-03,\n",
      "        0.0000e+00, 2.3510e-02, 1.1216e-04, 8.6390e-02, 2.6230e-02, 4.0374e-02,\n",
      "        3.7009e-04, 0.0000e+00, 1.2101e-02, 3.6417e-03, 1.3667e-02, 1.3945e-03,\n",
      "        8.2513e-03, 8.4804e-03, 1.2560e-04, 5.0493e-03, 1.1478e-02, 9.4356e-03,\n",
      "        5.2750e-03, 3.3723e-03, 4.8625e-04, 0.0000e+00, 2.2050e-02, 1.6185e-03,\n",
      "        8.2414e-03, 4.0892e-02, 4.2901e-02, 1.4023e-04, 0.0000e+00, 8.3830e-03,\n",
      "        1.3090e-02, 3.3989e-03, 0.0000e+00, 3.2532e-03, 4.1420e-03, 2.2883e-03,\n",
      "        0.0000e+00, 1.1764e-03, 7.2217e-03, 4.0045e-03, 1.5619e-03, 1.4726e-03,\n",
      "        4.9903e-03, 5.9048e-03, 1.3293e-03, 0.0000e+00, 2.4819e-02, 0.0000e+00,\n",
      "        7.4300e-03, 1.8708e-02, 4.7925e-05, 0.0000e+00, 0.0000e+00, 1.1703e-01,\n",
      "        7.6852e-03, 3.1772e-03, 6.9120e-03, 1.8492e-02, 3.6225e-02, 4.0710e-03,\n",
      "        0.0000e+00, 2.8545e-02, 3.2552e-03, 8.3530e-04, 0.0000e+00, 1.7421e-03,\n",
      "        9.1782e-03, 6.7153e-03, 7.3065e-04, 1.9536e-04, 6.0511e-03, 4.4361e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 2.2212e-03, 5.3095e-02, 1.6680e-02,\n",
      "        0.0000e+00, 3.2336e-02, 9.4331e-02, 0.0000e+00, 0.0000e+00, 1.2620e-02,\n",
      "        3.9121e-03, 0.0000e+00, 1.2121e-02, 2.1214e-05, 4.5559e-04, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 1.5129e-05, 0.0000e+00, 3.5453e-03, 6.5371e-02,\n",
      "        8.1437e-03, 5.8671e-03, 5.2592e-02, 1.6830e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.5683e-02, 2.9349e-03, 3.0014e-03, 0.0000e+00, 6.7260e-02, 1.2225e-01,\n",
      "        2.6221e-02, 3.0706e-03, 6.9473e-03, 1.7702e-03, 0.0000e+00, 7.6959e-03,\n",
      "        8.6478e-02, 7.8340e-03, 9.3918e-03, 4.7018e-03, 0.0000e+00, 7.5717e-03,\n",
      "        1.3191e-02, 7.3181e-03, 9.9033e-02, 4.9566e-03, 0.0000e+00, 0.0000e+00,\n",
      "        8.2987e-02, 1.3523e-02, 0.0000e+00, 2.5845e-02, 4.7726e-02, 1.8729e-03,\n",
      "        1.3483e-03, 3.4728e-02, 8.5692e-03, 5.0989e-03, 4.2929e-02, 2.6465e-02,\n",
      "        7.3457e-06, 3.6361e-03, 1.7697e-01, 2.9485e-03, 3.0082e-02, 3.8738e-03,\n",
      "        1.1009e-02, 2.1159e-02, 0.0000e+00, 6.5681e-04, 3.1904e-01, 4.6082e-02,\n",
      "        5.5371e-03, 4.5005e-03, 1.9667e-02, 3.1932e-01, 1.1810e-03, 4.7412e-02,\n",
      "        0.0000e+00, 4.6440e-03, 2.6095e-02, 2.6231e-02, 1.0581e-01, 0.0000e+00,\n",
      "        9.7942e-03, 7.6683e-03, 1.1068e-03, 6.3916e-04, 5.4849e-03, 0.0000e+00,\n",
      "        2.8744e-02, 0.0000e+00, 1.4259e-04, 0.0000e+00, 9.2950e-03, 1.9554e-03,\n",
      "        4.0546e-03, 0.0000e+00, 2.1225e-04, 6.2274e-03, 8.6318e-02, 0.0000e+00,\n",
      "        0.0000e+00, 4.6263e-03, 4.1468e-03, 6.2075e-04, 5.0688e-02, 5.3549e-02,\n",
      "        4.9904e-02, 6.1214e-03, 1.5224e-02, 1.9496e-03, 9.2062e-06, 9.3868e-02,\n",
      "        4.6855e-03, 8.1572e-03, 0.0000e+00, 6.2683e-03, 3.0497e-02, 0.0000e+00,\n",
      "        4.9883e-02, 0.0000e+00, 2.2970e-03, 6.2135e-04, 7.5417e-03, 3.7474e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.5983e-02, 7.5080e-04, 3.0909e-02, 2.8437e-02,\n",
      "        3.3757e-03, 1.7294e-02, 4.5295e-03, 1.5028e-03, 5.9574e-03, 1.9315e-04,\n",
      "        0.0000e+00, 1.6576e-02, 1.6405e-02, 4.1333e-03, 1.8489e-03, 1.6864e-02,\n",
      "        1.1450e-02, 9.7205e-03, 0.0000e+00, 7.5544e-05, 7.3815e-03, 0.0000e+00,\n",
      "        4.2640e-01, 2.0734e-04, 1.0446e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0992e-03, 2.1122e-02, 1.6844e-03, 1.4715e-02, 1.5803e-03, 1.3562e-03,\n",
      "        0.0000e+00, 1.7764e-03, 2.4939e-02, 2.9864e-03, 5.4563e-02, 0.0000e+00,\n",
      "        2.6414e-02, 4.1691e-02, 4.4202e-03, 2.2234e-03, 8.8392e-03, 2.7729e-03,\n",
      "        2.7733e-03, 2.8818e-02, 0.0000e+00, 1.6832e-02, 9.7898e-03, 5.7128e-02,\n",
      "        0.0000e+00, 1.1900e-02, 0.0000e+00, 2.1192e-02, 6.2120e-02, 0.0000e+00,\n",
      "        5.7548e-03, 4.8024e-02, 5.2667e-03, 7.9865e-03, 1.9016e-02, 1.6774e-04,\n",
      "        1.2918e-02, 1.3932e-02, 3.6617e-04, 0.0000e+00, 8.3164e-03, 0.0000e+00,\n",
      "        0.0000e+00, 4.2462e-03, 3.5702e-03, 4.7261e-03, 0.0000e+00, 0.0000e+00,\n",
      "        3.6326e-03, 1.4801e-03, 7.5340e-03, 1.9873e-02, 1.1641e-03, 8.7477e-02,\n",
      "        5.7734e-03, 1.7651e-03, 2.5033e-03, 1.1908e-02, 7.2080e-03, 1.2773e-02,\n",
      "        2.5740e-03, 0.0000e+00, 0.0000e+00, 1.5564e-02, 2.0229e-02, 8.9851e-03,\n",
      "        1.6587e-02, 1.5879e-02, 5.8510e-04, 1.1226e-02, 2.9143e-02, 2.0524e-02,\n",
      "        1.3262e-02, 0.0000e+00, 2.6437e-04, 1.0169e-01, 5.7651e-03, 1.0600e-02,\n",
      "        1.1902e-02, 8.3135e-04, 3.8323e-02, 1.7399e-02, 8.0217e-03, 0.0000e+00,\n",
      "        0.0000e+00, 2.1388e-02, 0.0000e+00, 1.0681e-02, 4.6153e-02, 2.2553e-04,\n",
      "        6.5413e-02, 2.0469e-02, 4.2118e-03, 8.2115e-03, 2.7153e-03, 1.5451e-04,\n",
      "        5.4711e-04, 6.1846e-03, 0.0000e+00, 5.0543e-02, 2.4058e-03, 3.6187e-03,\n",
      "        2.9387e-02, 0.0000e+00, 5.4032e-05, 1.2980e-02, 6.8929e-02, 2.7811e-05,\n",
      "        4.0419e-02, 2.1762e-02, 0.0000e+00, 1.6533e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.8922e-02, 2.9040e-03, 6.4413e-02, 3.5667e-03, 3.0119e-03, 1.1068e-03,\n",
      "        1.5706e-04, 3.3316e-03, 4.8928e-02, 8.3346e-03, 1.1873e-02, 0.0000e+00,\n",
      "        1.1479e-02, 4.2874e-02, 2.6937e-03, 5.0642e-03, 2.3866e-02, 1.7883e-03,\n",
      "        2.1339e-03, 1.2750e-04, 4.0818e-03, 4.1618e-04, 1.3778e-04, 5.0260e-03,\n",
      "        1.1281e-02, 3.1652e-03, 8.0314e-04, 5.7138e-03, 1.6757e-02, 6.1096e-03,\n",
      "        0.0000e+00, 3.1810e-03, 3.9845e-03, 1.4137e-03, 1.4881e-04, 2.0341e-03,\n",
      "        4.6564e-03, 5.0936e-03, 1.1292e-02, 1.3496e-02, 4.5071e-03, 4.9213e-05,\n",
      "        5.2711e-03, 3.2937e-02, 4.4623e-02, 0.0000e+00, 1.0925e-02, 5.8128e-02,\n",
      "        0.0000e+00, 5.8653e-03, 1.2929e-03, 3.8930e-03, 3.6961e-03, 1.7534e-02,\n",
      "        0.0000e+00, 2.1144e-03, 6.3577e-03, 4.8114e-02, 1.5837e-02, 0.0000e+00,\n",
      "        1.7047e-02, 3.5375e-02, 0.0000e+00, 6.3424e-03, 0.0000e+00, 1.5670e-02,\n",
      "        2.9854e-04, 0.0000e+00, 2.2256e-02, 0.0000e+00, 1.6216e-04, 0.0000e+00,\n",
      "        3.8624e-03, 1.2792e-02, 2.0002e-02, 7.5376e-03, 5.3974e-04, 1.6150e-02,\n",
      "        3.8876e-03, 1.2321e-04, 2.4647e-03, 3.8848e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.2994e-02, 0.0000e+00, 0.0000e+00, 3.8724e-05, 4.0559e-02, 8.4475e-04,\n",
      "        9.6931e-04, 0.0000e+00, 1.5984e-02, 0.0000e+00, 5.2222e-03, 2.4175e-03,\n",
      "        7.1591e-05, 9.8953e-03, 2.7119e-03, 5.4636e-03, 1.4134e-02, 1.4308e-03,\n",
      "        0.0000e+00, 5.5885e-04, 1.0142e-02, 2.6396e-02, 3.7138e-03, 5.6750e-04,\n",
      "        3.1366e-03, 1.1138e-02, 2.3524e-03, 8.0976e-03, 3.0903e-04, 1.8703e-03,\n",
      "        0.0000e+00, 1.5833e-02, 1.5364e-03, 1.2833e-02, 1.0055e-02, 1.8746e-02,\n",
      "        1.5080e-02, 1.8722e-03, 4.2536e-04, 3.9119e-03, 1.0810e-02, 3.4816e-03,\n",
      "        3.6567e-02, 1.3183e-02, 0.0000e+00, 0.0000e+00, 1.0503e-02, 7.4193e-04,\n",
      "        7.1408e-03, 1.1085e-02, 4.8446e-03, 1.3459e-02, 4.3721e-03, 6.7320e-03,\n",
      "        2.1486e-04, 0.0000e+00, 0.0000e+00, 4.7521e-03, 7.2077e-03, 2.5880e-03,\n",
      "        5.2960e-03, 1.1221e-01, 6.4171e-03, 4.4467e-04, 0.0000e+00, 1.2596e-03,\n",
      "        1.8876e-02, 1.0545e-02, 7.1286e-03, 2.5127e-02, 0.0000e+00, 2.4397e-03,\n",
      "        3.0102e-02, 2.3397e-03, 6.6618e-03, 3.8044e-03, 0.0000e+00, 4.8345e-03,\n",
      "        8.9462e-03, 2.8137e-02, 6.6974e-03, 4.0243e-02, 4.0903e-03, 3.7897e-02,\n",
      "        0.0000e+00, 1.0476e-02, 2.1785e-04, 1.0040e-02, 1.6332e-03, 6.1285e-05,\n",
      "        9.3941e-04, 2.5244e-02, 1.3727e-03, 3.2693e-03, 0.0000e+00, 2.5494e-04,\n",
      "        5.1664e-03, 3.8807e-03, 1.7851e-03, 4.2174e-03, 3.4660e-03, 2.7296e-03,\n",
      "        1.8040e-03, 1.8805e-02, 3.6845e-03, 6.1308e-03, 1.4358e-02, 0.0000e+00,\n",
      "        5.7121e-03, 4.9343e-04, 0.0000e+00, 9.9235e-03, 4.5949e-03, 4.5990e-02,\n",
      "        3.7583e-04, 1.3810e-02, 0.0000e+00, 0.0000e+00, 9.1023e-03, 7.0518e-03,\n",
      "        5.7912e-02, 7.2649e-05, 0.0000e+00, 1.3115e-02, 2.0280e-03, 0.0000e+00,\n",
      "        0.0000e+00, 5.9907e-02, 0.0000e+00, 2.0774e-02, 1.5939e-02, 0.0000e+00,\n",
      "        4.3494e-04, 1.8543e-03, 2.4788e-02, 0.0000e+00, 1.3067e-01, 7.6943e-03,\n",
      "        1.2078e-02, 3.8631e-03, 1.5455e-02, 2.0650e-02, 2.5496e-03, 1.1534e-02,\n",
      "        2.6192e-03, 1.0172e-02, 2.0839e-03, 4.9008e-03, 2.7261e-04, 3.7234e-04,\n",
      "        0.0000e+00, 1.9195e-02, 9.8980e-04, 9.5165e-02, 2.1461e-02, 3.7886e-02],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0019, 0.0050, 0.0027, 0.0048, 0.0033, 0.0057, 0.0019],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0181, 0.0291, 0.0235, 0.0266, 0.0256, 0.0322, 0.0187],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0000e+00, 0.0000e+00, 5.9943e-02, 0.0000e+00, 0.0000e+00, 1.6286e-02,\n",
      "        2.3551e-02, 1.2615e-02, 2.6209e-04, 0.0000e+00, 2.5662e-02, 8.3667e-02,\n",
      "        3.9897e-02, 5.2478e-02, 1.7567e-03, 1.6009e-01, 7.7202e-02, 5.0780e-03,\n",
      "        7.1820e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.4074e-05, 2.5239e-02,\n",
      "        4.3830e-02, 3.8737e-02, 8.0018e-01, 0.0000e+00, 5.7425e-01, 1.9697e-02,\n",
      "        1.0055e-02, 7.9088e-02, 3.2181e-02, 6.1297e-03, 6.5116e-03, 0.0000e+00,\n",
      "        3.1339e-02, 3.5630e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 2.1779e-02,\n",
      "        1.8597e-01, 8.4470e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        8.4098e-02, 5.7339e-03, 6.8445e-02, 1.7734e-02, 0.0000e+00, 4.2070e-03,\n",
      "        5.6631e-04, 1.8672e-02, 5.6263e-07, 0.0000e+00, 5.6881e-04, 1.6426e-03,\n",
      "        3.2966e-02, 2.7413e-02, 0.0000e+00, 1.5940e-02, 0.0000e+00, 8.1894e-03,\n",
      "        3.5779e-05, 0.0000e+00, 0.0000e+00, 1.6638e-02, 1.2108e-02, 1.3640e-02,\n",
      "        7.2265e-05, 5.7118e-02, 5.7784e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.7006e-03, 3.0460e-03, 2.2728e-03, 1.0511e-02, 4.2951e-02,\n",
      "        6.7418e-02, 1.0577e-01, 3.1372e-02, 7.7870e-02, 1.7138e-02, 4.1799e-02,\n",
      "        1.0787e-03, 8.3885e-04, 0.0000e+00, 0.0000e+00, 2.2275e-05, 1.8153e-02,\n",
      "        1.2316e-01, 1.5091e-01, 2.7224e-03, 1.4441e-03, 5.0080e-02, 5.5739e-02,\n",
      "        1.5611e-02, 5.4855e-02, 2.8687e-05, 1.9735e-01, 3.6872e-02, 3.6161e-03,\n",
      "        8.1065e-05, 1.0277e-01, 1.6100e-02, 7.3366e-02, 4.3457e-03, 7.8365e-03,\n",
      "        1.1247e-01, 0.0000e+00, 4.2248e-03, 1.1471e-01, 0.0000e+00, 2.4531e-03,\n",
      "        7.6433e-03, 0.0000e+00, 9.3546e-02, 0.0000e+00, 1.0666e-01, 6.4656e-03,\n",
      "        1.0315e-02, 2.2474e-02, 5.0593e-04, 1.9915e-02, 1.3778e-03, 1.4198e-02,\n",
      "        3.9503e-02, 0.0000e+00, 2.7359e-02, 4.5407e-02, 6.5793e-02, 2.8488e-03,\n",
      "        1.5244e-03, 1.9784e-02, 3.0674e-02, 4.5476e-02, 3.0981e-02, 2.3204e-02,\n",
      "        2.3101e-01, 4.1876e-03, 3.8336e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        4.3804e-05, 5.8011e-02, 5.5821e-03, 6.4116e-02, 1.3342e-02, 1.3130e-02,\n",
      "        1.2418e-02, 7.3459e-02, 5.0757e-02, 6.6954e-02, 0.0000e+00, 2.2526e-02,\n",
      "        0.0000e+00, 1.0357e-02, 1.8806e-03, 1.5832e-05, 1.1982e-02, 4.4165e-03,\n",
      "        7.6746e-02, 5.0241e-02, 9.7457e-02, 1.0645e-02, 9.6303e-02, 0.0000e+00,\n",
      "        3.5780e-02, 7.8977e-02, 0.0000e+00, 1.8060e-04, 4.4244e-03, 4.2546e-03,\n",
      "        3.4848e-03, 0.0000e+00, 1.4777e-02, 0.0000e+00, 9.8186e-05, 1.0167e-01,\n",
      "        9.1418e-03, 5.0914e-03, 4.0980e-02, 2.0898e-03, 8.1458e-03, 1.2382e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1858e-02, 0.0000e+00, 0.0000e+00, 7.7620e-03,\n",
      "        3.9609e-02, 1.1001e-02, 3.6325e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.5477e-02, 4.3714e-02, 4.1266e-02, 6.8925e-02, 1.0629e-02, 8.3237e-02,\n",
      "        1.0465e-02, 7.4013e-03, 9.2723e-02, 0.0000e+00, 1.0319e-02, 0.0000e+00,\n",
      "        6.8833e-02, 7.8601e-03, 3.6393e-02, 6.6940e-02, 0.0000e+00, 5.0425e-02,\n",
      "        0.0000e+00, 7.1944e-02, 2.8044e-02, 4.4815e-02, 1.4784e-02, 4.5018e-02,\n",
      "        5.1088e-02, 6.6371e-03, 3.0748e-02, 0.0000e+00, 8.0645e-02, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 9.7447e-03, 1.0180e-01, 0.0000e+00, 9.7657e-03,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.0693e-02, 0.0000e+00,\n",
      "        4.2269e-03, 5.2464e-02, 2.6993e-03, 2.9715e-02, 1.4671e-03, 1.0924e-01,\n",
      "        1.7943e-01, 0.0000e+00, 0.0000e+00, 4.7159e-02, 6.9755e-02, 8.3962e-02,\n",
      "        0.0000e+00, 4.7372e-02, 0.0000e+00, 1.0326e-03, 8.3498e-03, 6.0103e-02,\n",
      "        1.8167e-02, 0.0000e+00, 8.7941e-03, 1.1536e-01, 8.1876e-03, 1.1448e-01,\n",
      "        8.3785e-02, 4.6515e-04, 1.4866e-02, 6.1441e-03, 1.5160e-02, 1.5703e-01,\n",
      "        2.3207e-03, 9.0622e-03, 4.6953e-02, 0.0000e+00, 0.0000e+00, 3.1039e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.5827e-02, 7.1598e-02, 7.3359e-02, 0.0000e+00,\n",
      "        2.1534e-04, 0.0000e+00, 9.0540e-03, 0.0000e+00, 3.0266e-04, 0.0000e+00,\n",
      "        4.0609e-03, 9.9626e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.1933e-05,\n",
      "        7.9976e-02, 2.0701e-01, 2.7265e-03, 7.2063e-02, 8.3513e-02, 0.0000e+00,\n",
      "        0.0000e+00, 1.4926e-03, 0.0000e+00, 0.0000e+00, 4.7690e-02, 5.9247e-01,\n",
      "        4.3958e-02, 4.8789e-02, 4.8173e-02, 2.8221e-02, 1.0968e-01, 1.6009e-02,\n",
      "        0.0000e+00, 0.0000e+00, 1.1038e-01, 6.2581e-03, 0.0000e+00, 6.5896e-02,\n",
      "        5.4223e-02, 0.0000e+00, 8.3299e-02, 2.8212e-02, 5.9779e-01, 0.0000e+00,\n",
      "        4.3285e-05, 0.0000e+00, 0.0000e+00, 1.2890e-01, 1.0104e-03, 1.4929e-01,\n",
      "        0.0000e+00, 0.0000e+00, 4.0761e-02, 2.8143e-03, 0.0000e+00, 0.0000e+00,\n",
      "        2.1148e-04, 0.0000e+00, 3.8980e-03, 2.5496e-03, 2.5740e-01, 8.8188e-02,\n",
      "        0.0000e+00, 0.0000e+00, 3.1052e-03, 0.0000e+00, 2.1655e-02, 0.0000e+00,\n",
      "        1.7464e-02, 1.8965e-03, 0.0000e+00, 1.7861e-02, 2.6702e-02, 6.0438e-02,\n",
      "        0.0000e+00, 0.0000e+00, 5.9852e-02, 0.0000e+00, 0.0000e+00, 7.5807e-04,\n",
      "        0.0000e+00, 6.1640e-04, 4.0067e-02, 2.4529e-02, 0.0000e+00, 6.4308e-03,\n",
      "        0.0000e+00, 2.1119e-03, 1.2802e-01, 0.0000e+00, 6.2461e-02, 1.7086e-01,\n",
      "        0.0000e+00, 2.4320e-02, 1.6803e-02, 1.0858e-02, 6.7643e-03, 9.2623e-03,\n",
      "        1.3820e-03, 4.2794e-02, 2.8081e-02, 1.7113e-02, 5.8526e-03, 4.3167e-02,\n",
      "        0.0000e+00, 2.2719e-01, 9.2247e-02, 1.1692e-04, 1.0261e-01, 2.9566e-02,\n",
      "        1.2365e-02, 0.0000e+00, 2.3237e-02, 1.7788e-02, 6.1130e-02, 8.0902e-02,\n",
      "        2.2345e-04, 5.0093e-02, 0.0000e+00, 6.8581e-02, 7.1084e-05, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 9.8372e-02, 0.0000e+00, 2.5466e-02,\n",
      "        2.3482e-02, 0.0000e+00, 7.6725e-03, 2.6897e-02, 0.0000e+00, 3.6913e-02,\n",
      "        8.5075e-02, 0.0000e+00, 0.0000e+00, 6.7031e-02, 6.8549e-02, 1.4984e-02,\n",
      "        8.5824e-04, 6.0790e-02, 3.8499e-03, 2.2925e-02, 3.0191e-02, 3.6790e-04,\n",
      "        2.7028e-02, 6.5319e-02, 0.0000e+00, 2.4923e-01, 6.2350e-03, 0.0000e+00,\n",
      "        0.0000e+00, 1.8623e-02, 0.0000e+00, 8.1745e-03, 1.3652e-01, 3.5094e-02,\n",
      "        1.8699e-02, 2.0652e-02, 0.0000e+00, 3.1322e-02, 4.0868e-02, 0.0000e+00,\n",
      "        0.0000e+00, 3.3946e-03, 1.8752e-01, 0.0000e+00, 1.5357e-02, 3.4038e-03,\n",
      "        0.0000e+00, 3.0598e-02, 4.3158e-02, 5.2211e-02, 0.0000e+00, 9.0517e-02,\n",
      "        6.2415e-03, 0.0000e+00, 1.2053e-02, 1.2415e-03, 0.0000e+00, 1.2414e-02,\n",
      "        0.0000e+00, 2.6608e-02, 3.3202e-01, 0.0000e+00, 0.0000e+00, 3.7025e-02,\n",
      "        1.1547e-01, 1.9563e-03, 5.5737e-02, 8.7883e-02, 9.3717e-03, 3.6051e-02,\n",
      "        7.5522e-02, 0.0000e+00, 2.1759e-04, 3.7899e-02, 3.3679e-02, 3.0900e-02,\n",
      "        5.3396e-03, 0.0000e+00, 2.6530e-02, 8.2790e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.3211e-03, 0.0000e+00, 0.0000e+00, 9.9806e-03, 1.2348e-01,\n",
      "        6.6634e-03, 2.1123e-02, 5.6950e-02, 2.4545e-03, 0.0000e+00, 3.1597e-03,\n",
      "        1.2926e-02, 3.4584e-02, 5.0209e-02, 1.0093e-01, 2.4244e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.7863e-02, 4.2965e-03, 1.8308e-02, 1.1488e-02, 9.6212e-04,\n",
      "        3.7088e-03, 1.5307e-02, 8.6630e-02, 5.3903e-03, 0.0000e+00, 0.0000e+00,\n",
      "        9.7315e-03, 2.7618e-02, 4.1141e-02, 2.5161e-02, 7.2626e-02, 0.0000e+00,\n",
      "        1.2246e-02, 8.1083e-02, 9.2837e-02, 2.3371e-04, 3.4417e-02, 2.5099e-02,\n",
      "        7.3490e-02, 4.3060e-02, 2.1955e-02, 2.3163e-03, 0.0000e+00, 2.0539e-02,\n",
      "        0.0000e+00, 0.0000e+00, 7.8203e-02, 4.6618e-02, 1.5667e-02, 4.0337e-02,\n",
      "        8.6750e-02, 3.2280e-02, 6.9234e-03, 2.9053e-03, 1.9711e-03, 0.0000e+00,\n",
      "        3.1639e-03, 5.8108e-03, 0.0000e+00, 0.0000e+00, 8.1797e-02, 3.0479e-02,\n",
      "        0.0000e+00, 2.9357e-03, 1.2628e-03, 1.7371e-02, 1.3012e-04, 8.5721e-02,\n",
      "        0.0000e+00, 1.4390e-02, 1.4412e-03, 0.0000e+00, 3.7365e-04, 0.0000e+00,\n",
      "        1.7851e-01, 3.2110e-03, 2.4949e-01, 5.0983e-02, 3.7123e-02, 0.0000e+00,\n",
      "        1.6746e-02, 3.4827e-02, 4.0365e-03, 0.0000e+00, 1.0966e-02, 4.1497e-02,\n",
      "        1.5384e-02, 1.2249e-02, 5.7169e-03, 2.9536e-02, 6.4967e-02, 2.3311e-02,\n",
      "        8.3700e-03, 6.3103e-02, 3.4438e-02, 5.1629e-03, 8.6082e-02, 0.0000e+00,\n",
      "        4.7637e-02, 3.6515e-02, 0.0000e+00, 4.7051e-02, 1.5746e-02, 0.0000e+00,\n",
      "        0.0000e+00, 1.7090e-02, 2.3064e-02, 0.0000e+00, 1.7867e-03, 2.4968e-02,\n",
      "        2.5722e-04, 1.1235e-02, 3.0817e-02, 1.7380e-02, 0.0000e+00, 0.0000e+00,\n",
      "        2.3064e-02, 1.3576e-03, 1.7146e-02, 3.1119e-02, 1.7243e-02, 1.4618e-02,\n",
      "        0.0000e+00, 4.2510e-05, 2.5834e-04, 5.1965e-04, 0.0000e+00, 1.2147e-01,\n",
      "        0.0000e+00, 4.9587e-03, 2.4134e-02, 1.0048e-01, 4.1509e-05, 1.8265e-02,\n",
      "        1.1182e-02, 0.0000e+00, 0.0000e+00, 5.4824e-03, 1.4443e-02, 8.0759e-03,\n",
      "        3.6249e-02, 2.3204e-03, 0.0000e+00, 5.8446e-02, 0.0000e+00, 2.4226e-02,\n",
      "        0.0000e+00, 7.8437e-03, 2.8008e-02, 2.5521e-01, 3.8892e-03, 3.8419e-02,\n",
      "        2.1629e-02, 1.1944e-03, 9.0501e-02, 3.6714e-02, 3.2502e-02, 1.3723e-01,\n",
      "        0.0000e+00, 0.0000e+00, 1.3162e-01, 0.0000e+00, 7.5190e-03, 1.2600e-03,\n",
      "        7.4168e-04, 0.0000e+00, 1.6863e-02, 4.7268e-02, 1.5501e-02, 0.0000e+00,\n",
      "        9.4444e-04, 6.9034e-03, 1.4126e-01, 2.9240e-02, 6.9034e-03, 1.5196e-02,\n",
      "        3.7869e-02, 1.4373e-01, 2.3230e-04, 7.4230e-04, 7.6364e-02, 3.1720e-03,\n",
      "        3.6406e-02, 6.7137e-02, 3.6066e-02, 3.4310e-03, 2.3679e-04, 2.4268e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 5.7573e-03, 2.1680e-02, 0.0000e+00,\n",
      "        1.9899e-03, 0.0000e+00, 1.0517e-02, 0.0000e+00, 0.0000e+00, 2.8335e-04,\n",
      "        5.3403e-02, 1.6408e-02, 3.7136e-04, 1.6485e-02, 1.6714e-03, 0.0000e+00,\n",
      "        8.2176e-02, 0.0000e+00, 2.2841e-02, 1.3766e-02, 3.6215e-02, 3.9774e-04,\n",
      "        1.9314e-03, 2.5508e-03, 2.5368e-02, 2.0977e-02, 0.0000e+00, 0.0000e+00,\n",
      "        6.5108e-02, 6.7999e-02, 3.6592e-02, 0.0000e+00, 3.5041e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.6023e-04, 5.0848e-02, 0.0000e+00, 0.0000e+00, 8.1712e-02,\n",
      "        3.7267e-02, 2.1916e-03, 4.7731e-02, 1.8447e-02, 5.2180e-03, 6.4504e-02,\n",
      "        2.9042e-05, 1.6485e-03, 0.0000e+00, 1.3382e-02, 1.1106e-01, 0.0000e+00,\n",
      "        9.0855e-03, 2.0869e-03, 4.1500e-02, 0.0000e+00, 3.3022e-02, 5.1082e-02,\n",
      "        0.0000e+00, 1.5586e-03, 1.0006e-01, 3.6060e-03, 0.0000e+00, 3.9735e-05,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 5.1341e-03,\n",
      "        6.6574e-02, 2.5575e-02, 2.0521e-04, 3.3598e-02, 0.0000e+00, 7.3818e-02,\n",
      "        0.0000e+00, 0.0000e+00, 8.7895e-02, 0.0000e+00, 4.3592e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0014, 0.0164, 0.0017, 0.0082, 0.0019, 0.0173, 0.0018],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0178, 0.0446, 0.0219, 0.0336, 0.0225, 0.0454, 0.0188],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([1.8856e-02, 6.8049e-02, 0.0000e+00, 0.0000e+00, 2.0476e-02, 1.7816e-03,\n",
      "        5.9230e-03, 3.7255e-04, 7.0556e-02, 9.7829e-02, 9.4868e-04, 1.8745e-01,\n",
      "        1.7575e-02, 4.3309e-02, 4.4252e-03, 1.6984e-01, 0.0000e+00, 3.5434e-03,\n",
      "        0.0000e+00, 6.7484e-02, 7.0448e-02, 0.0000e+00, 1.1717e-02, 1.6988e-02,\n",
      "        2.7139e-03, 1.2062e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 3.1779e-03,\n",
      "        2.3660e-02, 0.0000e+00, 1.7891e-02, 4.2171e-02, 7.3583e-03, 1.6863e-01,\n",
      "        0.0000e+00, 1.3764e-02, 0.0000e+00, 0.0000e+00, 4.6859e-02, 2.6315e-02,\n",
      "        1.4986e-01, 6.1279e-02, 3.9956e-01, 2.7012e-02, 0.0000e+00, 0.0000e+00,\n",
      "        5.8391e-02, 0.0000e+00, 8.8342e-02, 1.1383e-02, 5.5877e-01, 3.2241e-02,\n",
      "        9.8563e-03, 9.0106e-03, 2.4318e-02, 0.0000e+00, 4.2678e-02, 2.5351e-03,\n",
      "        1.7266e-02, 0.0000e+00, 7.3493e-04, 3.5154e-02, 0.0000e+00, 2.6570e-02,\n",
      "        2.9522e-04, 1.0562e-02, 0.0000e+00, 3.7622e-03, 0.0000e+00, 6.7561e-05,\n",
      "        2.5168e-03, 9.0988e-03, 3.5714e-02, 1.5936e-01, 9.9770e-03, 0.0000e+00,\n",
      "        6.8619e-02, 7.5164e-04, 2.2681e-03, 8.9800e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.5913e-02, 4.3244e-02, 0.0000e+00, 2.3174e-03, 9.0090e-02,\n",
      "        0.0000e+00, 4.9470e-02, 0.0000e+00, 4.2606e-03, 6.2701e-03, 7.7243e-02,\n",
      "        1.3978e-01, 6.7144e-02, 9.5422e-04, 1.3670e-02, 5.5151e-03, 4.8894e-02,\n",
      "        3.2441e-02, 3.9453e-03, 0.0000e+00, 0.0000e+00, 1.2518e-03, 1.2416e-02,\n",
      "        4.8234e-03, 0.0000e+00, 3.9172e-02, 0.0000e+00, 0.0000e+00, 8.2042e-02,\n",
      "        3.6427e-02, 1.2356e-01, 1.6475e-02, 9.2305e-02, 1.1418e-01, 0.0000e+00,\n",
      "        4.9599e-03, 4.2599e-02, 1.7085e-01, 1.9862e-01, 9.7098e-02, 1.2176e-02,\n",
      "        1.7421e-02, 5.6907e-03, 0.0000e+00, 1.4681e-03, 5.6838e-03, 1.4243e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.6690e-03, 4.0214e-03, 3.9573e-02, 2.2151e-05,\n",
      "        6.5842e-03, 0.0000e+00, 2.8944e-02, 6.9978e-02, 4.3780e-02, 7.7891e-03,\n",
      "        6.3584e-05, 1.0295e-02, 0.0000e+00, 3.0635e-02, 2.3118e-03, 1.0685e-02,\n",
      "        4.7010e-03, 5.8204e-02, 3.1998e-04, 0.0000e+00, 1.3043e-02, 4.6338e-04,\n",
      "        1.2184e-02, 5.3564e-02, 6.2269e-02, 0.0000e+00, 1.2713e-01, 8.9674e-02,\n",
      "        1.8720e-02, 1.1174e-02, 7.8672e-03, 6.3747e-04, 2.9608e-02, 6.6813e-03,\n",
      "        5.8198e-02, 5.1570e-02, 5.2172e-03, 7.4541e-03, 8.7879e-02, 2.4663e-02,\n",
      "        2.4213e-02, 0.0000e+00, 6.3950e-02, 0.0000e+00, 3.4887e-03, 3.5289e-02,\n",
      "        1.1870e-02, 1.6638e-02, 6.3054e-04, 1.2287e-01, 3.0763e-02, 1.8467e-01,\n",
      "        4.5916e-03, 3.4766e-03, 5.3571e-02, 1.4339e-02, 2.9778e-02, 3.4686e-04,\n",
      "        0.0000e+00, 3.8697e-04, 0.0000e+00, 7.6711e-04, 3.7952e-02, 3.8421e-03,\n",
      "        4.0166e-03, 6.6200e-04, 0.0000e+00, 8.5362e-02, 8.4913e-02, 7.1346e-02,\n",
      "        0.0000e+00, 3.8982e-02, 0.0000e+00, 2.6286e-02, 1.5568e-02, 0.0000e+00,\n",
      "        1.0395e-03, 1.5876e-04, 0.0000e+00, 0.0000e+00, 2.4832e-03, 1.6186e-01,\n",
      "        5.3718e-02, 1.6228e-02, 1.4335e-03, 6.5232e-05, 1.3081e-01, 7.4725e-02,\n",
      "        0.0000e+00, 0.0000e+00, 2.1589e-02, 3.9701e-02, 0.0000e+00, 1.3331e-03,\n",
      "        9.8684e-03, 2.8948e-02, 6.8151e-02, 1.1853e-01, 0.0000e+00, 1.2298e-01,\n",
      "        4.3817e-02, 4.8752e-02, 2.1044e-02, 8.7395e-02, 3.1817e-02, 1.1129e-02,\n",
      "        1.4320e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        6.7302e-02, 4.9702e-04, 1.0968e-02, 1.6340e-03, 2.3004e-02, 1.3053e-01,\n",
      "        4.9998e-03, 9.1564e-03, 0.0000e+00, 7.6039e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 8.8574e-02, 8.3037e-02, 1.7172e-02, 1.4525e-02, 4.1259e-02,\n",
      "        4.9230e-02, 0.0000e+00, 7.3622e-03, 0.0000e+00, 1.4926e-02, 1.8826e-03,\n",
      "        0.0000e+00, 0.0000e+00, 2.1095e-05, 8.5414e-02, 0.0000e+00, 0.0000e+00,\n",
      "        1.2418e-02, 6.7533e-04, 8.1700e-04, 2.2639e-02, 1.9995e-01, 3.7409e-02,\n",
      "        2.6858e-02, 1.7225e-01, 3.8203e-02, 7.0534e-02, 0.0000e+00, 1.7700e-01,\n",
      "        0.0000e+00, 0.0000e+00, 2.1692e-03, 1.8837e-03, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 6.2669e-02, 3.6507e-03, 0.0000e+00, 4.3384e-04, 4.8959e-03,\n",
      "        4.6774e-02, 1.8405e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        1.8576e-01, 8.1085e-02, 9.6545e-02, 5.4175e-03, 4.5498e-02, 7.0886e-01,\n",
      "        2.0914e-01, 1.4524e-03, 3.2899e-02, 2.3581e-02, 0.0000e+00, 2.1014e-02,\n",
      "        1.0816e-01, 0.0000e+00, 1.3466e-01, 7.5558e-04, 2.0319e-02, 3.5794e-02,\n",
      "        0.0000e+00, 6.1361e-02, 0.0000e+00, 1.4648e-03, 0.0000e+00, 3.0271e-02,\n",
      "        1.2691e-02, 7.9539e-03, 0.0000e+00, 2.4657e-01, 1.3660e-02, 9.0333e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 8.1600e-04, 9.3181e-02, 0.0000e+00,\n",
      "        1.7765e-03, 7.7275e-02, 0.0000e+00, 1.1499e-03, 1.9656e-01, 7.9537e-02,\n",
      "        2.1216e-03, 1.6235e-01, 7.6840e-04, 1.7797e-01, 9.8664e-03, 0.0000e+00,\n",
      "        1.3076e-02, 5.5986e-02, 6.8053e-02, 1.2206e-01, 1.9686e-03, 7.5793e-02,\n",
      "        3.0566e-01, 1.3025e-01, 2.2527e-02, 0.0000e+00, 1.2718e-03, 9.7637e-03,\n",
      "        0.0000e+00, 2.3960e-02, 0.0000e+00, 0.0000e+00, 1.8235e-02, 1.9085e-02,\n",
      "        9.1370e-02, 1.2184e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.6074e-01,\n",
      "        5.5437e-02, 7.4676e-03, 6.9592e-02, 5.6659e-03, 0.0000e+00, 5.3552e-03,\n",
      "        0.0000e+00, 1.1240e-02, 0.0000e+00, 6.8023e-02, 2.6320e-04, 2.4104e-02,\n",
      "        7.3516e-02, 3.9484e-01, 5.2762e-02, 4.6914e-02, 0.0000e+00, 6.0037e-02,\n",
      "        1.4666e-03, 0.0000e+00, 3.3208e-03, 9.5113e-03, 0.0000e+00, 1.2561e-01,\n",
      "        9.5358e-02, 6.1873e-02, 5.4605e-04, 2.8474e-02, 2.8746e-02, 4.7839e-02,\n",
      "        3.7914e-01, 8.0460e-02, 1.6509e-04, 9.2886e-03, 5.4665e-02, 9.8555e-04,\n",
      "        2.6915e-03, 0.0000e+00, 2.1187e-02, 1.3245e-02, 3.5090e-04, 7.9288e-02,\n",
      "        0.0000e+00, 2.8665e-02, 2.9600e-02, 0.0000e+00, 7.5330e-02, 2.3163e-02,\n",
      "        1.2067e-01, 1.8233e-02, 1.3270e-02, 0.0000e+00, 0.0000e+00, 1.9888e-03,\n",
      "        9.3870e-03, 7.2769e-06, 1.4263e-02, 0.0000e+00, 2.8884e-05, 1.1490e-01,\n",
      "        0.0000e+00, 1.2777e-02, 3.5041e-02, 1.0408e-02, 1.5820e-01, 3.6547e-05,\n",
      "        1.1255e-02, 0.0000e+00, 4.7746e-02, 2.2743e-03, 0.0000e+00, 1.0974e-02,\n",
      "        5.9283e-02, 4.9719e-03, 0.0000e+00, 0.0000e+00, 8.3583e-03, 2.1484e-03,\n",
      "        0.0000e+00, 5.8690e-02, 7.8863e-02, 4.4335e-02, 0.0000e+00, 3.6801e-01,\n",
      "        0.0000e+00, 6.5851e-02, 2.6106e-03, 1.3309e-02, 1.0471e-02, 2.7515e-02,\n",
      "        2.2656e-03, 4.4894e-03, 0.0000e+00, 0.0000e+00, 3.9294e-02, 2.3758e-02,\n",
      "        0.0000e+00, 7.6152e-03, 3.2912e-02, 0.0000e+00, 6.9485e-03, 0.0000e+00,\n",
      "        7.8188e-02, 7.2355e-02, 0.0000e+00, 2.5006e-03, 1.5909e-01, 5.7272e-02,\n",
      "        5.7697e-02, 4.1426e+00, 5.9152e-02, 0.0000e+00, 0.0000e+00, 2.1557e-02,\n",
      "        0.0000e+00, 2.6557e-03, 1.4881e-01, 0.0000e+00, 1.0816e-02, 0.0000e+00,\n",
      "        0.0000e+00, 2.5204e-02, 8.1523e-04, 8.1811e-02, 2.0928e-01, 0.0000e+00,\n",
      "        7.3549e-03, 4.6818e-05, 0.0000e+00, 0.0000e+00, 1.7948e-04, 7.3495e-03,\n",
      "        2.0873e-03, 7.0197e-03, 1.9592e-03, 2.0224e-02, 0.0000e+00, 9.3225e-03,\n",
      "        7.9042e-03, 0.0000e+00, 3.2701e-02, 4.1086e-04, 0.0000e+00, 0.0000e+00,\n",
      "        2.7410e-03, 6.6049e-02, 9.6679e-03, 7.9725e-03, 2.5136e-01, 1.7286e-02,\n",
      "        0.0000e+00, 7.5205e-02, 7.8390e-02, 0.0000e+00, 0.0000e+00, 1.7890e-03,\n",
      "        7.8329e-02, 9.2353e-02, 3.6210e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 0.0000e+00, 7.7152e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        5.0970e-02, 0.0000e+00, 1.9744e-02, 6.7501e-03, 6.6811e-03, 4.8244e-02,\n",
      "        0.0000e+00, 1.7889e-04, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 5.8367e-04, 2.5222e-02, 7.1550e-03, 4.4258e-05, 0.0000e+00,\n",
      "        5.8129e-02, 1.9962e-04, 0.0000e+00, 2.3246e-02, 0.0000e+00, 7.3310e-05,\n",
      "        0.0000e+00, 0.0000e+00, 1.3686e-01, 4.4674e-02, 0.0000e+00, 0.0000e+00,\n",
      "        0.0000e+00, 2.4277e-02, 2.7142e-04, 1.4597e-01, 1.1267e-03, 2.1415e-02,\n",
      "        1.7125e-02, 4.1659e-02, 3.8450e-02, 4.1900e-02, 8.0726e-02, 6.3398e-02,\n",
      "        3.1145e-02, 1.1539e-01, 1.4110e-02, 2.9522e-02, 0.0000e+00, 1.0533e-01,\n",
      "        1.9104e-03, 6.7551e-04, 0.0000e+00, 0.0000e+00, 2.1001e-02, 2.8298e-02,\n",
      "        1.6112e-02, 2.6445e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.9483e-04,\n",
      "        5.6487e-03, 0.0000e+00, 5.3480e-04, 9.6919e-03, 8.8464e-03, 0.0000e+00,\n",
      "        1.0508e-02, 2.9146e-03, 2.8319e-02, 3.5206e-02, 1.3664e-03, 0.0000e+00,\n",
      "        4.7376e-02, 3.8703e-02, 8.4929e-04, 5.8882e-02, 0.0000e+00, 2.6645e-01,\n",
      "        9.4148e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3904e-02, 3.5755e-03,\n",
      "        0.0000e+00, 5.7055e-02, 9.5513e-02, 5.9988e-03, 5.8256e-03, 2.4508e-04,\n",
      "        0.0000e+00, 1.0678e-03, 3.7473e-02, 6.9391e-02, 0.0000e+00, 1.8564e-02,\n",
      "        0.0000e+00, 1.9100e-02, 0.0000e+00, 6.3514e-01, 0.0000e+00, 0.0000e+00,\n",
      "        1.9046e-02, 1.1204e-02, 0.0000e+00, 5.9437e-02, 4.7983e-02, 1.4648e-01,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.2869e-01, 1.0489e-01, 1.8663e-02,\n",
      "        2.9177e-03, 9.1538e-02, 2.8024e-02, 1.7241e-03, 7.5718e-03, 0.0000e+00,\n",
      "        2.0638e-04, 3.2593e-02, 0.0000e+00, 0.0000e+00, 4.8200e-02, 2.2022e-04,\n",
      "        4.1300e-04, 1.5607e-03, 7.0045e-03, 8.6415e-04, 1.3914e-01, 9.5273e-03,\n",
      "        2.3637e-02, 4.3219e-02, 3.8082e-03, 2.4686e-02, 0.0000e+00, 8.5043e-02,\n",
      "        3.7161e-03, 8.9510e-02, 1.9015e-01, 0.0000e+00, 5.8785e-03, 7.2330e-02,\n",
      "        1.3066e-03, 3.8819e-02, 1.1140e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "        7.0114e-02, 1.0452e-03, 0.0000e+00, 0.0000e+00, 0.0000e+00, 6.7732e-02,\n",
      "        0.0000e+00, 0.0000e+00, 0.0000e+00, 4.3891e-03, 0.0000e+00, 1.5012e-03,\n",
      "        8.1950e-02, 3.4401e-03, 1.4870e-03, 0.0000e+00, 0.0000e+00, 5.0956e-05,\n",
      "        8.0866e-02, 0.0000e+00, 0.0000e+00, 6.7076e-02, 4.6576e-03, 5.9930e-02,\n",
      "        0.0000e+00, 4.8452e-02, 6.2841e-06, 4.0155e-02, 5.9374e-03, 2.2678e-02,\n",
      "        0.0000e+00, 1.2831e-02, 1.2954e-02, 4.7025e-02, 2.4259e-03, 0.0000e+00,\n",
      "        1.6385e-02, 0.0000e+00, 3.9955e-03, 2.0784e-02, 9.1169e-02, 8.0446e-02,\n",
      "        4.7175e-04, 8.1356e-04, 9.4545e-02, 0.0000e+00, 1.6094e-02, 1.0382e-01,\n",
      "        2.9890e-04, 0.0000e+00, 1.0230e-01, 1.2274e-02, 0.0000e+00, 1.1495e-02,\n",
      "        3.9553e-03, 4.9165e-03, 2.0706e-01, 3.4394e-03, 1.1448e-01, 6.3313e-04,\n",
      "        0.0000e+00, 2.9415e-05, 0.0000e+00, 8.5533e-02, 5.2927e-02, 8.7695e-02,\n",
      "        6.3140e-03, 0.0000e+00, 4.5193e-02, 1.2357e-04, 8.8427e-02, 0.0000e+00],\n",
      "       device='cuda:0') torch.Size([768])\n",
      "score tensor([0.0003, 0.0328, 0.0015, 0.0085, 0.0014, 0.0369, 0.0004],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0121, 0.0476, 0.0156, 0.0317, 0.0159, 0.0511, 0.0128],\n",
      "       device='cuda:0') torch.Size([7])\n",
      "score tensor([0.0000, 0.0000, 0.1705, 0.3687, 0.9242, 0.0000, 0.0000, 0.5029, 0.0000,\n",
      "        0.0000], device='cuda:0') torch.Size([10])\n",
      "{'total_neurons': 8872, 'zero_count': 1560, 'dormant_count': 401, 'overactive_count': 623}\n",
      "torch.Size([2, 96, 56, 56])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "from utils import ActivationTracker, register_hooks, compute_stats\n",
    "from architectures import load_architecture, CustomModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import torch.distributed as dist\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config.yaml\")\n",
    "\n",
    "\n",
    "N = 10\n",
    "B = 2\n",
    "\n",
    "# Create a white image using NumPy\n",
    "white_image = np.ones((224, 224, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "white_tensor = torch.from_numpy(white_image).permute(2, 0, 1).float() / 255.0  # Shape: (3, 224, 224)\n",
    "\n",
    "# Add batch dimension and repeat for batch size B\n",
    "white_tensor = white_tensor.unsqueeze(0).repeat(B, 1, 1, 1)  # Shape: (B, 3, 224, 224)\n",
    "\n",
    "# Move the tensor to GPU\n",
    "white_tensor = white_tensor.to('cuda')\n",
    "\n",
    "print(white_tensor.shape)  # Verify shape: (B, 3, 224, 224)\n",
    "\n",
    "config.backbone = 'convnext_tiny'\n",
    "model = load_architecture(False, config, N, )\n",
    "model = CustomModel(config, model, )\n",
    "model.to('cuda')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tracker_nat = ActivationTracker()\n",
    "tracker_adv = ActivationTracker()\n",
    "\n",
    "handles = register_hooks(model, tracker_nat, tracker_adv)\n",
    "\n",
    "model.current_task = 'infer'\n",
    "model(white_tensor)\n",
    "\n",
    "# # Compute neuron statistics\n",
    "res_nat = compute_stats(tracker_nat.activations)\n",
    "# res_adv = compute_stats(tracker_adv.activations)\n",
    "\n",
    "print(res_nat)\n",
    "print(tracker_nat.activations['base_model.stem.0'].shape)\n",
    "# print(res_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 224, 224])\n",
      "torch.Size([96]) {'base_model.stem.0': 6272, 'base_model.stages.0.blocks.0.conv_dw': 6272, 'base_model.stages.0.blocks.0.mlp.fc1': 43008, 'base_model.stages.0.blocks.0.mlp.fc2': 10752, 'base_model.stages.0.blocks.1.conv_dw': 6272, 'base_model.stages.0.blocks.1.mlp.fc1': 43008, 'base_model.stages.0.blocks.1.mlp.fc2': 10752, 'base_model.stages.0.blocks.2.conv_dw': 6272, 'base_model.stages.0.blocks.2.mlp.fc1': 43008, 'base_model.stages.0.blocks.2.mlp.fc2': 10752, 'base_model.stages.1.downsample.1': 1568, 'base_model.stages.1.blocks.0.conv_dw': 1568, 'base_model.stages.1.blocks.0.mlp.fc1': 43008, 'base_model.stages.1.blocks.0.mlp.fc2': 10752, 'base_model.stages.1.blocks.1.conv_dw': 1568, 'base_model.stages.1.blocks.1.mlp.fc1': 43008, 'base_model.stages.1.blocks.1.mlp.fc2': 10752, 'base_model.stages.1.blocks.2.conv_dw': 1568, 'base_model.stages.1.blocks.2.mlp.fc1': 43008, 'base_model.stages.1.blocks.2.mlp.fc2': 10752, 'base_model.stages.2.downsample.1': 392, 'base_model.stages.2.blocks.0.conv_dw': 392, 'base_model.stages.2.blocks.0.mlp.fc1': 43008, 'base_model.stages.2.blocks.0.mlp.fc2': 10752, 'base_model.stages.2.blocks.1.conv_dw': 392, 'base_model.stages.2.blocks.1.mlp.fc1': 43008, 'base_model.stages.2.blocks.1.mlp.fc2': 10752, 'base_model.stages.2.blocks.2.conv_dw': 392, 'base_model.stages.2.blocks.2.mlp.fc1': 43008, 'base_model.stages.2.blocks.2.mlp.fc2': 10752, 'base_model.stages.2.blocks.3.conv_dw': 392, 'base_model.stages.2.blocks.3.mlp.fc1': 43008, 'base_model.stages.2.blocks.3.mlp.fc2': 10752, 'base_model.stages.2.blocks.4.conv_dw': 392, 'base_model.stages.2.blocks.4.mlp.fc1': 43008, 'base_model.stages.2.blocks.4.mlp.fc2': 10752, 'base_model.stages.2.blocks.5.conv_dw': 392, 'base_model.stages.2.blocks.5.mlp.fc1': 43008, 'base_model.stages.2.blocks.5.mlp.fc2': 10752, 'base_model.stages.2.blocks.6.conv_dw': 392, 'base_model.stages.2.blocks.6.mlp.fc1': 43008, 'base_model.stages.2.blocks.6.mlp.fc2': 10752, 'base_model.stages.2.blocks.7.conv_dw': 392, 'base_model.stages.2.blocks.7.mlp.fc1': 43008, 'base_model.stages.2.blocks.7.mlp.fc2': 10752, 'base_model.stages.2.blocks.8.conv_dw': 392, 'base_model.stages.2.blocks.8.mlp.fc1': 43008, 'base_model.stages.2.blocks.8.mlp.fc2': 10752, 'base_model.stages.3.downsample.1': 98, 'base_model.stages.3.blocks.0.conv_dw': 98, 'base_model.stages.3.blocks.0.mlp.fc1': 43008, 'base_model.stages.3.blocks.0.mlp.fc2': 10752, 'base_model.stages.3.blocks.1.conv_dw': 98, 'base_model.stages.3.blocks.1.mlp.fc1': 43008, 'base_model.stages.3.blocks.1.mlp.fc2': 10752, 'base_model.stages.3.blocks.2.conv_dw': 98, 'base_model.stages.3.blocks.2.mlp.fc1': 43008, 'base_model.stages.3.blocks.2.mlp.fc2': 10752, 'base_model.head.fc': 2}\n",
      "torch.Size([96]) {'base_model.stem.0': 12544, 'base_model.stages.0.blocks.0.conv_dw': 12544, 'base_model.stages.0.blocks.0.mlp.fc1': 86016, 'base_model.stages.0.blocks.0.mlp.fc2': 21504, 'base_model.stages.0.blocks.1.conv_dw': 12544, 'base_model.stages.0.blocks.1.mlp.fc1': 86016, 'base_model.stages.0.blocks.1.mlp.fc2': 21504, 'base_model.stages.0.blocks.2.conv_dw': 12544, 'base_model.stages.0.blocks.2.mlp.fc1': 86016, 'base_model.stages.0.blocks.2.mlp.fc2': 21504, 'base_model.stages.1.downsample.1': 3136, 'base_model.stages.1.blocks.0.conv_dw': 3136, 'base_model.stages.1.blocks.0.mlp.fc1': 86016, 'base_model.stages.1.blocks.0.mlp.fc2': 21504, 'base_model.stages.1.blocks.1.conv_dw': 3136, 'base_model.stages.1.blocks.1.mlp.fc1': 86016, 'base_model.stages.1.blocks.1.mlp.fc2': 21504, 'base_model.stages.1.blocks.2.conv_dw': 3136, 'base_model.stages.1.blocks.2.mlp.fc1': 86016, 'base_model.stages.1.blocks.2.mlp.fc2': 21504, 'base_model.stages.2.downsample.1': 784, 'base_model.stages.2.blocks.0.conv_dw': 784, 'base_model.stages.2.blocks.0.mlp.fc1': 86016, 'base_model.stages.2.blocks.0.mlp.fc2': 21504, 'base_model.stages.2.blocks.1.conv_dw': 784, 'base_model.stages.2.blocks.1.mlp.fc1': 86016, 'base_model.stages.2.blocks.1.mlp.fc2': 21504, 'base_model.stages.2.blocks.2.conv_dw': 784, 'base_model.stages.2.blocks.2.mlp.fc1': 86016, 'base_model.stages.2.blocks.2.mlp.fc2': 21504, 'base_model.stages.2.blocks.3.conv_dw': 784, 'base_model.stages.2.blocks.3.mlp.fc1': 86016, 'base_model.stages.2.blocks.3.mlp.fc2': 21504, 'base_model.stages.2.blocks.4.conv_dw': 784, 'base_model.stages.2.blocks.4.mlp.fc1': 86016, 'base_model.stages.2.blocks.4.mlp.fc2': 21504, 'base_model.stages.2.blocks.5.conv_dw': 784, 'base_model.stages.2.blocks.5.mlp.fc1': 86016, 'base_model.stages.2.blocks.5.mlp.fc2': 21504, 'base_model.stages.2.blocks.6.conv_dw': 784, 'base_model.stages.2.blocks.6.mlp.fc1': 86016, 'base_model.stages.2.blocks.6.mlp.fc2': 21504, 'base_model.stages.2.blocks.7.conv_dw': 784, 'base_model.stages.2.blocks.7.mlp.fc1': 86016, 'base_model.stages.2.blocks.7.mlp.fc2': 21504, 'base_model.stages.2.blocks.8.conv_dw': 784, 'base_model.stages.2.blocks.8.mlp.fc1': 86016, 'base_model.stages.2.blocks.8.mlp.fc2': 21504, 'base_model.stages.3.downsample.1': 196, 'base_model.stages.3.blocks.0.conv_dw': 196, 'base_model.stages.3.blocks.0.mlp.fc1': 86016, 'base_model.stages.3.blocks.0.mlp.fc2': 21504, 'base_model.stages.3.blocks.1.conv_dw': 196, 'base_model.stages.3.blocks.1.mlp.fc1': 86016, 'base_model.stages.3.blocks.1.mlp.fc2': 21504, 'base_model.stages.3.blocks.2.conv_dw': 196, 'base_model.stages.3.blocks.2.mlp.fc1': 86016, 'base_model.stages.3.blocks.2.mlp.fc2': 21504, 'base_model.head.fc': 4}\n",
      "torch.Size([96]) {'base_model.stem.0': 18816, 'base_model.stages.0.blocks.0.conv_dw': 18816, 'base_model.stages.0.blocks.0.mlp.fc1': 129024, 'base_model.stages.0.blocks.0.mlp.fc2': 32256, 'base_model.stages.0.blocks.1.conv_dw': 18816, 'base_model.stages.0.blocks.1.mlp.fc1': 129024, 'base_model.stages.0.blocks.1.mlp.fc2': 32256, 'base_model.stages.0.blocks.2.conv_dw': 18816, 'base_model.stages.0.blocks.2.mlp.fc1': 129024, 'base_model.stages.0.blocks.2.mlp.fc2': 32256, 'base_model.stages.1.downsample.1': 4704, 'base_model.stages.1.blocks.0.conv_dw': 4704, 'base_model.stages.1.blocks.0.mlp.fc1': 129024, 'base_model.stages.1.blocks.0.mlp.fc2': 32256, 'base_model.stages.1.blocks.1.conv_dw': 4704, 'base_model.stages.1.blocks.1.mlp.fc1': 129024, 'base_model.stages.1.blocks.1.mlp.fc2': 32256, 'base_model.stages.1.blocks.2.conv_dw': 4704, 'base_model.stages.1.blocks.2.mlp.fc1': 129024, 'base_model.stages.1.blocks.2.mlp.fc2': 32256, 'base_model.stages.2.downsample.1': 1176, 'base_model.stages.2.blocks.0.conv_dw': 1176, 'base_model.stages.2.blocks.0.mlp.fc1': 129024, 'base_model.stages.2.blocks.0.mlp.fc2': 32256, 'base_model.stages.2.blocks.1.conv_dw': 1176, 'base_model.stages.2.blocks.1.mlp.fc1': 129024, 'base_model.stages.2.blocks.1.mlp.fc2': 32256, 'base_model.stages.2.blocks.2.conv_dw': 1176, 'base_model.stages.2.blocks.2.mlp.fc1': 129024, 'base_model.stages.2.blocks.2.mlp.fc2': 32256, 'base_model.stages.2.blocks.3.conv_dw': 1176, 'base_model.stages.2.blocks.3.mlp.fc1': 129024, 'base_model.stages.2.blocks.3.mlp.fc2': 32256, 'base_model.stages.2.blocks.4.conv_dw': 1176, 'base_model.stages.2.blocks.4.mlp.fc1': 129024, 'base_model.stages.2.blocks.4.mlp.fc2': 32256, 'base_model.stages.2.blocks.5.conv_dw': 1176, 'base_model.stages.2.blocks.5.mlp.fc1': 129024, 'base_model.stages.2.blocks.5.mlp.fc2': 32256, 'base_model.stages.2.blocks.6.conv_dw': 1176, 'base_model.stages.2.blocks.6.mlp.fc1': 129024, 'base_model.stages.2.blocks.6.mlp.fc2': 32256, 'base_model.stages.2.blocks.7.conv_dw': 1176, 'base_model.stages.2.blocks.7.mlp.fc1': 129024, 'base_model.stages.2.blocks.7.mlp.fc2': 32256, 'base_model.stages.2.blocks.8.conv_dw': 1176, 'base_model.stages.2.blocks.8.mlp.fc1': 129024, 'base_model.stages.2.blocks.8.mlp.fc2': 32256, 'base_model.stages.3.downsample.1': 294, 'base_model.stages.3.blocks.0.conv_dw': 294, 'base_model.stages.3.blocks.0.mlp.fc1': 129024, 'base_model.stages.3.blocks.0.mlp.fc2': 32256, 'base_model.stages.3.blocks.1.conv_dw': 294, 'base_model.stages.3.blocks.1.mlp.fc1': 129024, 'base_model.stages.3.blocks.1.mlp.fc2': 32256, 'base_model.stages.3.blocks.2.conv_dw': 294, 'base_model.stages.3.blocks.2.mlp.fc1': 129024, 'base_model.stages.3.blocks.2.mlp.fc2': 32256, 'base_model.head.fc': 6}\n",
      "{'total_neurons': 8872, 'zero_fraction': 0.17560865644724977, 'dormant_fraction': 0.04519837691614067, 'overactive_fraction': 0.07022091974752029}\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from typing import Union, Tuple\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ActivationTrackerAggregated:\n",
    "    def __init__(self):\n",
    "        # For each layer: store cumulative sums and counts of activations\n",
    "        self.sums = {}   # Will hold accumulated sums of absolute activations\n",
    "        self.counts = {} # Will hold total counts of elements processed per neuron\n",
    "        self.is_conv = {} # Keep track if layer is Conv (for dimension handling)\n",
    "\n",
    "    def accumulate(self, name, activation):\n",
    "        # Move to CPU for safety\n",
    "        activation = activation.detach().cpu()\n",
    "\n",
    "        # Check if it's a conv layer or linear layer by dimensions\n",
    "        # Conv: (B, C, H, W)\n",
    "        # Linear: (B, C)\n",
    "        if activation.ndim == 4:\n",
    "            # Conv layer\n",
    "            # sum over batch, height, and width: result is shape (C,)\n",
    "            abs_sum = activation.abs().sum(dim=(0, 2, 3))\n",
    "            # count how many elements per channel\n",
    "            b, c, h, w = activation.shape\n",
    "            elem_count = b * h * w\n",
    "            if name not in self.sums:\n",
    "                self.sums[name] = torch.zeros(c, dtype=torch.float32)\n",
    "                self.counts[name] = 0\n",
    "                self.is_conv[name] = True\n",
    "            self.sums[name] += abs_sum\n",
    "            self.counts[name] += elem_count\n",
    "\n",
    "        else:\n",
    "            # Linear layer: (B, C)\n",
    "            abs_sum = activation.abs().sum(dim=0)  # shape (C,)\n",
    "            b, c = activation.shape\n",
    "            elem_count = b\n",
    "            if name not in self.sums:\n",
    "                self.sums[name] = torch.zeros(c, dtype=torch.float32)\n",
    "                self.counts[name] = 0\n",
    "                self.is_conv[name] = False\n",
    "            self.sums[name] += abs_sum\n",
    "            self.counts[name] += elem_count\n",
    "\n",
    "    def get_activations_mean(self):\n",
    "        # Compute mean absolute activation per neuron\n",
    "        activations_mean = {}\n",
    "        for name in self.sums:\n",
    "            activations_mean[name] = self.sums[name] / (self.counts[name] + 1e-9)\n",
    "        return activations_mean\n",
    "\n",
    "    def clear(self):\n",
    "        self.sums = {}\n",
    "        self.counts = {}\n",
    "        self.is_conv = {}\n",
    "\n",
    "def register_hooks_aggregated(model, tracker_nat, tracker_adv):\n",
    "    handles = []\n",
    "    for name, module in model.named_modules():\n",
    "        if isinstance(module, nn.Conv2d) or isinstance(module, nn.Linear):\n",
    "            module._name = name\n",
    "\n",
    "            def get_activation(mod, model):\n",
    "                def hook(mod, input, output):\n",
    "                    name = mod._name\n",
    "                    if model.current_tracker == 'nat' and model.current_task == 'infer':\n",
    "                        tracker_nat.accumulate(name, F.relu(output))\n",
    "                    if model.current_tracker == 'adv' and model.current_task == 'infer':\n",
    "                        tracker_adv.accumulate(name, F.relu(output))\n",
    "                return hook\n",
    "\n",
    "            handle = module.register_forward_hook(get_activation(module, model))\n",
    "            handles.append(handle)\n",
    "    return handles\n",
    "\n",
    "@torch.inference_mode()\n",
    "def _compute_masks_from_stats(activations_mean, is_conv, tau, ineq_type):\n",
    "    masks = []\n",
    "    for name, mean_vals in activations_mean.items():\n",
    "        # mean_vals is per-channel (conv) or per-neuron (linear)\n",
    "        score = mean_vals  # already mean per neuron over dataset\n",
    "        # Normalize by its own mean\n",
    "        normalized_score = score / (score.mean() + 1e-9)\n",
    "        layer_mask = torch.zeros_like(normalized_score, dtype=torch.bool)\n",
    "\n",
    "        if ineq_type == 'leq':\n",
    "            layer_mask[normalized_score <= tau] = True\n",
    "        elif ineq_type == 'geq':\n",
    "            layer_mask[normalized_score >= tau] = True\n",
    "        elif ineq_type == 'eq':\n",
    "            layer_mask[torch.isclose(normalized_score, torch.zeros_like(normalized_score))] = True\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid inequality type: {ineq_type}\")\n",
    "        masks.append(layer_mask)\n",
    "    return masks\n",
    "\n",
    "@torch.inference_mode()\n",
    "def compute_stats_aggregated(tracker):\n",
    "    # Compute the mean activation values\n",
    "    activations_mean = tracker.get_activations_mean()\n",
    "\n",
    "    # Compute zero masks (neurons with zero normalized activation)\n",
    "    zero_masks = _compute_masks_from_stats(activations_mean, tracker.is_conv, 0.0, 'eq')\n",
    "    zero_count = sum([mask.sum().item() for mask in zero_masks])\n",
    "\n",
    "    # Compute dormant masks (excluding zero neurons)\n",
    "    dormant_masks = _compute_masks_from_stats(activations_mean, tracker.is_conv, 0.01, 'leq')\n",
    "    adjusted_dormant_masks = [dormant & (~zero) for dormant, zero in zip(dormant_masks, zero_masks)]\n",
    "    dormant_count = sum([mask.sum().item() for mask in adjusted_dormant_masks])\n",
    "\n",
    "    # Compute overactive masks\n",
    "    overactive_masks = _compute_masks_from_stats(activations_mean, tracker.is_conv, 3.0, 'geq')\n",
    "    overactive_count = sum([mask.sum().item() for mask in overactive_masks])\n",
    "\n",
    "    # Compute total neurons\n",
    "    total_neurons = sum([mask.numel() for mask in zero_masks])\n",
    "\n",
    "    return {\n",
    "        \"total_neurons\": total_neurons,\n",
    "        \"zero_fraction\": zero_count/total_neurons,\n",
    "        \"dormant_fraction\": dormant_count/total_neurons,\n",
    "        \"overactive_fraction\": overactive_count/total_neurons,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "# from utils import ActivationTracker, register_hooks, compute_stats\n",
    "from architectures import load_architecture, CustomModel\n",
    "import numpy as np\n",
    "import torch\n",
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import torch.distributed as dist\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config.yaml\")\n",
    "\n",
    "N = 10\n",
    "B = 2\n",
    "\n",
    "# Create a white image using NumPy\n",
    "white_image = np.ones((224, 224, 3), dtype=np.uint8) * 255\n",
    "\n",
    "# Convert to PyTorch tensor\n",
    "white_tensor = torch.from_numpy(white_image).permute(2, 0, 1).float() / 255.0  # Shape: (3, 224, 224)\n",
    "\n",
    "# Add batch dimension and repeat for batch size B\n",
    "white_tensor = white_tensor.unsqueeze(0).repeat(B, 1, 1, 1)  # Shape: (B, 3, 224, 224)\n",
    "\n",
    "# Move the tensor to GPU\n",
    "white_tensor = white_tensor.to('cuda')\n",
    "\n",
    "print(white_tensor.shape)  # Verify shape: (B, 3, 224, 224)\n",
    "\n",
    "config.backbone = 'convnext_tiny'\n",
    "model = load_architecture(False, config, N, )\n",
    "model = CustomModel(config, model, )\n",
    "model.to('cuda')\n",
    "\n",
    "model.eval()\n",
    "\n",
    "tracker_nat = ActivationTrackerAggregated()\n",
    "tracker_adv = ActivationTrackerAggregated()\n",
    "\n",
    "handles = register_hooks_aggregated(model, tracker_nat, tracker_adv)\n",
    "\n",
    "model.current_task = 'infer'\n",
    "model(white_tensor)\n",
    "\n",
    "# # Compute neuron statistics\n",
    "# res_nat = compute_stats2(tracker_nat)\n",
    "# res_adv = compute_stats(tracker_adv.activations)\n",
    "\n",
    "print( tracker_nat.sums['base_model.stem.0'].shape , tracker_nat.counts )\n",
    "# print(res_adv)\n",
    "\n",
    "model.current_task = 'infer'\n",
    "model(white_tensor)\n",
    "\n",
    "print( tracker_nat.sums['base_model.stem.0'].shape , tracker_nat.counts )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Compute neuron statistics\n",
    "res_nat = compute_stats_aggregated(tracker_nat)\n",
    "print(res_nat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame.from_dict(backbones_result).T\n",
    "\n",
    "df.to_csv( 'neurons_results_{}.csv'.format(args.dataset) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrrrrrrr}\n",
      "\\toprule\n",
      " & mean total neurons & mean zero fraction & mean zero count & mean dormant fraction & mean dormant count & mean overactive fraction & mean overactive count & std total neurons & std zero fraction & std zero count & std dormant fraction & std dormant count & std overactive fraction & std overactive count \\\\\n",
      "\\midrule\n",
      "convnext base & 21280.0 & 0.047 & 1004.16 & 0.163 & 3469.93 & 0.056 & 1200.18 & 0.0 & 0.017 & 359.605 & 0.035 & 737.983 & 0.005 & 112.553 \\\\\n",
      "convnext base.fb in22k & 21280.0 & 0.043 & 921.53 & 0.158 & 3354.2 & 0.056 & 1183.79 & 0.0 & 0.017 & 355.33 & 0.035 & 742.071 & 0.005 & 112.939 \\\\\n",
      "robust convnext base & 21280.0 & 0.103 & 2194.19 & 0.257 & 5472.24 & 0.069 & 1463.75 & 0.0 & 0.053 & 1127.165 & 0.077 & 1641.495 & 0.012 & 262.539 \\\\\n",
      "convnext tiny & 8872.0 & 0.041 & 360.27 & 0.126 & 1115.94 & 0.049 & 432.75 & 0.0 & 0.017 & 154.956 & 0.037 & 325.717 & 0.007 & 57.75 \\\\\n",
      "convnext tiny.fb in22k & 8872.0 & 0.062 & 551.18 & 0.175 & 1550.68 & 0.057 & 508.52 & 0.0 & 0.02 & 179.576 & 0.04 & 354.41 & 0.006 & 51.651 \\\\\n",
      "robust convnext tiny & 8872.0 & 0.184 & 1631.45 & 0.319 & 2828.66 & 0.055 & 485.73 & 0.0 & 0.063 & 556.426 & 0.068 & 603.978 & 0.004 & 34.607 \\\\\n",
      "robust wideresnet 28 10 & 10106.0 & 0.002 & 22.67 & 0.03 & 299.25 & 0.015 & 155.63 & 0.0 & 0.0 & 4.517 & 0.002 & 23.743 & 0.001 & 11.808 \\\\\n",
      "deit small patch16 224.fb in1k & 8170378.0 & 0.689 & 5629036.05 & 0.7 & 5718239.13 & 0.088 & 719174.4 & 0.0 & 0.002 & 16697.483 & 0.002 & 19276.659 & 0.002 & 12425.182 \\\\\n",
      "robust deit small patch16 224 & 8170378.0 & 0.693 & 5660087.6 & 0.706 & 5768142.34 & 0.082 & 667615.79 & 0.0 & 0.005 & 42366.474 & 0.005 & 44279.519 & 0.004 & 29923.682 \\\\\n",
      "vit base patch16 224.augreg in1k & 16340746.0 & 0.688 & 11238575.65 & 0.699 & 11414423.78 & 0.089 & 1456864.7 & 0.0 & 0.002 & 36663.7 & 0.003 & 42468.413 & 0.002 & 29137.612 \\\\\n",
      "vit base patch16 224.augreg in21k & 16340746.0 & 0.697 & 11385388.6 & 0.709 & 11582456.66 & 0.083 & 1356215.27 & 0.0 & 0.002 & 34370.067 & 0.002 & 40188.727 & 0.001 & 20591.778 \\\\\n",
      "robust vit base patch16 224 & 16340746.0 & 0.685 & 11188585.69 & 0.698 & 11401988.29 & 0.086 & 1403947.81 & 0.0 & 0.009 & 143693.959 & 0.009 & 143664.192 & 0.005 & 77984.558 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = 'EuroSAT'\n",
    "\n",
    "df = pd.read_csv('neurons_results_{}.csv'.format(dataset), index_col=0)\n",
    "\n",
    "# Replace underscores with spaces in column names and data\n",
    "df.columns = df.columns.str.replace('_', ' ')\n",
    "df = df.replace('_', ' ', regex=True)\n",
    "df.index = df.index.str.replace('_', ' ')\n",
    "\n",
    "# Rounding a DataFrame to 3 decimal places\n",
    "df = df.round(3)\n",
    "\n",
    "latex_code = df.to_latex(\n",
    "    index=True,\n",
    "    formatters={\"name\": str.upper},\n",
    "    float_format=\"{}\".format\n",
    ")\n",
    "\n",
    "# Print the LaTeX code\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_total_neurons</th>\n",
       "      <th>mean_zero_fraction</th>\n",
       "      <th>mean_zero_count</th>\n",
       "      <th>mean_dormant_fraction</th>\n",
       "      <th>mean_dormant_count</th>\n",
       "      <th>mean_overactive_fraction</th>\n",
       "      <th>mean_overactive_count</th>\n",
       "      <th>std_total_neurons</th>\n",
       "      <th>std_zero_fraction</th>\n",
       "      <th>std_zero_count</th>\n",
       "      <th>std_dormant_fraction</th>\n",
       "      <th>std_dormant_count</th>\n",
       "      <th>std_overactive_fraction</th>\n",
       "      <th>std_overactive_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>convnext_base</th>\n",
       "      <td>21280.0</td>\n",
       "      <td>0.047139</td>\n",
       "      <td>1003.12</td>\n",
       "      <td>0.163013</td>\n",
       "      <td>3468.92</td>\n",
       "      <td>0.056383</td>\n",
       "      <td>1199.83</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016902</td>\n",
       "      <td>359.664602</td>\n",
       "      <td>0.034687</td>\n",
       "      <td>738.129524</td>\n",
       "      <td>0.005287</td>\n",
       "      <td>112.496760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_base.fb_in22k</th>\n",
       "      <td>21280.0</td>\n",
       "      <td>0.043351</td>\n",
       "      <td>922.50</td>\n",
       "      <td>0.157668</td>\n",
       "      <td>3355.18</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>1183.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016660</td>\n",
       "      <td>354.518956</td>\n",
       "      <td>0.034830</td>\n",
       "      <td>741.185609</td>\n",
       "      <td>0.005301</td>\n",
       "      <td>112.813678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_convnext_base</th>\n",
       "      <td>21280.0</td>\n",
       "      <td>0.103116</td>\n",
       "      <td>2194.30</td>\n",
       "      <td>0.257160</td>\n",
       "      <td>5472.37</td>\n",
       "      <td>0.068804</td>\n",
       "      <td>1464.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052942</td>\n",
       "      <td>1126.612387</td>\n",
       "      <td>0.077115</td>\n",
       "      <td>1641.006323</td>\n",
       "      <td>0.012328</td>\n",
       "      <td>262.334444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_tiny</th>\n",
       "      <td>8872.0</td>\n",
       "      <td>0.040629</td>\n",
       "      <td>360.46</td>\n",
       "      <td>0.125803</td>\n",
       "      <td>1116.12</td>\n",
       "      <td>0.048785</td>\n",
       "      <td>432.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.017429</td>\n",
       "      <td>154.629584</td>\n",
       "      <td>0.036688</td>\n",
       "      <td>325.500024</td>\n",
       "      <td>0.006506</td>\n",
       "      <td>57.721292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>convnext_tiny.fb_in22k</th>\n",
       "      <td>8872.0</td>\n",
       "      <td>0.062261</td>\n",
       "      <td>552.38</td>\n",
       "      <td>0.174923</td>\n",
       "      <td>1551.92</td>\n",
       "      <td>0.057359</td>\n",
       "      <td>508.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>178.889227</td>\n",
       "      <td>0.039880</td>\n",
       "      <td>353.814434</td>\n",
       "      <td>0.005824</td>\n",
       "      <td>51.673571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_convnext_tiny</th>\n",
       "      <td>8872.0</td>\n",
       "      <td>0.183944</td>\n",
       "      <td>1631.95</td>\n",
       "      <td>0.318894</td>\n",
       "      <td>2829.23</td>\n",
       "      <td>0.054776</td>\n",
       "      <td>485.97</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062596</td>\n",
       "      <td>555.355244</td>\n",
       "      <td>0.067971</td>\n",
       "      <td>603.036000</td>\n",
       "      <td>0.003891</td>\n",
       "      <td>34.522588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_wideresnet_28_10</th>\n",
       "      <td>10106.0</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>24.38</td>\n",
       "      <td>0.029793</td>\n",
       "      <td>301.09</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>155.63</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000455</td>\n",
       "      <td>4.599522</td>\n",
       "      <td>0.002347</td>\n",
       "      <td>23.719652</td>\n",
       "      <td>0.001168</td>\n",
       "      <td>11.808179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wideresnet_28_10</th>\n",
       "      <td>10106.0</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>22.90</td>\n",
       "      <td>0.026761</td>\n",
       "      <td>270.45</td>\n",
       "      <td>0.008736</td>\n",
       "      <td>88.29</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000831</td>\n",
       "      <td>8.401786</td>\n",
       "      <td>0.001652</td>\n",
       "      <td>16.699925</td>\n",
       "      <td>0.000352</td>\n",
       "      <td>3.556107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deit_small_patch16_224.fb_in1k</th>\n",
       "      <td>8170378.0</td>\n",
       "      <td>0.688957</td>\n",
       "      <td>5629035.05</td>\n",
       "      <td>0.699874</td>\n",
       "      <td>5718238.12</td>\n",
       "      <td>0.088022</td>\n",
       "      <td>719174.09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002044</td>\n",
       "      <td>16697.380857</td>\n",
       "      <td>0.002359</td>\n",
       "      <td>19276.447727</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>12425.288639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_deit_small_patch16_224</th>\n",
       "      <td>8170378.0</td>\n",
       "      <td>0.692757</td>\n",
       "      <td>5660087.78</td>\n",
       "      <td>0.705982</td>\n",
       "      <td>5768142.50</td>\n",
       "      <td>0.081712</td>\n",
       "      <td>667616.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.005185</td>\n",
       "      <td>42366.565605</td>\n",
       "      <td>0.005420</td>\n",
       "      <td>44279.603482</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>29923.361248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224.augreg_in1k</th>\n",
       "      <td>16340746.0</td>\n",
       "      <td>0.687764</td>\n",
       "      <td>11238576.69</td>\n",
       "      <td>0.698525</td>\n",
       "      <td>11414424.70</td>\n",
       "      <td>0.089155</td>\n",
       "      <td>1456864.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>36663.339613</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>42467.948763</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>29137.755516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vit_base_patch16_224.augreg_in21k</th>\n",
       "      <td>16340746.0</td>\n",
       "      <td>0.696748</td>\n",
       "      <td>11385387.42</td>\n",
       "      <td>0.708808</td>\n",
       "      <td>11582455.50</td>\n",
       "      <td>0.082996</td>\n",
       "      <td>1356214.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>34369.810994</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>40188.504032</td>\n",
       "      <td>0.001260</td>\n",
       "      <td>20592.086232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robust_vit_base_patch16_224</th>\n",
       "      <td>16340746.0</td>\n",
       "      <td>0.684705</td>\n",
       "      <td>11188584.22</td>\n",
       "      <td>0.697764</td>\n",
       "      <td>11401986.83</td>\n",
       "      <td>0.085917</td>\n",
       "      <td>1403947.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008794</td>\n",
       "      <td>143694.257379</td>\n",
       "      <td>0.008792</td>\n",
       "      <td>143664.552998</td>\n",
       "      <td>0.004772</td>\n",
       "      <td>77984.620367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   mean_total_neurons  mean_zero_fraction  \\\n",
       "convnext_base                                 21280.0            0.047139   \n",
       "convnext_base.fb_in22k                        21280.0            0.043351   \n",
       "robust_convnext_base                          21280.0            0.103116   \n",
       "convnext_tiny                                  8872.0            0.040629   \n",
       "convnext_tiny.fb_in22k                         8872.0            0.062261   \n",
       "robust_convnext_tiny                           8872.0            0.183944   \n",
       "robust_wideresnet_28_10                       10106.0            0.002412   \n",
       "wideresnet_28_10                              10106.0            0.002266   \n",
       "deit_small_patch16_224.fb_in1k              8170378.0            0.688957   \n",
       "robust_deit_small_patch16_224               8170378.0            0.692757   \n",
       "vit_base_patch16_224.augreg_in1k           16340746.0            0.687764   \n",
       "vit_base_patch16_224.augreg_in21k          16340746.0            0.696748   \n",
       "robust_vit_base_patch16_224                16340746.0            0.684705   \n",
       "\n",
       "                                   mean_zero_count  mean_dormant_fraction  \\\n",
       "convnext_base                              1003.12               0.163013   \n",
       "convnext_base.fb_in22k                      922.50               0.157668   \n",
       "robust_convnext_base                       2194.30               0.257160   \n",
       "convnext_tiny                               360.46               0.125803   \n",
       "convnext_tiny.fb_in22k                      552.38               0.174923   \n",
       "robust_convnext_tiny                       1631.95               0.318894   \n",
       "robust_wideresnet_28_10                      24.38               0.029793   \n",
       "wideresnet_28_10                             22.90               0.026761   \n",
       "deit_small_patch16_224.fb_in1k          5629035.05               0.699874   \n",
       "robust_deit_small_patch16_224           5660087.78               0.705982   \n",
       "vit_base_patch16_224.augreg_in1k       11238576.69               0.698525   \n",
       "vit_base_patch16_224.augreg_in21k      11385387.42               0.708808   \n",
       "robust_vit_base_patch16_224            11188584.22               0.697764   \n",
       "\n",
       "                                   mean_dormant_count  \\\n",
       "convnext_base                                 3468.92   \n",
       "convnext_base.fb_in22k                        3355.18   \n",
       "robust_convnext_base                          5472.37   \n",
       "convnext_tiny                                 1116.12   \n",
       "convnext_tiny.fb_in22k                        1551.92   \n",
       "robust_convnext_tiny                          2829.23   \n",
       "robust_wideresnet_28_10                        301.09   \n",
       "wideresnet_28_10                               270.45   \n",
       "deit_small_patch16_224.fb_in1k             5718238.12   \n",
       "robust_deit_small_patch16_224              5768142.50   \n",
       "vit_base_patch16_224.augreg_in1k          11414424.70   \n",
       "vit_base_patch16_224.augreg_in21k         11582455.50   \n",
       "robust_vit_base_patch16_224               11401986.83   \n",
       "\n",
       "                                   mean_overactive_fraction  \\\n",
       "convnext_base                                      0.056383   \n",
       "convnext_base.fb_in22k                             0.055629   \n",
       "robust_convnext_base                               0.068804   \n",
       "convnext_tiny                                      0.048785   \n",
       "convnext_tiny.fb_in22k                             0.057359   \n",
       "robust_convnext_tiny                               0.054776   \n",
       "robust_wideresnet_28_10                            0.015400   \n",
       "wideresnet_28_10                                   0.008736   \n",
       "deit_small_patch16_224.fb_in1k                     0.088022   \n",
       "robust_deit_small_patch16_224                      0.081712   \n",
       "vit_base_patch16_224.augreg_in1k                   0.089155   \n",
       "vit_base_patch16_224.augreg_in21k                  0.082996   \n",
       "robust_vit_base_patch16_224                        0.085917   \n",
       "\n",
       "                                   mean_overactive_count  std_total_neurons  \\\n",
       "convnext_base                                    1199.83                0.0   \n",
       "convnext_base.fb_in22k                           1183.79                0.0   \n",
       "robust_convnext_base                             1464.14                0.0   \n",
       "convnext_tiny                                     432.82                0.0   \n",
       "convnext_tiny.fb_in22k                            508.89                0.0   \n",
       "robust_convnext_tiny                              485.97                0.0   \n",
       "robust_wideresnet_28_10                           155.63                0.0   \n",
       "wideresnet_28_10                                   88.29                0.0   \n",
       "deit_small_patch16_224.fb_in1k                 719174.09                0.0   \n",
       "robust_deit_small_patch16_224                  667616.00                0.0   \n",
       "vit_base_patch16_224.augreg_in1k              1456864.84                0.0   \n",
       "vit_base_patch16_224.augreg_in21k             1356214.88                0.0   \n",
       "robust_vit_base_patch16_224                   1403947.14                0.0   \n",
       "\n",
       "                                   std_zero_fraction  std_zero_count  \\\n",
       "convnext_base                               0.016902      359.664602   \n",
       "convnext_base.fb_in22k                      0.016660      354.518956   \n",
       "robust_convnext_base                        0.052942     1126.612387   \n",
       "convnext_tiny                               0.017429      154.629584   \n",
       "convnext_tiny.fb_in22k                      0.020163      178.889227   \n",
       "robust_convnext_tiny                        0.062596      555.355244   \n",
       "robust_wideresnet_28_10                     0.000455        4.599522   \n",
       "wideresnet_28_10                            0.000831        8.401786   \n",
       "deit_small_patch16_224.fb_in1k              0.002044    16697.380857   \n",
       "robust_deit_small_patch16_224               0.005185    42366.565605   \n",
       "vit_base_patch16_224.augreg_in1k            0.002244    36663.339613   \n",
       "vit_base_patch16_224.augreg_in21k           0.002103    34369.810994   \n",
       "robust_vit_base_patch16_224                 0.008794   143694.257379   \n",
       "\n",
       "                                   std_dormant_fraction  std_dormant_count  \\\n",
       "convnext_base                                  0.034687         738.129524   \n",
       "convnext_base.fb_in22k                         0.034830         741.185609   \n",
       "robust_convnext_base                           0.077115        1641.006323   \n",
       "convnext_tiny                                  0.036688         325.500024   \n",
       "convnext_tiny.fb_in22k                         0.039880         353.814434   \n",
       "robust_convnext_tiny                           0.067971         603.036000   \n",
       "robust_wideresnet_28_10                        0.002347          23.719652   \n",
       "wideresnet_28_10                               0.001652          16.699925   \n",
       "deit_small_patch16_224.fb_in1k                 0.002359       19276.447727   \n",
       "robust_deit_small_patch16_224                  0.005420       44279.603482   \n",
       "vit_base_patch16_224.augreg_in1k               0.002599       42467.948763   \n",
       "vit_base_patch16_224.augreg_in21k              0.002459       40188.504032   \n",
       "robust_vit_base_patch16_224                    0.008792      143664.552998   \n",
       "\n",
       "                                   std_overactive_fraction  \\\n",
       "convnext_base                                     0.005287   \n",
       "convnext_base.fb_in22k                            0.005301   \n",
       "robust_convnext_base                              0.012328   \n",
       "convnext_tiny                                     0.006506   \n",
       "convnext_tiny.fb_in22k                            0.005824   \n",
       "robust_convnext_tiny                              0.003891   \n",
       "robust_wideresnet_28_10                           0.001168   \n",
       "wideresnet_28_10                                  0.000352   \n",
       "deit_small_patch16_224.fb_in1k                    0.001521   \n",
       "robust_deit_small_patch16_224                     0.003662   \n",
       "vit_base_patch16_224.augreg_in1k                  0.001783   \n",
       "vit_base_patch16_224.augreg_in21k                 0.001260   \n",
       "robust_vit_base_patch16_224                       0.004772   \n",
       "\n",
       "                                   std_overactive_count  \n",
       "convnext_base                                112.496760  \n",
       "convnext_base.fb_in22k                       112.813678  \n",
       "robust_convnext_base                         262.334444  \n",
       "convnext_tiny                                 57.721292  \n",
       "convnext_tiny.fb_in22k                        51.673571  \n",
       "robust_convnext_tiny                          34.522588  \n",
       "robust_wideresnet_28_10                       11.808179  \n",
       "wideresnet_28_10                               3.556107  \n",
       "deit_small_patch16_224.fb_in1k             12425.288639  \n",
       "robust_deit_small_patch16_224              29923.361248  \n",
       "vit_base_patch16_224.augreg_in1k           29137.755516  \n",
       "vit_base_patch16_224.augreg_in21k          20592.086232  \n",
       "robust_vit_base_patch16_224                77984.620367  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "white {'total_neurons': 8872, 'zero_count': 1560, 'dormant_count': 401, 'overactive_count': 623}\n",
      "black {'total_neurons': 8872, 'zero_count': 1838, 'dormant_count': 407, 'overactive_count': 617}\n",
      "white {'total_neurons': 8872, 'zero_fraction': 0.17583408476104598, 'zero_count': 1560, 'dormant_fraction': 0.04519837691614067, 'dormant_count': 401, 'overactive_fraction': 0.07022091974752029, 'overactive_count': 623}\n",
      "black {'total_neurons': 8872, 'zero_fraction': 0.20716862037871955, 'zero_count': 1838, 'dormant_fraction': 0.04587466185752931, 'dormant_count': 407, 'overactive_fraction': 0.06954463480613166, 'overactive_count': 617}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config.yaml\")\n",
    "N = 10\n",
    "\n",
    "# Create white and black images using NumPy\n",
    "white_image = np.ones((224, 224, 3), dtype=np.uint8) * 255\n",
    "black_image = np.zeros((224, 224, 3), dtype=np.uint8)\n",
    "white_tensor = torch.from_numpy(white_image).permute(2, 0, 1).float() / 255.0\n",
    "black_tensor = torch.from_numpy(black_image).permute(2, 0, 1).float() / 255.0\n",
    "white_tensor = white_tensor.unsqueeze(0)  # Shape: (1, 3, 224, 224)\n",
    "black_tensor = black_tensor.unsqueeze(0)  # Shape: (1, 3, 224, 224)\n",
    "\n",
    "\n",
    "backbones = [ \n",
    "            #   'convnext_base',  'convnext_base.fb_in22k', 'robust_convnext_base',\n",
    "              'convnext_tiny' #'robust_convnext_tiny' 'random_convnext_tiny'  'convnext_tiny.fb_in22k', \n",
    "\n",
    "            #   'robust_wideresnet_28_10', 'wideresnet_28_10',\n",
    "            #   'deit_small_patch16_224.fb_in1k',\n",
    "            #   'robust_deit_small_patch16_224',\n",
    "            #   'vit_base_patch16_224.augreg_in1k',\n",
    "            #   'vit_base_patch16_224.augreg_in21k',\n",
    "            #   'robust_vit_base_patch16_224'\n",
    "                ]\n",
    "\n",
    "backbones_result = {}\n",
    "for backbone_name in backbones:\n",
    "    # print(backbone_name)\n",
    "\n",
    "    backbone_result = {\n",
    "        \"total_neurons\":[],\n",
    "        \"zero_fraction\": [],\n",
    "        \"zero_count\": [],\n",
    "        \"dormant_fraction\": [],\n",
    "        \"dormant_count\": [],\n",
    "        \"overactive_fraction\": [],\n",
    "        \"overactive_count\": [],\n",
    "    }\n",
    "\n",
    "    config.backbone = backbone_name\n",
    "    model = load_architecture(False, config, N, )\n",
    "\n",
    "    from utils import ActivationTracker, register_hooks, compute_stats\n",
    "\n",
    "    tracker_nat = ActivationTracker()\n",
    "    tracker_adv = ActivationTracker()\n",
    "\n",
    "    model.current_tracker = 'nat'\n",
    "    handles = register_hooks(model, tracker_nat, tracker_adv)\n",
    "\n",
    "    stats = {'nb_correct_nat': 0, 'nb_correct_adv': 0, 'nb_examples': 0}\n",
    "    stats_nat = { \"zero_count\": 0, \"dormant_count\": 0, \"overactive_count\": 0, \"total_neurons\": 0 }\n",
    "    stats_adv = { \"zero_count\": 0, \"dormant_count\": 0, \"overactive_count\": 0, \"total_neurons\": 0 }\n",
    "            \n",
    "    # print('Evaluate the model on natural data', rank, flush=True)\n",
    "    model.current_tracker = 'nat'  # Set the tracker to natural data\n",
    "    nat_outputs = model(white_tensor)\n",
    "    _, preds_nat = torch.max(nat_outputs.data, 1)\n",
    "\n",
    "    # print('Evaluate the model on adversarial examples', rank, flush=True)\n",
    "    model.current_tracker = 'adv'  # Set the tracker to adversarial data\n",
    "    adv_outputs = model(black_tensor)\n",
    "    _, preds_adv = torch.max(adv_outputs.data, 1)\n",
    "\n",
    "    stats_nat = compute_stats(tracker_nat.activations)\n",
    "    stats_adv = compute_stats(tracker_adv.activations)\n",
    "\n",
    "    print('white', stats_nat)\n",
    "    print('black', stats_adv)\n",
    "\n",
    "    # Clear activations for next batch\n",
    "    tracker_nat.activations.clear()\n",
    "    tracker_adv.activations.clear()\n",
    "\n",
    "    result = run_redo(white_tensor, model) # compute amount of zero, dormant and overactive neurons\n",
    "\n",
    "    print('white', result)\n",
    "\n",
    "    result = run_redo(black_tensor, model) # compute amount of zero, dormant and overactive neurons\n",
    "\n",
    "    print('black', result)\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
