{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uc-merced-land-use-dataset\n",
      "Warning: test dataset has only 420 samples. No subsampling performed.\n",
      "Warning: test dataset has only 420 samples. No subsampling performed.\n",
      "✅ Saved to: /home/mheuillet/Desktop/processed_dataset/uc-merced-land-use-dataset_processed.pkl.gz\n",
      "flowers-102\n",
      "✅ Saved to: /home/mheuillet/Desktop/processed_dataset/flowers-102_processed.pkl.gz\n",
      "caltech101\n",
      "✅ Saved to: /home/mheuillet/Desktop/processed_dataset/caltech101_processed.pkl.gz\n",
      "stanford_cars\n",
      "✅ Saved to: /home/mheuillet/Desktop/processed_dataset/stanford_cars_processed.pkl.gz\n",
      "fgvc-aircraft-2013b\n",
      "✅ Saved to: /home/mheuillet/Desktop/processed_dataset/fgvc-aircraft-2013b_processed.pkl.gz\n",
      "oxford-iiit-pet\n",
      "✅ Saved to: /home/mheuillet/Desktop/processed_dataset/oxford-iiit-pet_processed.pkl.gz\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from databases import load_data\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import pickle\n",
    "import gzip\n",
    "from pathlib import Path\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config_linearprobe50.yaml\")\n",
    "config.datasets_path = './data' # where you store datasets locally \n",
    "\n",
    "for dataset in [ \n",
    "                'uc-merced-land-use-dataset',   \n",
    "                 'flowers-102', \n",
    "                 'caltech101',\n",
    "                 'stanford_cars', \n",
    "                 'fgvc-aircraft-2013b',\n",
    "                 'oxford-iiit-pet'\n",
    "                   ]:\n",
    "                #]: #'dtd', 'eurosat' ,\n",
    "\n",
    "    print(dataset)\n",
    "    \n",
    "    config.dataset = dataset\n",
    "    train_dataset, val_dataset, test_dataset, N = load_data(config, common_corruption=False)\n",
    "    _, _, common_test_dataset, N = load_data(config, common_corruption=True)\n",
    "\n",
    "    output_path = \"/home/mheuillet/Desktop/processed_dataset/{}_processed.pkl.gz\".format(config.dataset)\n",
    "    with gzip.open(output_path, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            \"train\": train_dataset,\n",
    "            \"val\": val_dataset,\n",
    "            \"test\": test_dataset,\n",
    "            \"test_common\":common_test_dataset,\n",
    "            \"N\": N\n",
    "        }, f)\n",
    "\n",
    "    print(f\"✅ Saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torchvision'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mzstandard\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mzstd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageFolder\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtempfile\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TemporaryDirectory\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torchvision'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import zstandard as zstd\n",
    "from pathlib import Path\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "def load_processed_dataset(archive_path, transform=None):\n",
    "    \"\"\"\n",
    "    Loads a dataset archive (.tar.zst), extracts it, and returns a dict of ImageFolder datasets.\n",
    "    Args:\n",
    "        archive_path (str or Path): Path to the .tar.zst archive\n",
    "        transform (torchvision.transforms): Transform to apply to all splits (optional)\n",
    "    Returns:\n",
    "        dict: {split_name: ImageFolder dataset}\n",
    "    \"\"\"\n",
    "    archive_path = Path(archive_path)\n",
    "\n",
    "    if transform is None:\n",
    "        transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor()\n",
    "        ])\n",
    "\n",
    "    temp_dir = TemporaryDirectory()\n",
    "    temp_path = Path(temp_dir.name)\n",
    "\n",
    "    # Decompress .tar.zst\n",
    "    with open(archive_path, 'rb') as f_in:\n",
    "        dctx = zstd.ZstdDecompressor()\n",
    "        with dctx.stream_reader(f_in) as zst_stream:\n",
    "            with tarfile.open(fileobj=zst_stream, mode='r|') as tar:\n",
    "                tar.extractall(path=temp_path)\n",
    "\n",
    "    # Load datasets for each split\n",
    "    datasets = {}\n",
    "    for split in [\"train\", \"val\", \"test\", \"test_common\"]:\n",
    "        split_path = temp_path / split\n",
    "        if split_path.exists():\n",
    "            datasets[split] = ImageFolder(split_path, transform=transform)\n",
    "\n",
    "    return datasets, temp_dir  # temp_dir must be kept alive while using datasets\n",
    "\n",
    "\n",
    "archive_path = \"/home/mheuillet/Desktop/uc-merced-land-use-dataset_processed.tar.zst\"\n",
    "datasets, tmp_dir = load_processed_dataset(archive_path)\n",
    "\n",
    "# Example: load a batch\n",
    "from torch.utils.data import DataLoader\n",
    "loader = DataLoader(datasets[\"train\"], batch_size=16, shuffle=True)\n",
    "\n",
    "for imgs, labels in loader:\n",
    "    print(imgs.shape, labels)\n",
    "    break\n",
    "\n",
    "# When you're done:\n",
    "tmp_dir.cleanup()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### don't pay attention to this cell\n",
    "\n",
    "# EuroSAT: seulement 8 runs on complete et tous les autres OOM\n",
    "# Caltech: 26 runs ok, \n",
    "# Stanford Cars: 34 ok\n",
    "# Aircraft: 26 ok\n",
    "# DTD : 26 ok\n",
    "# Oxford pet: 26 ok\n",
    "# Flowers: 26 ok\n",
    "\n",
    "stanford_cars = 6922 + 1222 + 8041 \n",
    "caltech101 = 5899 + 1042 + 1736 \n",
    "dtd = 1880 + 1880 + 1880 \n",
    "eurosat = 18360 + 3240 + 5400 \n",
    "fgvcaircraft2013b =  3334 + 3333 + 3333 \n",
    "flowers102 = 1020 + 1020 + 6149 \n",
    "oxfordiiitpet = 3128 + 552 + 3669 \n",
    "\n",
    "print(eurosat, caltech101, dtd, fgvcaircraft2013b, flowers102, oxfordiiitpet, stanford_cars)\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Initialize the Caltech101 dataset without transformations\n",
    "caltech101_sample = datasets.Caltech101(root='./data', download=False)\n",
    "print(len(caltech101_sample))\n",
    "for i in range( len(caltech101_sample) ) :\n",
    "    image, label = caltech101_sample[i]\n",
    "\n",
    "    # Check the image mode\n",
    "    # print(f\"Image Mode: {image.mode}\")  # Expected: 'RGB'\n",
    "    if image.mode != 'RGB':\n",
    "        print('issue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
