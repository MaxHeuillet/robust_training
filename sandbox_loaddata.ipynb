{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mheuillet/Desktop/robust_training/.venv2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2025-02-07 18:01:52,071\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-02-07 18:01:52,167\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n",
      "2025-02-07 18:01:52,251\tINFO util.py:154 -- Missing packages: ['ipywidgets']. Run `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: test dataset has only 420 samples. No subsampling performed.\n",
      "uc-merced-land-use-dataset 1428 252 420 21\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import numpy as np\n",
    "config = OmegaConf.load(\"./configs/default_config_linearprobe50.yaml\")\n",
    "\n",
    "for dataset in [ 'uc-merced-land-use-dataset' ]:\n",
    "                # 'kvasir-dataset'\n",
    "                # 'stanford_cars',\n",
    "                #'caltech101', 'dtd', 'eurosat' ,\n",
    "                # 'fgvc-aircraft-2013b', 'flowers-102', 'oxford-iiit-pet'\n",
    "                #'Imagenette' ]:\n",
    "    \n",
    "    config.dataset = dataset\n",
    "    train_dataset, val_dataset, test_dataset, N, train_transform, transform = load_data(False, config) \n",
    "\n",
    "    print(dataset, len(train_dataset), len(val_dataset), len(test_dataset),  N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes found: ['dyed-lifted-polyps', 'dyed-resection-margins', 'esophagitis', 'normal-cecum', 'normal-pylorus', 'normal-z-line', 'polyps', 'ulcerative-colitis']\n",
      "Batch images shape: torch.Size([32, 3, 224, 224])\n",
      "Batch labels shape: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Path to your unzipped Kvasir dataset\n",
    "dataset_root = '/home/mheuillet/Desktop/robust_training/data/kvasir_dataset_unzipped/kvasir-dataset'\n",
    "\n",
    "# Define any transforms you need (e.g., resizing, normalization, etc.)\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),   # or some other size\n",
    "    transforms.ToTensor(),\n",
    "    # Optional: transforms.Normalize(mean, std),\n",
    "])\n",
    "\n",
    "# Create an ImageFolder dataset\n",
    "kvasir_dataset = datasets.ImageFolder( root=dataset_root, transform=data_transforms )\n",
    "\n",
    "# Check the classes that ImageFolder identified\n",
    "print(\"Classes found:\", kvasir_dataset.classes)\n",
    "# e.g. [\"dyed-lifted-polyps\", \"dyed-resection-margins\", ...]\n",
    "# Each subfolder is assigned a class index in alphabetical order\n",
    "\n",
    "# Create a DataLoader for batching\n",
    "dataloader = DataLoader(kvasir_dataset, batch_size=32, shuffle=True, num_workers=4)\n",
    "\n",
    "# Iterate over a few batches to verify it works\n",
    "for images, labels in dataloader:\n",
    "    print(\"Batch images shape:\", images.shape)\n",
    "    print(\"Batch labels shape:\", labels.shape)\n",
    "    break  # Just show the first batch, then stop\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### don't pay attention to this cell\n",
    "\n",
    "# EuroSAT: seulement 8 runs on complete et tous les autres OOM\n",
    "# Caltech: 26 runs ok, \n",
    "# Stanford Cars: 34 ok\n",
    "# Aircraft: 26 ok\n",
    "# DTD : 26 ok\n",
    "# Oxford pet: 26 ok\n",
    "# Flowers: 26 ok\n",
    "\n",
    "stanford_cars = 6922 + 1222 + 8041 \n",
    "caltech101 = 5899 + 1042 + 1736 \n",
    "dtd = 1880 + 1880 + 1880 \n",
    "eurosat = 18360 + 3240 + 5400 \n",
    "fgvcaircraft2013b =  3334 + 3333 + 3333 \n",
    "flowers102 = 1020 + 1020 + 6149 \n",
    "oxfordiiitpet = 3128 + 552 + 3669 \n",
    "\n",
    "print(eurosat, caltech101, dtd, fgvcaircraft2013b, flowers102, oxfordiiitpet, stanford_cars)\n",
    "\n",
    "from PIL import Image\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "# Initialize the Caltech101 dataset without transformations\n",
    "caltech101_sample = datasets.Caltech101(root='./data', download=False)\n",
    "print(len(caltech101_sample))\n",
    "for i in range( len(caltech101_sample) ) :\n",
    "    image, label = caltech101_sample[i]\n",
    "\n",
    "    # Check the image mode\n",
    "    # print(f\"Image Mode: {image.mode}\")  # Expected: 'RGB'\n",
    "    if image.mode != 'RGB':\n",
    "        print('issue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
