{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mheuillet/Desktop/robust_training/.venv2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "edgenext_small.usi_in1k\n",
      "test edgenext_small.usi_in1k\n",
      "BACKBONE NAME edgenext_small.usi_in1k\n",
      "Loading timm model: edgenext_small.usi_in1k\n",
      "architecture loaded\n",
      "EdgeNeXt(\n",
      "  (stem): Sequential(\n",
      "    (0): Conv2d(3, 48, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (1): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (stages): Sequential(\n",
      "    (0): EdgeNeXtStage(\n",
      "      (downsample): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv_dw): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          (norm): LayerNorm((48,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=48, out_features=192, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=192, out_features=48, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): EdgeNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((48,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(48, 96, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv_dw): Conv2d(96, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=96)\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): SplitTransposeBlock(\n",
      "          (convs): ModuleList(\n",
      "            (0): Conv2d(48, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=48)\n",
      "          )\n",
      "          (pos_embd): PositionalEncodingFourier(\n",
      "            (token_projection): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1))\n",
      "          )\n",
      "          (norm_xca): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (xca): CrossCovarianceAttn(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (norm): LayerNorm((96,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): EdgeNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((96,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(96, 160, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (3): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (4): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (5): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (6): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (7): ConvBlock(\n",
      "          (conv_dw): Conv2d(160, 160, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=160)\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (8): SplitTransposeBlock(\n",
      "          (convs): ModuleList(\n",
      "            (0-1): 2 x Conv2d(54, 54, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=54)\n",
      "          )\n",
      "          (norm_xca): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (xca): CrossCovarianceAttn(\n",
      "            (qkv): Linear(in_features=160, out_features=480, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=160, out_features=160, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (norm): LayerNorm((160,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=160, out_features=640, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=640, out_features=160, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): EdgeNeXtStage(\n",
      "      (downsample): Sequential(\n",
      "        (0): LayerNorm2d((160,), eps=1e-06, elementwise_affine=True)\n",
      "        (1): Conv2d(160, 304, kernel_size=(2, 2), stride=(2, 2))\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): ConvBlock(\n",
      "          (conv_dw): Conv2d(304, 304, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=304)\n",
      "          (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=304, out_features=1216, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1216, out_features=304, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (1): ConvBlock(\n",
      "          (conv_dw): Conv2d(304, 304, kernel_size=(9, 9), stride=(1, 1), padding=(4, 4), groups=304)\n",
      "          (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=304, out_features=1216, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1216, out_features=304, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "        (2): SplitTransposeBlock(\n",
      "          (convs): ModuleList(\n",
      "            (0-2): 3 x Conv2d(76, 76, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=76)\n",
      "          )\n",
      "          (norm_xca): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "          (xca): CrossCovarianceAttn(\n",
      "            (qkv): Linear(in_features=304, out_features=912, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=304, out_features=304, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (norm): LayerNorm((304,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=304, out_features=1216, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1216, out_features=304, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path): Identity()\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm_pre): Identity()\n",
      "  (head): NormMlpClassifierHead(\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "    (norm): LayerNorm2d((304,), eps=1e-06, elementwise_affine=True)\n",
      "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "    (pre_logits): Identity()\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc): Linear(in_features=304, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "###################\n",
      "###################\n",
      "###################\n"
     ]
    }
   ],
   "source": [
    "from omegaconf import OmegaConf\n",
    "from datasets import load_data\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from architectures import load_architecture\n",
    "\n",
    "config = OmegaConf.load(\"./configs/default_config_linearprobe50.yaml\")\n",
    "config.statedicts_path = '/home/mheuillet/Desktop/state_dicts_share'\n",
    "\n",
    "\n",
    "# backbones=(\n",
    "#   'CLIP-convnext_base_w-laion_aesthetic-s13B-b82K'\n",
    "#   'CLIP-convnext_base_w-laion2B-s13B-b82K'\n",
    "#   'deit_small_patch16_224.fb_in1k'\n",
    "#   'robust_resnet50'\n",
    "#   'vit_small_patch16_224.augreg_in21k'\n",
    "#   'convnext_base.fb_in1k'\n",
    "#   'resnet50.a1_in1k'\n",
    "#   'robust_vit_base_patch16_224'\n",
    "#   'vit_base_patch16_224.mae'\n",
    "#   'vit_small_patch16_224.dino'\n",
    "#   'convnext_base.fb_in22k'\n",
    "#   'robust_convnext_base'\n",
    "#   'vit_base_patch16_224.augreg_in1k'\n",
    "#   'vit_base_patch16_224.augreg_in21k'\n",
    "#   'vit_base_patch16_224.dino'\n",
    "#   'vit_base_patch16_clip_224.laion2b'\n",
    "#   'convnext_tiny.fb_in1k'\n",
    "#   'robust_convnext_tiny'\n",
    "#   'robust_deit_small_patch16_224'\n",
    "#   'vit_small_patch16_224.augreg_in1k'\n",
    "#   'convnext_tiny.fb_in22k'\n",
    "# ) \n",
    "\n",
    "# backbones=(\n",
    "  # 'vit_base_patch16_clip_224.laion2b_ft_in1k'\n",
    "  # 'vit_base_patch16_224.augreg_in21k_ft_in1k'\n",
    "  # 'vit_small_patch16_224.augreg_in21k_ft_in1k'\n",
    "  # 'eva02_base_patch14_224.mim_in22k'\n",
    "  # 'eva02_tiny_patch14_224.mim_in22k'\n",
    "  # 'swin_base_patch4_window7_224.ms_in22k_ft_in1k'\n",
    "  # 'swin_tiny_patch4_window7_224.ms_in1k'\n",
    "  # 'convnext_base.clip_laion2b_augreg_ft_in12k_in1k'\n",
    "  # 'convnext_base.fb_in22k_ft_in1k'\n",
    "  # 'convnext_tiny.fb_in22k_ft_in1k',)\n",
    "\n",
    "backbones = (\n",
    "    # 'regnetx_004.pycls_in1k', \n",
    "    # 'efficientnet-b0',\n",
    "    # 'deit_tiny_patch16_224.fb_in1k',\n",
    "    # 'mobilevit-small',\n",
    "    # 'mobilenetv3_large_100.ra_in1k',\n",
    "    # 'edgenext_small.usi_in1k', )\n",
    "\n",
    "N = 10 # change the classification head to N classes\n",
    "\n",
    "for backbone in backbones:\n",
    "    print(backbone)\n",
    "    config.backbone = backbone\n",
    "    print('test', config.backbone)\n",
    "    hp_opt = False\n",
    "    model = load_architecture( config, N, )\n",
    "    print('architecture loaded')\n",
    "    print(model)\n",
    "    print('###################')\n",
    "    print('###################')\n",
    "    print('###################')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-v] [-q] [--locals] [-f] [-c] [-b]\n",
      "                             [-k TESTNAMEPATTERNS]\n",
      "                             [tests ...]\n",
      "ipykernel_launcher.py: error: argument -f/--failfast: ignored explicit argument '/home/mheuillet/.local/share/jupyter/runtime/kernel-v34a5fced182e2aa8fe5cb5a432163dba4369d2305.json'\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'tb_frame'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArgumentError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:1919\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1918\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1919\u001b[0m     namespace, args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1920\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:2140\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args\u001b[0;34m(self, arg_strings, namespace)\u001b[0m\n\u001b[1;32m   2139\u001b[0m     \u001b[38;5;66;03m# consume the next optional and any arguments for it\u001b[39;00m\n\u001b[0;32m-> 2140\u001b[0m     start_index \u001b[38;5;241m=\u001b[39m \u001b[43mconsume_optional\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2142\u001b[0m \u001b[38;5;66;03m# consume any positionals following the last Optional\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:2062\u001b[0m, in \u001b[0;36mArgumentParser._parse_known_args.<locals>.consume_optional\u001b[0;34m(start_index)\u001b[0m\n\u001b[1;32m   2061\u001b[0m         msg \u001b[38;5;241m=\u001b[39m _(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignored explicit argument \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2062\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ArgumentError(action, msg \u001b[38;5;241m%\u001b[39m explicit_arg)\n\u001b[1;32m   2064\u001b[0m \u001b[38;5;66;03m# if there is no explicit argument, try to match the\u001b[39;00m\n\u001b[1;32m   2065\u001b[0m \u001b[38;5;66;03m# optional's string arguments with the following strings\u001b[39;00m\n\u001b[1;32m   2066\u001b[0m \u001b[38;5;66;03m# if successful, exit the loop\u001b[39;00m\n\u001b[1;32m   2067\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mArgumentError\u001b[0m: argument -f/--failfast: ignored explicit argument '/home/mheuillet/.local/share/jupyter/runtime/kernel-v34a5fced182e2aa8fe5cb5a432163dba4369d2305.json'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Cell \u001b[0;32mIn[5], line 51\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Run the unit test\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# if __name__ == \"__main__\":\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m \u001b[43munittest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/unittest/main.py:101\u001b[0m, in \u001b[0;36mTestProgram.__init__\u001b[0;34m(self, module, defaultTest, argv, testRunner, testLoader, exit, verbosity, failfast, catchbreak, buffer, warnings, tb_locals)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprogName \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(argv[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 101\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparseArgs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunTests()\n",
      "File \u001b[0;32m/usr/lib/python3.11/unittest/main.py:136\u001b[0m, in \u001b[0;36mTestProgram.parseArgs\u001b[0;34m(self, argv)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_main_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtests:\n",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:1886\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1885\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparse_args\u001b[39m(\u001b[38;5;28mself\u001b[39m, args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, namespace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m-> 1886\u001b[0m     args, argv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse_known_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnamespace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1887\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m argv:\n",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:1921\u001b[0m, in \u001b[0;36mArgumentParser.parse_known_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1920\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ArgumentError \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m-> 1921\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1922\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:2652\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2651\u001b[0m args \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprog\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprog, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m: message}\n\u001b[0;32m-> 2652\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m%(prog)s\u001b[39;49;00m\u001b[38;5;124;43m: error: \u001b[39;49m\u001b[38;5;132;43;01m%(message)s\u001b[39;49;00m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/lib/python3.11/argparse.py:2639\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2638\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_print_message(message, _sys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[0;32m-> 2639\u001b[0m \u001b[43m_sys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/interactiveshell.py:2095\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2092\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   2093\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2094\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 2095\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2096\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2097\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2098\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2099\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   2100\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   2101\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:696\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    689\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    694\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    695\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 696\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:559\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    556\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    557\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    558\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 559\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m            \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    563\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    566\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    567\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    569\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:1396\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1395\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m etb\n\u001b[0;32m-> 1396\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1397\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1398\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:1287\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1284\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1285\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1286\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1289\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1290\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:1140\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m   1132\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1133\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1137\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m   1138\u001b[0m ):\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1140\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1141\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1143\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m   1144\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:1030\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1027\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m   1028\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(\u001b[38;5;28mstr\u001b[39m(etype), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m   1029\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1030\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m   1031\u001b[0m )\n\u001b[1;32m   1033\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1034\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv2/lib/python3.11/site-packages/IPython/core/ultratb.py:1098\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1096\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m cf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1098\u001b[0m         mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(\u001b[43mcf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtb_frame\u001b[49m)\n\u001b[1;32m   1099\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m mod \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m             mod_name \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'tb_frame'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Identity()"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classifier head Parameter containing:\n",
      "tensor([[ 0.0294,  0.0237,  0.0258,  ...,  0.0338, -0.0350, -0.0164],\n",
      "        [ 0.0066,  0.0014,  0.0061,  ...,  0.0100, -0.0278,  0.0146],\n",
      "        [-0.0158, -0.0233, -0.0346,  ..., -0.0275, -0.0056, -0.0018],\n",
      "        ...,\n",
      "        [ 0.0355, -0.0206, -0.0198,  ...,  0.0258, -0.0101, -0.0175],\n",
      "        [ 0.0114,  0.0098,  0.0102,  ...,  0.0221,  0.0138, -0.0354],\n",
      "        [ 0.0240,  0.0036,  0.0103,  ...,  0.0259, -0.0246, -0.0201]],\n",
      "       requires_grad=True)\n",
      "layer weights Parameter containing:\n",
      "tensor([[-0.0074,  0.0016, -0.0288,  ...,  0.0513,  0.0080,  0.0372],\n",
      "        [ 0.0423, -0.0129, -0.0011,  ..., -0.0144, -0.0145,  0.0023],\n",
      "        [ 0.0033, -0.1214,  0.1055,  ..., -0.0056,  0.0207, -0.0025],\n",
      "        ...,\n",
      "        [ 0.0523,  0.0593, -0.0085,  ..., -0.0426,  0.0150, -0.0129],\n",
      "        [-0.0376, -0.0006, -0.0060,  ..., -0.0340, -0.0179, -0.0015],\n",
      "        [-0.0458,  0.0587,  0.0152,  ...,  0.0464,  0.0506,  0.0137]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print('classifier head', model.head.fc.weight)\n",
    "\n",
    "print('layer weights', model.layers[0].blocks[0].attn.proj.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172 251 1 1\n"
     ]
    }
   ],
   "source": [
    "from utils import load_optimizer\n",
    "\n",
    "optimizer = load_optimizer(config, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BACKBONE] cls_token\n",
      "[BACKBONE] pos_embed\n",
      "[BACKBONE] patch_embed.proj.weight\n",
      "[BACKBONE] patch_embed.proj.bias\n",
      "[BACKBONE] blocks.0.norm1.weight\n",
      "[BACKBONE] blocks.0.norm1.bias\n",
      "[BACKBONE] blocks.0.attn.q_proj.weight\n",
      "[BACKBONE] blocks.0.attn.q_proj.bias\n",
      "[BACKBONE] blocks.0.attn.k_proj.weight\n",
      "[BACKBONE] blocks.0.attn.v_proj.weight\n",
      "[BACKBONE] blocks.0.attn.v_proj.bias\n",
      "[BACKBONE] blocks.0.attn.proj.weight\n",
      "[BACKBONE] blocks.0.attn.proj.bias\n",
      "[BACKBONE] blocks.0.norm2.weight\n",
      "[BACKBONE] blocks.0.norm2.bias\n",
      "[BACKBONE] blocks.0.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.0.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.0.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.0.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.0.mlp.norm.weight\n",
      "[BACKBONE] blocks.0.mlp.norm.bias\n",
      "[BACKBONE] blocks.0.mlp.fc2.weight\n",
      "[BACKBONE] blocks.0.mlp.fc2.bias\n",
      "[BACKBONE] blocks.1.norm1.weight\n",
      "[BACKBONE] blocks.1.norm1.bias\n",
      "[BACKBONE] blocks.1.attn.q_proj.weight\n",
      "[BACKBONE] blocks.1.attn.q_proj.bias\n",
      "[BACKBONE] blocks.1.attn.k_proj.weight\n",
      "[BACKBONE] blocks.1.attn.v_proj.weight\n",
      "[BACKBONE] blocks.1.attn.v_proj.bias\n",
      "[BACKBONE] blocks.1.attn.proj.weight\n",
      "[BACKBONE] blocks.1.attn.proj.bias\n",
      "[BACKBONE] blocks.1.norm2.weight\n",
      "[BACKBONE] blocks.1.norm2.bias\n",
      "[BACKBONE] blocks.1.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.1.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.1.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.1.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.1.mlp.norm.weight\n",
      "[BACKBONE] blocks.1.mlp.norm.bias\n",
      "[BACKBONE] blocks.1.mlp.fc2.weight\n",
      "[BACKBONE] blocks.1.mlp.fc2.bias\n",
      "[BACKBONE] blocks.2.norm1.weight\n",
      "[BACKBONE] blocks.2.norm1.bias\n",
      "[BACKBONE] blocks.2.attn.q_proj.weight\n",
      "[BACKBONE] blocks.2.attn.q_proj.bias\n",
      "[BACKBONE] blocks.2.attn.k_proj.weight\n",
      "[BACKBONE] blocks.2.attn.v_proj.weight\n",
      "[BACKBONE] blocks.2.attn.v_proj.bias\n",
      "[BACKBONE] blocks.2.attn.proj.weight\n",
      "[BACKBONE] blocks.2.attn.proj.bias\n",
      "[BACKBONE] blocks.2.norm2.weight\n",
      "[BACKBONE] blocks.2.norm2.bias\n",
      "[BACKBONE] blocks.2.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.2.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.2.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.2.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.2.mlp.norm.weight\n",
      "[BACKBONE] blocks.2.mlp.norm.bias\n",
      "[BACKBONE] blocks.2.mlp.fc2.weight\n",
      "[BACKBONE] blocks.2.mlp.fc2.bias\n",
      "[BACKBONE] blocks.3.norm1.weight\n",
      "[BACKBONE] blocks.3.norm1.bias\n",
      "[BACKBONE] blocks.3.attn.q_proj.weight\n",
      "[BACKBONE] blocks.3.attn.q_proj.bias\n",
      "[BACKBONE] blocks.3.attn.k_proj.weight\n",
      "[BACKBONE] blocks.3.attn.v_proj.weight\n",
      "[BACKBONE] blocks.3.attn.v_proj.bias\n",
      "[BACKBONE] blocks.3.attn.proj.weight\n",
      "[BACKBONE] blocks.3.attn.proj.bias\n",
      "[BACKBONE] blocks.3.norm2.weight\n",
      "[BACKBONE] blocks.3.norm2.bias\n",
      "[BACKBONE] blocks.3.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.3.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.3.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.3.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.3.mlp.norm.weight\n",
      "[BACKBONE] blocks.3.mlp.norm.bias\n",
      "[BACKBONE] blocks.3.mlp.fc2.weight\n",
      "[BACKBONE] blocks.3.mlp.fc2.bias\n",
      "[BACKBONE] blocks.4.norm1.weight\n",
      "[BACKBONE] blocks.4.norm1.bias\n",
      "[BACKBONE] blocks.4.attn.q_proj.weight\n",
      "[BACKBONE] blocks.4.attn.q_proj.bias\n",
      "[BACKBONE] blocks.4.attn.k_proj.weight\n",
      "[BACKBONE] blocks.4.attn.v_proj.weight\n",
      "[BACKBONE] blocks.4.attn.v_proj.bias\n",
      "[BACKBONE] blocks.4.attn.proj.weight\n",
      "[BACKBONE] blocks.4.attn.proj.bias\n",
      "[BACKBONE] blocks.4.norm2.weight\n",
      "[BACKBONE] blocks.4.norm2.bias\n",
      "[BACKBONE] blocks.4.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.4.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.4.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.4.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.4.mlp.norm.weight\n",
      "[BACKBONE] blocks.4.mlp.norm.bias\n",
      "[BACKBONE] blocks.4.mlp.fc2.weight\n",
      "[BACKBONE] blocks.4.mlp.fc2.bias\n",
      "[BACKBONE] blocks.5.norm1.weight\n",
      "[BACKBONE] blocks.5.norm1.bias\n",
      "[BACKBONE] blocks.5.attn.q_proj.weight\n",
      "[BACKBONE] blocks.5.attn.q_proj.bias\n",
      "[BACKBONE] blocks.5.attn.k_proj.weight\n",
      "[BACKBONE] blocks.5.attn.v_proj.weight\n",
      "[BACKBONE] blocks.5.attn.v_proj.bias\n",
      "[BACKBONE] blocks.5.attn.proj.weight\n",
      "[BACKBONE] blocks.5.attn.proj.bias\n",
      "[BACKBONE] blocks.5.norm2.weight\n",
      "[BACKBONE] blocks.5.norm2.bias\n",
      "[BACKBONE] blocks.5.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.5.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.5.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.5.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.5.mlp.norm.weight\n",
      "[BACKBONE] blocks.5.mlp.norm.bias\n",
      "[BACKBONE] blocks.5.mlp.fc2.weight\n",
      "[BACKBONE] blocks.5.mlp.fc2.bias\n",
      "[BACKBONE] blocks.6.norm1.weight\n",
      "[BACKBONE] blocks.6.norm1.bias\n",
      "[BACKBONE] blocks.6.attn.q_proj.weight\n",
      "[BACKBONE] blocks.6.attn.q_proj.bias\n",
      "[BACKBONE] blocks.6.attn.k_proj.weight\n",
      "[BACKBONE] blocks.6.attn.v_proj.weight\n",
      "[BACKBONE] blocks.6.attn.v_proj.bias\n",
      "[BACKBONE] blocks.6.attn.proj.weight\n",
      "[BACKBONE] blocks.6.attn.proj.bias\n",
      "[BACKBONE] blocks.6.norm2.weight\n",
      "[BACKBONE] blocks.6.norm2.bias\n",
      "[BACKBONE] blocks.6.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.6.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.6.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.6.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.6.mlp.norm.weight\n",
      "[BACKBONE] blocks.6.mlp.norm.bias\n",
      "[BACKBONE] blocks.6.mlp.fc2.weight\n",
      "[BACKBONE] blocks.6.mlp.fc2.bias\n",
      "[BACKBONE] blocks.7.norm1.weight\n",
      "[BACKBONE] blocks.7.norm1.bias\n",
      "[BACKBONE] blocks.7.attn.q_proj.weight\n",
      "[BACKBONE] blocks.7.attn.q_proj.bias\n",
      "[BACKBONE] blocks.7.attn.k_proj.weight\n",
      "[BACKBONE] blocks.7.attn.v_proj.weight\n",
      "[BACKBONE] blocks.7.attn.v_proj.bias\n",
      "[BACKBONE] blocks.7.attn.proj.weight\n",
      "[BACKBONE] blocks.7.attn.proj.bias\n",
      "[BACKBONE] blocks.7.norm2.weight\n",
      "[BACKBONE] blocks.7.norm2.bias\n",
      "[BACKBONE] blocks.7.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.7.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.7.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.7.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.7.mlp.norm.weight\n",
      "[BACKBONE] blocks.7.mlp.norm.bias\n",
      "[BACKBONE] blocks.7.mlp.fc2.weight\n",
      "[BACKBONE] blocks.7.mlp.fc2.bias\n",
      "[BACKBONE] blocks.8.norm1.weight\n",
      "[BACKBONE] blocks.8.norm1.bias\n",
      "[BACKBONE] blocks.8.attn.q_proj.weight\n",
      "[BACKBONE] blocks.8.attn.q_proj.bias\n",
      "[BACKBONE] blocks.8.attn.k_proj.weight\n",
      "[BACKBONE] blocks.8.attn.v_proj.weight\n",
      "[BACKBONE] blocks.8.attn.v_proj.bias\n",
      "[BACKBONE] blocks.8.attn.proj.weight\n",
      "[BACKBONE] blocks.8.attn.proj.bias\n",
      "[BACKBONE] blocks.8.norm2.weight\n",
      "[BACKBONE] blocks.8.norm2.bias\n",
      "[BACKBONE] blocks.8.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.8.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.8.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.8.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.8.mlp.norm.weight\n",
      "[BACKBONE] blocks.8.mlp.norm.bias\n",
      "[BACKBONE] blocks.8.mlp.fc2.weight\n",
      "[BACKBONE] blocks.8.mlp.fc2.bias\n",
      "[BACKBONE] blocks.9.norm1.weight\n",
      "[BACKBONE] blocks.9.norm1.bias\n",
      "[BACKBONE] blocks.9.attn.q_proj.weight\n",
      "[BACKBONE] blocks.9.attn.q_proj.bias\n",
      "[BACKBONE] blocks.9.attn.k_proj.weight\n",
      "[BACKBONE] blocks.9.attn.v_proj.weight\n",
      "[BACKBONE] blocks.9.attn.v_proj.bias\n",
      "[BACKBONE] blocks.9.attn.proj.weight\n",
      "[BACKBONE] blocks.9.attn.proj.bias\n",
      "[BACKBONE] blocks.9.norm2.weight\n",
      "[BACKBONE] blocks.9.norm2.bias\n",
      "[BACKBONE] blocks.9.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.9.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.9.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.9.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.9.mlp.norm.weight\n",
      "[BACKBONE] blocks.9.mlp.norm.bias\n",
      "[BACKBONE] blocks.9.mlp.fc2.weight\n",
      "[BACKBONE] blocks.9.mlp.fc2.bias\n",
      "[BACKBONE] blocks.10.norm1.weight\n",
      "[BACKBONE] blocks.10.norm1.bias\n",
      "[BACKBONE] blocks.10.attn.q_proj.weight\n",
      "[BACKBONE] blocks.10.attn.q_proj.bias\n",
      "[BACKBONE] blocks.10.attn.k_proj.weight\n",
      "[BACKBONE] blocks.10.attn.v_proj.weight\n",
      "[BACKBONE] blocks.10.attn.v_proj.bias\n",
      "[BACKBONE] blocks.10.attn.proj.weight\n",
      "[BACKBONE] blocks.10.attn.proj.bias\n",
      "[BACKBONE] blocks.10.norm2.weight\n",
      "[BACKBONE] blocks.10.norm2.bias\n",
      "[BACKBONE] blocks.10.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.10.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.10.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.10.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.10.mlp.norm.weight\n",
      "[BACKBONE] blocks.10.mlp.norm.bias\n",
      "[BACKBONE] blocks.10.mlp.fc2.weight\n",
      "[BACKBONE] blocks.10.mlp.fc2.bias\n",
      "[BACKBONE] blocks.11.norm1.weight\n",
      "[BACKBONE] blocks.11.norm1.bias\n",
      "[BACKBONE] blocks.11.attn.q_proj.weight\n",
      "[BACKBONE] blocks.11.attn.q_proj.bias\n",
      "[BACKBONE] blocks.11.attn.k_proj.weight\n",
      "[BACKBONE] blocks.11.attn.v_proj.weight\n",
      "[BACKBONE] blocks.11.attn.v_proj.bias\n",
      "[BACKBONE] blocks.11.attn.proj.weight\n",
      "[BACKBONE] blocks.11.attn.proj.bias\n",
      "[BACKBONE] blocks.11.norm2.weight\n",
      "[BACKBONE] blocks.11.norm2.bias\n",
      "[BACKBONE] blocks.11.mlp.fc1_g.weight\n",
      "[BACKBONE] blocks.11.mlp.fc1_g.bias\n",
      "[BACKBONE] blocks.11.mlp.fc1_x.weight\n",
      "[BACKBONE] blocks.11.mlp.fc1_x.bias\n",
      "[BACKBONE] blocks.11.mlp.norm.weight\n",
      "[BACKBONE] blocks.11.mlp.norm.bias\n",
      "[BACKBONE] blocks.11.mlp.fc2.weight\n",
      "[BACKBONE] blocks.11.mlp.fc2.bias\n",
      "[BACKBONE] fc_norm.weight\n",
      "[BACKBONE] fc_norm.bias\n",
      "[HEAD]     head.weight\n",
      "[HEAD]     head.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if any(param is p for p in model.head.parameters()):\n",
    "        print(f\"[HEAD]     {name}\")\n",
    "    else:\n",
    "        print(f\"[BACKBONE] {name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "model, _, _ = open_clip.create_model_and_transforms(\n",
    "    'convnext_base_w',  # architecture\n",
    "    pretrained=None     # because youre loading your own checkpoint\n",
    ")\n",
    "\n",
    "# Then load the checkpoint you saved\n",
    "# state_dict = torch.load('/path/to/your/hf_checkpoint.pt', map_location='cpu')\n",
    "# model.load_state_dict(state_dict, strict=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): TimmModel(\n",
       "    (trunk): ConvNeXt(\n",
       "      (stem): Sequential(\n",
       "        (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "        (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "      )\n",
       "      (stages): Sequential(\n",
       "        (0): ConvNeXtStage(\n",
       "          (downsample): Identity()\n",
       "          (blocks): Sequential(\n",
       "            (0): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): Identity()\n",
       "            )\n",
       "            (1): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.003)\n",
       "            )\n",
       "            (2): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "              (norm): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.006)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ConvNeXtStage(\n",
       "          (downsample): Sequential(\n",
       "            (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "            (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.009)\n",
       "            )\n",
       "            (1): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.011)\n",
       "            )\n",
       "            (2): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "              (norm): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.014)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ConvNeXtStage(\n",
       "          (downsample): Sequential(\n",
       "            (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "            (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.017)\n",
       "            )\n",
       "            (1): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.020)\n",
       "            )\n",
       "            (2): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.023)\n",
       "            )\n",
       "            (3): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.026)\n",
       "            )\n",
       "            (4): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.029)\n",
       "            )\n",
       "            (5): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.031)\n",
       "            )\n",
       "            (6): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.034)\n",
       "            )\n",
       "            (7): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.037)\n",
       "            )\n",
       "            (8): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.040)\n",
       "            )\n",
       "            (9): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.043)\n",
       "            )\n",
       "            (10): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.046)\n",
       "            )\n",
       "            (11): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.049)\n",
       "            )\n",
       "            (12): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.051)\n",
       "            )\n",
       "            (13): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.054)\n",
       "            )\n",
       "            (14): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.057)\n",
       "            )\n",
       "            (15): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.060)\n",
       "            )\n",
       "            (16): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.063)\n",
       "            )\n",
       "            (17): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.066)\n",
       "            )\n",
       "            (18): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.069)\n",
       "            )\n",
       "            (19): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.071)\n",
       "            )\n",
       "            (20): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.074)\n",
       "            )\n",
       "            (21): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.077)\n",
       "            )\n",
       "            (22): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.080)\n",
       "            )\n",
       "            (23): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.083)\n",
       "            )\n",
       "            (24): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.086)\n",
       "            )\n",
       "            (25): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.089)\n",
       "            )\n",
       "            (26): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "              (norm): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.091)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ConvNeXtStage(\n",
       "          (downsample): Sequential(\n",
       "            (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "            (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "          )\n",
       "          (blocks): Sequential(\n",
       "            (0): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.094)\n",
       "            )\n",
       "            (1): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.097)\n",
       "            )\n",
       "            (2): ConvNeXtBlock(\n",
       "              (conv_dw): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "              (norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "              (mlp): Mlp(\n",
       "                (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "                (act): GELU()\n",
       "                (drop1): Dropout(p=0.0, inplace=False)\n",
       "                (norm): Identity()\n",
       "                (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "                (drop2): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (shortcut): Identity()\n",
       "              (drop_path): DropPath(drop_prob=0.100)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm_pre): Identity()\n",
       "      (head): NormMlpClassifierHead(\n",
       "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "        (norm): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "        (pre_logits): Identity()\n",
       "        (drop): Dropout(p=0.0, inplace=False)\n",
       "        (fc): Identity()\n",
       "      )\n",
       "    )\n",
       "    (head): Sequential(\n",
       "      (drop): Dropout(p=0.0, inplace=False)\n",
       "      (proj): Linear(in_features=1024, out_features=640, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=640, out_features=640, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=640, out_features=2560, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2560, out_features=640, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 640)\n",
       "  (ln_final): LayerNorm((640,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mheuillet/Desktop/robust_training/.venv2/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vit_base_patch16_clip_224.datacompxl\n",
      "vit_base_patch16_clip_224.dfn2b\n",
      "vit_base_patch16_clip_224.laion2b\n",
      "vit_base_patch16_clip_224.laion2b_ft_in1k\n",
      "vit_base_patch16_clip_224.laion2b_ft_in12k\n",
      "vit_base_patch16_clip_224.laion2b_ft_in12k_in1k\n",
      "vit_base_patch16_clip_224.laion400m_e32\n",
      "vit_base_patch16_clip_224.metaclip_2pt5b\n",
      "vit_base_patch16_clip_224.metaclip_400m\n",
      "vit_base_patch16_clip_224.openai\n",
      "vit_base_patch16_clip_224.openai_ft_in1k\n",
      "vit_base_patch16_clip_224.openai_ft_in12k\n",
      "vit_base_patch16_clip_224.openai_ft_in12k_in1k\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "vit_models = timm.list_models('*vit_base_patch16_clip_224*', pretrained=True)\n",
    "for model_name in vit_models:\n",
    "    print(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "state_dict = torch.load('./state_dicts/resnet50_linf_eps4.0.ckpt', weights_only=False)\n",
    "# 2. Create a new dict with comprehension that excludes certain keys\n",
    "\n",
    "# Keys to remove exactly\n",
    "exact_keys_to_remove = {\"module.normalizer.new_std\", \"module.normalizer.new_mean\"}\n",
    "\n",
    "# Prefixes we want to remove if a key starts with them\n",
    "prefixes_to_remove = (\"module.attacker\",)  # tuple of prefixes, you can add more if needed\n",
    "\n",
    "filtered_state_dict = {\n",
    "    k: v\n",
    "    for k, v in state_dict[\"model\"].items()\n",
    "    # Keep this entry only if:\n",
    "    # 1) its not in exact_keys_to_remove, AND\n",
    "    # 2) it doesn't start with any of the given prefixes\n",
    "    if k not in exact_keys_to_remove\n",
    "    and not any(k.startswith(prefix) for prefix in prefixes_to_remove)\n",
    "}\n",
    "\n",
    "ckpt = {k.replace('module.model.', ''): v for k, v in filtered_state_dict.items()}\n",
    "\n",
    "# model = timm.models.resnest50(pretrained=False)\n",
    "# model.load_state_dict(ckpt)\n",
    "import timm\n",
    "\n",
    "model = timm.create_model(\"resnet50\", pretrained=False)\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "torch.save(model.state_dict(), \"./state_dicts/resnet50_linf_eps4.0.pt\")\n",
    "\n",
    "\n",
    "state_dict = torch.load(\"./state_dicts/resnet50_linf_eps4.0.pt\", weights_only=False)\n",
    "model = timm.create_model(\"resnet50\", pretrained=False)\n",
    "model.load_state_dict(state_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
