{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import IndexedDataset, WeightedDataset, load_data\n",
    "from torch.utils.data import DataLoader, DistributedSampler\n",
    "\n",
    "from utils import get_args\n",
    "from architectures import load_architecture\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from architectures import CustomModel, load_architecture, add_lora, set_lora_gradients #load_statedict\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "args = get_args()\n",
    "\n",
    "args.dataset = 'Flowers'\n",
    "args.selection_method = 'random'\n",
    "args.aug = 'aug'\n",
    "args.loss_function = 'CLASSIC_AT'\n",
    "\n",
    "args.iterations = 10\n",
    "args.pruning_ratio = 0\n",
    "args.delta = 1\n",
    "args.batch_size = 24\n",
    "args.init_lr = 0.001\n",
    "args.freeze_epochs = 5\n",
    "args.backbone = 'convnext_tiny' #deit_small_patch16_224.fb_in1k\n",
    "args.ft_type = 'full_fine_tuning'\n",
    "\n",
    "# train_dataset, val_dataset, test_dataset, N, train_transform, transform = load_data(args) \n",
    "# # print(N)\n",
    "\n",
    "# train_dataset = WeightedDataset(args, train_dataset, train_transform, N, prune_ratio = args.pruning_ratio,  )\n",
    "\n",
    "# # # train_sampler = DistributedCustomSampler(args, train_dataset, num_replicas=2, rank=0, drop_last=True)\n",
    "# train_sampler = DistributedSampler(train_dataset, num_replicas=2, rank=0, shuffle=True, drop_last=True)\n",
    "\n",
    "# trainloader = DataLoader(train_dataset, batch_size=3, sampler = train_sampler, )\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# rank = 0\n",
    "# model = load_architecture(args, N= 100, rank=0 )\n",
    "# model = CustomModel(args, model)\n",
    "\n",
    "# model.set_fine_tuning_strategy()\n",
    "# model.to(rank)\n",
    "# model = DDP(model, device_ids=[rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 18:12:56,967\tWARNING __init__.py:21 -- Package pickle5 becomes unnecessary in Python 3.8 and above. Its presence may confuse libraries including Ray. Please uninstall the package.\n",
      "2024-11-27 18:12:59,740\tINFO worker.py:1743 -- Started a local Ray instance. View the dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265 \u001b[39m\u001b[22m\n",
      "2024-11-27 18:13:00,977\tINFO tune.py:263 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2024-11-27 18:13:00,979\tINFO tune.py:613 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2024-11-27 18:13:40</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:39.22        </td></tr>\n",
       "<tr><td>Memory:      </td><td>9.5/15.5 GiB       </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 4.000: None | Iter 2.000: None | Iter 1.000: None<br>Logical resource usage: 0/12 CPUs, 0/1 GPUs (0.0/1.0 accelerator_type:G)\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "<div class=\"messages\">\n",
       "  <h3>Messages</h3>\n",
       "  \n",
       "  \n",
       "  Number of errored trials: 10<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th style=\"text-align: right;\">  # failures</th><th>error file                                                                                                                                                                                                                          </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_25ae8_00000</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00000_0_lr1=0.0009,lr2=0.0002,weight_decay=0.0004_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00001</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00001_1_lr1=0.0002,lr2=0.0003,weight_decay=0.0000_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00002</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00002_2_lr1=0.0000,lr2=0.0001,weight_decay=0.0006_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00003</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00003_3_lr1=0.0003,lr2=0.0480,weight_decay=0.0028_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00004</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00004_4_lr1=0.0001,lr2=0.0018,weight_decay=0.0000_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00005</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00005_5_lr1=0.0455,lr2=0.0006,weight_decay=0.0002_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00006</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00006_6_lr1=0.0007,lr2=0.0002,weight_decay=0.0000_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00007</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00007_7_lr1=0.0004,lr2=0.0058,weight_decay=0.0001_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00008</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00008_8_lr1=0.0003,lr2=0.0000,weight_decay=0.0002_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00009</td><td style=\"text-align: right;\">           1</td><td>/tmp/ray/session_2024-11-27_18-12-57_774759_28972/artifacts/2024-11-27_18-13-00/005ae05dda4d162ccb4b1367a3da48ce/driver_artifacts/TorchTrainer_25ae8_00009_9_lr1=0.0042,lr2=0.0002,weight_decay=0.0001_2024-11-27_18-13-01/error.txt</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".messages {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  padding-left: 1em;\n",
       "  overflow-y: auto;\n",
       "}\n",
       ".messages h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n",
       "\n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th><th>status  </th><th>loc  </th><th style=\"text-align: right;\">        lr1</th><th style=\"text-align: right;\">        lr2</th><th style=\"text-align: right;\">  weight_decay</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_25ae8_00000</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000889918</td><td style=\"text-align: right;\">0.000204619</td><td style=\"text-align: right;\">   0.000394109</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00001</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000168221</td><td style=\"text-align: right;\">0.000255622</td><td style=\"text-align: right;\">   1.24205e-06</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00002</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">1.18308e-05</td><td style=\"text-align: right;\">7.07259e-05</td><td style=\"text-align: right;\">   0.000580306</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00003</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000329372</td><td style=\"text-align: right;\">0.048013   </td><td style=\"text-align: right;\">   0.0028054  </td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00004</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">5.27587e-05</td><td style=\"text-align: right;\">0.0017739  </td><td style=\"text-align: right;\">   1.23748e-05</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00005</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.0455136  </td><td style=\"text-align: right;\">0.000571367</td><td style=\"text-align: right;\">   0.00024559 </td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00006</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000737342</td><td style=\"text-align: right;\">0.000160978</td><td style=\"text-align: right;\">   2.23099e-06</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00007</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000412602</td><td style=\"text-align: right;\">0.00581142 </td><td style=\"text-align: right;\">   0.000116585</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00008</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.000289108</td><td style=\"text-align: right;\">3.07034e-05</td><td style=\"text-align: right;\">   0.000183081</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00009</td><td>ERROR   </td><td>     </td><td style=\"text-align: right;\">0.00421516 </td><td style=\"text-align: right;\">0.000220428</td><td style=\"text-align: right;\">   0.000142795</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-27 18:13:04,652\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00000\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=29784, ip=192.168.2.12, actor_id=9e4023c18eb1f68322001e5701000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name              </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>TorchTrainer_25ae8_00000</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00001</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00002</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00003</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00004</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00005</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00006</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00007</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00008</td></tr>\n",
       "<tr><td>TorchTrainer_25ae8_00009</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m Traceback (most recent call last):\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     obj = pickle.loads(in_band)\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=29784, ip=192.168.2.12, actor_id=9e4023c18eb1f68322001e5701000000, repr=TorchTrainer)\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     self.setup(copy.deepcopy(self.config))\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m     return ray.get(self.references[k])\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m traceback: Traceback (most recent call last):\n",
      "\u001b[36m(TrainTrainable pid=29784)\u001b[0m ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "2024-11-27 18:13:08,120\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00001\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=29900, ip=192.168.2.12, actor_id=3da5a948504e1d6a4415198001000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "2024-11-27 18:13:12,248\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00002\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=29968, ip=192.168.2.12, actor_id=9047d24fed50abfd18bd62e801000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/ray-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m ModuleNotFoundError: No module named 'distributed_experiment2'\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=29968, ip=192.168.2.12, actor_id=9047d24fed50abfd18bd62e801000000, repr=TorchTrainer)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     self.setup(copy.deepcopy(self.config))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     setup_kwargs[k] = parameter_registry.get(prefix + k)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m     return ray.get(self.references[k])\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=29968)\u001b[0m traceback: Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-11-27 18:13:16,123\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00003\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30030, ip=192.168.2.12, actor_id=552528cb8fed04cd1f9729dc01000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "2024-11-27 18:13:20,129\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00004\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30086, ip=192.168.2.12, actor_id=a4c09789600ceeb271e7e9b601000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m ModuleNotFoundError: No module named 'distributed_experiment2'\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30086, ip=192.168.2.12, actor_id=a4c09789600ceeb271e7e9b601000000, repr=TorchTrainer)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     self.setup(copy.deepcopy(self.config))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     setup_kwargs[k] = parameter_registry.get(prefix + k)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m     return ray.get(self.references[k])\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30086)\u001b[0m traceback: Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-11-27 18:13:24,106\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00005\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30145, ip=192.168.2.12, actor_id=c50678996e0cf7b2ab20f53a01000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "2024-11-27 18:13:28,152\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00006\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30201, ip=192.168.2.12, actor_id=78564e4cf2d6dec885a20fe201000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m ModuleNotFoundError: No module named 'distributed_experiment2'\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30201, ip=192.168.2.12, actor_id=78564e4cf2d6dec885a20fe201000000, repr=TorchTrainer)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     self.setup(copy.deepcopy(self.config))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     setup_kwargs[k] = parameter_registry.get(prefix + k)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m     return ray.get(self.references[k])\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30201)\u001b[0m traceback: Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-11-27 18:13:32,220\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00007\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30258, ip=192.168.2.12, actor_id=d7abc88308048b7e731cab5d01000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "2024-11-27 18:13:36,126\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00008\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30341, ip=192.168.2.12, actor_id=1f5532e162564eed9a8aced801000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 404, in deserialize_objects\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     obj = self._deserialize_object(data, metadata, object_ref)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 270, in _deserialize_object\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     return self._deserialize_msgpack_data(data, metadata_fields)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 225, in _deserialize_msgpack_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     python_objects = self._deserialize_pickle5_data(pickle5_data)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/serialization.py\", line 215, in _deserialize_pickle5_data\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     obj = pickle.loads(in_band)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m ModuleNotFoundError: No module named 'distributed_experiment2'\u001b[32m [repeated 4x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m Exception raised in creation task: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30341, ip=192.168.2.12, actor_id=1f5532e162564eed9a8aced801000000, repr=TorchTrainer)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     self.setup(copy.deepcopy(self.config))\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     setup_kwargs[k] = parameter_registry.get(prefix + k)\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m   File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m     return ray.get(self.references[k])\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "\u001b[36m(TrainTrainable pid=30341)\u001b[0m traceback: Traceback (most recent call last):\u001b[32m [repeated 2x across cluster]\u001b[0m\n",
      "2024-11-27 18:13:40,231\tERROR tune_controller.py:1332 -- Trial task failed for trial TorchTrainer_25ae8_00009\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/air/execution/_internal/event_manager.py\", line 110, in resolve_future\n",
      "    result = ray.get(future)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/auto_init_hook.py\", line 21, in auto_init_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/client_mode_hook.py\", line 103, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 2667, in get\n",
      "    values, debugger_breakpoint = worker.get_objects(object_refs, timeout=timeout)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/_private/worker.py\", line 866, in get_objects\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died because of an error raised in its creation task, \u001b[36mray::ResourceTrainable.__init__()\u001b[39m (pid=30419, ip=192.168.2.12, actor_id=3df3218b84fd074ce474e81f01000000, repr=TorchTrainer)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/trainable.py\", line 161, in __init__\n",
      "    self.setup(copy.deepcopy(self.config))\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/trainable/util.py\", line 119, in setup\n",
      "    setup_kwargs[k] = parameter_registry.get(prefix + k)\n",
      "  File \"/home/mheuillet/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/registry.py\", line 301, in get\n",
      "    return ray.get(self.references[k])\n",
      "ray.exceptions.RaySystemError: System error: No module named 'distributed_experiment2'\n",
      "traceback: Traceback (most recent call last):\n",
      "ModuleNotFoundError: No module named 'distributed_experiment2'\n",
      "2024-11-27 18:13:40,240\tINFO tune.py:1016 -- Wrote the latest version of all result files and experiment state to '/home/mheuillet/ray_results/005ae05dda4d162ccb4b1367a3da48ce' in 0.0051s.\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [TorchTrainer_25ae8_00000, TorchTrainer_25ae8_00001, TorchTrainer_25ae8_00002, TorchTrainer_25ae8_00003, TorchTrainer_25ae8_00004, TorchTrainer_25ae8_00005, TorchTrainer_25ae8_00006, TorchTrainer_25ae8_00007, TorchTrainer_25ae8_00008, TorchTrainer_25ae8_00009])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# set_seeds(args.seed)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m experiment \u001b[38;5;241m=\u001b[39m BaseExperiment(args, world_size)\n\u001b[0;32m----> 8\u001b[0m \u001b[43mexperiment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhyperparameter_optimization\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/robust_training/distributed_experiment2.py:329\u001b[0m, in \u001b[0;36mBaseExperiment.hyperparameter_optimization\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m trainer \u001b[38;5;241m=\u001b[39m TorchTrainer(\n\u001b[1;32m    320\u001b[0m     train_loop_per_worker\u001b[38;5;241m=\u001b[39mtrain_func,\n\u001b[1;32m    321\u001b[0m     train_loop_config\u001b[38;5;241m=\u001b[39m{},  \u001b[38;5;66;03m# No direct config for TorchTrainer (managed by Ray Tune)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    325\u001b[0m     )\n\u001b[1;32m    326\u001b[0m )\n\u001b[1;32m    328\u001b[0m \u001b[38;5;66;03m# Define the Ray Tune run\u001b[39;00m\n\u001b[0;32m--> 329\u001b[0m analysis \u001b[38;5;241m=\u001b[39m \u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtune\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_resources\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    331\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mas_trainable\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresources\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Per trial resource allocation\u001b[39;49;00m\n\u001b[1;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Hyperparameter search space\u001b[39;49;00m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexp_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[38;5;66;43;03m# Experiment ID\u001b[39;49;00m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_samples\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# Number of hyperparameter samples\u001b[39;49;00m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Early stopping scheduler\u001b[39;49;00m\n\u001b[1;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtime_total_s\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3600\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Total time allocated for optimization\u001b[39;49;00m\n\u001b[1;32m    339\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;66;03m# Retrieve and print the best hyperparameters\u001b[39;00m\n\u001b[1;32m    342\u001b[0m best_config \u001b[38;5;241m=\u001b[39m analysis\u001b[38;5;241m.\u001b[39mget_best_config(metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/robust_training/.venv/lib/python3.8/site-packages/ray/tune/tune.py:1042\u001b[0m, in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, storage_path, storage_filesystem, search_alg, scheduler, checkpoint_config, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, resume, resume_config, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, chdir_to_trial_dir, local_dir, _remote, _remote_string_queue, _entrypoint)\u001b[0m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m incomplete_trials:\n\u001b[1;32m   1041\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raise_on_failed_trial \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment_interrupted_event\u001b[38;5;241m.\u001b[39mis_set():\n\u001b[0;32m-> 1042\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TuneError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete\u001b[39m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n\u001b[1;32m   1043\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1044\u001b[0m         logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrials did not complete: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, incomplete_trials)\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [TorchTrainer_25ae8_00000, TorchTrainer_25ae8_00001, TorchTrainer_25ae8_00002, TorchTrainer_25ae8_00003, TorchTrainer_25ae8_00004, TorchTrainer_25ae8_00005, TorchTrainer_25ae8_00006, TorchTrainer_25ae8_00007, TorchTrainer_25ae8_00008, TorchTrainer_25ae8_00009])"
     ]
    }
   ],
   "source": [
    "from distributed_experiment2 import BaseExperiment\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"./Desktop/robust_training\")\n",
    "\n",
    "world_size = torch.cuda.device_count()\n",
    "# set_seeds(args.seed)\n",
    "\n",
    "experiment = BaseExperiment(args, world_size)\n",
    "\n",
    "experiment.hyperparameter_optimization()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
