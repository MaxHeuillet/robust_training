{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "\n",
    "vit_models = timm.list_models('*deit_small_patch16_224*', pretrained=True)\n",
    "for model_name in vit_models:\n",
    "    print(model_name)\n",
    "\n",
    "# ckpt = torch.load('./state_dicts/tiny_linf_wrn28-10.pt')\n",
    "# ckpt = {k.replace('module.0.', ''): v for k, v in ckpt['model_state_dict'].items()}\n",
    "# model.load_state_dict(ckpt)\n",
    "\n",
    "# torch.save(model.state_dict(), './state_dicts/robust_wideresnet_28_10.pt'.format(backbone) )\n",
    "\n",
    "from architectures.wideresnetswish import wideresnet\n",
    "ckpt = torch.load('./state_dicts/wideresnet_28_10.pt')\n",
    "ckpt = {k.replace('module.0.', ''): v for k, v in ckpt['model_state_dict'].items()}\n",
    "model = wideresnet(depth = 28, widen = 10, act_fn = 'swish', num_classes = 200)\n",
    "model.load_state_dict(ckpt)\n",
    "torch.save(model.state_dict(), './state_dicts/wideresnet_28_10.pt' )\n",
    "\n",
    "from architectures.wideresnetswish import wideresnet\n",
    "from typing import Tuple\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from collections import OrderedDict\n",
    "import timm\n",
    "from timm.models import create_model\n",
    "\n",
    "backbones =  [ 'convnext_base',  'convnext_base.fb_in22k', 'robust_convnext_base', 'random_convnext_base',\n",
    "               'convnext_tiny',  'convnext_tiny.fb_in22k', 'robust_convnext_tiny', 'random_convnext_tiny',\n",
    "\n",
    "              'deit_small_patch16_224.fb_in1k', 'robust_deit_small_patch16_224', 'random_deit_small_patch16_224',\n",
    "              \n",
    "              'vit_base_patch16_224.augreg_in1k', 'vit_base_patch16_224.augreg_in21k', 'robust_vit_base_patch16_224', 'random_vit_base_patch16_224' ] \n",
    "\n",
    "#'robust_wideresnet_28_10', 'wideresnet_28_10', \n",
    "\n",
    "\n",
    "for backbone in backbones:\n",
    "    print(backbone)\n",
    "    args.backbone = backbone\n",
    "    N = 10\n",
    "    model = load_architecture(args,N, rank= 0)\n",
    "    # for name, param in model.named_parameters():\n",
    "    #     print(name)\n",
    "\n",
    "    print()\n",
    "\n",
    "from architectures.wideresnetswish import wideresnet\n",
    "\n",
    "depth = 28\n",
    "widen = 10\n",
    "act_fn = 'swish'  # Assuming 'swish' is the desired activation function\n",
    "num_classes = 200\n",
    "model = wideresnet(depth, widen, act_fn, num_classes)\n",
    "ckpt = torch.load('./state_dicts/tiny_linf_wrn28-10.pt')\n",
    "ckpt = {k.replace('module.0.', ''): v for k, v in ckpt['model_state_dict'].items()}\n",
    "model.load_state_dict(ckpt)\n",
    "\n",
    "model\n",
    "\n",
    "import timm\n",
    "\n",
    "from timm.models import create_model\n",
    "\n",
    "model = timm.create_model('convnext_tiny.fb_in22k', pretrained=True)\n",
    "model_save_path = \"./state_dicts/test.pth\"\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "state_dict = torch.load('./state_dicts/test.pth')\n",
    "model = timm.models.convnext.convnext_tiny(pretrained=False)\n",
    "num_features = model.head.fc.in_features\n",
    "model.head.fc = nn.Linear(num_features, 21841)  \n",
    "model.load_state_dict(state_dict)\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "\n",
    "equivalencies = { 'convnext_base':'convnext_base',\n",
    "                      'convnext_base.fb_in22k':'convnext_base.fb_in22k', \n",
    "                      'robust_convnext_base':'convnext_base',\n",
    "                      \n",
    "                      'convnext_tiny':'convnext_tiny',\n",
    "                      'convnext_tiny.fb_in22k':'convnext_tiny.fb_in22k',\n",
    "                      'robust_convnext_tiny':'convnext_tiny',\n",
    "\n",
    "                      'robust_wideresnet_28_10': 'robust_wideresnet_28_10',\n",
    "\n",
    "                      'deit_small_patch16_224.fb_in1k': 'deit_small_patch16_224.fb_in1k',\n",
    "                      'robust_deit_small_patch16_224': 'deit_small_patch16_224',\n",
    "\n",
    "                      'vit_base_patch16_224.augreg_in1k':'vit_base_patch16_224.augreg_in1k',\n",
    "                      'vit_base_patch16_224.augreg_in21k':'vit_base_patch16_224.augreg_in21k',\n",
    "                      'robust_vit_base_patch16_224': 'vit_base_patch16_224'\n",
    "                           \n",
    "                }\n",
    "\n",
    "backbone = 'robust_wideresnet_28_10'\n",
    "\n",
    "from architectures.wideresnetswish import wideresnet\n",
    "model = wideresnet(depth = 28, widen = 10, act_fn = 'swish', num_classes = 200)\n",
    "\n",
    "# model = timm.create_model( equivalencies[backbone], pretrained=False )\n",
    "state_dict = torch.load('./state_dicts/{}.pt'.format(backbone) )\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WideResNet(\n",
       "  (init_conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (layer): Sequential(\n",
       "    (0): _BlockGroup(\n",
       "      (block): Sequential(\n",
       "        (0): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(16, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(16, 160, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (shortcut): Conv2d(16, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        )\n",
       "        (1): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (3): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(160, 160, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): _BlockGroup(\n",
       "      (block): Sequential(\n",
       "        (0): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(160, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(160, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (shortcut): Conv2d(160, 320, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (1): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (3): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(320, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): _BlockGroup(\n",
       "      (block): Sequential(\n",
       "        (0): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(320, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(320, 640, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (shortcut): Conv2d(320, 640, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        )\n",
       "        (1): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (2): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "        (3): _Block(\n",
       "          (batchnorm_0): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_0): SiLU(inplace=True)\n",
       "          (conv_0): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "          (batchnorm_1): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          (relu_1): SiLU(inplace=True)\n",
       "          (conv_1): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (batchnorm): BatchNorm2d(640, eps=1e-05, momentum=0.01, affine=True, track_running_stats=True)\n",
       "  (relu): SiLU(inplace=True)\n",
       "  (logits): Linear(in_features=640, out_features=200, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
